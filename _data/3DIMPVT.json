{"3DIMPVT.csv":[{"venue":"3DIMPVT","id":"3c48a4da85e25aa516f95a72d55e0604405e3f7a","venue_1":"3DIMPVT","year":"2012","title":"A Patch Prior for Dense 3D Reconstruction in Man-Made Environments","authors":"Christian Häne, Christopher Zach, Bernhard Zeisl, Marc Pollefeys","author_ids":"2172959, 1713941, 2247283, 1742208","abstract":"—Dense 3D reconstruction in man-made environments has to contend with weak and ambiguous observations due to texture-less surfaces which are predominant in such environments. This challenging task calls for strong, domain-specific priors. These are usually modeled via regularization or smoothness assumptions. Generic smoothness priors, e.g. total variation are often not sufficient to produce convincing results. Consequently, we propose a more powerful prior directly modeling the expected local surface-structure, without the need to utilize expensive methods such as higher-order MRFs. Our approach is inspired by patch-based representations used in image processing. In contrast to the over-complete dictionaries used e.g. for sparse representations our patch dictionary is much smaller. The proposed energy can be optimized by utilizing an efficient first-order primal dual algorithm. Our formulation is in particular very natural to model priors on the 3D structure of man-made environments. We demonstrate the applicability of our prior on synthetic data and on real data, where we recover dense, piece-wise planar 3D models using stereo and fusion of multiple depth images. I. INTRODUCTION Dense 3D modeling from images often suffers from a lack of strong matching costs, especially in man-made environments. Such environments usually exhibit texture-less surfaces and also non-Lambertian ones violating underlying, e.g. brightness constancy assumptions. The presence of weak data terms must be compensated by strong model priors in order to obtain plausible 3D reconstructions. In this work we propose to utilize a spatial regularization prior for depth maps inspired by sparse representations. While our energy clearly resembles the dictionary-based energy functionals employed in image processing formulations (e.g. [1]), there are important differences due to the different characteristics of image (intensity) data and depth maps. Most prominently, depth maps representing man-made environments are typically comprised of very few structural elements, but the specific sparsity assumption used for processing intensity images is not necessarily appropriate for depth maps. Thus, the over-complete dictionary used for sparse representations can be substituted by a small one, replacing the sparseness assumption on dictionary coefficients by different priors. One benefit of this reduced model is the significant reduction in the number of unknowns, therefore increasing the efficiency of numerical optimization.","cites":"11","conferencePercentile":"84"},{"venue":"3DIMPVT","id":"1bba6f683eb683f4eaee655ca92b0f20190b15cf","venue_1":"3DIMPVT","year":"2012","title":"An Evaluation Method for Multiview Surface Reconstruction Algorithms","authors":"Ran Song, Yonghuai Liu, Yitian Zhao, Ralph R. Martin, Paul L. Rosin","author_ids":"3094070, 1990125, 1956017, 4326042, 1734823","abstract":"We propose a new method, 3DGiC, for evaluating the performances of various multiview surface reconstruction methods. It does not need a complete ground truth model, providing a much wider range of applications. More importantly , most existing methods only measure the quality of reconstruction in a global manner but local surface details are not involved. In contrast, 3DGiC depends on both global consistency and local accuracy of reconstruction in order to deliver a more comprehensive evaluation. The key idea is to compute a cumulative distribution of the joint probability of two local surface descriptors. We also designed experiments based on both synthetic and real data to demonstrate the advantages as well as the effectiveness of 3DGiC.","cites":"0","conferencePercentile":"10"},{"venue":"3DIMPVT","id":"338051dd267e9daedafe3d96ace0d673b70d9aeb","venue_1":"3DIMPVT","year":"2011","title":"Higher Order CRF for Surface Reconstruction from Multi-view Data Sets","authors":"Ran Song, Yonghuai Liu, Ralph R. Martin, Paul L. Rosin","author_ids":"3094070, 1990125, 4326042, 1734823","abstract":"—We propose a novel method based on higher order Conditional Random Field (CRF) for reconstructing surface models from multi-view data sets. This method is automatic and robust to inevitable scanning noise and registration errors involved in the stages of data acquisition and registration. By incorporating the information within the input data sets into the energy function more sufficiently than existing methods, it more effectively captures spatial relations between 3D points, making the reconstructed surface both topologically and geometrically consistent with the data sources. We employ the state-of-the-art belief propagation algorithm to infer this higher order CRF while utilizing the sparseness of the CRF labeling to reduce the computational complexity. Experiments show that the proposed approach provides improved surface reconstruction.","cites":"2","conferencePercentile":"25.75757576"},{"venue":"3DIMPVT","id":"df7a1fffb5218cc6b22d61187a26577cc7e24bb9","venue_1":"3DIMPVT","year":"2012","title":"Difference of Normals as a Multi-scale Operator in Unorganized Point Clouds","authors":"Yani Ioannou, Babak Taati, Robin Harrap, Michael A. Greenspan","author_ids":"2935943, 2783791, 3046480, 1680747","abstract":"A novel multi-scale operator for unorganized 3D point clouds is introduced. The Difference of Normals (DoN) provides a computationally efficient, multi-scale approach to processing large unorganized 3D point clouds. The application of DoN in the multi-scale filtering of two different real-world outdoor urban LIDAR scene datasets is quantitatively and qualitatively demonstrated. In both datasets the DoN operator is shown to segment large 3D point clouds into scale-salient clusters, such as cars, people, and lamp posts towards applications in semi-automatic annotation, and as a pre-processing step in automatic object recognition. The application of the operator to segmentation is evaluated on a large public dataset of outdoor LIDAR scenes with ground truth annotations.","cites":"15","conferencePercentile":"96"},{"venue":"3DIMPVT","id":"a8a618363b8dee8037df9133668ec8dcd532ee4e","venue_1":"3DIMPVT","year":"2012","title":"Modeling Kinect Sensor Noise for Improved 3D Reconstruction and Tracking","authors":"Chuong V. Nguyen, Shahram Izadi, David R. Lovell","author_ids":"5369974, 1699068, 3008221","abstract":"We contribute an empirically derived noise model for the Kinect sensor. We systematically measure both lateral and axial noise distributions, as a function of both distance and angle of the Kinect to an observed surface. The derived noise model can be used to filter Kinect depth maps for a variety of applications. Our second contribution applies our derived noise model to the KinectFusion system to extend filtering, volumetric fusion, and pose estimation within the pipeline. Qualitative results show our method allows reconstruction of finer details and the ability to reconstruct smaller objects and thinner surfaces. Quantitative results also show our method improves pose estimation accuracy.","cites":"50","conferencePercentile":"100"},{"venue":"3DIMPVT","id":"d76c2e761c7adb2e92e50141a00597d250c00669","venue_1":"3DIMPVT","year":"2012","title":"Dynamic Mosaics","authors":"Rahul Garg, Steven M. Seitz","author_ids":"1779656, 1679223","abstract":"Past mosaicing approaches stitch a set of photos into a single static mosaic. We present a novel approach where we visualize a photo collection in an interactive viewer that allows the user to smoothly and seamlessly transition between a collection of local mosaics instead of a single static mosaic. Such an approach works with more general photo collections than possible with static mosaicing while preserving the straight lines in the scene. Moreover, the viewer dynamically selects optimal seams between images in a semi-online fashion that handles misalignment, scene motion and parallax and also recreates dynamic aspects such as moving objects and exposure changes.","cites":"1","conferencePercentile":"24"},{"venue":"3DIMPVT","id":"f1ead644e708bf04d87e7c5795b01ddc0c363753","venue_1":"3DIMPVT","year":"2012","title":"Real-Time Reshaping of Humans","authors":"Michal Richter, Kiran Varanasi, Nils Hasler, Christian Theobalt","author_ids":"2341046, 1715245, 2735303, 1680185","abstract":"We present a system for real-time deformation of the shape and appearance of people who are standing in front of a depth+RGB camera, such as the Microsoft Kinect. Our system allows manipulating human body shape parameters such as height, muscularity, weight, waist girth and leg length. The manipulated appearance is displayed in real-time. Thus, instead of posing in front a real mirror and visualizing their appearance, users can pose in front of a 'virtual mirror' and visualize themselves in different body shapes. Our system is made possible by a morphable model of 3D human shape that was learnt from a large database of 3D scans of people in various body shapes and poses. In an initialization step, which lasts a couple of seconds, this model is fit to the 3D shape parameters of the people as observed in the depth data. Then, a succession of pose tracking, body segmentation, shape deformation and image warping steps are performed – in real-time and independently for multiple people. We present a variety of results in the paper and the video, showing the interactive virtual mirror cabinet experience.","cites":"6","conferencePercentile":"60"},{"venue":"3DIMPVT","id":"0d36967e764e59405ff598c84e24ef03faf0d356","venue_1":"3DIMPVT","year":"2012","title":"Photo Tours","authors":"Avanish Kushal, Ben Self, Yasutaka Furukawa, David Gallup, Carlos Hernández, Brian Curless, Steven M. Seitz","author_ids":"3201468, 2062852, 1798912, 1796345, 1964741, 1810052, 1679223","abstract":"This paper describes an effort to automatically create \" tours \" of thousands of the world's landmarks from geo-tagged user-contributed photos on the Internet. These photo tours take you through each site's most popular viewpoints on a tour that maximizes visual quality and traversal efficiency. This planning problem is framed as a form of the Traveling Salesman Problem on a graph with photos as nodes and transition costs on edges and pairs of edges, permitting efficient solution even for large graphs containing thousands of photos. Our approach is highly scalable and is the basis for the Photo Tours feature in Google Maps, which can be viewed at http://maps.google.com/phototours","cites":"8","conferencePercentile":"72"},{"venue":"3DIMPVT","id":"fe890da7b591e0883044cdc7f98738f8af539b18","venue_1":"3DIMPVT","year":"2012","title":"High-Resolution Performance Capture by Zoom-in Pan-Tilt Cameras","authors":"Norimichi Ukita, Shigenobu Fujine, Norihiro Hagita","author_ids":"3081689, 3296073, 1781078","abstract":"We have developed a system with multiple pan-tilt cameras for capturing high-resolution videos of a moving person. This system controls the cameras so that each camera captures the best view of the person (i.e. one of body parts such as the head, torso, and limbs) based on criteria for camera-work optimization. For achieving this optimization in real time, time-consuming pre-processes, which give useful clues for the optimization, are performed in a training stage. Specifically, a target performance (e.g. a dance) is captured to acquire the configuration of the body parts at each frame. In a real capture stage, the system compares an online-reconstructed shape with those in the training data for fast retrieval of the configuration of the body parts. The retrieved configuration is used by an efficient scheme for optimizing a camera work. Experimental results show the camera work optimized in accordance with given criteria. A high-resolution 3D videos produced by the proposed system are also shown as a typical use of high-resolution videos.","cites":"0","conferencePercentile":"10"},{"venue":"3DIMPVT","id":"897277f01891303fa8ff17793cb3f8e2e0e2ea8d","venue_1":"3DIMPVT","year":"2012","title":"Robust Simultaneous 3D Registration via Rank Minimization","authors":"Diego Thomas, Yasuyuki Matsushita, Akihiro Sugimoto","author_ids":"3104270, 1774618, 1691286","abstract":"We present a robust and accurate 3D registration method for a dense sequence of depth images taken from unknown viewpoints. Our method simultaneously estimates multiple extrinsic parameters of the depth images to obtain a registered full 3D model of the scanned scene. By arranging the depth measurements in a matrix form, we formulate the problem as a simultaneous estimation of multiple extrinsics and a low-rank matrix, which corresponds to the aligned depth images as well as a sparse error matrix. Unlike previous approaches that use sequential or heuristic global registration approaches, our solution method uses an advanced convex optimization technique for obtaining a robust solution via rank minimization. To achieve accurate computation , we develop a depth projection method that has minimum sensitivity to sampling by reading projected depth values in the input depth images. We demonstrate the effectiveness of the proposed method through extensive experiments and compare it with previous standard techniques.","cites":"0","conferencePercentile":"10"},{"venue":"3DIMPVT","id":"31b16f7907c9fa475eab681e4fef06099ade77f5","venue_1":"3DIMPVT","year":"2011","title":"Integrating LIDAR into Stereo for Fast and Improved Disparity Computation","authors":"Hernán Badino, Daniel F. Huber, Takeo Kanade","author_ids":"2863682, 2452413, 7642093","abstract":"—The fusion of stereo and laser range finders (LIDARs) has been proposed as a method to compensate for each individual sensor's deficiencies − stereo output is dense, but noisy for large distances, while LIDAR is more accurate, but sparse. However, stereo usually performs poorly on textureless areas and on scenes containing repetitive structures , and the subsequent fusion with LIDAR leads to a degraded estimation of the 3D structure. In this paper, we propose to integrate LIDAR data directly into the stereo algorithm to reduce false positives while increasing the density of the resulting disparity image on textureless regions. We demonstrate with extensive experimental results with real data that the disparity estimation is substantially improved while speeding up the stereo computation by as much as a factor of five.","cites":"1","conferencePercentile":"18.18181818"},{"venue":"3DIMPVT","id":"867adaa4c81e5621e142e10a3c0099179d6fb00c","venue_1":"3DIMPVT","year":"2012","title":"Grid-Based Active Stereo with Single-Colored Wave Pattern for Dense One-shot 3D Scan","authors":"Ryusuke Sagawa, Kazuhiro Sakashita, Nozomu Kasuya, Hiroshi Kawasaki, Ryo Furukawa, Yasushi Yagi","author_ids":"1706605, 3134984, 2868487, 1710962, 1697820, 1715071","abstract":"In this paper, we propose a method to reconstruct the shapes of moving objects. The proposed method is a projector-camera system that reconstructs a shape from a single image where a static pattern is cast by a projector; such a method is ideal for acquisition of moving objects at a high frame rate. The issues tackled in this paper are as follows: 1) realize one-shot 3D reconstruction with a single-colored pattern, and 2) obtain accurate shapes by finding correspondences in sub-pixel accuracy. To achieve these goals, we propose the following methods: 1) implicit encoding of projector information by a grid of wave lines, 2) grid-based stereo between projector pattern and camera images to determine unique correspondences, 3) (quasi-)pixel-wise interpolations and optimizations to reconstruct dense shapes, and 4) a single-colored pattern which contributes to simplify pattern projecting devices compared to color-coded methods. In the experiment, we show the proposed method is efficient to solve the issues above.","cites":"3","conferencePercentile":"46"},{"venue":"3DIMPVT","id":"b61d31ff4fe4383e7511b8b261971e39a357b48d","venue_1":"3DIMPVT","year":"2012","title":"Fast and Stable Color Balancing for Images and Augmented Reality","authors":"Thomas Oskam, Alexander Sorkine-Hornung, Robert W. Sumner, Markus H. Gross","author_ids":"3032690, 2893744, 1693475, 1743207","abstract":"This paper addresses the problem of globally balancing colors between images. The input to our algorithm is a sparse set of desired color correspondences between a source and a target image. The global color space transformation problem is then solved by computing a smooth vector field in CIE Lab color space that maps the gamut of the source to that of the target. We employ normalized radial basis functions for which we compute optimized shape parameters based on the input images, allowing for more faithful and flexible color matching compared to existing RBF-, regression-or histogram-based techniques. Furthermore , we show how the basic per-image matching can be efficiently and robustly extended to the temporal domain using RANSAC-based correspondence classification. Besides interactive color balancing for images, these properties render our method extremely useful for automatic, consistent embedding of synthetic graphics in video, as required by applications such as augmented reality.","cites":"12","conferencePercentile":"87"},{"venue":"3DIMPVT","id":"ba161f88f0f120f1fe3a6796c89acc0fe4af9773","venue_1":"3DIMPVT","year":"2012","title":"Sensor Fusion for Depth Estimation, including TOF and Thermal Sensors","authors":"Jeroen van Baar, Paul A. Beardsley, Marc Pollefeys, Markus H. Gross","author_ids":"1751880, 1777539, 1742208, 1743207","abstract":"—This paper describes the computation of depth maps for a high-quality reference camera augmented by a set of satellite sensors. The satellite sensors include support cameras, a TOF (time-of-flight) sensor, and a thermal camera, all rigidly attached to the reference camera. There is extensive previous work on computing depth maps with stereo alone, and high-quality results have been achieved. However it has proved difficult to achieve good results for cases such as textureless areas, or similar fore-and background colors. We show that with our proposed sensor fusion we can achieve high quality results. The paper makes two contributions. The first is a method for combining TOF data with multi-camera data that includes reasoning about occlusions, to produce an improved depth estimate near depth discontinuities. The second contribution is to show the benefit of thermal sensing as a segmentation prior. Thermal cameras were formerly high-cost devices but are now available at the same cost as machine vision cameras. This work demonstrates their advantages, particularly for scenes including humans.","cites":"1","conferencePercentile":"24"}]}