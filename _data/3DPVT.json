{"3DPVT.csv":[{"venue":"3DPVT","id":"1a02e6ce5f288c3c6a58d825a44e1cae69e35f97","venue_1":"3DPVT","year":"2002","title":"Filling Holes in Complex Surfaces using Volumetric Diffusion","authors":"James Davis, Steve Marschner, Matt Garr, Marc Levoy","author_ids":"3050723, 2593798, 2938428, 1801789","abstract":"We address the problem of building watertight 3D models from surfaces that contain holes—for example, sets of range scans that observe most but not all of a surface. We specifically address situations in which the holes are too geometrically and topologically complex to fill using triangulation algorithms. Our solution begins by constructing a signed distance function, the zero set of which defines the surface. Initially, this function is defined only in the vicinity of observed surfaces. We then apply a diffusion process to extend this function through the volume until its zero set bridges whatever holes may be present. If additional information is available , such as known-empty regions of space inferred from the lines of sight to a 3D scanner, it can be incorporated into the diffusion process. Our algorithm is simple to implement, is guaranteed to produce manifold non-interpenetrating surfaces, and is efficient to run on large datasets because computation is limited to areas near holes. By showing results for complex range scans, we demonstrate that our algorithm produces hole-free surfaces that are plausible, visually acceptable, and usually close to the intended geometry.","cites":"242","conferencePercentile":"100"},{"venue":"3DPVT","id":"11fe566b94769b588fbda300282f323540694a25","venue_1":"3DPVT","year":"2006","title":"Image Guided Geometry Inference","authors":"Songhua Xu, Athinodoros S. Georghiades, Holly E. Rushmeier, Julie Dorsey, Leonard McMillan","author_ids":"3231501, 3230391, 1690595, 1775220, 1748115","abstract":"We introduce a new method for filling holes in geometry obtained from 3D range scanners. Our method makes use of 2D images of the areas where geometric data is missing. The 2D images guide the filling using the relationship between the images and geometry learned from the existing 3D scanned data. Our method builds on existing techniques for using scanned geometry and for estimating shape from shaded images. Rather than creating plausibly filled holes, we attempt to approximate the missing geometry. We present results for scanned data from both triangulation and time-of-flight scanners for various types of materials. To quantitatively validate our proposed method, we also compare the filled areas with ground-truth data.","cites":"12","conferencePercentile":"75.92592593"},{"venue":"3DPVT","id":"e8cd6c6bf40b1ce2270299f79036f505b6598809","venue_1":"3DPVT","year":"2002","title":"Browsing 3-D spaces with 3-D vision: body-driven navigation through the Internet city","authors":"Flavia Sparacino, Christopher Richard Wren, Ali Azarbayejani, Alex Pentland","author_ids":"2951448, 7717997, 3251894, 1682773","abstract":"This paper presents a computer vision stereo based interface to navigate inside a 3-D Internet city, using body gestures. A wide-baseline stereo pair of cameras is used to obtain 3-D body models of the user's hands and head in a small desk-area environment. The interface feeds this information to an HMM gesture classifier to reliably recognize the user's browsing commands. To illustrate the features of this interface we describe its application to our 3-D Internet browser which facilitates the recollection of information by organizing and embedding it inside a virtual city through which the user navigates.","cites":"8","conferencePercentile":"63.97058824"},{"venue":"3DPVT","id":"7d7b58efd346e44c432cc31bf470fa672d05bc41","venue_1":"3DPVT","year":"2004","title":"Adaptive Online Transmission of 3D TexMesh Using Scale-Space Analysis","authors":"L. Irene Cheng, Pierre Boulanger","author_ids":"8267051, 1798278","abstract":"Efficient online visualization of 3D mesh and photo realistic texture is essential for a variety of applications, such as museum exhibits and medical images. In these applications synthetic texture and a predefined set of views is not an option. We propose using a mesh simplification algorithm based on scale-space analysis of the feature point distribution, combined with an associated analysis of the surface texture, to address the needs of adaptive online transmission of high quality 3D objects. The premise of the proposed textured mesh (TexMesh) simplification is the following: minor variations in texture can be ignored in relatively smooth regions of a 3D surface, without significantly affecting human perception. Statistics on 3D feature point distribution and their associated texture fragments are gathered during preprocessing. Online transmission is based on these statistics, which can be retrieved in constant time. Based on monitored bandwidth a scaled mesh is first transmitted. Starting from a default texture quality, we apply an efficient Harmonic Time Compensation Algorithm based on the current bandwidth and a time limit, to adaptively adjust the texture quality of the next fragment. Properties of the algorithm are proved. Experimental results show the usefulness of our approach. 1. Introduction Efficient bandwidth utilization and optimal transmission quality are among the main objectives when transmitting 3D models. Since mesh data is usually small compared with texture data, our focus is to adapt the texture quality to the current bandwidth and a specified time. A historic average can be used to estimate current bandwidth [6], but this approach can cause unacceptable over or under estimation because of bandwidth fluctuations. An optimal bandwidth monitoring approach can provide a more accurate estimation by sacrificing a portion of the transmission time [28]. In this paper, we propose an adaptive approach, which does not need to sacrifice transmission time for bandwidth estimation, while efficiently adjusting the quality of the fragments not yet transmitted.","cites":"3","conferencePercentile":"33.5443038"},{"venue":"3DPVT","id":"2d7a141eb0f76edc63a20bb056971834f63a86e4","venue_1":"3DPVT","year":"2006","title":"Motion Parallax without Motion Compensation in 3D Cluttered Scenes","authors":"Michael S. Langer, Vincent Chapdelaine-Couture, Richard Mann, Sébastien Roy","author_ids":"1825455, 2617671, 4814403, 1708198","abstract":"When an observer moves through a rigid 3D scene, points that are near to the observer move with a different image velocity than points that are far away. The difference between image velocity vectors is the direction of motion parallax. This direction vector points towards the observer's translation direction. Hence estimates of the direction of motion parallax are useful for estimating the observer's translation direction. Standard ways to compute the direction of motion parallax either rely on precomputed optical flow, or rely on motion compensation to remove the local image shift caused by observer rotation. Here we present a simple Fourier-based method for estimating the direction of motion parallax directly, that does not require optical flow and motion compensation. The method is real-time and performs accurately for image regions in which multiple motions are present.","cites":"0","conferencePercentile":"4.166666667"},{"venue":"3DPVT","id":"c630b3f3b050b42e0186c17c0d75abc239961cc9","venue_1":"3DPVT","year":"2004","title":"Thickness Histogram and Statistical Harmonic Representation for 3D Model Retrieval","authors":"Yi Liu, Jiantao Pu, Hongbin Zha, Weibin Liu, Yusuke Uehara","author_ids":"1691635, 3327232, 1687248, 1943870, 3113033","abstract":"Similarity measuring is a key problem for 3D model retrieval. In this paper, we propose a novel shape descriptor \" Thickness Histogram \" (TH) by uniformly estimating thickness of a model using statistical methods. It is translation and rotation-invariant, discriminative to different shapes, and very efficient to compute with the Shape Distribution (SD) proposed by Osada etc. For high performance of the retrieval, we propose a robust method for translating the directional form of the statistical distribution to the harmonic representation. By summing up energies at different frequencies, a matrix shape signature is formed to provide an exhaustive characterization of 3D geometry. Experiments show that the performance of the statistical harmonic representation is among the top ones of existing shape descriptors.","cites":"5","conferencePercentile":"45.56962025"},{"venue":"3DPVT","id":"c2f1f04673ff9beed37290980d54a5b92faa2686","venue_1":"3DPVT","year":"2004","title":"An Easy Viewer for Out-of-Core Visualization of Huge Point-Sampled Models","authors":"Fang Meng, Hongbin Zha","author_ids":"5863723, 1687248","abstract":"In this paper, we propose a viewer for huge point-sampled models by combining out-of-core technologies with view-dependent level-of-detail (LOD) control. This viewer is designed on the basis of a multiresolution data structure we have developed for gaze-guided visualization and transmission of 3D point sets. In order to reduce memory loads for huge point sets on general PC platforms, we introduce a partition-based out-of-core strategy to balance usage of main and external memories. At first, the data surface is partitioned into small blocks and points in each block are reorganized into error-controlled LODs by hierarchical clustering and LOD organization. In the interactive rendering process, a data block scheduling algorithm is used to realize the view-dependent paging. Experimental results show that the viewer can perform interactive visualization of huge point models on commodity graphics platforms with ease.","cites":"1","conferencePercentile":"12.02531646"},{"venue":"3DPVT","id":"63020ba839ded773d52328eb27a77168879abb00","venue_1":"3DPVT","year":"2004","title":"Spacetime-Coherent Geometry Reconstruction from Multiple Video Streams","authors":"Marcus A. Magnor, Bastian Goldlücke","author_ids":"1686739, 2065814","abstract":"By reconstructing time-varying geometry one frame at a time, one ignores the continuity of natural motion, wasting useful information about the underlying video-image formation process and taking into account temporally dis-continuous reconstruction results. In 4D spacetime, the surface of a dynamic object describes a continuous 3D hyper-surface. This hyper-surface can be implicitly defined as the minimum of an energy functional designed to optimize photo-consistency. Based on an Euler-Lagrange re-formulation of the problem, we find this hyper-surface from a handful of synchronized video recordings. The resulting object geometry varies smoothly over time, and intermittently invisible object regions are correctly interpolated from previously and/or future frames.","cites":"13","conferencePercentile":"70.88607595"},{"venue":"3DPVT","id":"c52a655b79f0d907315168f4a6e400a0819c1d9d","venue_1":"3DPVT","year":"2004","title":"Fan-Meshes: A Geometric Primitive for Point-Based Description of 3D Models and Scenes","authors":"Xiaotian Yan, Fang Meng, Hongbin Zha","author_ids":"2755175, 5863723, 1687248","abstract":"We propose a new data structure, called Fan-Meshes (FM), for reconstructing 3D models and scenes represented by dense scanning point clouds. It is a local piecewise linear approximation to the data geometry, and can serve as primitives in reconstruction with a good balance between computational loads and reconstruction quality. In our algorithm, local remeshing is performed in preprocessing to obtain regular FMs, and a three-level-point data structure called Triangle Selection Record (TSR) is then used to reduce redundancies in the raw data and overlapping in the original FMs. Furthermore, to apply the method to raw 3D scanning data, we use a smoothing operator to the point cloud in order to eliminate some sensor noises. Experimental results demonstrate that our scheme is effective even for large-scale scenes with real data.","cites":"1","conferencePercentile":"12.02531646"},{"venue":"3DPVT","id":"601873cb0f49737b4bad94d88209312829306e6e","venue_1":"3DPVT","year":"2006","title":"Multi-View Multi-Exposure Stereo","authors":"Alejandro J. Troccoli, Sing Bing Kang, Steven M. Seitz","author_ids":"2476088, 1738740, 1679223","abstract":"Multi-view stereo algorithms typically rely on same-exposure images as inputs due to the brightness constancy assumption. While state-of-the-art depth results are excellent , they do not produce high-dynamic range textures required for high-quality view reconstruction. In this paper, we propose a technique that adapts multi-view stereo for different exposure inputs to simultaneously recover reliable dense depth and high dynamic range textures. In our technique , we use an exposure-invariant similarity statistic to establish correspondences, through which we robustly extract the camera radiometric response function and the image exposures. This enables us to then convert all images to radiance space and selectively use the radiance data for dense depth and high dynamic range texture recovery. We show results for synthetic and real scenes.","cites":"10","conferencePercentile":"69.90740741"},{"venue":"3DPVT","id":"defae61133a0797619e4a4585f3ab9ca8de65d82","venue_1":"3DPVT","year":"2006","title":"Efficient Constraint Evaluation Algorithms for Hierarchical Next-Best-View Planning","authors":"Kok-Lim Low, Anselmo Lastra","author_ids":"2924341, 2535203","abstract":"We recently proposed a new and efficient next-best-view algorithm for 3D reconstruction of indoor scenes using active range sensing. We overcome the computation difficulty of evaluating the view metric function by using an adaptive hierarchical approach to exploit the various spatial coherences inherent in the acquisition constraints and quality requirements. The impressive speedups have allowed our NBV algorithm to become the first to be able to exhaustively evaluate a large set of 3D views with respect to a large set of surfaces, and to include many practical acquisition constraints and quality requirements. The success of the algorithm is greatly dependent on the implementation efficiency of the constraint and quality evaluations. In this paper, we describe the algorithmic details of the hierarchical view evaluation, and present efficient algorithms that evaluate sensing constraints and surface sampling densities between a view volume and a surface patch instead of simply between a single view point and a surface point. The presentation here provides examples for the design of efficient algorithms for new sensing constraints.","cites":"11","conferencePercentile":"73.61111111"},{"venue":"3DPVT","id":"d0ce61bfbc0dce8b5250eddad104a37ceb5a4768","venue_1":"3DPVT","year":"2002","title":"Real-Time Speech-Driven 3D Face Animation","authors":"Pengyu Hong, Zhen Wen, Thomas S. Huang, Harry Shum","author_ids":"3278420, 1735018, 1739208, 1698102","abstract":"In this paper, we present an approach for real-time speech-driven 3D face animation using neural networks. We first analyze a 3D facial movement sequence of a talking subject and learn a quantitative representation of the facial deformations, called the 3D Motion Units (MUs). A 3D facial deformation can be approximated by a linear combination of the MUs weighted by the MU parameters (MUPs) – the visual features of the facial deformation. The facial movement sequence synchronizes with a audio track. The audio track is digitized and the audio features of each frame are calculated. A real-time audio-to-MUP mapping is constructed by training a set of neural networks using the calculated audiovisual features. The audiovisual features are divided into several groups based on the audio features. One neural network is trained per group to map the audio features to the corresponding MUPs. Given a new audio feature vector, we first classify it into one of the groups and select the corresponding neural network to map the audio feature vector to MUPs, which are used for face animation. The quantitative evaluation shows the effectiveness of the proposed approach.","cites":"7","conferencePercentile":"58.08823529"},{"venue":"3DPVT","id":"ffb427a8f022468fc1785c7af159cb44ffd751f7","venue_1":"3DPVT","year":"2006","title":"Graph Cut Based Multiple View Segmentation for 3D Reconstruction","authors":"Mario Sormann, Christopher Zach, Konrad F. Karner","author_ids":"2643707, 1713941, 1814788","abstract":"In this paper we propose a novel framework for efficiently extracting foreground objects in so called short-baseline image sequences. We apply the obtained segmen-tation to improve subsequent 3D reconstruction results. Essentially , our framework combines a graph cut based optimization algorithm with an intuitive user interface. At first a meanshift segmentation algorithm partitions each image of the sequence into a certain number of regions. Additionally we provide an intelligent graphical user interface for easy specification of foreground as well as background regions across all images of the sequence. Within the graph cut optimization algorithm we define new energy terms to increase the robustness and to keep the segmentation of the foreground object coherent across all images of the sequence. Finally, a refined graph cut segmentation and several adjustment operations allow an accurate and effective foreground extraction. The obtained results are demonstrated on several real world data sets.","cites":"12","conferencePercentile":"75.92592593"},{"venue":"3DPVT","id":"034d5783019f271903280337bae75a0973b2e6e7","venue_1":"3DPVT","year":"2006","title":"Efficient Sparse 3D Reconstruction by Space Sweeping","authors":"Joachim Bauer, Christopher Zach, Horst Bischof","author_ids":"2880980, 1713941, 8312193","abstract":"This paper introduces a feature based method for the fast generation of sparse 3D point clouds from multiple images with known pose. We extract sub-pixel edge elements (2D position plus associated orientation) and use a space sweeping scheme to compute the accurate 3D location of these edge features. Our approach relies mainly on the geometric properties of the extracted primitives and incorporates a robust uncertainty estimation to detect outliers. Epipolar constraints between views are used to narrow down the search space of potential candidates in the images. In order to improve the efficiency of spatial queries, for detecting edgels lying close to an epipolar line, we utilise a pairwise stereo rectification scheme. The detection and verification of tentative hypotheses is carried out in 3D-space, thus allowing to perform an event driven search mode. An uncertainty measure that models the location inaccuracies in the feature extraction process and errors introduced in the camera pose estimation stage allows to assign a likelihood value to each hypothesis. Optionally an image-based similarity measure can be used to verify the 3D hypotheses and to identify false positives. We perform experiments on a synthetic data set and on several real datasets. The results indicate that the proposed method yields accurate measurements on depth discontinuities and thus represents a complementary technique to standard dense matching approaches.","cites":"3","conferencePercentile":"37.03703704"},{"venue":"3DPVT","id":"668d014b1de3084cf526985e73e3d0daadb6e0e4","venue_1":"3DPVT","year":"2006","title":"Scanline Optimization for Stereo on Graphics Hardware","authors":"Christopher Zach, Mario Sormann, Konrad F. Karner","author_ids":"1713941, 2643707, 1814788","abstract":"In this work we propose a scanline optimization procedure for computational stereo using a linear smoothness cost model performed by programmable graphics hardware. The main idea for an efficient implementation of this dynamic programming approach is a recursive scheme to calculate the min-convolution in a manner suitable for the parallel stream computation model of graphics processing units. Since many image similarity functions can be efficiently calculated by modern graphics hardware, it is reasonable to address the final disparity extraction by graphics processors as well. Our timing results indicate that the proposed approach is beneficial for larger image resolutions and disparity ranges in particular.","cites":"7","conferencePercentile":"57.87037037"},{"venue":"3DPVT","id":"49d4726779e5354f84b0a7d9e7d65aed5f467440","venue_1":"3DPVT","year":"2006","title":"Global Depth from Epipolar Volumes--A General Framework for Reconstructing Non-Lambertian Surfaces","authors":"Timo Stich, Art Tevs, Marcus A. Magnor","author_ids":"2501208, 3320218, 1686739","abstract":"Using Epipolar Image Analysis in the context of the correspondence finding problem in depth reconstruction has several advantages. One is the elegant incorporation of prior knowledge about the scene or the surface reflection properties into the reconstruction process. The proposed framework in conjunction with graph cut optimization is able to reconstruct also highly specular surfaces. The use of prior knowledge and multiple images opens new ways to reconstruct surfaces and scenes impossible or error prone with previous methods. Another advantage is improved occlu-sion handling. Pixels that are partly occluded contribute to the reconstruction results. The proposed shifting of some of the computation to graphics hardware (GPU) results in a significant speed improvement compared to pure CPU-based implementations.","cites":"7","conferencePercentile":"57.87037037"},{"venue":"3DPVT","id":"fc03456fc65cf0229bda638c2226fc0580957c58","venue_1":"3DPVT","year":"2002","title":"Probabilistic 3D Data Fusion for Adaptive Resolution Surface Generation","authors":"Andrew E. Johnson, Roberto Manduchi","author_ids":"4415091, 1737048","abstract":"In this paper we present an algorithm for adaptive resolution integration of 3D data collected from multiple distributed sensors. The input to the algorithm is a set of 3D surface points and associated sensor models. Using a probabilistic rule, a surface probability function is generated that represents the probability that a particular volume of space contains the surface. The surface probability function is represented using an octree data structure; regions of space with samples of large covariance are stored at a coarser level than regions of space containing samples with smaller covariance. The algorithm outputs an adaptive resolution surface generated by connecting points that lie on the ridge of surface probability with triangles scaled to match the local discretization of space given by the octree. To demonstrate the performance of our algorithm, we present results from 3D data generated by scanning lidar and structure from motion.","cites":"2","conferencePercentile":"22.79411765"},{"venue":"3DPVT","id":"a03b7d6dd1f1d5afc548666b123d44fafdd409b9","venue_1":"3DPVT","year":"2006","title":"RDTC Optimized Streaming for Remote Browsing in Image-Based Scene Representations","authors":"Ingo Bauermann, Yang Peng, Eckehard G. Steinbach","author_ids":"1748117, 1683254, 7252930","abstract":"Remote navigation in compressed image-based scene representations requires random access to arbitrary parts of the reference image data to recompose virtual views. The degree of inter-frame dependencies exploited during compression has an impact on the effort needed to access reference images and delimits the rate distortion (RD) trade-off that can be achieved. If, additionally, a given receiver hardware and a maximum available channel bitrate is taken into account, the traditional rate-distortion optimization is extended to an RDTC trade-off between rate (R), distortion (D), transmission data rate (T), and decoding complexity (C). In this work we introduce our RDTC optimized compression framework. In addition, an experimental testbed for streaming of these RDTC optimally compressed image-based scene representations is described and the impact of client side caching is investigated. Our results show a significant reduction in user perceived delay for RDTC optimized streams in such a remote browsing environment compared to RD optimized or independently encoded scene representations.","cites":"1","conferencePercentile":"15.27777778"},{"venue":"3DPVT","id":"79048fa396d126b60e3088bd702fceffa98d4b76","venue_1":"3DPVT","year":"2006","title":"Resolution Scalable Coding and Region of Interest Access with Three-Dimensional SBHP Algorithm","authors":"Ying Liu, William A. Pearlman","author_ids":"1718041, 1718894","abstract":"A low-complexity three-dimensional image compression algorithm based on wavelet transforms and set-partitioning strategy is presented. The Subband Block Hierarchial Partitioning (SBHP) algorithm is modified and extended to three dimensions, and applied to every code block independently. The resultant algorithm, 3D-SBHP, efficiently encodes 3D image data by the exploitation of the dependencies in all dimensions, while enabling progressive SNR and resolution decompression and Region-of-Interest (ROI) access from the same bit stream. The code-block selection method by which random access decoding can be achieved is outlined.The resolution scalable and random access performances are empirically investigated. The results show 3D-SBHP is a good candidate to compress 3D image data sets for multimedia applications.","cites":"1","conferencePercentile":"15.27777778"},{"venue":"3DPVT","id":"c5dab43f60c16e2324729dd3cc5e36356c816041","venue_1":"3DPVT","year":"2006","title":"A Spatio-Temporal Modeling Method for Shape Representation","authors":"Heng Huang, Li Shen, Rong Zhang, Fillia Makedon, Justin D. Pearlman","author_ids":"1748032, 1712125, 3575684, 1728274, 2855131","abstract":"The spherical harmonic (SPHARM) description is a powerful surface modeling technique that can model arbitrarily shaped but simply connected three dimensional (3D) objects. Because SPHARM based 3D models can derive functional information analysis and classify different pathological symptoms, it has been used in many applications in biomedical image computing. There is an urgent requirement for efficient spatio-temporal shape modeling to represent the dynamic anatomical structures in many applications (e.g., medical image analysis, geospatial information systems). In this paper we propose a novel real spherical harmonics based spatio-temporal shape model-ing method to efficiently and flexibly represent the shapes sequence of anatomical structures in medical images. Our method works well on the simply connected 3D objects and the effectiveness of our approach is demonstrated through theoretic and experimental exploration of a set of medical image applications. Furthermore, an evaluation criterion for spatio-temporal shape modeling efficiency is proposed and the comparison results showed the good performance of our method.","cites":"1","conferencePercentile":"15.27777778"},{"venue":"3DPVT","id":"1ca79bea417fcb9dc552df556a615a2e8b3dcd23","venue_1":"3DPVT","year":"2006","title":"Large-Scale Modeling of Parametric Surfaces Using Spherical Harmonics","authors":"Li Shen, Moo K. Chung","author_ids":"1712125, 1699826","abstract":"We present an approach for large-scale modeling of parametric surfaces using spherical harmonics (SHs). A standard least square fitting (LSF) method for SH expansion is not scalable and cannot accurately model large 3D surfaces. We propose an iterative residual fitting (IRF) algorithm , and demonstrate its effectiveness and scalability in creating accurate SH models for large 3D surfaces. These large-scale and accurate parametric models can be used in many applications in computer vision, graphics, and bio-medical imaging. As a simple extension of LSF, IRF is very easy to implement and requires few machine resources.","cites":"24","conferencePercentile":"93.51851852"},{"venue":"3DPVT","id":"2731af655540453935fbb0b50676fd43631327d2","venue_1":"3DPVT","year":"2006","title":"Shape Analysis and Spatio-Temporal Tracking of Mesoscale Eddies in Miami Isopycnic Coordinate Ocean Model","authors":"Veena Moolani, Ramprasad Balasubramanian, Li Shen, Amit Tandon","author_ids":"2319376, 3074960, 1712125, 3071898","abstract":"Detection and analysis of ocean surface phenomena have so far relied on manual analysis of long sequences of satellite images or images produced from the mathematical models. In this paper a technique for the three-dimensional shape analysis and spato-temporall tracking of mesoscale eddies from MICOM dataset is presented. Mesoscale eddies play a strong role in carrying heat poleward. The shape analysis of eddies provides a volumetric estimation which can be further used to determine the heat trapped in eddies. Eddies are detected and the region of swirling currents around the detected center is segmented. Segmented eddies are stacked to generate 3D visualization. A 3D skeleton is obtained with the centroids of all the layers in the segmented eddy and represented parametrically. Coefficients of the parametric representation are used for motion tracking of eddies.","cites":"1","conferencePercentile":"15.27777778"},{"venue":"3DPVT","id":"6c262ee147b1a633fb8f0e8fb7601d99cf8ee662","venue_1":"3DPVT","year":"2006","title":"Hemispherical Harmonic Surface Description and Applications to Medical Image Analysis","authors":"Heng Huang, Lei Zhang, Dimitris Samaras, Li Shen, Rong Zhang, Fillia Makedon, Justin D. Pearlman","author_ids":"1748032, 2813779, 1686020, 1712125, 3575684, 1728274, 2855131","abstract":"The use of surface harmonics for rigid and nonrigid shape description is well known. In this paper we define a set of complete hemispherical harmonic basis functions on a hemisphere domain and propose a novel parametric shape description method to efficiently and flexibly represent the surfaces of anatomical structures in medical images. As the first application of hemispherical harmonic theory in shape description, our technique differs from the previous surface harmonics shape descriptors, all of which don't work efficiently on the hemisphere-like objects that often exist in medical anatomical structures (e.g., ventricles, atri-ums, etc.). We demonstrate the effectiveness of our approach through theoretic and experimental exploration of a set of medical image applications. Furthermore, an evaluation criterion for surface modeling efficiency is described and the comparison results demonstrated that our method outperformed the previous approaches using spherical harmonic models.","cites":"2","conferencePercentile":"27.31481481"},{"venue":"3DPVT","id":"0b656a50190af6d6073757b88b13ee17576e279b","venue_1":"3DPVT","year":"2006","title":"A System for Reconstructing Integrated Texture Maps for Large Structures","authors":"Chen Xu, Athinodoros S. Georghiades, Holly E. Rushmeier, Julie Dorsey","author_ids":"3805057, 3230391, 1690595, 1775220","abstract":"We consider the problem of creating integrated texture maps of large structures scanned with a time-of-flight laser scanner and imaged with a digital camera. The key issue in creating integrated textures is correcting for the spatially varying illumination across the structure. In most cases, the illumination cannot be controlled, and dense spatial estimates of illumination are not possible. We present a system for processing multiple color images into an integrated texture that makes use of the laser scanner return intensity and the captured geometry, together with color balancing and mapping of illumination-corrected images onto the target geometry after filtering into two spatial frequency bands.","cites":"4","conferencePercentile":"44.44444444"},{"venue":"3DPVT","id":"0e15f9cac6165941e5a1f3fe7e9eea57050ffe32","venue_1":"3DPVT","year":"2004","title":"3D Model Retrieval Based on 2D Slice Similarity Measurements","authors":"Jiantao Pu, Yi Liu, Guyu Xin, Hongbin Zha, Weibin Liu, Yusuke Uehara","author_ids":"3327232, 1691635, 2878892, 1687248, 1943870, 3113033","abstract":"In this paper, we present an approach based on 2D slices for measuring similarity between 3D models. The key idea is to represent the 3D model by a series of slices along certain directions so that the shape-matching problem between 3D models is transformed into similarity measuring between 2D slices. Here, we have to deal with the following problems: selection of cutting directions, cutting methods, and similarity measuring. To solve these problems, some strategies and rules are proposed. Firstly, a maximum normal distribution method is presented to get three ortho-axes that coincide better with human visual perception mechanism. Secondly, a cutting method is given which can be used to get a series of slices composed of a set of closed polygons. Thirdly, on the basis of 3D shape distribution method presented by Robert et al., we develop a 2D shape distribution method to measure the similarity between the 2D slices. Some experiments are given in this paper to show the validity of this method for 3D model retrieval.","cites":"14","conferencePercentile":"72.15189873"},{"venue":"3DPVT","id":"ae0dcd7d0c90e22f496e6b6dc35879ec0354f373","venue_1":"3DPVT","year":"2004","title":"Markerless Human Motion Transfer","authors":"German K. M. Cheung, Simon Baker, Jessica K. Hodgins, Takeo Kanade","author_ids":"2450108, 1737297, 1788773, 7642093","abstract":"extract joint skeleton acquire 3D shape kinematic model turntable images joint exercise images kinematic model frames cameras source videos motion videos motion data motion data kinematic model render video of new motion (subject #1) (subject #2) (transfer motion from subject #2 to subject #1) extract joint skeleton acquire 3D shape kinematic model turntable images joint exercise images kinematic model frames cameras source videos motion videos motion data motion data kinematic model render video of new motion (subject #1) (subject #2) (transfer motion from subject #2 to subject #1) Figure 1: Our system consists of three steps: (a) kinematic modeling: extracting segmented 3D shape and joint locations, (b) markerless motion capture: articulated tracking of joint angles and (c) image-based rendering of the motion applied to the other subject. Generating animations of real-life characters with realistic motion and appearance is one of the most difficult problems in computer graphics. The ability to create realistic videos of a person performing new motions is essential to games development and special effects in movie production. In this research, we describe a markerless system to transfer articulated motion from one person to another: given video sequences of two people performing two different motions, we generate videos of each person performing the motion of the other person. Our system is based on computer vision techniques and uses no markers in any of the steps. Figure 1 illustrates the structure of our markerless motion transfer system. Our system uses eight synchronized, calibrated and color balanced cameras. The motion transfer process consists of three steps: (a) human kinematic modeling of both subjects #1 and #2, (b) markerless motion capture of both subjects and (c) image-based rendering of the motion of one subject applied to the other. The first two steps are based on our recent work in the computer vision literature [Cheung et al. 2003]. The main contributions of this research are the development of the image-based rendering algorithm in Step 3 and the demonstration of a complete end-to-end markerless motion transfer system. The first step is to build kinematic models of the two subjects. Based on a recently proposed shape reconstruction algorithm called Shape-From-Silhouette Across Time [Cheung et al. 2003], we acquired detailed 3D shapes of the two subjects by asking them to stand on an uncalibrated turntable for 30 seconds. Using a similar algorithm for articulated objects, we also recover the joint location and segmentation of the …","cites":"19","conferencePercentile":"77.84810127"},{"venue":"3DPVT","id":"f5a7be586d9958cf84b50643a200db2972e947d7","venue_1":"3DPVT","year":"2004","title":"Entire Model Acquisition System using Handheld 3D Digitizer","authors":"Hiroshi Kawasaki, Ryo Furukawa","author_ids":"1710962, 1697820","abstract":"In this paper, a real-time, handheld 3D model acquisition system consisting of a laser projector, a video camera and a turntable is described. The user projects a stripe of light at the 3D object by hand while rotating the object on a turntable. The projected light and LED markers attached to the laser projector and turntable are captured by the video camera. By estimating the 3D orientation of the laser projector and the turntable angle from the 2D locations of the markers, the 3D location of the surface lit by the laser can be calculated. In addition, post-processing algorithms for refining the estimated 3D data have been proposed. The algorithm not only improves the accuracy of the 3D measurement , but also achieves to decrease the number of LEDs for 3D data estimation; therefore, it significantly improves the user's convenience in scanning the object. With this system, users can measure an entire 3D object in real-time.","cites":"1","conferencePercentile":"12.02531646"},{"venue":"3DPVT","id":"48975c63b4b56625a2397ac8a526eec0ec3ab132","venue_1":"3DPVT","year":"2006","title":"Line-Based Structure from Motion for Urban Environments","authors":"Grant Schindler, Panchapagesan Krishnamurthy, Frank Dellaert","author_ids":"2582852, 1920142, 2038264","abstract":"We present a novel method for recovering the 3D-line structure of a scene from multiple widely separated views. Traditional optimization-based approaches to line-based structure from motion minimize the error between measured line segments and the projections of corresponding 3D lines. In such a case, 3D lines can be optimized using a minimum of 4 parameters. We show that this number of parameters can be further reduced by introducing additional constraints on the orientations of lines in a 3D scene. In our approach, 2D-lines are automatically detected in images with the assistance of an EM-based vanishing point estimation method which assumes the existence of edges along mutally orthogonal vanishing directions. Each detected line is automatically labeled with the orientation (e.g. vertical, horizontal) of the 3D line which generated the measurement , and it is this additional knowledge that we use to reduce the number of degrees of freedom of 3D lines during optimization. We present 3D reconstruction results for urban scenes based on manually established feature correspondences across images.","cites":"46","conferencePercentile":"97.22222222"},{"venue":"3DPVT","id":"58233ed1f81e8671f9d63b5ba12625c909db33f1","venue_1":"3DPVT","year":"2002","title":"Implementation of a Shadow Carving System for Shape Capture","authors":"Silvio Savarese, Holly E. Rushmeier, Fausto Bernardini, Pietro Perona","author_ids":"1702137, 1690595, 1699532, 1690922","abstract":"We present a new technique for estimating the 3D shape of an object that combines previous ideas from shape from silhouettes and shape from shadows. We begin with a setup for robustly extracting object silhouettes by casting a shadow of the object with a point light-source onto a translucent panel. A camera on the opposite side of the panel records an image which is readily processed to obtain the object boundary. We use a space carving technique to extract an initial estimate of the object shape. In a second phase, we record a series of images of the object lit by point light sources. We compare the areas of self shadowing in these images to those expected if our estimated shape from the space carving were correct. The shape of the object is refined by a shadow carving step that adjusts the current shape to resolve contradictions between the captured images and the current shape estimate. The result of the space carving and shadow carving is an estimate of shape that can be further refined by methods that work well in local regions, such as photometric stereo. We have implemented our approach in a simple table top system and present the results of scanning a small object with deep concavities.","cites":"5","conferencePercentile":"45.58823529"},{"venue":"3DPVT","id":"48729624729cdd298a9d2587318768f1dca7ea67","venue_1":"3DPVT","year":"2006","title":"Vanishing Hull","authors":"Jinhui Hu, Suya You, Ulrich Neumann","author_ids":"5838664, 1715900, 1745263","abstract":"Vanishing points are valuable in many vision tasks such as orientation estimation, pose recovery and 3D reconstruction from a single image. Many methods have been proposed to address the problem, however, a consistent framework to quantitatively analyze the stability and accuracy of vanishing point estimation is still absent. This paper proposes a new concept, vanishing hull, which solves the problem. Given an edge error model, the range of a true edge can be modeled using a fan region. The intersection of all these fan regions is a convex hull, which is called vanishing hull. A vanishing hull gives the region of a true vanishing point, and its distribution determines the probability of the vanishing point. The expectation of the vanishing hull is the optimal solution of the vanishing point, its variance defines the accuracy of the estimation, and its shape determines the stability of the vanishing point. Hence, we can quantitatively analyze the stability and accuracy of the vanishing point estimation using vanishing hull. Simulation results show that our method is significantly better than one state-of-the-art technique, and real data results are also promising.","cites":"2","conferencePercentile":"27.31481481"},{"venue":"3DPVT","id":"f43f791234d633bbcb1b81e134f6259e21332f62","venue_1":"3DPVT","year":"2002","title":"ATTEST: Advanced Three-dimensional Television System Technologies","authors":"André Redert, Marc Op de Beeck, Christoph Fehn, Wijnand A. IJsselsteijn, Marc Pollefeys, Luc Van Gool, Eyal Ofek, Ian Sexton, Philip Surman","author_ids":"3251153, 7391437, 2236543, 1679478, 1742208, 1715797, 1735652, 2971776, 2076516","abstract":"We describe the goals of the ATTEST project, which started in March 2002 as part of the Information Society Technologies (IST) programme, sponsored by the European Commission. In the 2-year project, several industrial and academic partners cooperate towards a flexible, 2D-compatible and commercially feasible 3D-TV system for broadcast environments. An entire 3D-video chain will be developed. We discuss the goals for content creation, coding, transmission, display and the central role that human 3D perception research will play in optimizing the entire chain. The goals include the development of a new 3D camera, algorithms to convert existing 2D-video material into 3D, a 2D-compatible coding and transmission scheme for 3D video using MPEG-2/4/7, and two new autostereoscopic displays. With the combination of industrial and academic partners and the technological progress obtained from earlier 3D projects, we expect to achieve the ATTEST goal of developing the first commercially feasible European 3D-TV broadcast system.","cites":"47","conferencePercentile":"96.32352941"},{"venue":"3DPVT","id":"b70a46e74d4e4fa87a274140f4121640d326202a","venue_1":"3DPVT","year":"2006","title":"Building a 3D Virtual Museum of Native American Baskets","authors":"Volkan Isler, Bradford Wilson, Ruzena Bajcsy","author_ids":"1698835, 2142107, 1784213","abstract":"— In this paper we report our progress in building a system for the acquisition, analysis, and visualization of a collection of Native Californian baskets from the Phoebe A. Hearst Museum of Anthropology. Our project differs from existing cultural heritage applications in terms of its focus: to build tools and techniques for visualizing and studying a large number of related objects – in this case, baskets. We present our progress in the following system components: (i) laser-scanning of baskets, (ii) construction and processing of 3D models, and (iii) building virtual exhibits. We conclude the paper with our experiences and a summary of challenges we anticipate in building a completely automated system for processing and analyzing a large set of models – such as might be encountered when digitizing a large museum collection. Efficient retrieval and visualization of artifact collections are important to a number of communities, including anthropology researchers, Native American tribes, and the general public. I. INTRODUCTION Advances in three dimensional data acquisition, processing, and visualization technologies enable new methods for not only preserving our cultural heritage but making it vastly more accessible to both researchers and society alike. In this paper, we report our experiences and progress in building a virtual exhibit for the Phoebe A. Hearst Museum of Anthropology. Home to an estimated 3.8 million objects, the Hearst Museum has extensive collections devoted to Native California peoples, including a unique research collection of California Indian baskets which it has been gathering for nearly a hundred years. In addition to being the largest collection of its type in the world, with approximately 9,000 baskets, the collection's remarkable breadth – there are representative specimens from almost every tribe in California – make it a particularly attractive, and heavily used, resource for study. As is common with managing research collections of this size, providing access to scientists and the public is a continual problem for museums. Due to space limitations in its crowded quarters, the Hearst Museum must house its collection of Cal-ifornia Indian baskets in an off-site storage facility. Physical access to the collection is strictly controlled, since handling of the often fragile objects hastens their deterioration. Before researchers can gain access to the baskets, they must first make an appointment to visit the storage facility, during which museum staff must be on hand to supervise and handle the artifacts, a less than efficient arrangement. Researchers who","cites":"3","conferencePercentile":"37.03703704"},{"venue":"3DPVT","id":"3e24027cad2e0469114133463d796db847983374","venue_1":"3DPVT","year":"2006","title":"Integrating LiDAR, Aerial Image and Ground Images for Complete Urban Building Modeling","authors":"Jinhui Hu, Suya You, Ulrich Neumann","author_ids":"5838664, 1715900, 1745263","abstract":"This paper presents a hybrid modeling system that fuses LiDAR data, an aerial image and ground view images for rapid creation of accurate building models. Outlines for complex building shapes are interactively extracted from a high-resolution aerial image, surface information is automatically fit with a primitive based method from LiDAR data, and high-resolution ground view images are integrated into the model to generate fully textured CAD models. Our method benefits from the merit of each dataset, and evaluation results are presented on a university campus-size model.","cites":"18","conferencePercentile":"86.57407407"},{"venue":"3DPVT","id":"355f52923ff5ac77af812d50b0403791b2617763","venue_1":"3DPVT","year":"2006","title":"An Improved 3D Human Face Reconstruction Approach Based on Cubic Splines Models","authors":"Boulbaba Ben Amor, Mohsen Ardabilian, Liming Chen","author_ids":"2125606, 2758323, 1699578","abstract":"In this paper, we develop a new hybrid active vi-sion/geometric modeling approach dedicated to 3D human face recovery. Initially, a 3D coarse reconstruction is obtained via a structured-light assisted stereo sensor. Here, the stereo matching problem is resolved through two main stages: (a) sub-pixel stripe edge localization of projected patterns of light, and (b) correspondences establishing based on adaptive dynamic programming optimization technique. Next, the introduction of smooth interpolation models achieves the fine reconstruction. Here, cubic Spline curves are employed in order to improve the quality of the reconstructed models. Indeed, they allow us to produce dense and details preserving reconstructions by following the control points from the coarse reconstruction stage. Furthermore, we present some reconstruction results and discuss both qualitative and quantitative evaluations of the proposed reconstruction scheme.","cites":"2","conferencePercentile":"27.31481481"},{"venue":"3DPVT","id":"bdaf683c067a09ab7de619177ad736fd6880de33","venue_1":"3DPVT","year":"2006","title":"ShapeLab: A Unified Framework for 2D & 3D Shape Retrieval","authors":"Jiantao Pu, Karthik Ramani","author_ids":"3327232, 1766368","abstract":"2D or 3D shapes are the most important visual information that we use to recognize an object. We propose a unified framework \" ShapeLab \" to search similar 2D or 3D shapes from an existing database. Users can search 3D shapes with a 2D input, and vice versa. ShapeLab is composed of four key components: (1) pose determination for 3D models; (2) 2D orthogonal view generation based on multiple levels of detail; (3) similarity measurement between 2D shapes; and (4) freehand sketch-based user interface. Key algorithms supporting the above components are briefly described. Experiments show ShapeLab can provide a better performance such as high accuracy, flexibility and scalability compared to the available methods.","cites":"2","conferencePercentile":"27.31481481"},{"venue":"3DPVT","id":"52a7435d23345c156be50bc15a450f14c3b5605a","venue_1":"3DPVT","year":"2004","title":"Seeing into the Past: Creating a 3D Modeling Pipeline for Archaeological Visualization","authors":"Peter K. Allen, Steven K. Feiner, Alejandro J. Troccoli, Hrvoje Benko, Edward W. Ishak, Benjamin Smith","author_ids":"2433855, 1809403, 2476088, 2704133, 2192767, 1680827","abstract":"Archaeology is a destructive process in which accurate and detailed recording of a site is imperative. As a site is exposed, documentation is required in order to recreate and understand the site in context. We have developed a 3D modeling pipeline that can assist archaeologists in the documentation effort by building rich, geometrically and photo-metrically accurate 3D models of the site. The modeling effort begins with data acquisition (images, range scans, GIS data, and video) and ends with the use of a sophisticated visualization tool that can be used by researchers to explore and understand the site. The pipeline includes new methods for shadow-based registration of 2D images and temporal change detection. Our multimodal augmented reality system allows users wearing head-tracked, see-through, head-worn displays to visualize the site model and associated archaeological artifacts, and to interact with them using speech and gesture.","cites":"21","conferencePercentile":"81.01265823"},{"venue":"3DPVT","id":"8f39bb7841a931b4ccc510c6bb2add073f010b0f","venue_1":"3DPVT","year":"2002","title":"Fast 3D Model Acquisition from Stereo Images","authors":"Louis-Philippe Morency, Ali Rahimi, Trevor Darrell","author_ids":"1767184, 1752073, 1753210","abstract":"We propose a fast 3D model acquisition system that aligns intensity and depth images, and reconstructs a tex-tured 3D mesh. 3D views are registered with shape alignment based on intensity gradient constraints and a global registration algorithm. We reconstruct the 3D model using a new Cubic Ray Projection merging algorithm which takes advantage of a novel data structure: the linked voxel space. Finally, we present experiments to test the accuracy of our approach on 3D face modeling using real-time stereo images .","cites":"6","conferencePercentile":"51.47058824"},{"venue":"3DPVT","id":"5f8112731bd0a2bfa91158753242bae2f540d72d","venue_1":"3DPVT","year":"2002","title":"Rapid Shape Acquisition Using Color Structured Light and Multi-pass Dynamic Programming","authors":"Li Zhang, Brian Curless, Steven M. Seitz","author_ids":"1735367, 1810052, 1679223","abstract":"Figure 1. In this paper, we show how to reconstruct the shape of a scene, such as the two hands shown on the left, given a single photograph of the scene under color-striped illumination shown at center. A novel dynamic programming method leads to the geometric reconstruction on the right, shown as a shaded rendering from a new viewpoint. Abstract This paper presents a color structured light technique for recovering object shape from one or more images. The technique works by projecting a pattern of stripes of alternating colors and matching the projected color transitions with observed edges in the image. The correspondence problem is solved using a novel, multi-pass dynamic programming algorithm that eliminates global smoothness assumptions and strict ordering constraints present in previous formulations. The resulting approach is suitable for generating both high-speed scans of moving objects when projecting a single stripe pattern and high-resolution scans of static scenes using a short sequence of time-shifted stripe patterns. In the latter case, spacetime analysis is used at each sensor pixel to obtain inter-frame depth localization. Results are demonstrated for a variety of complex scenes.","cites":"181","conferencePercentile":"98.52941176"},{"venue":"3DPVT","id":"184a613a39c07201643b050696feec368689ce1e","venue_1":"3DPVT","year":"2006","title":"Self-Calibration of Multiple Laser Planes for 3D Scene Reconstruction","authors":"Ryo Furukawa, Hiroshi Kawasaki","author_ids":"1697820, 1710962","abstract":"Self-calibration is one of the most active issues concerning vision-based 3D measurements. However, in the case of the light sectioning method, there has been little research conducted on self-calibration techniques. In this paper, we study the problem of self-calibration for an active vision system which uses line lasers and a single camera. The problem can be defined as the estimation of multiple laser planes from the curves of laser reflections observed from a sequence of images captured by a single camera. The constraints of the problem can be obtained from observed intersection points between the curves. In this condition, the problem is formulated as simultaneous polynomial equations , in which the number of equations is larger than the number of variables. Approximated solutions of the equations can be computed by using Gröbner bases. By refining them using nonlinear optimization, the final result can be obtained. We developed an actual 3D measurement system using the proposed method, which consists of only a laser projector with two line lasers and a single camera. Users are just required to move the projector freely so that the projected lines sweep across the surface of the scene to get the 3D shape.","cites":"7","conferencePercentile":"57.87037037"},{"venue":"3DPVT","id":"55e678b13d7940457f37521c6591c4580db73756","venue_1":"3DPVT","year":"2006","title":"Constraint Integration for Multiview Pose Estimation of Humans with Self-Occlusions","authors":"Abhinav Gupta, Anurag Mittal, Larry S. Davis","author_ids":"1776251, 1717115, 1693428","abstract":"Detection of articulated objects such as humans is an important task in computer vision. We present a system that incorporates a variety of constraints in a unified multi-view framework to automatically detect humans in possibly crowded scenes. These constraints include the kinematic constraints, the occlusion of one part by another and the high correlation between the appearance of parts such as the two arms. The graphical structure (non-tree) obtained is optimized in a nonparametric belief propagation framework using prior based search.","cites":"3","conferencePercentile":"37.03703704"},{"venue":"3DPVT","id":"1ec96f6d00a9f1cf10fce186e33088ff125dbd59","venue_1":"3DPVT","year":"2002","title":"3D Shape Estimation Based on Density Driven Model Fitting","authors":"Eugene Borovikov, Larry S. Davis","author_ids":"1744255, 1693428","abstract":"We introduce a generic and efficient method for 2D and 3D shape estimation via density Þelds. Our method models shape as a density map and uses the notion of density to Þt a model to a rapidly computed occupancy map of the foreground object. We show how to utilize hierarchical (pyramid-like) object segmentation data to regularize a hierarchical model Þtting. With primary focus on estimating 3D shapes of non-rigid articulated objects such as human bodies, we illustrate our approach with examples of efficient model Þtting to 3D occupancy maps of human Þgures. We also discuss a number of extensions of our method to applications involving non-rigid object tracking and movement analysis .","cites":"11","conferencePercentile":"70.58823529"},{"venue":"3DPVT","id":"625bbfb61baa482210052f8d22faaefaea91495f","venue_1":"3DPVT","year":"2006","title":"High-Performance Multi-View Reconstruction","authors":"Christopher Zach, Mario Sormann, Konrad F. Karner","author_ids":"1713941, 2643707, 1814788","abstract":"We present a high performance reconstruction approach, which generates true 3D models from multiple views with known camera parameters. The complete pipeline from depth map generation over depth image integration to the final 3D model visualization is performed on programmable graphics processing units (GPUs). The proposed pipeline is suitable for long image sequences and uses a plane-sweep depth estimation procedure optionally employing robust image similarity functions to generate a set of depth images. The subsequent volumetric fusion step combines these depth maps into an impicit surface representation of the final model, which can be directly displayed using GPU-based raycasting methods. Depending on the number of input views and the desired resolution of the final model the computing times range from several seconds to a few minutes. The quality of the obtained models is illustrated with real-world datasets.","cites":"13","conferencePercentile":"79.62962963"}]}