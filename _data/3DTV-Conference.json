{"3DTV-Conference.csv":[{"venue":"3DTV-Conference","id":"b0b1ab667d49da5c6b2f73733e346638eca20e30","venue_1":"3DTV-Conference","year":"2014","title":"Image interpolation for DIBR viewsynthesis using graph fourier transform","authors":"Yu Mao, Gene Cheung, Yusheng Ji","author_ids":"3217860, 1705205, 7753600","abstract":"Given texture and depth maps of one or more reference view-point(s), depth-image-based rendering (DIBR) can synthesize a novel viewpoint image by mapping texture pixels from reference to virtual view using geometric information provided by corresponding depth pixels. If the virtual view camera is located closer to the 3D scene than the reference view camera, objects close to the camera will increase in size in the virtual view, and DIBR's simple pixel-to-pixel mapping will result in expansion holes that require proper filling. Leveraging on recent advances in graph signal processing (GSP), in this paper we propose to select appropriate graph Fourier transforms (GFT)—adaptive to unique signal structures of the local pixel patches—for expansion hole filling. Our algorithm consists of two steps. First, using structure tensor we compute an adaptive kernel centered at a target empty pixel to identify suitable neighboring pixels for construction of a sparse graph. Second, given the constructed graph with carefully tuned edge weights, to complete the target pixel we formulate an iterative quadratic programming problem (with a closed form solution in each iteration) using a smoothness prior in the GFT domain. Experimental results show that our algorithm can outperform in-painting procedure employed in VSRS 3.5 by up to 4.57dB.","cites":"5","conferencePercentile":"100"},{"venue":"3DTV-Conference","id":"90581a4195ce872c86ed83b93f25d472fe22663e","venue_1":"3DTV-Conference","year":"2013","title":"Single and multi-user head tracked glasses-free 3D displays","authors":"Philip Surman, Sally E. Day, Kaan Aksit, Hakan Urey, Joshua Benjamin, Kuber Jain, Hao Chen","author_ids":"2076516, 2357263, 2413675, 2651404, 2946684, 2786175, 1749993","abstract":"This paper describes two head tracked displays; both provide glasses-free 3D (autostereoscopic) to viewers by producing pairs of exit pupils where the left and right stereo images are directed to the appropriate viewers' eyes under the control of a head tracker. The first display is single viewer where exit pupils are formed by a pair of picoprojectors whose position moves in accordance with the viewer's head position. Light is reflected back to the viewer's eyes using a retroreflecting screen. The second display is multiuser and is laser-based. A Gabor superlens screen is scanned with a vertical illumination column that acts as the backlight for a direct-view liquid crystal display (LCD). The emergent beam directions are controlled by a spatial light modulator (SLM) such that they land on the viewers' left and right eyes alternately. For each display the principle of operation, the display hardware and the results are presented here.","cites":"0","conferencePercentile":"50"},{"venue":"3DTV-Conference","id":"4a789de146c2520040996b80f2927527d6e00fd7","venue_1":"3DTV-Conference","year":"2012","title":"Adaptive arithmetic coding for point cloud compression","authors":"Ismaël Daribo, Ryo Furukawa, Ryusuke Sagawa, Hiroshi Kawasaki","author_ids":"2311207, 1697820, 1706605, 1710962","abstract":"Recently, structured-light-based scanning systems have gain in popularity and are capable of modeling entire dense shapes that evolve over time with a single scan (a.k.a. one-shot scan). By projecting a static grid pattern onto the object surface, one-shot shape reconstruction methods can scan moving objects while still maintaining dense reconstruction. However, the amount of 3D data produced by these systems grows rapidly with point cloud of millions of points. As a consequence, effective point cloud compression scheme is required to face the transmission need. In this paper we propose a new approach to compress point cloud by taking advantage of the fact that arithmetic coding can be split into two parts: an encoder that actually produces the compressed bit-stream, and a modeler that feeds information into the encoder. In particular, for each position point and normal, we propose to calculate the distribution of probabilities based on their spatial prediction as modeler, while classical point cloud coder mainly focus on the reduction of the prediction residual. Experimental results demonstrate the effectiveness of the proposed method.","cites":"0","conferencePercentile":"23.91304348"},{"venue":"3DTV-Conference","id":"e1bac2765ad60f8a64f0bcef245c9b7e7b122aba","venue_1":"3DTV-Conference","year":"2012","title":"Interactive video segmentation supported by multiple modalities, with an application to depth maps","authors":"Jeroen van Baar, Paul A. Beardsley, Marc Pollefeys, Markus H. Gross","author_ids":"1751880, 1777539, 1742208, 1743207","abstract":"In this paper we propose an interactive method for the segmen-tation of objects in video. We aim to exploit multiple modalities to reduce the dependency on color discrimination alone. Given an initial segmentation for the first and last frame of a video sequence , we aim to propagate the segmentation to the intermediate frames of the sequence. Video frames are first segmented into superpixels. The segmentation propagation is then regarded as a superpixels labeling problem. The problem is formulated as an energy minimization problem which can be solved efficiently. Higher-order energy terms are included to represent temporal constraints. Our proposed method is interactive, to ensure correct propagation and relabel incorrectly labeled superpixels. As a final step the initial segmentation boundaries are refined to obtain accurate object boundaries. We then exploit these object boundaries in an application for computing depth maps.","cites":"0","conferencePercentile":"23.91304348"},{"venue":"3DTV-Conference","id":"8035edb45fe87a879bb8ac0f7d43cab4fc59d47e","venue_1":"3DTV-Conference","year":"2014","title":"Freehand interaction with large-scale 3D map data","authors":"Vamsi Kiran Adhikarla, Pawel Wozniak, Attila Barsi, Dave Singhal, Péter Tamás Kovács, Tibor Balogh","author_ids":"3309933, 3336776, 3309809, 2648538, 8674009, 2282346","abstract":"In this paper, we present our method and apparatus to visualize and interact with large-scale 3D map data on a 3D light-field display in real time. 3D map data are streamed over Internet to the display in real-time based on request sent by the application. On the user side, data is processed and visualized on a large-scale 3D light field display. We present a method to efficiently interact with the visualized 3D map using freehand gestures. We use a Leap Motion sensor that supports sufficient refresh rate for our current application and is able to accurately track and acquire information on the user hand position. This information is further processed to support natural and fast interaction. We have also developed a method to automatically adjust the map's plane to the screen plane of the display. The visualization and interaction method is scalable and allows the exploration of large-scale 3D maps down to the street level.","cites":"2","conferencePercentile":"84.21052632"},{"venue":"3DTV-Conference","id":"6d06997bd96049bf28799eb401abf56c034c259b","venue_1":"3DTV-Conference","year":"2012","title":"Towards next generation 3D teleconferencing systems","authors":"Claudia Kuster, Nicola Ranieri, Agustina, Henning Zimmer, Jean Charles Bazin, Chengzheng Sun, Tiberiu Popa, Markus H. Gross","author_ids":"3346309, 2335103, 2702174, 1788459, 1745931, 1688131, 2822563, 1743207","abstract":"Teleconferencing is becoming more and more important and popular in today's society and is mostly accomplished using 2D video conferencing systems. However, we believe there is a lot of room for improving the communication experience: one crucial aspect is to add 3D information, but also freeing the user from sitting in front of a computer. With these improvements, we aim at eventually creating a fully immersive 3D telepresence system that might improve the way we communicate over long distances. In this paper we review and analyze existing technology to achieve this goal and present a proof-of-concept, but fully functional prototype. In our globalized world, people want to communicate with persons far away. Consequently, advanced communication and remote collaboration are a central pillar of our modern society, affecting both our private and work life. Classical means of remote communication are telephones and more recently video confer-encing systems like Skype. While video conferencing enhanced the communication experience by adding visual information, it still suffers from a number of shortcomings. First, users are required to sit in front of a computer or at least carry a smartphone or similar device. So it is tedious to roam around freely and using gestures is almost impossible although they are a vital part of human communication. Second, users do not make eye contact as they look into the screens instead of the cameras capturing them. Third, today's video conferencing is typically restricted to capture only the upper part of the human body and also does not provide any 3D information, but just 2D video. To solve above shortcomings, we aim to develop a communication system that seamlessly integrates the remote person in the environment of the other participants, resulting in a fully immer-sive 3D telepresence experience. To achieve this, we envision a mobile robot platform with a transparent auto-stereoscopic display and a 3D capture device; see Figure 1b. The latter captures full-body 3D information of the users. After applying a gaze correction algorithm to ensure eye contact, the 3D information is transmitted to the other platforms where it is eventually visualized in 3D on the autostereoscopic displays. This system would solve all mentioned problems as it is mobile, provides full body 3D information and also ensures eye contact. We believe that such a system has the potential to change the way people communicate. However, there are several perceptual and technical issues that need to be tackled. …","cites":"4","conferencePercentile":"86.95652174"}]}