{"AAAI.csv":[{"venue":"AAAI","id":"6693b6feeb8ff600fb7a17159a32b48e53b00b1b","venue_1":"AAAI","year":"2007","title":"Analyzing Reading Behavior by Blog Mining","authors":"Tadanobu Furukawa, Mitsuru Ishizuka, Yutaka Matsuo, Ikki Ohmukai, Koki Uchiyama","author_ids":"3088859, 1687719, 1692267, 1701584, 2200902","abstract":"This paper presents a study of the various aspects of blog reading behavior. The analyzed data are obtained from a Japanese weblog hosting service, Doblog. Four kinds of social networks are generated and analyzed: citation , comment, trackback, and blogroll networks. In addition, the user log data are used to identify readership relations among bloggers. After analysis of more than 50,000 users for about two years, we reveal some interactions between social relations and readership relations. We first show that bloggers read other weblogs on a regular basis (50% of weblogs that are read at least three times are read every five times a user logs in). We call this relation a regular reading relation (RR relation). Then, prediction of RR relations is done using features from the four kinds of social networks. Lastly, information diffusion on RR relations is analyzed and characterized. Results of this study show that the blogs in RR relations have an important role in bloggers' activities. We find the features which have a correlation with RR relations.","cites":"14","conferencePercentile":"62.31454006"},{"venue":"AAAI","id":"56485721404b277665a09ddaa0154629026d916e","venue_1":"AAAI","year":"2006","title":"Activity-Centric Email: A Machine Learning Approach","authors":"Nicholas Kushmerick, Tessa A. Lau, Mark Dredze, Rinat Khoussainov","author_ids":"8551365, 1800706, 1782853, 1752705","abstract":"Our use of ordinary desktop applications (such as email, Web, calendars) is often a manifestation of the activities with which we are engaged (Moran, Cozzi, & Farrell 2005). Planning a conference trip involves sending travel expense forms, and visits to airline and hotel sites. Renovating a kitchen involves sketches, product specifications, emails with the architect and spreadsheets for tracking expenses. Every enterprise has (often implicit) processes for managing customer queries, requesting maintenance, hiring a new employee, purchasing equipment, and so on. Unfortunately, ordinary desktop applications do not know anything about these activities. Within an enterprise, many activities have been formalized into business workflows such as hiring or ordering equipment. However, the way people interact with these workflows is often through email and desktop applications. If these applications are not aware of the activity context, people bear the burden of organizing their information into activities, typically using crude techniques such as manual search, file directories, and email folders/threads. Email has emerged as the primary tool for people to communicate about their work and manage activities. Motivated by the importance of email in conducting activities, we have recently developed several machine learning algorithms for automatically discovering and tracking activities in email. We observe that activities come in many forms, from struc-tured workflows to informal person-to-person communication. In this paper, we summarize our efforts to provide automated assistance with two types of activities: rigid struc-tured activities, and unstructured conversational activities. We first discuss highly structured activities such as e-commerce transactions. A consumer purchasing an item may receive email messages confirming the order, warning of a delay and then a shipment notification. Existing email clients do not understand this structure, so users must manage their transactions by sifting through lists of messages. As a step to providing high-level support for structured activities , we consider the problem of automatically learning an activity's structure. This structure could be used to support features such as notifying the user if an item failed to ship within an expected length of time. We formalize such structured activities as finite-state automata (where states correspond to the status of the process, and transitions represent messages sent between participants), and propose several unsupervised machine learning algorithms in this context. A paper describing this work was awarded honorable mention for best paper at the Conference on Intelligent User Interfaces (Kushmerick & Lau 2005). Second, we discuss less-structured activities such as organizing meetings …","cites":"7","conferencePercentile":"43.08357349"},{"venue":"AAAI","id":"4a79923948c6ccda965077287dc6fd1d3728d680","venue_1":"AAAI","year":"2014","title":"Dropout Training for Support Vector Machines","authors":"Ning Chen, Jun Zhu, Jianfei Chen, Bo Zhang","author_ids":"3524369, 1748711, 3268966, 1696318","abstract":"Dropout and other feature noising schemes have shown promising results in controlling over-fitting by artificially corrupting the training data. Though extensive theoretical and empirical studies have been performed for generalized linear models, little work has been done for support vector machines (SVMs), one of the most successful approaches for supervised learning. This paper presents dropout training for linear SVMs. To deal with the intractable expectation of the non-smooth hinge loss under corrupting distributions, we develop an iteratively re-weighted least square (IRLS) algorithm by exploring data augmentation techniques. Our algorithm iteratively minimizes the expectation of a re-weighted least square problem, where the re-weights have closed-form solutions. The similar ideas are applied to develop a new IRLS algorithm for the expected logistic loss under corrupting distributions. Our algorithms offer insights on the connection and difference between the hinge loss and logistic loss in dropout training. Empirical results on several real datasets demonstrate the effectiveness of dropout training on significantly boosting the classification accuracy of linear SVMs.","cites":"7","conferencePercentile":"77.5"},{"venue":"AAAI","id":"cb16f8a7e4b12c9bc058f07b92f498cd45ea2ef3","venue_1":"AAAI","year":"2010","title":"Local Search in Histogram Construction","authors":"Felix Halim, Panagiotis Karras, Roland H. C. Yap","author_ids":"2839854, 1731655, 1713932","abstract":"The problem of dividing a sequence of values into segments occurs in database systems, information retrieval, and knowledge management. The challenge is to select a finite number of boundaries for the segments so as to optimize an objective error function defined over those segments. Although this optimization problem can be solved in polynomial time, the algorithm which achieves the minimum error does not scale well, hence it is not practical for applications with massive data sets. There is considerable research with numerous approximation and heuristic algorithms. Still, none of those approaches has resolved the quality-efficiency tradeoff in a satisfactory manner. In (Halim, Karras, and Yap 2009), we obtain near linear time algorithms which achieve both the desired scalability and near-optimal quality, thus dominating earlier approaches. In this paper, we show how two ideas from artificial intelligence, an efficient local search and re-combination of multiple solutions reminiscent of genetic algorithms , are combined in a novel way to obtain state of the art histogram construction algorithms.","cites":"0","conferencePercentile":"3.754266212"},{"venue":"AAAI","id":"645656417aeb89f0d7a138d52cbbd6b13ee61c73","venue_1":"AAAI","year":"2007","title":"Search Space Reduction and Russian Doll Search","authors":"Kenil C. K. Cheng, Roland H. C. Yap","author_ids":"2695280, 1713932","abstract":"In a constraint optimization problem (COP), many feasible valuations lead to the same objective value. This often means a huge search space and poor performance in the propagation between the objective and problem variables. In this paper, we propose a different modeling and search strategy which focuses on the cost function. We show that by constructing a dual model on the objective variables, we can get strong propagation between the objective variables and the problem variables which allows search on the objective variables. We explain why and when searching on the objective variables can lead to large gains. We present a new Russian Doll Search algorithm, ORDS, which works on objective variables with dynamic variable ordering. Finally, we demonstrate using the hard Still-Life optimization problem the benefits of changing to the objective function model and ORDS.","cites":"3","conferencePercentile":"25.22255193"},{"venue":"AAAI","id":"2671ec16cda9c4ae9ad03e23e3e66df0a1b7c2c2","venue_1":"AAAI","year":"2006","title":"Spinning Multiple Social Networks for Semantic Web","authors":"Yutaka Matsuo, Masahiro Hamasaki, Yoshiyuki Nakamura, Takuichi Nishimura, Kôiti Hasida, Hideaki Takeda, Junichiro Mori, Danushka Bollegala, Mitsuru Ishizuka","author_ids":"1692267, 1783855, 2260588, 1765625, 1752952, 1696371, 7324514, 2720656, 1687719","abstract":"Social networks are important for the Semantic Web. Several means can be used to obtain social networks: using social networking services, aggregating Friend-of-a-Friend (FOAF) documents, mining text information on the Web or in e-mail messages, and observing face-to-face communication using sensors. Integrating multiple social networks is a key issue for further utilization of social networks in the Semantic Web. This paper describes our attempt to extract, analyze and integrate multiple social networks from the same community: user-registered knows networks, web-mined collaborator networks, and face-to-face meets networks. We operated a social network-based community support system called Polyphonet at the 17th, 18th and 19th Annual Conferences of the Japan Society of Artificial Intelligence (JSAI2003, JSAI2004, and JSAI2005) and at The International Conference on Ubiquitous Computing (UbiComp 2005). Multiple social networks were obtained and analyzed. We discuss the integration of multiple networks based on the analyses.","cites":"26","conferencePercentile":"74.49567723"},{"venue":"AAAI","id":"0a65858b985b70597f7707d497867730ca1d5c08","venue_1":"AAAI","year":"2005","title":"Constrained Decision Diagrams","authors":"Kenil C. K. Cheng, Roland H. C. Yap","author_ids":"2695280, 1713932","abstract":"A general n-ary constraint is usually represented explicitly as a set of its solution tuples, which may need exponential space. In this paper, we introduce a new representation for general n-ary constraints called Constrained Decision Diagram (CDD). CDD generalizes BDD-style representations and the main feature is that it combines constraint reason-ing/consistency techniques with a compact data structure. We present an application of CDD for recording all solutions of a conjunction of constraints. Instead of an explicit representation , we can implicitly encode the solutions by means of constraint propagation. Our experiments confirm the scala-bility and demonstrate that CDDs can drastically reduce the space needed over explicit and ZBDD representations.","cites":"12","conferencePercentile":"50.17482517"},{"venue":"AAAI","id":"be2a90765706473d075fb9b8a26afca10c59d372","venue_1":"AAAI","year":"2007","title":"Robust Estimation of Google Counts for Social Network Extraction","authors":"Yutaka Matsuo, Hironori Tomobe, Takuichi Nishimura","author_ids":"1692267, 2884208, 1765625","abstract":"Various studies within NLP and Semantic Web use the so-called Google count, which is the hit count on a query returned by a search engine (not only Google). However, sometimes the Google count is unreliable, especially when the count is large, or when advanced operators such as OR and NOT are used. In this paper, we propose a novel algorithm that estimates the Google count robustly. It (i) uses the co-occurrence of terms as evidence to estimate the occurrence of a given word, and (ii) integrates multiple evidence for robust estimation. We evaluated our algorithm for more than 2000 queries on three datasets using Google, Yahoo! and MSN search engine. Our algorithm also provides estimate counts for any classifier that judges a web page as positive or negative. Consequently, we can estimate the number of documents with included references of a particular person (among namesakes) on the entire web.","cites":"8","conferencePercentile":"46.29080119"},{"venue":"AAAI","id":"26f5544ffbb8ae35f77e7632f7578b19d13c8884","venue_1":"AAAI","year":"2008","title":"Generating Useful Network-based Features for Analyzing Social Networks","authors":"Jun Karamon, Yutaka Matsuo, Mitsuru Ishizuka","author_ids":"2142086, 1692267, 1687719","abstract":"Recently, many Web services such as social networking services, blogs, and collaborative tagging have become widely popular. Many attempts are being made to investigate user interactions by analyzing social networks among users. However, analyzing a social network with attributional data is often not an easy task because numerous ways exist to define features through aggregation of different tables. In this study, we propose an algorithm to identify important network-based features systematically from a given social network to analyze user behavior efficiently and to expand the services. We apply our method for link-based classification and link prediction tasks with two different datasets, i.e., an @cosme (an online viral marketing site) dataset and a Hatena Bookmark (collaborative tagging service) dataset, to demonstrate the usefulness of our algorithm. Our algorithm is general and can provide useful network-based features for social network analyses.","cites":"6","conferencePercentile":"41.4556962"},{"venue":"AAAI","id":"71214b3a60fb87b159b73f4f3a33bedbb5751cbf","venue_1":"AAAI","year":"2015","title":"SimSensei Demonstration: A Perceptive Virtual Human Interviewer for Healthcare Applications","authors":"Louis-Philippe Morency, Giota Stratou, David DeVault, Arno Hartholt, Margot Lhommet, Gale M. Lucas, Fabrizio Morbini, Kallirroi Georgila, Stefan Scherer, Jonathan Gratch, Stacy Marsella, David R. Traum, Albert A. Rizzo","author_ids":"1767184, 2624478, 8004024, 1705118, 1930380, 2419453, 2223582, 3194430, 1770312, 1730824, 1788771, 1784659, 1698877","abstract":"We present the SimSensei system, a fully automatic virtual agent that conducts interviews to assess indicators of psychological distress. We emphasize on the perception part of the system, a multimodal framework which captures and analyzes user state for both behavioral understanding and interactional purposes.","cites":"2","conferencePercentile":"51.65354331"},{"venue":"AAAI","id":"2b69f5611fd33a02e6106c416b1c08a4cf706fae","venue_1":"AAAI","year":"1994","title":"Model-Based Automated Generation of User Interfaces","authors":"Angel R. Puerta, Henrik Eriksson, John H. Gennari, Mark A. Musen","author_ids":"2810933, 7753658, 8626264, 8691132","abstract":"1 User interface design and development for knowledge-based systems and most other types of applications is a resource-consuming activity. Thus, many attempts have been made to automate, to certain degrees, the construction of user interfaces. Current tools for automated design of user interfaces are able to generate the static layout of an interface from the application's data model using an intelligent program that applies design rules. These tools, however, are not capable of generating the dynamic behavior of the interface, which must be specified programmatically, and which constitutes most of the effort of interface construction. Mecano is a model-based user-interface development environment that uses a domain model to generate both the static layout and the dynamic behavior of an interface. A knowledge-based system applies sets of dialog design and layout rules to produce interfaces from the domain model. Mecano has been used successfully to completely generate the layout and the dynamic behavior of relatively large and complex, domain-specific, form-and graph-based interfaces for applications in medicine and several other domains.","cites":"32","conferencePercentile":"73.34801762"},{"venue":"AAAI","id":"137125453565021b600531992dce3e1071f72fca","venue_1":"AAAI","year":"2007","title":"Relation Extraction from Wikipedia Using Subtree Mining","authors":"Dat P. T. Nguyen, Yutaka Matsuo, Mitsuru Ishizuka","author_ids":"2405021, 1692267, 1687719","abstract":"The exponential growth and reliability of Wikipedia have made it a promising data source for intelligent systems. The first challenge of Wikipedia is to make the encyclopedia machine-processable. In this study, we address the problem of extracting relations among entities from Wikipedia's En-glish articles, which in turn can serve for intelligent systems to satisfy users' information needs. Our proposed method first anchors the appearance of entities in Wikipedia articles using some heuristic rules that are supported by their encyclo-pedic style. Therefore, it uses neither the Named Entity Rec-ognizer (NER) nor the Coreference Resolution tool, which are sources of errors for relation extraction. It then classifies the relationships among entity pairs using SVM with features extracted from the web structure and subtrees mined from the syntactic structure of text. The innovations behind our work are the following: a) our method makes use of Wikipedia characteristics for entity allocation and entity classification, which are essential for relation extraction; b) our algorithm extracts a core tree, which accurately reflects a relationship between a given entity pair, and subsequently identifies key features with respect to the relationship from the core tree. We demonstrate the effectiveness of our approach through evaluation of manually annotated data from actual Wikipedia articles.","cites":"47","conferencePercentile":"89.91097923"},{"venue":"AAAI","id":"b8f8980efb2684ba2a0b7ddf8ea88a9fe09f2ade","venue_1":"AAAI","year":"2015","title":"Predicting the Demographics of Twitter Users from Website Traffic Data","authors":"Aron Culotta, Nirmal Ravi Kumar, Jennifer Cutler","author_ids":"1741453, 6483664, 3023372","abstract":"Understanding the demographics of users of online social networks has important applications for health, marketing, and public messaging. In this paper, we predict the demographics of Twitter users based on whom they follow. Whereas most prior approaches rely on a supervised learning approach, in which individual users are labeled with demographics, we instead create a distantly labeled dataset by collecting audience measurement data for 1,500 websites (e.g., 50% of visitors to gizmodo.com are estimated to have a bachelor's degree). We then fit a regression model to predict these demographics using information about the followers of each website on Twitter. The resulting average held-out correlation is .77 across six different variables (gender , age, ethnicity, education, income, and child status). We additionally validate the model on a smaller set of Twitter users labeled individually for ethnicity and gender , finding performance that is surprisingly competitive with a fully supervised approach.","cites":"19","conferencePercentile":"97.79527559"},{"venue":"AAAI","id":"f1fa5fd58b643d7eb362de42e1e946750d20cbe9","venue_1":"AAAI","year":"2016","title":"Understanding City Traffic Dynamics Utilizing Sensor and Textual Observations","authors":"Pramod Anantharam, Krishnaprasad Thirunarayan, Surendra Marupudi, Amit P. Sheth, Tanvi Banerjee","author_ids":"2446751, 3195814, 2569135, 1709950, 2482676","abstract":"Understanding speed and travel-time dynamics in response to various city related events is an important and challenging problem. Sensor data (numerical) containing average speed of vehicles passing through a road segment can be interpreted in terms of near real-time report of traffic related incidents from city authorities and social media data (textual), providing a complementary understanding of traffic dynamics. State-of-the-art research is focused on either analyzing sensor observations or citizen observations; we seek to exploit both in a synergistic manner. We demonstrate the role of domain knowledge in capturing the non-linearity of speed and travel-time dynamics by segmenting speed and travel-time observations into simpler components amenable to description using linear models such as Linear Dynamical System (LDS). Specifically, we propose Restricted Switching Linear Dynamical System (RSLDS) to model normal speed and travel time dynamics and thereby characterize anomalous dynamics. We utilize the city traffic events extracted from text to explain anomalous dynamics. We present a large scale evaluation of the proposed approach on a real-world traffic and twitter dataset collected over a year with promising results.","cites":"1","conferencePercentile":"40.70945946"},{"venue":"AAAI","id":"0254e5a1e4981f18d07b3ed2f957a14709eac3d1","venue_1":"AAAI","year":"2015","title":"A Planning-Based Assistance System for Setting Up a Home Theater","authors":"Pascal Bercher, Felix Richter, Thilo Hoernle, Thomas Geier, Daniel Höller, Gregor Behnke, Florian Nothdurft, Frank Honold, Wolfgang Minker, Michael Weber, Susanne Biundo-Stephan","author_ids":"1961287, 1682120, 3257635, 1750390, 2362304, 2964152, 3187780, 1692306, 1720942, 1693292, 3270041","abstract":"Modern technical devices are often too complex for many users to be able to use them to their full extent. Based on planning technology, we are able to provide advanced user assistance for operating technical devices. We present a system that assists a human user in setting up a complex home theater consisting of several HiFi devices. For a human user, the task is rather challenging due to a large number of different ports of the devices and the variety of available cables. The system supports the user by giving detailed instructions how to assemble the theater. Its performance is based on advanced user-centered planning capabilities including the generation, repair, and explanation of plans.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"9066c710effdb312a294d26fe698ef37730c6357","venue_1":"AAAI","year":"2008","title":"User Identification by Means of Sketched Stroke Features","authors":"Brian Eoff, Tracy Anne Hammond","author_ids":"2130169, 2662321","abstract":"We present preliminary results of using physical features of a user's sketching style, such as pen tilt and pressure, to identify a user from their sketched strokes.","cites":"0","conferencePercentile":"7.120253165"},{"venue":"AAAI","id":"417f51169edbeb4af7adcdfe5dc24eda856e959c","venue_1":"AAAI","year":"2008","title":"Eliminating False Positives during Corner Finding by Merging Similar Segments","authors":"Aaron Wolin, Brandon Paulson, Tracy Anne Hammond","author_ids":"2697823, 2276485, 2662321","abstract":"We present a new corner finding algorithm based on merging like stroke segmentations together in order to eliminate false positive corners. We compare our system to two benchmark corner finders with substantial improvements in both polyline and complex fits. Sketch recognition is an emerging field that utilizes pen-based interaction with computers. Handwriting recognition software in the modern operating systems allows users to write naturally, and applications have been created to recognize sketches in domains such as UML diagrams (Hammond & Davis 2002) and family trees (Alvarado & Davis 2004). In an attempt to perform free-sketch recognition, which allows users to draw as they would naturally without training or being trained by the system, certain geometric sketch recognition systems require a shape to be defined by a set of primitives (Hammond & Davis 2007). Individual strokes can be classified as primitive shapes using Paulson (Paulson & Hammond 2008). However, we would like to allow users to draw multiple primitives in a continuous stroke as they would naturally. Corner detection allows a user to draw in their own style while still allowing a user's drawn shapes to benefit from sketch recognition systems that rely on primitives. In a corner detection system, algorithms automatically break a user's drawn stroke into primitive lines and arcs. This task can be completed during stroke preprocessing, and the resulting primitives can then be sent to a geometric recognizer for stroke classification. We propose MergeCF, a corner detection algorithm that utilizes the stroke's curvature and the user's drawing pen speed in order to find the corners of a stroke. MergeCF then eliminates false positives by removing similar corners, merging like stroke segments together, and examining stroke segments' direction values. Our corner finder is powerful and improves upon current state-of-the-art techniques using two different accuracy measures. Implementation MergeCF utilizes curvature and speed differences within a stroke to obtain an initial corner segmentation for our stroke. We then repeatedly merge smaller stroke segments with longer segments, and, if the fit for the merged segment is below a certain threshold, we eliminate the corner between the two segments. Our curvature and speed values are based on the equations given by (Stahovich 2004). The chord length between two points is the euclidean distance between the points, and the path length across a series of points p a , p a+1 ,. .. , p b is taken to be the sum of …","cites":"0","conferencePercentile":"7.120253165"},{"venue":"AAAI","id":"e3ea0f53085106604364062894c7bb26bb013df2","venue_1":"AAAI","year":"2008","title":"GLADDER: Combining Gesture and Geometric Sketch Recognition","authors":"Paul Corey, Tracy Anne Hammond","author_ids":"2744644, 2662321","abstract":"Sketch recognition systems usually recognize strokes either as stylistic gestures or geometric shapes. Both techniques have their advantages. This paper presents a method for integrating gesture-based and geometric recognition techniques, significantly outperforming either technique on its own.","cites":"3","conferencePercentile":"28.16455696"},{"venue":"AAAI","id":"028e30472714b8ed97d8c337d92bb092a9dcb4e5","venue_1":"AAAI","year":"2014","title":"Learning Temporal Dynamics of Behavior Propagation in Social Networks","authors":"Jun Zhang, Chaokun Wang, Jianmin Wang","author_ids":"1752214, 8205851, 1751179","abstract":"Social influence has been widely accepted to explain people's cascade behaviors and further utilized in many related applications. However, few of existing work studied the direct, microscopic and temporal impact of social influence on people's behaviors in detail. In this paper we concentrate on the behavior modeling and systematically formulate the family of behavior propagation models (BPMs) including the static models (BP and IBP), and their discrete temporal variants (DBP and DIBP). To address the temporal dynamics of behavior propagation over continuous time, we propose a continuous temporal interest-aware behavior propagation model, called CIBP. As a new member of the BPM family , CIBP exploits the continuous-temporal functions (CTFs) to model the fully-continuous dynamic variance of social influence over time. Experiments on real-world datasets evaluated the family of BPMs and demonstrated the effectiveness of our proposed approach. The society is such highly-connected that our behaviors will inevitably affect and meanwhile be affected by others around us (Kelman 1958). The social influence works in either an implicit way via influencing one's interests and emotions, or an explicit way via propagating behaviors from one to another. As shown in the literature, individuals usually have incentives to directly adopt the behaviors of their neighbors in the network (Easley and Kleinberg 2010). We refer to such phenomenon under the explicit and direct social influence as behavior propagation. The behavior propagations are fundamental for the famous viral marketing (Subramani and Rajagopalan 2003) which promotes products via word-of-mouth recommendation and expects to cause cascade adoption behaviors. Lu, and Zhang 2012) focused on the optimal design of marketing strategies by selecting most influential seed users effectively and efficiently based on the given social network, but didn't study the modeling of propagation-driven behaviors. In our previous work (Zhang et al. 2013b; 2013c), we have studied the direct impact of social influence on peo-ple's friend-making behaviors in terms of friendship propagation , and proposed cascade (discrete) approaches to mod-eling the temporal behaviors by discretizing the continuous time. However, the network is always evolving and the social influence is continuously changing. Discrete approaches are unable to capture the continuous dynamics due to its discrete nature. Thus, an interesting and challenging question is: Can we depict and learn the fully-continuous temporal dynamics of social influence for behavior propagation? In this work, we generalize our previous work and formulate the family of behavior propagation models. More importantly , we address the problem …","cites":"2","conferencePercentile":"38.63636364"},{"venue":"AAAI","id":"71f4460dd5c8afcc3186a08dad3257096e020653","venue_1":"AAAI","year":"2008","title":"Distinguishing between Sketched Scribble Look Alikes","authors":"Katie Dahmen, Tracy Anne Hammond","author_ids":"2650710, 2662321","abstract":"In hand-sketched drawings, nearly identical strokes may have different meanings to a user. For instance, a scribble could signify either that a shape should be filled in or that it should be deleted. This work describes a method for determining user intention in drawing scribbles in the context of a pen-based computer sketch. Our study shows that given two strokes, a circle and a scribble, two features (bounding ratio and density) can quickly and effectively determine a user's intention.","cites":"2","conferencePercentile":"23.41772152"},{"venue":"AAAI","id":"9adb9b8bb48de0153239d4ac138d01cd8bc7e176","venue_1":"AAAI","year":"2012","title":"Mobile Robot Planning to Seek Help with Spatially-Situated Tasks","authors":"Stephanie Rosenthal, Manuela M. Veloso","author_ids":"1742107, 1703940","abstract":"Indoor autonomous mobile service robots can overcome their hardware and potential algorithmic limitations by asking humans for help. In this work, we focus on mobile robots that need human assistance at specific spatially-situated locations (e.g., to push buttons in an elevator or to make coffee in the kitchen). We address the problem of what the robot should do when there are no humans present at such help locations. As the robots are mobile, we argue that they should plan to proac-tively seek help and travel to offices or occupied locations to bring people to the help locations. Such planning involves many trade-offs, including the wait time at the help location before seeking help, and the time and potential interruption to find and displace someone in an office. In order to choose appropriate parameters to represent such decisions, we first conduct a survey to understand potential helpers' travel preferences in terms of distance, interruptibility, and frequency of providing help. We then use these results to contribute a decision-theoretic algorithm to evaluate the possible choices in offices and plan where to proactively seek help. We demonstrate that our algorithm aims to minimize the number of office interruptions as well as task completion time.","cites":"18","conferencePercentile":"86.73780488"},{"venue":"AAAI","id":"99d73437f096a2890e496b33565b731683e2702b","venue_1":"AAAI","year":"2011","title":"Learning Accuracy and Availability of Humans Who Help Mobile Robots","authors":"Stephanie Rosenthal, Manuela M. Veloso, Anind K. Dey","author_ids":"1742107, 1703940, 1703700","abstract":"When mobile robots perform tasks in environments with humans, it seems appropriate for the robots to rely on such humans for help instead of dedicated human oracles or supervisors. However, these humans are not always available nor always accurate. In this work, we consider human help to a robot as concretely providing observations about the robot's state to reduce state uncertainty as it executes its policy autonomously. We model the probability of receiving an observation from a human in terms of their availability and accuracy by introducing Human Observation Providers POMDPs (HOP-POMDPs). We contribute an algorithm to learn human availability and accuracy online while the robot is executing its current task policy. We demonstrate that our algorithm is effective in approximating the true availability and accuracy of humans without depending on oracles to learn, thus increasing the tractability of deploying a robot that can occasionally ask for help.","cites":"18","conferencePercentile":"82.98969072"},{"venue":"AAAI","id":"b9d8173c4a3eba884bc812540fd3e4bc39cb603a","venue_1":"AAAI","year":"2008","title":"Sketch Recognition Based on Manifold Learning","authors":"Heeyoul Choi, Tracy Anne Hammond","author_ids":"1685900, 2662321","abstract":"Current feature-based methods for sketch recognition systems rely on human-selected features. Certain machine learning techniques have been found to be good nonlinear features extractors. In this paper, we apply a manifold learning method, kernel Isomap, with a new algorithm for multi-stroke sketch recognition, which significantly outperforms the standard feature-based techniques.","cites":"0","conferencePercentile":"7.120253165"},{"venue":"AAAI","id":"3edb9f88724113e051bd3f12b2a86fbd7767e1a9","venue_1":"AAAI","year":"2005","title":"Data-Driven MCMC for Learning and Inference in Switching Linear Dynamic Systems","authors":"Sang Min Oh, James M. Rehg, Tucker R. Balch, Frank Dellaert","author_ids":"2555193, 1692956, 2787209, 2038264","abstract":"Switching Linear Dynamic System (SLDS) models are a popular technique for modeling complex nonlinear dynamic systems. An SLDS has significantly more descriptive power than an HMM, but inference in SLDS models is computationally intractable. This paper describes a novel inference algorithm for SLDS models based on the Data-Driven MCMC paradigm. We describe a new proposal distribution which substantially increases the convergence speed. Comparisons to standard deterministic approximation methods demonstrate the improved accuracy of our new approach. We apply our approach to the problem of learning an SLDS model of the bee dance. Honeybees communicate the location and distance to food sources through a dance that takes place within the hive. We learn SLDS model parameters from tracking data which is automatically extracted from video. We then demonstrate the ability to successfully segment novel bee dances into their constituent parts, effectively decoding the dance of the bees.","cites":"22","conferencePercentile":"71.15384615"},{"venue":"AAAI","id":"daf30e6709631aba291e8084fad853db325594e8","venue_1":"AAAI","year":"2015","title":"Learning Face Hallucination in the Wild","authors":"Erjin Zhou, Haoqiang Fan, Zhimin Cao, Yuning Jiang, Qi Yin","author_ids":"1848243, 1934546, 8538782, 1691963, 7477615","abstract":"Face hallucination method is proposed to generate high-resolution images from low-resolution ones for better visualization. However, conventional hallucination methods are often designed for controlled settings and cannot handle varying conditions of pose, resolution degree , and blur. In this paper, we present a new method of face hallucination, which can consistently improve the resolution of face images even with large appearance variations. Our method is based on a novel network architecture called Bi-channel Convolutional Neu-ral Network (Bi-channel CNN). It extracts robust face representations from raw input by using deep convolu-tional network, then adaptively integrates two channels of information (the raw input image and face representations) to predict the high-resolution image. Experimental results show our system outperforms the prior state-of-the-art methods.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"a7cb7de7329f1145626a3689349ce92e54f81756","venue_1":"AAAI","year":"2015","title":"FACES: Diversity-Aware Entity Summarization Using Incremental Hierarchical Conceptual Clustering","authors":"Kalpa Gunaratna, Krishnaprasad Thirunarayan, Amit P. Sheth","author_ids":"1755867, 3195814, 1709950","abstract":"Semantic Web documents that encode facts about entities on the Web have been growing rapidly in size and evolving over time. Creating summaries on lengthy Semantic Web documents for quick identification of the corresponding entity has been of great contemporary interest. In this paper, we explore automatic summa-rization techniques that characterize and enable identification of an entity and create summaries that are human friendly. Specifically, we highlight the importance of diversified (faceted) summaries by combining three dimensions: diversity, uniqueness, and popularity. Our novel diversity-aware entity summarization approach mimics human conceptual clustering techniques to group facts, and picks representative facts from each group to form concise (i.e., short) and comprehensive (i.e., improved coverage through diversity) summaries. We evaluate our approach against the state-of-the-art techniques and show that our work improves both the quality and the efficiency of entity summarization.","cites":"4","conferencePercentile":"73.46456693"},{"venue":"AAAI","id":"c8fb41282abe1787071ff7fb64909415ed830477","venue_1":"AAAI","year":"2011","title":"Recognizing Text Through Sound Alone","authors":"Wenzhe Li, Tracy Anne Hammond","author_ids":"2752207, 2662321","abstract":"This paper presents an acoustic sound recognizer to recognize what people are writing on a table or wall by utilizing the sound signal information generated from a key, pen, or fingernail moving along a textured surface. Sketching provides a natural modality to interact with text, and sound is an effective modality for distinguishing text. However, limited research has been conducted in this area. Our system uses a dynamic time-warping approach to recognize 26 hand-sketched characters (A-Z) solely through their acoustic signal. Our initial prototype system is user-dependent and relies on fixed stroke ordering. Our algorithm relied mainly on two features: mean amplitude and MFCCs (Mel-frequency cepstral coefficients). Our results showed over 80% recognition accuracy.","cites":"1","conferencePercentile":"16.15120275"},{"venue":"AAAI","id":"cb0d7fb034d9c0542521682cdeb1d49d959c776a","venue_1":"AAAI","year":"1992","title":"When Should a Cheetah Remind You of a Bat? Reminding in Case-Based Teaching","authors":"Daniel C. Edelson","author_ids":"1783780","abstract":"Case-based teaching systems, like good human teachers, tell stories in order to help students learn. A case-based teaching system engages a student i n a c hallenging task and monitors his actions looking for opportunities to tell stories that will assist the learning process. In order to produce stories at the appropriate moment, a case-based teaching system must have a library of stories that are indexed according to how they should be used and a set of reminding strategies to retrieve stories when they are relevant. In this paper , I discuss CreANIMate, a biology tutor that uses stories to help teach elementary school students about animal morphology. In particular, I discuss the reminding strategies and indexing schemes that enable the system to achieve its educational objectives. These reminding strategies are example remindings, similarity-based r emind-ings, and expectation violation remindings.","cites":"7","conferencePercentile":"7.142857143"},{"venue":"AAAI","id":"0cf6baf97bdedd95d0748f6330cc5b51dea931b0","venue_1":"AAAI","year":"2004","title":"Interactive Information Extraction with Constrained Conditional Random Fields","authors":"Trausti T. Kristjansson, Aron Culotta, Paul A. Viola, Andrew McCallum","author_ids":"2769671, 1741453, 1731948, 8725751","abstract":"Information Extraction methods can be used to automatically \" fill-in \" database forms from unstructured data such as Web documents or email. State-of-the-art methods have achieved low error rates but invariably make a number of errors. The goal of an interactive information extraction system is to assist the user in filling in database fields while giving the user confidence in the integrity of the data. The user is presented with an interactive interface that allows both the rapid verification of automatic field assignments and the correction of errors. In cases where there are multiple errors, our system takes into account user corrections, and immediately propagates these constraints such that other fields are often corrected automatically. Linear-chain conditional random fields (CRFs) have been shown to perform well for information extraction and other language modelling tasks due to their ability to capture arbitrary, overlapping features of the input in a Markov model. We apply this framework with two extensions: a constrained Viterbi decoding which finds the optimal field assignments consistent with the fields explicitly specified or corrected by the user; and a mechanism for estimating the confidence of each extracted field, so that low-confidence extractions can be highlighted. Both of these mechanisms are incorporated in a novel user interface for form filling that is intuitive and speeds the entry of data—providing a 23% reduction in error due to automated corrections.","cites":"92","conferencePercentile":"95.50898204"},{"venue":"AAAI","id":"035fd812961f3694d46c48165ed97a2ce48833ff","venue_1":"AAAI","year":"2005","title":"Reducing Labeling Effort for Structured Prediction Tasks","authors":"Aron Culotta, Andrew McCallum","author_ids":"1741453, 8725751","abstract":"A common obstacle preventing the rapid deployment of supervised machine learning algorithms is the lack of labeled training data. This is particularly expensive to obtain for structured prediction tasks, where each training instance may have multiple, interacting labels, all of which must be correctly annotated for the instance to be of use to the learner. Traditional active learning addresses this problem by optimizing the order in which the examples are labeled to increase learning efficiency. However, this approach does not consider the difficulty of labeling each example, which can vary widely in structured prediction tasks. For example, the labeling predicted by a partially trained system may be easier to correct for some instances than for others. We propose a new active learning paradigm which reduces not only how many instances the annotator must label, but also how difficult each instance is to annotate. The system leverages information from partially correct predictions to efficiently solicit annotations from the user. We validate this active learning framework in an interactive information extraction system, reducing the total number of annotation actions by 22%.","cites":"77","conferencePercentile":"96.5034965"},{"venue":"AAAI","id":"48d1305fe5461d18914165b7f2c5302bf05d41c9","venue_1":"AAAI","year":"2014","title":"Anytime Active Learning","authors":"Maria Eugenia Ramirez-Loaiza, Aron Culotta, Mustafa Bilgic","author_ids":"3153061, 1741453, 2696727","abstract":"A common bottleneck in deploying supervised learning systems is collecting human-annotated examples. In many domains, annotators form an opinion about the label of an example incrementally — e.g., each additional word read from a document or each additional minute spent inspecting a video helps inform the annotation. In this paper, we investigate whether we can train learning systems more efficiently by requesting an annotation before inspection is fully complete — e.g., after reading only 25 words of a document. While doing so may reduce the overall annotation time, it also introduces the risk that the annotator might not be able to provide a label if interrupted too early. We propose an anytime active learning approach that optimizes the annotation time and response rate simultaneously. We conduct user studies on two document classification datasets and develop simulated annotators that mimic the users. Our simulated experiments show that anytime active learning outperforms several baselines on these two datasets. For example, with an annotation budget of one hour, training a classifier by annotating the first 25 words of each document reduces classification error by 17% over annotating the first 100 words of each document.","cites":"5","conferencePercentile":"67.5"},{"venue":"AAAI","id":"368064c7c072ac5df0358de9608c42c7fda45013","venue_1":"AAAI","year":"2016","title":"The Ostomachion Process","authors":"Xuhui Fan, Bin Li, Yi Wang, Yang Wang, Fang Chen","author_ids":"2157773, 1740979, 1737720, 1747927, 3991227","abstract":"Stochastic partition processes for exchangeable graphs produce axis-aligned blocks on a product space. In relational modeling, the resulting blocks uncover the underlying interactions between two sets of entities of the relational data. Although some flexible axis-aligned partition processes, such as the Mondrian process, have been able to capture complex interacting patterns in a hierarchical fashion, they are still in short of capturing dependence between dimensions. To overcome this limitation, we propose the Ostomachion process (OP), which relaxes the cutting direction by allowing for oblique cuts. The partitions generated by an OP are convex polygons that can capture inter-dimensional dependence. The OP also exhibits interesting properties: 1) Along the time line the cutting times can be characterized by a homogeneous Poisson process, and 2) on the partition space the areas of the resulting components comply with a Dirichlet distribution. We can thus control the expected number of cuts and the expected areas of components through hyper-parameters. We adapt the reversible-jump MCMC algorithm for inferring OP partition structures. The experimental results on relational modeling and decision tree classification have validated the merit of the OP.","cites":"2","conferencePercentile":"61.31756757"},{"venue":"AAAI","id":"c9ec8556d256d4c98ee36e4f71a6f041c3ba79a7","venue_1":"AAAI","year":"2015","title":"Using Matched Samples to Estimate the Effects of Exercise on Mental Health via Twitter","authors":"Virgile Landeiro Dos Reis, Aron Culotta","author_ids":"1817073, 1741453","abstract":"Recent work has demonstrated the value of social media monitoring for health surveillance (e.g., tracking influenza or depression rates). It is an open question whether such data can be used to make causal inferences (e.g., determining which activities lead to increased depression rates). Even in traditional, restricted domains, estimating causal effects from observational data is highly susceptible to confounding bias. In this work, we estimate the effect of exercise on mental health from Twitter, relying on statistical matching methods to reduce confounding bias. We train a text classifier to estimate the volume of a user's tweets expressing anxiety, depression, or anger, then compare two groups: those who exercise regularly (identified by their use of physical activity trackers like Nike+), and a matched control group. We find that those who exercise regularly have significantly fewer tweets expressing depression or anxiety ; there is no significant difference in rates of tweets expressing anger. We additionally perform a sensitivity analysis to investigate how the many experimental design choices in such a study impact the final conclusions , including the quality of the classifier and the construction of the control group.","cites":"8","conferencePercentile":"90.23622047"},{"venue":"AAAI","id":"325c61255539abf1e53fb5774aeed724e22980f2","venue_1":"AAAI","year":"2016","title":"Robust Text Classification in the Presence of Confounding Bias","authors":"Virgile Landeiro Dos Reis, Aron Culotta","author_ids":"1817073, 1741453","abstract":"As text classifiers become increasingly used in real-time applications, it is critical to consider not only their accuracy but also their robustness to changes in the data distribution. In this paper, we consider the case where there is a confounding variable Z that influences both the text features X and the class variable Y. For example , a classifier trained to predict the health status of a user based on their online communications may be confounded by socioeconomic variables. When the influence of Z changes from training to testing data, we find that classifier accuracy can degrade rapidly. Our approach, based on Pearl's back-door adjustment, estimates the underlying effect of a text variable on the class variable while controlling for the confounding variable. Although our goal is prediction, not causal inference, we find that such adjustments are essential to building text classifiers that are robust to confounding variables. On three diverse text classifications tasks, we find that covariate adjustment results in higher accuracy than competing baselines over a range of confounding relationships (e.g., in one setting, accuracy improves from 60% to 81%).","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"a81f9bf8f8f90b13cc43b3591f8affeb64eab241","venue_1":"AAAI","year":"2004","title":"Centibots: Very Large Scale Distributed Robotic Teams","authors":"Charlie Ortiz, Kurt Konolige, Régis Vincent, Benoit Morisset, Andrew Agno, Michael Eriksen, Dieter Fox, Benson Limketkai, Jonathan Ko, Benjamin Stewart, Dirk Schulz","author_ids":"2717129, 1781188, 1803044, 2480475, 2048974, 7016858, 1776234, 2215820, 2019511, 2678473, 5762226","abstract":"1 100 Robots We describe the development of Centibots, a framework for very large teams of robots that are able to perceive, explore, plan and collaborate in unknown environments. The Centibots team currently consist of approximately 100 robots (Figure 1). The Centibots team can be deployed in unexplored areas, and can efficiently distribute tasks among themselves; the system also makes use of a mixed initiative mode of interaction in which a user can influence missions as necessary. In contrast to simulation-based systems which abstract away aspects of the environment for the purposes of exploring component technologies, the Centibots design reflects an integrated end-to-end system. Fig. 1. 100 robots. Four of the robots are Pioneer IIs with SICK laser range-finders. The rest are Amigo-bots with sonars, a camera and a small PC on top. The OOI is in the hand of one of the authors. As part of DARPA's Software for Distributed Robotics (SDR) project, the Centibots were tested on a mapping and search mission in a new, unknown environment. This experiment involved deployment of Centibots in three successive stages: (1) a mapping stage for the coordinated exploration of the environment while simultaneously constructing a very high accuracy occupancy map using a laser range finder; (2) a search stage in which the environment is exhaustively searched for a predefined object of interest (OOI), chosen so that it could be easily distinguished within the environment by its shape and its color; and (3) an intruder detection stage in which robots are distributed throughout the environment to \" guard \" the OOI by continuously searching the environment for human intruders. This stage included recharging a portion of the robots to prove the system could continue indefinitely. Previous work has largely focused on isolated aspects of our system, including multi-robot exploration [1], architecture [3], task allocation [12], coordination [9],","cites":"53","conferencePercentile":"88.0239521"},{"venue":"AAAI","id":"39eee32985bb98bd61123b04f8db2774e9dae1aa","venue_1":"AAAI","year":"2013","title":"Compact RGBD Surface Models Based on Sparse Coding","authors":"Michael Ruhnke, Liefeng Bo, Dieter Fox, Wolfram Burgard","author_ids":"1867451, 1766509, 1776234, 1725973","abstract":"In this paper, we describe a novel approach to construct compact colored 3D environment models representing local surface attributes via sparse coding. Our method decomposes a set of colored point clouds into local surface patches and encodes them based on an overcomplete dictionary. Instead of storing the entire point cloud, we store a dictionary, surface patch positions, and a sparse code description of the depth and RGB attributes for every patch. The dictionary is learned in an unsupervised way from surface patches sampled from indoor maps. We show that better dictionaries can be learned by extending the K-SVD method with a binary weighting scheme that ignores undefined surface cells. Through experimental evaluation on real world laser and RGBD datasets we demonstrate that our method produces compact and accurate models. Furthermore, we clearly outperform an existing state of the art method in terms of compactness, accuracy, and computation time. Additionally, we demonstrate that our sparse code descriptions can be utilized for other important tasks such as object detection.","cites":"3","conferencePercentile":"47.09090909"},{"venue":"AAAI","id":"1818bdee5bb946207b51a434e734fe60eacb9688","venue_1":"AAAI","year":"2016","title":"Collective Supervision of Topic Models for Predicting Surveys with Social Media","authors":"Adrian Benton, Michael J. Paul, Braden Hancock, Mark Dredze","author_ids":"2929905, 3319930, 2812237, 1782853","abstract":"This paper considers survey prediction from social media. We use topic models to correlate social media messages with survey outcomes and to provide an inter-pretable representation of the data. Rather than rely on fully unsupervised topic models, we use existing aggre-gated survey data to inform the inferred topics, a class of topic model supervision referred to as collective supervision. We introduce and explore a variety of topic model variants and provide an empirical analysis, with conclusions of the most effective models for this task.","cites":"3","conferencePercentile":"72.63513514"},{"venue":"AAAI","id":"fb1c8ad813be715309b00b7f52dd4351ebc7e3f6","venue_1":"AAAI","year":"2008","title":"Intelligent Email: Aiding Users with AI","authors":"Mark Dredze, Hanna M. Wallach, Danny Puller, Tova Brooks, Josh Carroll, Joshua Magarick, John Blitzer, Fernando Pereira","author_ids":"1782853, 3151858, 2349546, 2651547, 2885794, 2444766, 2116927, 1685287","abstract":"Intelligent Email Email occupies a central role in the modern workplace. This has led to a vast increase in the number of email messages that users are expected to handle daily. Furthermore , email is no longer simply a tool for asynchronous online communication—email is now used for task management , personal archiving, as well both synchronous and asynchronous online communication (Whittaker and Sidner 1996). This explosion can lead to \" email overload \" —many users are overwhelmed by the large quantity of information in their mailboxes. In the human–computer interaction community, there has been much research on tackling email overload. Recently, similar efforts have emerged in the artificial intelligence (AI) and machine learning communities to form an area of research known as intelligent email. In this paper, we take a user-oriented approach to applying AI to email. We identify enhancements to email user interfaces and employ machine learning techniques to support these changes. We focus on three tasks—summary keyword generation, reply prediction and attachment prediction—and summarize recent work in these areas. Email inboxes typically display a limited amount of information about each email, usually the subject, sender and date. Users are then expected to perform email triage— the process of making decisions about how to handle these emails—based on this information. In practice, such limited information is often insufficient to perform good triage and can lead to missed messages or wasted time. Additional concise and relevant information about each message can speed up the decision-making process and reduce errors. Muresan, Tzoukermann, and Klavans (2001) introduced the task of keyword summarization, where keywords that convey the gist of an email in just a few words are generated for each email message. The user can quickly glance at these email summary keywords when checking the subject and sender information for each message. Muresan, Tzouk-ermann, and Klavans used a two-stage supervised learning system to generate summary keywords. Unfortunately, supervised learning techniques rely on the availability of large numbers of user-specific annotated emails for training. In contrast, we use an unsupervised approach based on latent concept models of a user's mailbox (Dredze et al. 2008b). This requires no annotated training data and generates keywords that describe each message in the context of other related messages in the user's mailbox. The key insight behind our approach is that a good summary keyword for an email message is not simply a word unique to that …","cites":"8","conferencePercentile":"49.52531646"},{"venue":"AAAI","id":"b17dac00377a97a486a0467749e7fad9212de1fc","venue_1":"AAAI","year":"2004","title":"On the Relationship between Lexical Semantics and Syntax for the Inference of Context-Free Grammars","authors":"Tim Oates, Tom Armstrong, Justin Harris, Mark Nejman","author_ids":"1756624, 2749754, 3332253, 2976722","abstract":"Context-free grammars cannot be identified in the limit from positive examples (Gold 1967), yet natural language grammars are more powerful than context-free grammars and humans learn them with remarkable ease from positive examples (Marcus 1993). Identifiability results for formal languages ignore a potentially powerful source of information available to learners of natural languages, namely, meanings. This paper explores the learnability of syntax (i.e. context-free grammars) given positive examples and knowledge of lexical semantics, and the learnability of lexical semantics given knowledge of syntax. The long-term goal is to develop an approach to learning both syntax and semantics that boot-straps itself, using limited knowledge about syntax to infer additional knowledge about semantics, and limited knowledge about semantics to infer additional knowledge about syntax.","cites":"4","conferencePercentile":"31.13772455"},{"venue":"AAAI","id":"6d25cf4c4d41a3c65bffc869486beab82b51ef73","venue_1":"AAAI","year":"2012","title":"Approximately Revenue-Maximizing Auctions for Deliberative Agents","authors":"L. Elisa Celis, Anna R. Karlin, Kevin Leyton-Brown, C. Thach Nguyen, David Robert Martin Thompson","author_ids":"3246450, 1693265, 2360288, 2819496, 7182485","abstract":"In many real-world auctions, a bidder does not know her exact value for an item, but can perform a costly deliberation to reduce her uncertainty. Relatively little is known about such deliberative environments, which are fundamentally different from classical auction environments. In this paper, we propose a new approach that allows us to leverage classical revenue-maximization results in de-liberative environments. In particular, we use Myerson (1981) to construct the first non-trivial (i.e., dependent on deliberation costs) upper bound on revenue in delib-erative auctions. This bound allows us to apply existing results in the classical environment to a deliberative environment. In addition, we show that in many delib-erative environments the only optimal dominant strategy mechanisms take the form of sequential posted price auctions.","cites":"4","conferencePercentile":"39.17682927"},{"venue":"AAAI","id":"5d9aab77ed0148b31153a5e38ad848e4f3f20cf2","venue_1":"AAAI","year":"2006","title":"Decision Making in Uncertain Real-World Domains Using DT-Golog","authors":"Mikhail Soutchanski, Huy Pham, John Mylopoulos","author_ids":"3141928, 3157723, 1750566","abstract":"DTGolog, a decision-theoretic agent programming language based on the situation calculus, was proposed to ease some of the computational difficulties associated with Markov Decision Processes (MDPs) by using natural ordering constraints on execution of actions. Using DTGolog, domain specific constraints on a set of policies can be expressed in a high-level program to reduce significantly computations required to find a policy optimal in this set. We explore whether the DTGolog framework can be used to evaluate different designs of a decision making agent in a large real-world domain. Each design is understood as combination of a template (expressed as a Golog program) for available policies and a reward function. To evaluate and compare alternative designs we estimate the probability of goal satisfaction for each design. As a domain, we choose the London Ambulance Service (LAS) case study that is well known in software engineering, but remains unknown in AI. We demonstrate that DTGolog can be applied successfully to quantitative evaluation of alternative designs in terms of their ability to satisfy a system goal with a high probability. The full version of this paper includes a detailed axiomatization of the domain in the temporal situation calculus with stochastic actions. The main advantage of this representation is that neither actions, nor states require explicit enumeration. We do an experimental analysis using an on-line implementation of DTGolog coupled with a simulator that models real time actions of many external agents. There are many practical domains where the task of designing a decision making agent (that guarantees goal satisfaction with a sufficiently high probability) is difficult due to a very large number of the state features and (ground) actions with uncertain effects. In these domains, the main problem is that state of the art planners cannot scale up to compute (or approximate) an optimal policy due to extremely large size of the state space. Even the task of computing the value of a single policy can be prohibitively difficult in these domains. The second common problem is that in some domains the goal of interest is characterized in terms * This is a summary of a long version of the paper available at A version of this paper has been accepted (with another title) as a poster by ECAI06 and will be also published in the proceedings of the ECAI06 W/Sh on Planning, Learning and Monitoring with Uncertainty and Dynamic Worlds. of quality of …","cites":"2","conferencePercentile":"20.31700288"},{"venue":"AAAI","id":"57a9f7700d6ccf4f5b4eaa5ce25f9dc14762604e","venue_1":"AAAI","year":"2016","title":"Discriminative Nonparametric Latent Feature Relational Models with Data Augmentation","authors":"Bei Chen, Ning Chen, Jun Zhu, Jiaming Song, Bo Zhang","author_ids":"2571156, 3524369, 1748711, 3169966, 1696318","abstract":"We present a discriminative nonparametric latent feature re-lational model (LFRM) for link prediction to automatically infer the dimensionality of latent features. Under the generic RegBayes (regularized Bayesian inference) framework, we handily incorporate the prediction loss with probabilistic inference of a Bayesian model; set distinct regularization parameters for different types of links to handle the imbalance issue in real networks; and unify the analysis of both the smooth logistic log-loss and the piecewise linear hinge loss. For the nonconjugate posterior inference, we present a simple Gibbs sampler via data augmentation, without making restricting assumptions as done in variational methods. We further develop an approximate sampler using stochastic gradient Langevin dynamics to handle large networks with hundreds of thousands of entities and millions of links, orders of magnitude larger than what existing LFRM models can process. Extensive studies on various real networks show promising performance.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"47362f4ad2859ad5a67a4742db409516e3f7ea55","venue_1":"AAAI","year":"2013","title":"A Hybrid Architectural Approach to Understanding and Appropriately Generating Indirect Speech Acts","authors":"Gordon Briggs, Matthias Scheutz","author_ids":"2867857, 1793014","abstract":"Current approaches to handling indirect speech acts (ISAs) do not account for their sociolinguistic underpinnings (i.e., politeness strategies). Deeper understanding and appropriate generation of indirect acts will require mechanisms that integrate natural language (NL) understanding and generation with social information about agent roles and obligations, which we introduce in this paper. Additionally, we tackle the problem of understanding and handling indirect answers that take the form of either speech acts or physical actions, which requires an inferential, plan-reasoning approach. In order to enable artificial agents to handle an even wider-variety of ISAs, we present a hybrid approach, utilizing both the idiomatic and inferential strategies. We then demonstrate our system successfully generating indirect requests and handling indirect answers, and discuss avenues of future research.","cites":"14","conferencePercentile":"90.90909091"},{"venue":"AAAI","id":"f09fd88951c21ca60827791e2f64c2e7187addef","venue_1":"AAAI","year":"2013","title":"Grounding Natural Language References to Unvisited and Hypothetical Locations","authors":"Thomas Emrys Williams, Rehj Cantrell, Gordon Briggs, Paul W. Schermerhorn, Matthias Scheutz","author_ids":"8701739, 3239319, 2867857, 2510893, 1793014","abstract":"While much research exists on resolving spatial natural language references to known locations, little work deals with handling references to unknown locations. In this paper we introduce and evaluate algorithms integrated into a cognitive architecture which allow an agent to learn about its environment while resolving references to both known and unknown locations. We also describe how multiple components in the architecture jointly facilitate these capabilities.","cites":"12","conferencePercentile":"87.09090909"},{"venue":"AAAI","id":"2ccce645d90082886e6b98b044b04c8b5b72cf43","venue_1":"AAAI","year":"2012","title":"Crossing Boundaries: Multi-Level Introspection in a Complex Robotic Architecture for Automatic Performance Improvements","authors":"Evan A. Krause, Paul W. Schermerhorn, Matthias Scheutz","author_ids":"2489549, 2510893, 1793014","abstract":"Introspection mechanisms are employed in agent architec-tures to improve agent performance. However, there is currently no approach to introspection that makes automatic adjustments at multiple levels in the implemented agent system. We introduce our novel multi-level introspection framework that can be used to automatically adjust architectural configurations based on the introspection results at the agent, infrastructure and component level. We demonstrate the utility of such adjustments in a concrete implementation on a robot where the high-level goal of the robot is used to automatically configure the vision system in a way that minimizes resource consumption while improving overall task performance.","cites":"4","conferencePercentile":"39.17682927"},{"venue":"AAAI","id":"967336d926ec6582756ddb5b628a641de2cfa774","venue_1":"AAAI","year":"2010","title":"Integrating a Closed World Planner with an Open World Robot: A Case Study","authors":"Kartik Talamadupula, J. Benton, Paul W. Schermerhorn, Subbarao Kambhampati, Matthias Scheutz","author_ids":"2940762, 3058407, 2510893, 1740315, 1793014","abstract":"In this paper, we present an integrated planning and robotic architecture that actively directs an agent engaged in an urban search and rescue (USAR) scenario. We describe three salient features that comprise the planning component of this system, namely (1) the ability to plan in a world open with respect to objects, (2) execution monitoring and replanning abilities, and (3) handling soft goals, and detail the interaction of these parts in representing and solving the USAR scenario at hand. We show that though insufficient in an individual capacity, the integration of this trio of features is sufficient to solve the scenario that we present. We test our system with an example problem that involves soft and hard goals, as well as goal deadlines and action costs, and show that the planner is capable of incorporating sensing actions and execution monitoring in order to produce goal-fulfilling plans that maximize the net benefit accrued.","cites":"27","conferencePercentile":"82.93515358"},{"venue":"AAAI","id":"0c00480dae9d6ddfd09b7bf869329421d9156a28","venue_1":"AAAI","year":"2006","title":"DIARC: A Testbed for Natural Human-Robot Interaction","authors":"Paul W. Schermerhorn, James F. Kramer, Christopher Middendorff, Matthias Scheutz","author_ids":"2510893, 2609362, 2541719, 1793014","abstract":"DIARC, a distributed integrated affect, reflection, cognition architecture for robots, provides many features that are critical to successful natural human-robot interaction. As such, DIARC is an ideal platform for experimentation in HRI. In this paper we describe the architecture and and its implementation in ADE, paying particular attention to its interaction capabilities and features that allow robust operation. These features are evaluated in the context of the 2006 AAAI Robot Competition.","cites":"12","conferencePercentile":"57.20461095"},{"venue":"AAAI","id":"2386de655670b2ce9bc48a8bb29da632bf7445d6","venue_1":"AAAI","year":"2004","title":"Useful Roles of Emotions in Artificial Agents: A Case Study from Artificial Life","authors":"Matthias Scheutz","author_ids":"1793014","abstract":"In this paper, we discuss the role of emotions in AI and possible ways to determine their utility for the design of artificial agents. We propose a research methodology for determining the utility of emotional control and apply it to the study of autonomous agents that compete for resources in an artificial life environment. The results show that the emotional control can improve performance in some circumstances.","cites":"24","conferencePercentile":"68.56287425"},{"venue":"AAAI","id":"0f5eb8827d7a71ed6d2af68722a4c0f7373fc40c","venue_1":"AAAI","year":"2004","title":"A Robotic Model of Human Reference Resolution","authors":"Matthias Scheutz, Virgil Andronache, Kathleen M. Eberhard","author_ids":"1793014, 2086885, 2678528","abstract":"Evidence from psychology suggests that humans process definite descriptions that refer to objects present in a visual scene incrementally upon hearing them, rather than constructing explicit parse trees after the whole sentence was said, which are then used to determine the referents. In this paper, we describe a real-time distributed robotic architectures for human reference resolution that demonstrates various interactions of auditory, visual, and semantic processing components hypothesized to underlie human processes.","cites":"1","conferencePercentile":"12.5748503"},{"venue":"AAAI","id":"146b71e25d0f723fc0a3518caeea959ed24e944b","venue_1":"AAAI","year":"2005","title":"Real-Time Classification of Electromyographic Signals for Robotic Control","authors":"Beau Crawford, Kai J. Miller, Pradeep Shenoy, Rajesh P. N. Rao","author_ids":"1828699, 2168720, 8275579, 1777466","abstract":"Advances in bioengineering have led to increasingly sophisticated prosthetic devices for amputees and paralyzed individuals. Control of such devices necessitates real-time classification of biosignals, e.g., electromyo-graphic (EMG) signals recorded from intact muscles. In this paper, we show that a 4-degrees-of-freedom robotic arm can be controlled in real-time using non-invasive surface EMG signals recorded from the forearm. The innovative features of our system include a physiologically-informed selection of forearm muscles for recording EMG signals, intelligent choice of hand gestures for easy classification, and fast, simple feature extraction from EMG signals. Our selection of gestures is meant to intuitively map to appropriate degrees of freedom in the robotic arm. These design decisions allow us to build fast accurate classifiers online, and control a 4-DOF robotic arm in real-time. In a study involving 3 subjects, we achieved accuracies of 92-98% on an 8-class classification problem using linear SVMs. These classifiers can be learned on-line in under 10 minutes, including data collection and training. Our study also analyzes the issues and tradeoffs involved in designing schemes for robotic control using EMG. Finally, we present details of online experiments where subjects successfully solved tasks of varying complexity using EMG to control the robotic arm.","cites":"25","conferencePercentile":"74.47552448"},{"venue":"AAAI","id":"4962da25f66f725a6c14659bf995806337c57e5e","venue_1":"AAAI","year":"2007","title":"An Intelligent System for Chinese Calligraphy","authors":"Songhua Xu, Hao Jiang, Francis Chi-Moon Lau, Yunhe Pan","author_ids":"3231501, 4795925, 1708000, 1778259","abstract":"Our work links Chinese calligraphy to computer science through an integrated intelligence approach. We first extract strokes of existent calligraphy using a semi-automatic, two-phase mechanism: the first phase tries to do the best possible extraction using a combination of algorithmic techniques; the second phase presents an intelligent user interface to allow the user to provide input to the extraction process for the difficult cases such as those in highly random, cursive, or distorted styles. Having derived a parametric representation of calligraphy, we employ a supervised learning based method to explore the space of visually pleasing calligraphy. A numeric grading method for judging the beauty of callig-raphy is then applied to the space. We integrate such a grading unit into an existent constraint-based reasoning system for calligraphy generation, which results in a significant enhancement in terms of visual quality in the automatically generated calligraphic characters. Finally, we construct an intelligent calligraphy tutoring system making use of the above. This work represents our first step towards understanding the human process of appreciating beauty through modeling the process with an integration of available AI techniques. More results and supplementary materials are provided at","cites":"7","conferencePercentile":"42.58160237"},{"venue":"AAAI","id":"67730774735a26ff7acdf26833436d69e017a512","venue_1":"AAAI","year":"2008","title":"A User-Oriented Webpage Ranking Algorithm Based on User Attention Time","authors":"Songhua Xu, Yi Zhu, Hao Jiang, Francis Chi-Moon Lau","author_ids":"3231501, 1749901, 4795925, 1708000","abstract":"We propose a new webpage ranking algorithm which is per-sonalized. Our idea is to rely on the attention time spent on a document by the user as the essential clue for producing the user-oriented webpage ranking. The prediction of the attention time of a new webpage is based on the attention time of other previously browsed pages by this user. To acquire the attention time of the latter webpages, we developed a browser plugin which is able to record the time a user spends reading a certain webpage and then automatically send that data to a server. Once the user attention time is acquired, we calibrate it to account for potential repetitive occurrences of the web-page before using it in the prediction process. After the user's attention times of a collection of documents are known, our algorithm can predict the user's attention time of a new document through document content similarity analysis, which is applied to both texts and images. We evaluate the webpage ranking results from our algorithm by comparing them with the ones produced by Google's Pagerank algorithm.","cites":"12","conferencePercentile":"61.86708861"},{"venue":"AAAI","id":"5786cde2b086dc80f4af40f958bce3ec7f526e12","venue_1":"AAAI","year":"2005","title":"Using Modified Lasso Regression to Learn Large Undirected Graphs in a Probabilistic Framework","authors":"Fan Li, Yiming Yang","author_ids":"1706783, 1723413","abstract":"Learning the structures of large undirected graphs with thousands of nodes from data has been an open challenge. In this paper, we use graphical Gaussian model (GGM) as the underlying model and propose a novel ARD style Wishart prior for the precision matrix of the GGM, which encodes the graph structure we want to learn. With this prior, we can get the MAP estimation of the precision matrix by solving (a modified version of) Lasso regressions and achieve a sparse solution. We use our approach to learn genetic regulatory networks from genome-wide expression microarray data and protein-binding location analysis data. Evaluated on the basis of consistency with the GO annotations, the experiments show that our approach has a much better performance than the clustering-based approaches and BN learning approaches in discovering gene regulatory modules.","cites":"10","conferencePercentile":"43.53146853"},{"venue":"AAAI","id":"6badcdbea3b6998b400a594ae15edb43ad560dff","venue_1":"AAAI","year":"2011","title":"Recommendation Sets and Choice Queries: There Is No Exploration/Exploitation Tradeoff!","authors":"Paolo Viappiani, Craig Boutilier","author_ids":"2188691, 2105432","abstract":"Utility elicitation is an important component of many applications, such as decision support systems and rec-ommender systems. Such systems query users about their preferences and offer recommendations based on the system's belief about the user's utility function. We analyze the connection between the problem of generating optimal recommendation sets and the problem of generating optimal choice queries, in the context of both Bayesian and regret-based elicitation. Our results show that, somewhat surprisingly, under very general circumstances , the optimal recommendation set coincides with the optimal query. Preference elicitation is a challenging task for a number of reasons. First of all, full elicitation of user preferences is prohibitively expensive in most cases (w.r.t. time, cognitive effort, etc.) and we must often rely on partial information. Second, many decision problems have large outcome or decision spaces; techniques for elicitation and recommendation must therefore be scalable. Third, it should be easy for users to provide information about their preferences, possibly accounting for noisy responses. Adaptive utility elicitation (Braziunas and Boutilier 2008) tackles these challenges by representing the system knowledge about the user in form of beliefs, that are updated following user responses. Elicitation queries can be chosen adaptively given the current belief. In this way, one can often make good (or even optimal) recommendations with sparse knowledge of the user's utility function. There are two main frameworks for representing utility uncertainty. In one approach (Boutilier et al. 2006) the system maintains an explicit representation of a set of feasible utility functions, usually represented compactly by constraints; recommendations are generated using the min-imax regret criterion. Alternatively, a pure Bayesian approach (Chajewska et al. 2000; Boutilier 2002) places a probabilistic prior over the possible utility functions (typically in the form of a density over utility function parame-1 We summarize the key contributions of two earlier papers (Vi-appiani and Boutilier 2009; 2010), providing a unified view. ters), and updates the distribution based on observations; the option with greatest expected utility is recommended. Given the current belief about the user's utility function, it is important to select good queries so that recommendations can quickly improve. In the case of Bayesian preference elicitation, a natural criterion for queries is expected value of information (EVOI); it is, however, extremely expensive computationally and, because of this, most approaches select queries using heuristics with no theoretical guarantees. For regret-based elicitation, we introduce a non-probabilistic analogue of EVOI. Such informative criteria can …","cites":"3","conferencePercentile":"29.3814433"},{"venue":"AAAI","id":"1962ed88d066efba4c64e2f5f5bcbe2a055330c4","venue_1":"AAAI","year":"2014","title":"Signals in the Silence: Models of Implicit Feedback in a Recommendation System for Crowdsourcing","authors":"Christopher H. Lin, Ece Kamar, Eric Horvitz","author_ids":"1999020, 1783184, 1688884","abstract":"We exploit the absence of signals as informative observations in the context of providing task recommendations in crowd-sourcing. Workers on crowdsourcing platforms do not provide explicit ratings about tasks. We present methods that enable a system to leverage implicit signals about task preferences. These signals include types of tasks that have been available and have been displayed, and the number of tasks workers select and complete. In contrast to previous work, we present a general model that can represent both positive and negative implicit signals. We introduce algorithms that can learn these models without exceeding the computational complexity of existing approaches. Finally, using data from a high-throughput crowdsourcing platform, we show that reasoning about both positive and negative implicit feedback can improve the quality of task recommendations.","cites":"7","conferencePercentile":"77.5"},{"venue":"AAAI","id":"ea9e218a766763045f23d391f902742940ce5871","venue_1":"AAAI","year":"2006","title":"Building Semantic Mappings from Databases to Ontologies","authors":"Yuan An, John Mylopoulos, Alexander Borgida","author_ids":"1739276, 1750566, 1727750","abstract":"A recent special issue of AI Magazine (AAAI 2005) was dedicated to the topic of semantic integration — the problem of sharing data across disparate sources. At the core of the solution lies the discovery the \" semantics \" of different data sources. Ideally, the semantics of data are captured by a formal ontology of the domain together with a semantic mapping connecting the schema describing the data to the ontology. However, establishing the semantic mapping from a database schema to a formal ontology in terms of formal logic expressions is inherently difficult to automate, so the task was left to humans. In this paper, we report on our study (An, Borgida, & Mylopoulos 2005a; 2005b) of a semi-automatic tool, called MAPONTO, that assists users to discover plausible semantic relationships between a database schema (relational or XML) and an ontology, expressing them as logical formu-las/rules.","cites":"19","conferencePercentile":"69.16426513"},{"venue":"AAAI","id":"b6cacdcf62c8ed25551c18c9b0a5104cd3b7ea7d","venue_1":"AAAI","year":"2011","title":"Towards Evolutionary Nonnegative Matrix Factorization","authors":"Fei Wang, Hanghang Tong, Ching-Yung Lin","author_ids":"1682816, 8163721, 1689953","abstract":"Nonnegative Matrix Factorization (NMF) techniques has aroused considerable interests from the field of artificial intelligence in recent years because of its good interpretability and computational efficiency. However, in many real world applications, the data features usually evolve over time smoothly. In this case, it would be very expensive in both computation and storage to rerun the whole NMFprocedure after each time when the data feature changing. In this paper, we propose Evolutionary Nonnegative Matrix Factorization (eNMF), which aims to incrementally update the factorized matrices in a computation and space efficient manner with the variation of the data matrix. We devise such evolutionary procedure for both asymmetric and symmetric NMF. Finally we conduct experiments on several real world data sets to demonstrate the efficacy and efficiency of eNMF.","cites":"12","conferencePercentile":"73.02405498"},{"venue":"AAAI","id":"042bb39b9bc9f9a9baee13c971e80462717b7f72","venue_1":"AAAI","year":"2012","title":"Efficient Approximate Value Iteration for Continuous Gaussian POMDPs","authors":"Jur P. van den Berg, Sachin Patil, Ron Alterovitz","author_ids":"1764300, 1702660, 1682091","abstract":"We introduce a highly efficient method for solving continuous partially-observable Markov decision processes (POMDPs) in which beliefs can be modeled using Gaussian distributions over the state space. Our method enables fast solutions to sequential decision making under uncertainty for a variety of problems involving noisy or incomplete observations and stochastic actions. We present an efficient approach to compute locally-valid approximations to the value function over continuous spaces in time polynomial (O[n 4 ]) in the dimension n of the state space. To directly tackle the intractabil-ity of solving general POMDPs, we leverage the assumption that beliefs are Gaussian distributions over the state space, approximate the belief update using an extended Kalman filter (EKF), and represent the value function by a function that is quadratic in the mean and linear in the variance of the belief. Our approach iterates towards a linear control policy over the state space that is locally-optimal with respect to a user defined cost function, and is approximately valid in the vicinity of a nominal trajectory through belief space. We demonstrate the scalability and potential of our approach on problems inspired by robot navigation under uncertainty for state spaces of up to 128 dimensions.","cites":"12","conferencePercentile":"74.54268293"},{"venue":"AAAI","id":"208c62665d8c9c2eea7ec49912f5f3ad19c0f3da","venue_1":"AAAI","year":"2008","title":"COACH - Cumulative Online Algorithm for Classification of Handwriting Deficiencies","authors":"Ariella Richardson, Sarit Kraus, Patrice L. Weiss, Sara Rosenblum","author_ids":"2817130, 1691597, 2619060, 2364463","abstract":"In this paper we present COACH-a Cumulative Online Algorithm for Classiication of Handwriting deeciencies. A description of our algorithm along with a performance evaluation of COACH on real data is provided. COACH is an innovative algorithm designed for building an online handwriting evaluation tool to be used for classifying and remediating handwriting deeciencies. COACH adapts learning and data mining techniques from AI to handwriting deeciency clas-siication in an innovative fashion. Until now handwriting classiication has been performed manually by trained therapists causing expensive and subjective evaluation. This application lowers the cost of evaluation, increases objective-ness, and enables repeated testing that can accompany therapy. COACH is evaluated on real data obtained from children with poor handwriting using a digitizer tablet. Results show that COACH manages to successfully differentiate between poor to proocient handwriting. Differentiation is obtained even after using data from only a few words. These results prove that COACH is a promising emerging application for online evaluation.","cites":"6","conferencePercentile":"41.4556962"},{"venue":"AAAI","id":"aa05431d82f5d85a3abdf2f4d416c36993b1284b","venue_1":"AAAI","year":"2010","title":"Reinforcement Learning Via Practice and Critique Advice","authors":"Kshitij Judah, Saikat Roy, Alan Fern, Thomas G. Dietterich","author_ids":"1719050, 2120286, 1791751, 1699720","abstract":"We consider the problem of incorporating end-user advice into reinforcement learning (RL). In our setting, the learner alternates between practicing, where learning is based on actual world experience, and end-user critique sessions where advice is gathered. During each critique session the end-user is allowed to analyze a trajectory of the current policy and then label an arbitrary subset of the available actions as good or bad. Our main contribution is an approach for integrating all of the information gathered during practice and critiques in order to effectively optimize a parametric policy. The approach optimizes a loss function that linearly combines losses measured against the world experience and the critique data. We evaluate our approach using a prototype system for teaching tactical battle behavior in a real-time strategy game engine. Results are given for a significant evaluation involving ten end-users showing the promise of this approach and also highlighting challenges involved in inserting end-users into the RL loop.","cites":"33","conferencePercentile":"88.39590444"},{"venue":"AAAI","id":"1a05cd6f83e65ced41230fc83c19d232c383c78b","venue_1":"AAAI","year":"2008","title":"Integrating Multiple Learning Components through Markov Logic","authors":"Thomas G. Dietterich, Xinlong Bao","author_ids":"1699720, 1953940","abstract":"This paper addresses the question of how statistical learning algorithms can be integrated into a larger AI system both from a practical engineering perspective and from the perspective of correct representation, learning, and reasoning. Our goal is to create an integrated intelligent system that can combine observed facts, handwritten rules, learned rules, and learned classifiers to perform joint learning and reasoning. Our solution, which has been implemented in the CALO system, integrates multiple learning components with a Markov Logic inference engine, so that the components can benefit from each other's predictions. We introduce two designs of the learning and reasoning layer in CALO: the MPE Architecture and the Marginal Probability Architecture. The architectures, interfaces, and algorithms employed in our two designs are described , followed by experimental evaluations of the performance of the two designs. We show that by integrating multiple learning components through Markov Logic, the performance of the system can be improved and that the Marginal Probability Architecture performs better than the MPE Architecture.","cites":"2","conferencePercentile":"23.41772152"},{"venue":"AAAI","id":"65768a45ff65c0c31f3b54ef44b7e568297998ba","venue_1":"AAAI","year":"1991","title":"Error-Correcting Output Codes: A General Method for Improving Multiclass Inductive Learning Programs","authors":"Thomas G. Dietterich, Ghulum Bakiri","author_ids":"1699720, 3242194","abstract":"Multiclass learning problems involve nding a deeni-tion for an unknown function f (x) whose range is a discrete set containing k > 2 values (i.e., k \\classes\"). The deenition is acquired by studying large collections of training examples of the form hx i ; f (x i)i. Existing approaches to this problem include (a) direct application of multiclass algorithms such as the decision-tree algorithms ID3 and CART, (b) application of binary concept learning algorithms to learn individual binary functions for each of the k classes, and (c) application of binary concept learning algorithms with distributed output codes such as those employed by Sejnowski and Rosenberg in the NETtalk system. This paper compares these three approaches to a new technique in which BCH error-correcting codes are employed as a distributed output representation. We show that these output representations improve the performance of ID3 on the NETtalk task and of backpropagation on an isolated-letter speech-recognition task. These results demonstrate that error-correcting output codes provide a general-purpose method for improving the performance of inductive learning programs on multiclass problems.","cites":"110","conferencePercentile":"88.63636364"},{"venue":"AAAI","id":"7008bc0709341ae19d260dbeda6b65a4c4467ee1","venue_1":"AAAI","year":"1991","title":"Learning with Many Irrelevant Features","authors":"Hussein Almuallim, Thomas G. Dietterich","author_ids":"2522754, 1699720","abstract":"In many domains, an appropriate inductive bias is the MIN-FEATURES bias, which prefers consistent hypotheses deenable over as few features as possible. This paper deenes and studies this bias. First, it is shown that any learning algorithm implementing the MIN-FEATURES bias requires (1 ln 1 + 1 2 p + p lnn]) training examples to guarantee PAC-learning a concept having p relevant features out of n available features. This bound is only logarithmic in the number of irrelevant features. The paper also presents a quasi-polynomial time algorithm, FOCUS, which implements MIN-FEATURES. Experimental studies are presented that compare FOCUS to the ID3 and FRINGE algorithms. These experiments show that| contrary to expectations|these algorithms do not implement good approximations of MIN-FEATURES. The coverage, sample complexity, and generalization performance of FOCUS is substantially better than either ID3 or FRINGE on learning problems where the MIN-FEATURES bias is appropriate. This suggests that, in practical applications, training data should be preprocessed to remove irrelevant features before being given to ID3 or FRINGE.","cites":"286","conferencePercentile":"97.72727273"},{"venue":"AAAI","id":"fc93a6793422ee2cd10768efcc11032e59209302","venue_1":"AAAI","year":"1994","title":"Coalition, Cryptography, and Stability: Mechanisms for Coalition Formation in Task Oriented Domains","authors":"Gilad Zlotkin, Jeffrey S. Rosenschein","author_ids":"2381550, 1735970","abstract":"Negotiation among multiple agents remains an important topic of research in Distributed Artiicial Intelligence (DAI). Most previous work on this subject, however, has focused on bilateral negotiation, deals that are reached between two agents. There has also been research on n-agent agreement which has considered \\consensus mechanisms\" (such as voting), that allow the full group to coordinate itself. These group decision-making techniques, however, assume that the entire group will (or has to) coordinate its actions. Subgroups cannot make sub-agreements that exclude other members of the group. In some domains, however, it may be possible for ben-eecial agreements to be reached among subgroups of agents, who might be individually motivated to work together to the exclusion of others outside the group. This paper considers this more general case of n-agent coalition formation. We present a simple coalition formation mechanism that uses cryptographic techniques for subadditive Task Oriented Domains. The mechanism is eecient, symmetric, and individual rational. When the domain is also concave, the mechanism also satisses coalition rationality.","cites":"95","conferencePercentile":"92.2907489"},{"venue":"AAAI","id":"dac4ea7cc75a8ad2c36968bed70e9c2b1dab26c4","venue_1":"AAAI","year":"2016","title":"Relaxed Majorization-Minimization for Non-smooth and Non-convex Optimization","authors":"Chen Xu, Zhouchen Lin, Zhenyu Zhao, Hongbin Zha","author_ids":"3805057, 1692743, 2388652, 1687248","abstract":"We propose a new majorization-minimization (MM) method for non-smooth and non-convex programs, which is general enough to include the existing MM methods. Besides the local majorization condition, we only require that the difference between the directional derivatives of the objective function and its surrogate function vanishes when the number of iterations approaches infinity, which is a very weak condition. So our method can use a surrogate function that directly approximates the non-smooth objective function. In comparison , all the existing MM methods construct the sur-rogate function by approximating the smooth component of the objective function. We apply our relaxed MM methods to the robust matrix factorization (RMF) problem with different regularizations, where our locally majorant algorithm shows great advantages over the state-of-the-art approaches for RMF. This is the first algorithm for RMF ensuring, without extra assumptions , that any limit point of the iterates is a stationary point.","cites":"1","conferencePercentile":"40.70945946"},{"venue":"AAAI","id":"2057837e059a1dde8c6c4c0587e652b79c04780a","venue_1":"AAAI","year":"2014","title":"Learning to Recognize Novel Objects in One Shot through Human-Robot Interactions in Natural Language Dialogues","authors":"Evan A. Krause, Michael Zillich, Thomas Emrys Williams, Matthias Scheutz","author_ids":"2489549, 1682587, 8701739, 1793014","abstract":"Being able to quickly and naturally teach robots new knowledge is critical for many future open-world human-robot interaction scenarios. In this paper we present a novel approach to using natural language context for one-shot learning of visual objects, where the robot is immediately able to recognize the described object. We describe the architectural components and demonstrate the proposed approach on a robotic platform in a proof-of-concept evaluation.","cites":"6","conferencePercentile":"72.84090909"},{"venue":"AAAI","id":"22a92b0628ffe066e66ffc5ea95839061a358e32","venue_1":"AAAI","year":"2008","title":"Dimension Amnesic Pyramid Match Kernel","authors":"Yi Liu, Xulei Wang, Hongbin Zha","author_ids":"1691635, 2339366, 1687248","abstract":"With the success of local features in object recognition , feature-set representations are widely used in computer vision and related domains. Pyramid match kernel (PMK) is an efficient approach to quantifying the similarity between two unordered feature-sets, which allows well established kernel machines to learn with such representations. However, the approximation of PMK to the optimal feature matches deteriorates linearly with the dimension of local features, which prohibits the direct use of high dimensional features. In this paper, we propose a general, data-independent kernel to quantify the feature-set similarities, which gives an upper bound of approximation error independent of the dimension of local features. The key idea is to employ the technique of normal random projection to construct a number of low dimensional subspaces, and perform the original PMK algorithm therein. By leveraging on the invariance property of p-stable distributions, our approach achieves the desirable dimension-free property. Extensive experiments on the ETH-80 image database solidly demonstrate the advantage of our approach to high dimensional features.","cites":"3","conferencePercentile":"28.16455696"},{"venue":"AAAI","id":"224f533edc454a33ea1e2b60fd6b7bafa0001980","venue_1":"AAAI","year":"2010","title":"Constrained Coclustering for Textual Documents","authors":"Yangqiu Song, Shimei Pan, Shixia Liu, Furu Wei, Michelle X. Zhou, Weihong Qian","author_ids":"1809614, 2728986, 5487167, 2517592, 1705742, 3069375","abstract":"In this paper, we present a constrained co-clustering approach for clustering textual documents. Our approach combines the benefits of information-theoretic co-clustering and constrained clustering. We use a two-sided hidden Markov random field (HMRF) to model both the document and word constraints. We also develop an alternating expectation max-imization (EM) algorithm to optimize the constrained co-clustering model. We have conducted two sets of experiments on a benchmark data set: (1) using human-provided category labels to derive document and word constraints for semi-supervised document clustering, and (2) using automatically extracted named entities to derive document constraints for unsupervised document clustering. Compared to several representative constrained clustering and co-clustering approaches, our approach is shown to be more effective for high-dimensional, sparse text data.","cites":"16","conferencePercentile":"69.62457338"},{"venue":"AAAI","id":"fae7e65bef052452b8a999c618103200a9eba7ce","venue_1":"AAAI","year":"2016","title":"Tracking Idea Flows between Social Groups","authors":"Yangxin Zhong, Shixia Liu, Xiting Wang, Jiannan Xiao, Yangqiu Song","author_ids":"1917785, 5487167, 1882695, 2215306, 1809614","abstract":"In many applications, ideas that are described by a set of words often flow between different groups. To facilitate users in analyzing the flow, we present a method to model the flow behaviors that aims at identifying the lead-lag relationships between word clusters of different user groups. In particular, an improved Bayesian conditional cointegration based on dynamic time warping is employed to learn links between words in different groups. A tensor-based technique is developed to cluster these linked words into different clusters (ideas) and track the flow of ideas. The main feature of the tensor representation is that we introduce two additional dimensions to represent both time and lead-lag relationships. Experiments on both synthetic and real datasets show that our method is more effective than methods based on traditional clustering techniques and achieves better accuracy. A case study was conducted to demonstrate the usefulness of our method in helping users understand the flow of ideas between different user groups on social media.","cites":"1","conferencePercentile":"40.70945946"},{"venue":"AAAI","id":"478dac375b3dc60be161e2fb5091ac44a247a48a","venue_1":"AAAI","year":"2008","title":"Route Planning under Uncertainty: The Canadian Traveller Problem","authors":"Evdokia Nikolova, David R. Karger","author_ids":"2627861, 1743286","abstract":"The Canadian Traveller problem is a stochastic shortest paths problem in which one learns the cost of an edge only when arriving at one of its endpoints. The goal is to find an optimal policy that minimizes the expected cost of travel. The problem is known to be #P-hard. Since there has been no significant progress on approximation algorithms for several decades, we have chosen to seek out special cases for which exact solutions exist, in the hope of demonstrating techniques that could lead to further progress. Applying a mix of techniques from algorithm analysis and the theory of Markov Decision Processes , we provide efficient exact algorithms for directed acyclic graphs and (undirected) graphs of disjoint paths from source to destination with random two-valued edge costs. We also give worst-case performance analysis and experimental data for two natural heuristics.","cites":"29","conferencePercentile":"87.02531646"},{"venue":"AAAI","id":"032db1a374783c2a8881be44b3099ad1d5138019","venue_1":"AAAI","year":"2014","title":"Grandpa Hates Robots - Interaction Constraints for Planning in Inhabited Environments","authors":"Uwe Köckemann, Federico Pecora, Lars Karlsson","author_ids":"2510624, 2766656, 4620262","abstract":"Consider a family whose home is equipped with several service robots. The actions planned for the robots must adhere to Interaction Constraints (ICs) relating them to human activities and preferences. These constraints must be sufficiently expressive to model both temporal and logical dependencies among robot actions and human behavior, and must accommodate incomplete information regarding human activities. In this paper we introduce an approach for automatically generating plans that are conformant wrt. given ICs and partially specified human activities. The approach allows to separate causal reasoning about actions from reasoning about ICs, and we illustrate the computational advantage this brings with experiments on a large-scale (semi-)realistic household domain with hundreds of human activities and several robots. We address the challenge of automatically generating plans that have to accommodate scheduled activities, features and preferences of a set of uncontrollable agents (such as humans). Consider, e.g., a domain in which a set of robots have to plan for a whole day in a household environment that is co-inhabited by a human family. The schedules and preferences of humans impose complex constraints on robot plans. We may, for instance, be required to avoid that a robot is vacuuming a room in which an inhabitant is reading. This could be resolved by separating these two events in time. The applicability of such constraints may not only be based on the activity (such as reading), but also on the preferences of the inhabitant. The above example may only apply to inhabitants that are easily distracted. In many cases we can also allow to violate these constraints by paying a social cost (Alami et al., 2006). To handle such domains we propose to use Interaction Constraints (ICs) to model how robot plans and human activities should relate to each other. The building blocks of ICs are also constraints, albeit at a lower level of abstraction , which enforce temporal and logical requirements or costs on robot plans. We show through the use of examples how the expressiveness of constraint-based planning is well suited for modeling interaction requirements with humans. The constraint-based nature of the domain definition language also allows to account for partially specified human behavior. We propose a planning algorithm which leverages the richness of the language to decompose the overall problem into easier sub-problems that are separated from causal reasoning (assuming robot and human activities are only connected via ICs). The planner computes plans …","cites":"7","conferencePercentile":"77.5"},{"venue":"AAAI","id":"300e4f15c910f1770900b51fad3cfe7bcd5b9f79","venue_1":"AAAI","year":"2014","title":"Semantic Data Representation for Improving Tensor Factorization","authors":"Makoto Nakatsuji, Yasuhiro Fujiwara, Hiroyuki Toda, Hiroshi Sawada, Jinguang Zheng, James A. Hendler","author_ids":"3110902, 1935168, 1717891, 1741725, 1761642, 1701341","abstract":"Predicting human activities is important for improving recommender systems or analyzing social relationships among users. Those human activities are usually represented as multi-object relationships (e.g. user's tagging activities for items or user's tweeting activities at some locations). Since multi-object relationships are naturally represented as a tensor, tensor factorization is becoming more important for predicting users' possible activities. However, its prediction accuracy is weak for ambiguous and/or sparsely observed objects. Our solution, Semantic data Representation for Tensor Factorization (SRTF), tackles these problems by incorporating semantics into tensor factorization based on the following ideas: (1) It first links objects to vocabularies/taxonomies and resolves the ambiguity caused by objects that can be used for multiple purposes. (2) It next links objects to composite classes that merge classes in different kinds of vocabularies/taxonomies (e.g. classes in vocabularies for movie genres and those for directors) to avoid low prediction accuracy caused by rough-grained semantics. (3) It then lifts sparsely observed objects into their classes to solve the sparsity problem for rarely observed objects. To the best of our knowledge, this is the first study that leverages semantics to inject expert knowledge into ten-sor factorization. Experiments show that SRTF achieves up to 10% higher accuracy than state-of-the-art methods.","cites":"3","conferencePercentile":"49.43181818"},{"venue":"AAAI","id":"fbac063f4f3f7af66b89335b81711a45aeba30f3","venue_1":"AAAI","year":"2013","title":"Personalized Recommendation Based on Co-Ranking and Query-Based Collaborative Diffusion","authors":"Xiao Yang, Zhaoxin Zhang, Qiang Wang","author_ids":"1777526, 1764064, 1715161","abstract":"In this paper, we present an adaptive graph-based personalized recommendation method based on co-ranking and query-based collaborative diffusion. By utilizing the unique network structure of n-partite heterogeneous graph, we attempt to address the problem of personalized recommendation in a two-layer ranking process with the help of reasonable measure of high and low order relationships and analyzing the representation of user's preference in the graph. The experiments show that this algorithm can outperform the traditional CF methods and achieve competitive performance compared with many model-based and graph-based recommendation methods, and have better scalability and flexibility.","cites":"1","conferencePercentile":"25.09090909"},{"venue":"AAAI","id":"b4dd4cf72f2e778d6030e0bb3a64e13562985ab3","venue_1":"AAAI","year":"1994","title":"Knowledge Representation for Video","authors":"Marc Davis","author_ids":"1777964","abstract":"Current computing systems are just beginning to enable the computational manipulation of temporal media like video and audio. Because of the opacity of these media they must be represented in order to be manipulable according to their contents. Knowledge representation techniques have been implicitly designed for representing the physical world and its textual representations. Temporal media pose unique problems and opportunities for knowledge representation which challenge many of its assumptions about the structure and function of what is represented. The semantics and syntax of temporal media require representational designs which employ fundamentally different conceptions of space, time, identity, and action. In particular, the effects of the syntax of video sequences on the semantics of video shots demands a representational design which can clearly articulate the differences between the context-dependent and context-independent semantics of video data. This paper outlines the theoretical foundations for designing representations of video, discusses Media Streams, an implemented system for video representation and retrieval, and critiques related efforts in this area.","cites":"23","conferencePercentile":"64.53744493"},{"venue":"AAAI","id":"d9f7032f1636253be1bf42fce5791cafb64c60ee","venue_1":"AAAI","year":"2015","title":"Going Beyond Literal Command-Based Instructions: Extending Robotic Natural Language Interaction Capabilities","authors":"Tom Williams, Gordon Briggs, Bradley Oosterveld, Matthias Scheutz","author_ids":"3883266, 2867857, 2323545, 1793014","abstract":"The ultimate goal of human natural language interaction is to communicate intentions. However, these intentions are often not directly derivable from the semantics of an utterance (e.g., when linguistic modulations are employed to convey politeness , respect, and social standing). Robotic architectures with simple command-based natural language capabilities are thus not equipped to handle more liberal, yet natural uses of linguistic communicative exchanges. In this paper, we propose novel mechanisms for inferring intentions from utterances and generating clarification requests that will allow robots to cope with a much wider range of task-based natural language interactions. We demonstrate the potential of these inference algorithms for natural human-robot interactions by running them as part of an integrated cognitive robotic architecture on a mobile robot in a dialogue-based instruction task.","cites":"8","conferencePercentile":"90.23622047"},{"venue":"AAAI","id":"56c5fcaf7af32e3575ad07d3437e63ae6a10d55b","venue_1":"AAAI","year":"2016","title":"A Framework for Resolving Open-World Referential Expressions in Distributed Heterogeneous Knowledge Bases","authors":"Tom Williams, Matthias Scheutz","author_ids":"3883266, 1793014","abstract":"We present a domain-independent approach to reference resolution that allows a robotic or virtual agent to resolve references to entities (e.g., objects and locations) found in open worlds when the information needed to resolve such references is distributed among multiple heterogeneous knowledge bases in its architecture. An agent using this approach can combine information from multiple sources without the computational bottleneck associated with centralized knowledge bases. The proposed approach also facilitates \" lazy constraint evaluation \" , i.e., verifying properties of the refer-ent through different modalities only when the information is needed. After specifying the interfaces by which a reference resolution algorithm can request information from distributed knowledge bases, we present an algorithm for performing open-world reference resolution within that framework , analyze the algorithm's performance, and demonstrate its behavior on a simulated robot.","cites":"2","conferencePercentile":"61.31756757"},{"venue":"AAAI","id":"099368f4361aa8f050836acd46140c022846eff2","venue_1":"AAAI","year":"2010","title":"Simultaneous Elicitation of Preference Features and Utility","authors":"Craig Boutilier, Kevin Regan, Paolo Viappiani","author_ids":"2105432, 2558734, 2188691","abstract":"Most frameworks for utility elicitation assume a predefined set of features over which user preferences are expressed. We consider utility elicitation in the presence of subjective or user-defined features, whose definitions are not known in advance. We treat the problem of learning a user's feature definition as one of concept learning, but whose goal is to learn only enough about the concept definition to enable a good decision to be made. This is complicated by the fact that user utility is unknown. We describe computational procedures for identifying optimal alternatives w.r.t minimax regret in the presence of both utility and concept uncertainty; and develop several heuristic query strategies that focus simultaneously on reduction of relevant concept and utility uncertainty.","cites":"8","conferencePercentile":"43.85665529"},{"venue":"AAAI","id":"0941c04cc69460dcddbe2b337e21e9cb5cec52fb","venue_1":"AAAI","year":"2013","title":"A Hierarchical Aspect-Sentiment Model for Online Reviews","authors":"Suin Kim, Jianwen Zhang, Zheng Chen, Alice H. Oh, Shixia Liu","author_ids":"2844832, 1875470, 1705657, 1725588, 5487167","abstract":"To help users quickly understand the major opinions from massive online reviews, it is important to automatically reveal the latent structure of the aspects, sentiment polarities, and the association between them. However, there is little work available to do this effectively. In this paper, we propose a hierarchical aspect sentiment model (HASM) to discover a hierarchical structure of aspect-based sentiments from unlabeled online reviews. In HASM, the whole structure is a tree. Each node itself is a two-level tree, whose root represents an aspect and the children represent the sentiment polarities associated with it. Each aspect or sentiment polarity is modeled as a distribution of words. To automatically extract both the structure and parameters of the tree, we use a Bayesian nonparametric model, recursive Chinese Restaurant Process (rCRP), as the prior and jointly infer the aspect-sentiment tree from the review texts. Experiments on two real datasets show that our model is comparable to two other hierarchical topic models in terms of quantitative measures of topic trees. It is also shown that our model achieves better sentence-level classification accuracy than previously proposed aspect-sentiment joint models.","cites":"31","conferencePercentile":"98.54545455"},{"venue":"AAAI","id":"8f7799ecbdfcfc218c96c2ca71030afba1c2b98c","venue_1":"AAAI","year":"2006","title":"CPM: Context-Aware Power Management in WLANs","authors":"Fahd Albinali, Chris Gniady","author_ids":"3072621, 2672452","abstract":"In this paper, we present a novel approach for tuning power modes of wireless 802.11 interfaces. We use K-means and simple correlation techniques to analyze user's interaction with applications based on mouse clicks. This provides valuable contextual hints that are used to anticipate future network access patterns and intent of users. Based on those hints, we adapt the power mode of the wireless network interface to optimize both energy usage and bandwidth usage. Evaluation results (based on real data gathered from interaction with a desktop) show significant improvements over earlier power management schemes.","cites":"2","conferencePercentile":"20.31700288"},{"venue":"AAAI","id":"87bf74549b5f2e45889668b326a523ad1b7b4737","venue_1":"AAAI","year":"2012","title":"Generating Pictorial Storylines Via Minimum-Weight Connected Dominating Set Approximation in Multi-View Graphs","authors":"Dingding Wang, Tao Li, Mitsunori Ogihara","author_ids":"7496442, 1726351, 1774705","abstract":"This paper introduces a novel framework for generating pictorial storylines for given topics from text and image data on the Internet. Unlike traditional text summarization and timeline generation systems, the proposed framework combines text and image analysis and delivers a storyline containing textual, pictorial, and structural information to provide a sketch of the topic evolution. A key idea in the framework is the use of an approximate solution for the dominating set problem. Given a collection of topic-related objects consisting of images and their text descriptions, a weighted multi-view graph is first constructed to capture the contex-tual and temporal relationships among these objects. Then the objects are selected by solving the minimum-weighted connected dominating set problem defined on this graph. Comprehensive experiments on real-world data sets demonstrate the effectiveness of the proposed framework.","cites":"21","conferencePercentile":"90.24390244"},{"venue":"AAAI","id":"29b49584dc993ddc17a99bb3b02b25022b1a5da3","venue_1":"AAAI","year":"2011","title":"Integrating Clustering and Multi-Document Summarization by Bi-Mixture Probabilistic Latent Semantic Analysis (PLSA) with Sentence Bases","authors":"Chao Shen, Tao Li, Chris H. Q. Ding","author_ids":"8518333, 1726351, 1737469","abstract":"Probabilistic Latent Semantic Analysis (PLSA) has been popularly used in document analysis. However, as it is currently formulated, PLSA strictly requires the number of word latent classes to be equal to the number of document latent classes. In this paper, we propose Bi-mixture PLSA, a new formulation of PLSA that allows the number of latent word classes to be different from the number of latent document classes. We further extend Bi-mixture PLSA to incorporate the sentence information , and propose Bi-mixture PLSA with sentence bases (Bi-PLSAS) to simultaneously cluster and summarize the documents utilizing the mutual influence of the document clustering and summarization procedures. Experiments on real-world datasets demonstrate the effectiveness of our proposed methods.","cites":"9","conferencePercentile":"64.08934708"},{"venue":"AAAI","id":"dc9014d1e7b97405be7c48ff9de9d2694e87b0f5","venue_1":"AAAI","year":"2008","title":"Semi-supervised Classification Using Local and Global Regularization","authors":"Fei Wang, Tao Li, Gang Wang, Changshui Zhang","author_ids":"1682816, 1726351, 4148672, 1700883","abstract":"In this paper, we propose a semi-supervised learning (SSL) algorithm based on local and global regularization. In the local regularization part, our algorithm constructs a regularized classifier for each data point using its neighborhood, while the global regularization part adopts a Laplacian regularizer to smooth the data labels predicted by those local classifiers. We show that some existing SSL algorithms can be derived from our framework. Finally we present some experimental results to show the effectiveness of our method.","cites":"6","conferencePercentile":"41.4556962"},{"venue":"AAAI","id":"37207044b442ac096b6684c5048ac862293be3ea","venue_1":"AAAI","year":"2006","title":"A Platform to Evaluate the Technology for Service Discovery in the Semantic Web","authors":"Cécile Aberg, Johan Aberg, Patrick Lambrix, Nahid Shahmehri","author_ids":"2923053, 6181282, 1793342, 1723372","abstract":"Since the description of the Semantic Web paradigm in 2001, technology has been proposed to allow its deployment and use. However, there is not yet any large and widely deployed set of semantically annotated Web resources available. As a result, it is not possible to evaluate the use of the technology in a real environment, and several assumptions about how the Semantic Web should work are emerging. In order to further investigate these assumptions and the related technology, we propose a simulation and evaluation platform. The platform provides tools to create Semantic Web simulations using different technologies for different purposes, and to evaluate their performance. In this paper we introduce the model of the platform and describe the current implementation. The implementation facilitates the integration of technology for an essential operation on the Semantic Web, namely Semantic Web service discovery. We illustrate the use of the platform in a case study by implementing a Semantic Web where the Jade multi-agent platform provides the framework to describe the agents, and a number of existing Semantic Web technologies are embedded in agent behavior.","cites":"1","conferencePercentile":"14.4092219"},{"venue":"AAAI","id":"295661c1a4ed08ba7aed824b2a6bb2b709b177fb","venue_1":"AAAI","year":"2007","title":"Adaptive Timeout Policies for Fast Fine-Grained Power Management","authors":"Branislav Kveton, Prashant Gandhi, Georgios Theocharous, Shie Mannor, Barbara Rosario, Nilesh Shah","author_ids":"1681967, 2118330, 1709005, 1712535, 3199842, 2654759","abstract":"Power management techniques for mobile appliances put the components of the systems into low power states to maximize battery life while minimizing the impact on the perceived performance of the devices. Static timeout policies are the state-of-the-art approach for solving power management problems. In this work, we propose adaptive timeout policies as a simple and efficient solution for fine-grained power management. As discussed in the paper, the policies reduce the latency of static timeout policies by nearly one half at the same power savings. This result can be also viewed as increasing the power savings of static timeout policies at the same latency target. The main objective of our work is to propose practical adaptive policies. Therefore, our adaptive solution is fast enough to be executed within less than one millisecond, and sufficiently simple to be deployed directly on a microcontroller. We validate our ideas on two recorded CPU activity traces, which involve more than 10 million entries each.","cites":"6","conferencePercentile":"38.4272997"},{"venue":"AAAI","id":"c4375d5e10d3118a433a12e7fbfcafc5b3507257","venue_1":"AAAI","year":"2008","title":"Multi-View Local Learning","authors":"Dan Zhang, Fei Wang, Changshui Zhang, Tao Li","author_ids":"3385810, 1682816, 1700883, 1726351","abstract":"The idea of local learning, i.e., classifying a particular example based on its neighbors, has been successfully applied to many semi-supervised and clustering problems recently. However, the local learning methods developed so far are all devised for single-view problems. In fact, in many real-world applications, examples are represented by multiple sets of features. In this paper, we extend the idea of local learning to multi-view problem, design a multi-view local model for each example, and propose a Multi-View Local Learning Regular-ization (MVLL-Reg) matrix. Both its linear and kernel version are given. Experiments are conducted to demonstrate the superiority of the proposed method over several state-of-the-art ones.","cites":"12","conferencePercentile":"61.86708861"},{"venue":"AAAI","id":"4318dafa6591bfe7c94d995c7a5d519bdb9aaa7a","venue_1":"AAAI","year":"2008","title":"Transferring Multi-device Localization Models using Latent Multi-task Learning","authors":"Vincent Wenchen Zheng, Sinno Jialin Pan, Qiang Yang, Jeffrey Junfeng Pan","author_ids":"3113725, 1790541, 1733090, 1730133","abstract":"In this paper, we propose a latent multi-task learning algorithm to solve the multi-device indoor localization problem. Traditional indoor localization systems often assume that the collected signal data distributions are fixed, and thus the localization model learned on one device can be used on other devices without adaptation. However, by empirically studying the signal variation over different devices, we found this assumption to be invalid in practice. To solve this problem, we treat multiple devices as multiple learning tasks, and propose a multi-task learning algorithm. Different from algorithms assuming that the hypotheses learned from the original data space for related tasks can be similar, we only require the hypotheses learned in a latent feature space are similar. To establish our algorithm, we employ an alternating optimization approach to iteratively learn feature mappings and multi-task regression models for the devices. We apply our latent multi-task learning algorithm to real-world indoor localization data and demonstrate its effectiveness.","cites":"19","conferencePercentile":"76.26582278"},{"venue":"AAAI","id":"34df85f4db9d1389c63da17f3ffbb7af1ed2ea0c","venue_1":"AAAI","year":"2007","title":"Coordinating Hundreds of Cooperative, Autonomous Vehicles in Warehouses","authors":"Peter R. Wurman, Raffaello D'Andrea, Mick Mountz","author_ids":"1722857, 7997128, 2301583","abstract":"ccasionally, mature industries are turned upside down by innovations. The years of research on robotics and multia-gent systems are coming together to provide just such a disruption to the material-handling industry. While autonomous guided vehicles (AGVs) have been used to move material within warehouses since the 1950s, they have been used primarily to transport very large, very heavy objects like rolls of uncut paper or engine blocks. The confluence of inexpensive wireless communications, computational power , and robotic components are making autonomous vehicles cheaper, smaller, and more capable. In recent years, we have seen an increase in the use of autonomous vehicles in the field. Examples include teleoperated military devices like iRobot's Packbot and the pilotless Predator aircraft, both of which have seen service in Iraq and Afghanistan. The Mars rovers, Spirit and Opportunity, exemplify the use of autonomous robots in scientific exploration. Closer to home, the Aerosonde autonomous aircraft has been used to plumb weather systems and recently flew in tropical storms that are unsafe for piloted aircraft. Commercially , autonomous vehicles are just hitting the market. ActivMedia's PatrolBot is a mobile monitoring system for buildings, and Aethon's Tug maneuvers supply carts around hospitals. Robots have even penetrated the home in an attempt to relieve homeowners of their most tiresome chores. iRobot sells the Roomba autonomous vacuum and the Scooba floor washer, and Friendly Robotics, among others, markets robotic lawn mowers. Many more research projects are under way to build robots for search and rescue, mine exploration, land ■ The Kiva warehouse-management system creates a new paradigm for pick-pack-and-ship warehouses that significantly improves worker productivity. The Kiva system uses movable storage shelves that can be lifted by small, autonomous robots. By bringing the product to the worker, productivity is increased by a factor of two or more, while simultaneously improving accountability and flexibility. A Kiva installation for a large distribution center may require 500 or more vehicles. As such, the Kiva system represents the first commercially available, large-scale autonomous robot system. The first permanent installation of a Kiva system was deployed in the summer of 2006.","cites":"91","conferencePercentile":"98.21958457"},{"venue":"AAAI","id":"745d33d1589d9dbdae6356918cfe1cab1ca6cc92","venue_1":"AAAI","year":"2008","title":"Transferring Localization Models over Time","authors":"Vincent Wenchen Zheng, Evan Wei Xiang, Qiang Yang, Dou Shen","author_ids":"3113725, 1687976, 1733090, 1680850","abstract":"Learning-based localization methods typically consist of an offline phase to collect the wireless signal data to build a statistical model, and an online phase to apply the model on new data. Many of these methods treat the training data as if their distributions are fixed across time. However, due to complex environmental changes such as temperature changes and multi-path fading effect , the signals can significantly vary from time to time, causing the localization accuracy to drop. We address this problem by introducing a novel semi-supervised Hidden Markov Model (HMM) to transfer the learned model from one time period to another. This adaptive model is referred to as transferred HMM (TrHMM), in which we aim to transfer as much knowledge from the old model as possible to reduce the calibration effort for the current time period. Our contribution is that we can successfully transfer out-of-date model to fit a current model through learning, even though the training data have very different distributions. Experimental results show that the TrHMM method can greatly improve the localization accuracy while saving a great amount of the calibration effort.","cites":"22","conferencePercentile":"80.69620253"},{"venue":"AAAI","id":"2ce197501c7dda0df483fc5a0651e144a7f356f4","venue_1":"AAAI","year":"2012","title":"Towards Population Scale Activity Recognition: A Framework for Handling Data Diversity","authors":"Saeed Abdullah, Nicholas D. Lane, Tanzeem Choudhury","author_ids":"2746906, 2772904, 1729948","abstract":"The rising popularity of the sensor-equipped smartphone is changing the possible scale and scope of human activity inference. The diversity in user population seen in large user bases can overwhelm conventional one-size-fits-all classication approaches. Although personalized models are better able to handle population diversity, they often require increased effort from the end user during training and are computationally expensive. In this paper, we propose an activity classification framework that is scalable and can tractably handle an increasing number of users. Scalability is achieved by maintaining distinct groups of similar users during the training process, which makes it possible to account for the differences between users without resorting to training individualized clas-sifiers. The proposed framework keeps user burden low by leveraging crowd-sourced data labels, where simple natural language processing techniques in combination with multi-instance learning are used to handle labeling errors introduced by low-commitment everyday users. Experiment results on a large public dataset demonstrate that the framework can cope with population diversity irrespective of population size.","cites":"7","conferencePercentile":"55.18292683"},{"venue":"AAAI","id":"c3c54686fa8613b7ed9d6f31692aee35cbf3a0d9","venue_1":"AAAI","year":"2008","title":"Prediction and Change Detection in Sequential Data for Interactive Applications","authors":"Jun Zhou, Li Cheng, Walter F. Bischof","author_ids":"1728391, 4826623, 1766762","abstract":"We consider the problems of sequential prediction and change detection that arise often in interactive applications: A semi-automatic predictor is applied to a time-series and is expected to make proper predictions and request new human input when change points are detected. Motivated by the Trans-ductive Support Vector Machines (Vapnik 1998), we propose an online framework that naturally addresses these problems in a unified manner. Our empirical study with a synthetic dataset and a road tracking dataset demonstrates the efficacy of the proposed approach.","cites":"4","conferencePercentile":"32.75316456"},{"venue":"AAAI","id":"97f1d7c360a1c7961b18fea65be4d7f5943ca946","venue_1":"AAAI","year":"2010","title":"Grouping Strokes into Shapes in Hand-Drawn Diagrams","authors":"Eric Jeffrey Peterson, Thomas F. Stahovich, Eric Doi, Christine Alvarado","author_ids":"7632258, 1706168, 2193378, 1836654","abstract":"Objects in freely-drawn sketches often have no spatial or temporal separation, making object recognition difficult. We present a two-step stroke-grouping algorithm that first classifies individual strokes according to the type of object to which they belong, then groups strokes with like classifications into clusters representing individual objects. The first step facilitates clustering by naturally separating the strokes, and both steps fluidly integrate spatial and temporal information. Our approach to grouping is unique in its formulation as an efficient classification task rather than, for example, an expensive search task. Our single-stroke classifier performs at least as well as existing single-stroke classifiers on text vs. non-text classification, and we present the first three-way single-stroke classification results. Our stroke grouping results are the first reported of their kind; our grouping algorithm correctly groups between 86% and 91% of the ink in diagrams from two domains, with between 69% and 79% of shapes being perfectly clustered.","cites":"13","conferencePercentile":"60.58020478"},{"venue":"AAAI","id":"0062b9ff8522498b34f467e36af218d87fcf5d9a","venue_1":"AAAI","year":"2006","title":"Nonnegative Matrix Factorization and Probabilistic Latent Semantic Indexing: Equivalence Chi-Square Statistic, and a Hybrid Method","authors":"Chris H. Q. Ding, Tao Li, Wei Peng","author_ids":"1737469, 1726351, 1716703","abstract":"Non-negative Matrix Factorization (NMF) and Probabilistic Latent Semantic Indexing (PLSI) have been successfully applied to document clustering recently. In this paper, we show that PLSI and NMF optimize the same objective function, although PLSI and NMF are different algorithms as verified by experiments. This provides a theoretical basis for a new hybrid method that runs PLSI and NMF alternatively, each jumping out of local minima of the other method successively , thus achieving better final solution. Extensive experiments on 5 real-life datasets show relations between NMF and PLSI, and indicate the hybrid method lead to significant improvements over NMF-only or PLSI-only methods. We also show that at first order approximation, NMF is identical to χ 2-statistic.","cites":"47","conferencePercentile":"88.04034582"},{"venue":"AAAI","id":"ad60c5eae7f7ad1f35c7a028c18445ea895f5709","venue_1":"AAAI","year":"2011","title":"Incorporating Boosted Regression Trees into Ecological Latent Variable Models","authors":"Rebecca A. Hutchinson, Li-Ping Liu, Thomas G. Dietterich","author_ids":"2491371, 2296568, 1699720","abstract":"Important ecological phenomena are often observed indirectly. Consequently, probabilistic latent variable models provide an important tool, because they can include explicit models of the ecological phenomenon of interest and the process by which it is observed. However, existing latent variable methods rely on hand-formulated parametric models, which are expensive to design and require extensive preprocessing of the data. Nonparametric methods (such as regression trees) automate these decisions and produce highly accurate models. However, existing tree methods learn direct map-pings from inputs to outputs—they cannot be applied to latent variable models. This paper describes a methodology for integrating non-parametric tree methods into probabilistic latent variable models by extending functional gradient boosting. The approach is presented in the context of occupancy-detection (OD) modeling, where the goal is to model the distribution of a species from imperfect detections. Experiments on 12 real and 3 synthetic bird species compare standard and tree-boosted OD models (latent variable models) with standard and tree-boosted logistic regression models (without latent structure). All methods perform similarly when predicting the observed variables , but the OD models learn better representations of the latent process. Most importantly, tree-boosted OD models learn the best latent representations when non-linearities and interactions are present. For many problems in ecology and ecosystem management, the phenomena of interest are not directly observed. Examples range from the basic spatial distribution of species to more complex phenomena such as dispersal, migration, and species interactions (mating, predation, etc.). Instead of direct observations, we often can obtain only indirect information such as animal sightings, abandoned nests, animal droppings, and so on. A fundamental challenge for data-driven modeling in ecology is to construct models of the phenemona of interest from such indirect information. In this paper, we consider a particular instance of this problem: modeling the habitat requirements of a species. A habitat model is a function f : X → Y , where x ∈ X describes the habitat at a site and y ∈ {0, 1} indicates whether the habitat is suitable or unsuitable for the species. To construct such a model using machine learning methods, one would like to visit a variety of sites and measure whether the species is present or absent at those sites. The resulting data could be applied to train a habitat model. Unfortunately , many species are difficult to detect (e.g., because they actively hide from people, they are camouflaged, or they roam …","cites":"7","conferencePercentile":"55.67010309"},{"venue":"AAAI","id":"4d5ddd81107b4db676c734d67aba7cc15498dd17","venue_1":"AAAI","year":"2008","title":"Online Learning with Expert Advice and Finite-Horizon Constraints","authors":"Branislav Kveton, Jia Yuan Yu, Georgios Theocharous, Shie Mannor","author_ids":"1681967, 3152306, 1709005, 1712535","abstract":"In this paper, we study a sequential decision making problem. The objective is to maximize the average reward accumulated over time subject to temporal cost constraints. The novelty of our setup is that the rewards and constraints are controlled by an adverse opponent. To solve our problem in a practical way, we propose an expert algorithm that guarantees both a vanishing regret and a sublinear number of violated constraints. The quality of this solution is demonstrated on a real-world power management problem. Our results support the hypothesis that online learning with convex cost constraints can be performed successfully in practice.","cites":"7","conferencePercentile":"45.41139241"},{"venue":"AAAI","id":"773ae063e3880008647af089cf1bc53cf369bcf7","venue_1":"AAAI","year":"2016","title":"Generalized Emphatic Temporal Difference Learning: Bias-Variance Analysis","authors":"Assaf Hallak, Aviv Tamar, Rémi Munos, Shie Mannor","author_ids":"2178037, 3025260, 1708654, 1712535","abstract":"We consider the off-policy evaluation problem in Markov decision processes with function approximation. We propose a generalization of the recently introduced emphatic temporal differences (ETD) algorithm (Sutton, Mahmood, and White, 2015), which encompasses the original ETD(λ), as well as several other off-policy evaluation algorithms as special cases. We call this framework ETD(λ, β), where our introduced parameter β controls the decay rate of an importance-sampling term. We study conditions under which the projected fixed-point equation underlying ETD(λ, β) involves a contraction operator , allowing us to present the first asymptotic error bounds (bias) for ETD(λ, β). Our results show that the original ETD algorithm always involves a contraction operator, and its bias is bounded. Moreover, by controlling β, our proposed generalization allows trading-off bias for variance reduction, thereby achieving a lower total error.","cites":"4","conferencePercentile":"79.72972973"},{"venue":"AAAI","id":"33e79d2ddc250a2a27dd8283b58d50af11935891","venue_1":"AAAI","year":"2006","title":"Evaluating Preference-based Search Tools: A Tale of Two Approaches","authors":"Paolo Viappiani, Boi Faltings, Pearl Pu","author_ids":"2188691, 1735128, 1781996","abstract":"People frequently use the worldwide web to find their most preferred item among a large range of options. We call this task preference-based search. The most common tool for preference-based search on the WWW today obtains users' preferences by asking them to fill in a form. It then returns a list of items that most closely match these preferences. Recently, several researchers have proposed tools for preference-based search that elicit preferences from the critiques a user actively makes on examples shown to them. We carried out a user study in order to compare the performance of traditional preference-based search tools using form-filling with two different versions of an example-critiquing tool. The results show that example critiquing achieves almost three times the decision accuracy, while requiring only slightly higher interaction effort.","cites":"19","conferencePercentile":"69.16426513"},{"venue":"AAAI","id":"127561f45a856571cd28cc6b9c94dd9c6176472b","venue_1":"AAAI","year":"2015","title":"Metric Learning Driven Multi-Task Structured Output Optimization for Robust Keypoint Tracking","authors":"Liming Zhao, Xi Li, Jun Xiao, Fei Wu, Yueting Zhuang","author_ids":"1789846, 1742869, 2781973, 1695826, 1755711","abstract":"As an important and challenging problem in computer vision and graphics, keypoint-based object tracking is typically formulated in a spatio-temporal statistical learning framework. However, most existing keypoint trackers are incapable of effectively model-ing and balancing the following three aspects in a simultaneous manner: temporal model coherence across frames, spatial model consistency within frames, and discriminative feature construction. To address this issue , we propose a robust keypoint tracker based on spatio-temporal multi-task structured output optimization driven by discriminative metric learning. Consequently , temporal model coherence is characterized by multi-task structured keypoint model learning over several adjacent frames, while spatial model consistency is modeled by solving a geometric verification based structured learning problem. Discriminative feature construction is enabled by metric learning to ensure the intra-class compactness and inter-class separability. Finally, the above three modules are simultaneously optimized in a joint learning scheme. Experimental results have demonstrated the effectiveness of our tracker.","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"4499ecc8a215d15c5e54a7389b6cadfd811a7e66","venue_1":"AAAI","year":"1991","title":"Making Design Objects Relevant to the Task at Hand","authors":"Gerhard Fischer, Kumiyo Nakakoji","author_ids":"2449381, 3204676","abstract":"Many problem-solving approaches are based on the assumption that a problem can be precisely defined before it is solved. These approaches are inadequate for dealing with ill-defined problems, which require the coevolution of problem setting and problem solving. In this paper, we describe integrated, domain-oriented. knowledge-based design environments and their underlying multifaceted architecture. The environments empower humans to cope with ill-defined problems. such as design. by supporting an incremental approach to problem setting and problem solving. We focus on the integration of specification, construction, and a catalog of prestored design objects in those environments. The synergy of integration enables the environments to make those objects relevant to the task at hand. Taking architectural design as a domain to illustrate our approach. we describe an operational, prototype system (CATALOOEXPWRER) that assists designers in locating examples in the catalog that are relevant to the task at hand as articulated by a partial specification and a partial construction. Users are thereby relieved of the task of forming queries and navigating in information spaces. Acknowledgements: The authors would like to thank the members of the Human-Computer Communication Group at the University of Colorado, who contributed to the development of the architecture of the multifaceted design environment and instantiated different components of it","cites":"24","conferencePercentile":"56.81818182"},{"venue":"AAAI","id":"88be79c9f8e247cbf8f6dfb494d63870f69fc1b0","venue_1":"AAAI","year":"2004","title":"CAMEO: Modeling Human Activity in Formal Meeting Situations","authors":"Paul E. Rybski, Fernando De la Torre, Raju Patil, Carlos Vallespí, Manuela M. Veloso, Brett Browning","author_ids":"1795451, 7821918, 3234486, 2668321, 1703940, 1699032","abstract":"We present CAMEO, the Camera Assisted Meeting Event Observer, which is a physical awareness system designed for use by an agent-based electronic assistant. CAMEO is used to observe formal meeting environments and infer the activities of people attending them.","cites":"0","conferencePercentile":"5.089820359"},{"venue":"AAAI","id":"c75e77ccc0feec272e7ca6d91a031e1b06e0f813","venue_1":"AAAI","year":"1994","title":"An Instructional Environment for Practicing Argumentation Skills","authors":"Vincent Aleven, Kevin D. Ashley","author_ids":"1779915, 1770311","abstract":"CAT0 is an instructions environment for practicing basic skills of legal research: to use cases in arguments about a problem situation and to test a theory about a legal domain. Using the CAT0 tools, law students analyze a legal problem, frame queries of CATO'S database of legal cases, and judge how relevant the retrieved cases are to their developing argument or theory. CAT0 aids hming by making explicit an abstract model of the process of argument. It allows students to focus on the high-level argumenta-tion issues, by assisting the student in various ways. By providing an abstract representation of the text of cases, it helps students to reason about the texts and helps guide their critical analysis of the texts. CAT0 makes available opportunities for practice that are hard to set up with traditional instructional methods. CAT0 differs from other instructional environments in the following respects: Few instructional environments focus on argumentation skills. Although there are other instructional environments in which students work with an abstract representation of the task domain , abstracting from text is unusual. CATO demonstrates a contribution that case-based reasoning techniques can make to instructional environments.","cites":"13","conferencePercentile":"50.66079295"},{"venue":"AAAI","id":"d2f94e1ababe4ac7438d159cc390075e70ca0928","venue_1":"AAAI","year":"2010","title":"Intelligently Aiding Human-Guided Correction of Speech Recognition","authors":"Keith Vertanen, Per Ola Kristensson","author_ids":"2314856, 1683133","abstract":"Correcting recognition errors is often necessary in a speech interface. The process of correcting errors can not only reduce users' performance, but can also lead to frustration. While making fewer recognition errors is undoubtedly helpful, facilities for supporting user-guided correction are also critical. We explore how to better support user corrections using Parakeet – a continuous speech recognition system for text entry. Para-keet's interface is designed for easy error correction on a mobile touch-screen device. Users correct errors by selecting alternative words from a word confusion network and by typing on a predictive software keyboard. Our interface design was guided by computational experiments and used a variety of information sources to aid the correction process. In user studies, participants were able to write text efficiently despite sometimes high initial recognition error rates. Using Parakeet as an example, we discuss principles we found were important for building an effective speech correction interface .","cites":"2","conferencePercentile":"17.57679181"},{"venue":"AAAI","id":"2e939ed3bb378ea966bf9f710fc1138f4e16ef38","venue_1":"AAAI","year":"2015","title":"Optimizing the CVaR via Sampling","authors":"Aviv Tamar, Yonatan Glassner, Shie Mannor","author_ids":"3025260, 2136461, 1712535","abstract":"Conditional Value at Risk (CVaR) is a prominent risk measure that is being used extensively in various domains. We develop a new formula for the gradient of the CVaR in the form of a conditional expectation. Based on this formula, we propose a novel sampling-based es-timator for the gradient of the CVaR, in the spirit of the likelihood-ratio method. We analyze the bias of the es-timator, and prove the convergence of a corresponding stochastic gradient descent algorithm to a local CVaR optimum. Our method allows to consider CVaR optimization in new domains. As an example, we consider a reinforcement learning application, and learn a risk-sensitive controller for the game of Tetris.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"252626cc5108e90f5c3c37e0712140bc4eeca037","venue_1":"AAAI","year":"2014","title":"Efficient Object Detection via Adaptive Online Selection of Sensor-Array Elements","authors":"Matthai Philipose","author_ids":"3041721","abstract":"We examine how to use emerging far-infrared imager ensembles to detect certain objects of interest (e.g., faces, hands, people and animals) in synchronized RGB video streams at very low power. We formulate the problem as one of selecting subsets of sensing elements (among many thousand possibilities) from the ensembles for tests. The subset selection problem is naturally adaptive and online: testing certain elements early can obviate the need for testing many others later, and selection policies must be updated at inference time. We pose the ensemble sensor selection problem as a struc-tured extension of test-cost-sensitive classification, propose a principled suite of techniques to exploit ensemble structure to speed up processing and show how to re-estimate policies fast. We estimate reductions in power consumption of roughly 50x relative to even highly optimized implementations of face detection, a canonical object-detection problem. We also illustrate the benefits of adaptivity and online estimation. Consider face detection on video streamed from a wearable device. The standard detection algorithm, due to Viola and Jones (Viola and Jones 2004), computes local features for every window in every video frame at various scales (while taking care to stay efficient by avoiding recomputing features) and classifies every window using a cascaded binary classifier that on average performs a dozen multiplications and additions on each window. Algorithms for detecting hands, objects and pedestrians have a similar windowed feature matching structure (Dalal, Triggs, and Schmid 2006). Proposed silicon implementations of the Viola-Jones algorithm would consume 600-800mW (Hori and Kuroda 2007; Aptina 2011) to process 10 frames/sec of 180 field-of-view (FOV) video. Given a realistic budget of roughly 7mW (based on a generous fraction of a 200mAh battery), we seek efficiency improvements approaching 100x even relative to silicon implementations. Our solution rests on two observations. First, as Viola and Jones originally noted, most pixel windows do not contain objects of interest (e.g., over 99% of windows in our day-today first-person video dataset contain no faces). Second, given gating imagers that measure quantities (e.g., tempera-Figure 1: Output from a 4-level FIR Ensemble. A single temperature threshold check at a small number of pixels (e.g., image 3 above has 400x fewer pixels than image 0!) suffices to reject most pixels. When possibly interesting pixels appear, finer-grained sensors may be used adaptively to confirm the object. E.g., image 2 may be used to find the whole head and image 1 to then confirm eye and …","cites":"0","conferencePercentile":"9.431818182"},{"venue":"AAAI","id":"3613a256a21f63a71e42a416126f8388fae2608d","venue_1":"AAAI","year":"2007","title":"Learning Large Scale Common Sense Models of Everyday Life","authors":"William Pentney, Matthai Philipose, Jeff A. Bilmes, Henry A. Kautz","author_ids":"2945977, 3041721, 1748118, 1690271","abstract":"Recent work has shown promise in using large, publicly available , hand-contributed commonsense databases as joint models that can be used to infer human state from day-today sensor data. The parameters of these models are mined from the web. We show in this paper that learning these parameters using sensor data (with the mined parameters as priors) can improve performance of the models significantly. The primary challenge in learning is scale. Since the model comprises roughly 50,000 irregularly connected nodes in each time slice, it is intractable either to completely label observed data manually or to compute the expected likelihood of even a single time slice. We show how to solve the resulting semi-supervised learning problem by combining a variety of conventional approximation techniques and a novel technique for simplifying the model called context-based pruning. We show empirically that the learned model is substantially better at interpreting sensor data and an detailed analysis of how various techniques contribute to the performance.","cites":"16","conferencePercentile":"64.9851632"},{"venue":"AAAI","id":"4867b6a9d556f7191da9b59f56f30734943c3304","venue_1":"AAAI","year":"2005","title":"Unsupervised Activity Recognition Using Automatically Mined Common Sense","authors":"Danny Wyatt, Matthai Philipose, Tanzeem Choudhury","author_ids":"2173752, 3041721, 1729948","abstract":"A fundamental difficulty in recognizing human activities is obtaining the labeled data needed to learn models of those activities. Given emerging sensor technology , however, it is possible to view activity data as a stream of natural language terms. Activity models are then mappings from such terms to activity names, and may be extracted from text corpora such as the web. We show that models so extracted are sufficient to automatically produce labeled segmentations of activity data with an accuracy of 42% over 26 activities, well above the 3.8% baseline. The segmentation so obtained is sufficient to bootstrap learning, with accuracy of learned models increasing to 52%. To our knowledge, this is the first human activity inferencing system shown to learn from sensed activity data with no human intervention per activity learned, even for labeling.","cites":"92","conferencePercentile":"97.2027972"},{"venue":"AAAI","id":"0679bcb9eca1e0d73a8d72f6f7f0e4cd9ba6557b","venue_1":"AAAI","year":"2014","title":"Learning Word Representation Considering Proximity and Ambiguity","authors":"Lin Qiu, Yong Cao, Zaiqing Nie, Yong Yu, Yong Rui","author_ids":"7653218, 4610410, 1786471, 3578922, 1728806","abstract":"Distributed representations of words (aka word embedding) have proven helpful in solving natural language processing (NLP) tasks. Training distributed representations of words with neural networks has lately been a major focus of researchers in the field. Recent work on word embedding, the Continuous Bag-of-Words (CBOW) model and the Continuous Skip-gram (Skip-gram) model, have produced particularly impressive results, significantly speeding up the training process to enable word representation learning from large-scale data. However, both CBOW and Skip-gram do not pay enough attention to word proximity in terms of model or word ambiguity in terms of linguistics. In this paper, we propose Proximity-Ambiguity Sensitive (PAS) models (i.e. PAS CBOW and PAS Skip-gram) to produce high quality distributed representations of words considering both word proximity and ambiguity. From the model perspective, we introduce proximity weights as parameters to be learned in PAS CBOW and used in PAS Skip-gram. By better modeling word proximity, we reveal the strength of pooling-structured neu-ral networks in word representation learning. The proximity-sensitive pooling layer can also be applied to other neural network applications that employ pooling layers. From the linguistics perspective, we train multiple representation vectors per word. Each representation vector corresponds to a particular group of POS tags of the word. By using PAS models, we achieved a 16.9% increase in accuracy over state-of-the-art models.","cites":"11","conferencePercentile":"89.54545455"},{"venue":"AAAI","id":"dc81be6bdf58ab9f17dfe5dbb513910a5bbf326e","venue_1":"AAAI","year":"2016","title":"Deploying nEmesis: Preventing Foodborne Illness by Data Mining Social Media","authors":"Adam Sadilek, Henry A. Kautz, Lauren DiPrete, Brian Labus, Eric Portman, Jack Teitel, Vincent Silenzio","author_ids":"1743087, 1690271, 3389665, 3369127, 2493227, 3376271, 7888142","abstract":"Foodborne illness afflicts 48 million people annually in the U.S. alone. Over 128,000 are hospitalized and 3,000 die from the infection. While preventable with proper food safety practices, the traditional restaurant inspection process has limited impact given the predictability and low frequency of inspections, and the dynamic nature of the kitchen environment. Despite this reality, the inspection process has remained largely unchanged for decades. We apply machine learning to Twitter data and develop a system that automatically detects venues likely to pose a public health hazard. Health professionals subsequently inspect individual flagged venues in a double blind experiment spanning the entire Las Vegas metropolitan area over three months. By contrast, previous research in this domain has been limited to indirect correlative validation using only aggregate statistics. We show that adaptive inspection process is 63% more effective at identifying problematic venues than the current state of the art. The live deployment shows that if every inspection in Las Vegas became adaptive, we can prevent over 9,000 cases of foodborne illness and 557 hospitalizations annually. Additionally, adap-tive inspections result in unexpected benefits, including the identification of venues lacking permits, contagious kitchen staff, and fewer customer complaints filed with the Las Vegas health department.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"3a6f2da37184d084a52deae39f35b631ab72ffae","venue_1":"AAAI","year":"2015","title":"Tackling Mental Health by Integrating Unobtrusive Multimodal Sensing","authors":"Dawei Zhou, Jiebo Luo, Vincent Silenzio, Yun Zhou, Jile Hu, Glenn Currier, Henry A. Kautz","author_ids":"2040018, 1717319, 7888142, 1733083, 2534582, 8737490, 1690271","abstract":"Mental illness is becoming a major plague in modern societies and poses challenges to the capacity of current public health systems worldwide. With the widespread adoption of social media and mobile devices, and rapid advances in artificial intelligence, a unique opportunity arises for tackling mental health problems. In this study, we investigate how users' online social activities and physiological signals detected through ubiquitous sensors can be utilized in realistic scenarios for monitoring their mental health states. First, we extract a suite of multimodal time-series signals using modern computer vision and signal processing techniques, from recruited participants while they are immersed in online social media that elicit emotions and emotion transitions. Next, we use machine learning techniques to build a model that establishes the connection between mental states and the extracted multimodal signals. Finally, we validate the effectiveness of our approach using two groups of recruited subjects .","cites":"4","conferencePercentile":"73.46456693"},{"venue":"AAAI","id":"6a4868e704774d2e23dab6802674898aad558676","venue_1":"AAAI","year":"2012","title":"Predicting Disease Transmission from Geo-Tagged Micro-Blog Data","authors":"Adam Sadilek, Henry A. Kautz, Vincent Silenzio","author_ids":"1743087, 1690271, 7888142","abstract":"Researchers have begun to mine social network data in order to predict a variety of social, economic, and health related phenomena. While previous work has focused on predicting aggregate properties, such as the prevalence of seasonal influenza in a given country, we consider the task of fine-grained prediction of the health of specific people from noisy and incomplete data. We construct a probabilistic model that can predict if and when an individual will fall ill with high precision and good recall on the basis of his social ties and co-locations with other people, as revealed by their Twitter posts. Our model is highly scalable and can be used to predict general dynamic properties of individuals in large real-world social networks. These results provide a foundation for research on fundamental questions of public health, including the identification of non-cooperative disease carriers (\" Typhoid Marys \"), adaptive vaccination policies, and our understanding of the emergence of global epidemics from day-today interpersonal interactions.","cites":"47","conferencePercentile":"97.56097561"},{"venue":"AAAI","id":"1c6f56c8cb224fb62c2dccd684b97110dc2a068b","venue_1":"AAAI","year":"2008","title":"Structure Learning on Large Scale Common Sense Statistical Models of Human State","authors":"William Pentney, Matthai Philipose, Jeff A. Bilmes","author_ids":"2945977, 3041721, 1748118","abstract":"Research has shown promise in the design of large scale common sense probabilistic models to infer human state from environmental sensor data. These models have made use of mined and preexisting common sense data and traditional probabilistic machine learning techniques to improve recognition of the state of everyday human life. In this paper, we demonstrate effective techniques for structure learning on graphical models designed for this domain, improving the SRCS system of (Pentney et al. 2006) by learning additional dependencies between variables. Because the models used for common sense reasoning typically involve a large number of variables, issues of scale arise in searching for additional dependencies; we discuss how we use data mining techniques to address this problem. We show experimentally that these techniques improve the accuracy of state prediction, and that, with a good prior model, the use of a common sense model with structure learning provides better prediction of unlabeled variables as well as labeled variables. The results also demonstrate that it is possible to collect new common sense information about daily life using such a statistical model and labeled data.","cites":"5","conferencePercentile":"37.65822785"},{"venue":"AAAI","id":"0ebc50b6e4b01eb5eba5279ce547c838890b1418","venue_1":"AAAI","year":"2014","title":"Similarity-Preserving Binary Signature for Linear Subspaces","authors":"Jianqiu Ji, Jianmin Li, Shuicheng Yan, Qi Tian, Bo Zhang","author_ids":"1901939, 8549039, 1698982, 1724745, 1696318","abstract":"Linear subspace is an important representation for many kinds of real-world data in computer vision and pattern recognition, e.g. faces, motion videos, speeches. In this paper, first we define pairwise angular similarity and angular distance for linear subspaces. The angular distance satisfies non-negativity, identity of indiscernibles, symmetry and triangle inequality, and thus it is a metric. Then we propose a method to compress linear sub-spaces into compact similarity-preserving binary signatures , between which the normalized Hamming distance is an unbiased estimator of the angular distance. We provide a lower bound on the length of the binary signatures which suffices to guarantee uniform distance-preservation within a set of subspaces. Experiments on face recognition demonstrate the effectiveness of the binary signature in terms of recognition accuracy, speed and storage requirement. The results show that, compared with the exact method, the approximation with the binary signatures achieves an order of magnitude speed-up, while requiring significantly smaller amount of storage space, yet it still accurately preserves the similarity, and achieves high recognition accuracy comparable to the exact method in face recognition.","cites":"0","conferencePercentile":"9.431818182"},{"venue":"AAAI","id":"b2bbb662be4b3e661c3ad3b9f42e978a2cfef8e5","venue_1":"AAAI","year":"2013","title":"Guiding Scientific Discovery with Explanations Using DEMUD","authors":"Kiri Wagstaff, Nina L. Lanza, David R. Thompson, Thomas G. Dietterich, Martha S. Gilmore","author_ids":"1717062, 1975686, 6151966, 1699720, 2329735","abstract":"In the era of large scientific data sets, there is an urgent need for methods to automatically prioritize data for review. At the same time, for any automated method to be adopted by scientists, it must make decisions that they can understand and trust. In this paper, we propose Discovery through Eigenbasis Modeling of Uninteresting Data (DEMUD), which uses principal components modeling and reconstruction error to prioritize data. DEMUD's major advance is to offer domain-specific explanations for its prioritizations. We evaluated DE-MUD's ability to quickly identify diverse items of interest and the value of the explanations it provides. We found that DEMUD performs as well or better than existing class discovery methods and provides, uniquely, the first explanations for why those items are of interest. Further, in collaborations with planetary scientists, we found that DEMUD (1) quickly identifies very rare items of scientific value, (2) maintains high diversity in its selections, and (3) provides explanations that greatly improve human classification accuracy.","cites":"5","conferencePercentile":"62.54545455"},{"venue":"AAAI","id":"6f617e755127a883c5b7e4f992b61c08e02db98d","venue_1":"AAAI","year":"2013","title":"Approximate Bayesian Inference for Reconstructing Velocities of Migrating Birds from Weather Radar","authors":"Daniel Sheldon, Andrew Farnsworth, Jed Irvine, Benjamin Van Doren, Kevin F. Webb, Thomas G. Dietterich, Steve Kelling","author_ids":"1777803, 5097676, 2079303, 2004116, 5798501, 1699720, 1767465","abstract":"Archived data from the WSR-88D network of weather radars in the US hold detailed information about the continent-scale migratory movements of birds over the last 20 years. However, significant technical challenges must be overcome to understand this information and harness its potential for science and conservation. We present an approximate Bayesian inference algorithm to reconstruct the velocity fields of birds migrating in the vicinity of a radar station. This is part of a larger project to quantify bird migration at large scales using weather radar data.","cites":"4","conferencePercentile":"55.45454545"},{"venue":"AAAI","id":"25c6a00407908a956e147daea6685bd222994dbb","venue_1":"AAAI","year":"2015","title":"Plurality Voting Under Uncertainty","authors":"Reshef Meir","author_ids":"1769579","abstract":"Understanding the nature of strategic voting is the holy grail of social choice theory, where game-theory, social science and recently computational approaches are all applied in order to model the incentives and behavior of voters. In a recent paper, Meir et al. [15] made another step in this direction, by suggesting a behavioral game-theoretic model for voters under uncertainty. For a specific variation of best-response heuristics, they proved initial existence and convergence results in the Plurality voting system. In this paper, we extend the model in multiple directions, considering voters with different uncertainty levels, simultaneous strategic decisions, and a more permissive notion of best-response. We prove that a voting equilibrium exists even in the most general case. Further, any society voting in an iterative setting is guaranteed to converge. We also analyze an alternative behavior where voters try to minimize their worst-case regret. We show that the two behaviors coincide in the simple setting of Meir et al., but not in the general case.","cites":"4","conferencePercentile":"73.46456693"},{"venue":"AAAI","id":"7cf88aae176b480fdffabfaddcb7afbb83b6d99e","venue_1":"AAAI","year":"2013","title":"Bundling Attacks in Judgment Aggregation","authors":"Noga Alon, Dvir Falik, Reshef Meir, Moshe Tennenholtz","author_ids":"1734327, 2334124, 1769579, 1708847","abstract":"We consider judgment aggregation over multiple independent issues, where the chairperson has her own opinion, and can try to bias the outcome by bundling several issues together. Since for each bundle judges must give a uniform answer on all issues, different partitions of the issues may result in an outcome that significantly differs from the \" true \" , issue-wise, decision. We prove that the bundling problem faced by the chairperson, i.e. trying to bias the outcome towards her own opinion, is computationally difficult in the worst case. Then we study the probability that an effective bundling attack exists as the disparity between the opinions of the judges and the chair varies. We show that if every judge initially agrees with the chair on every issue with probability of at least 1 /2, then there is almost always a bundling attack (i.e. a partition) where the opinion of the chair on all issues is approved. Moreover, such a partition can be found efficiently. In contrast, when the probability is lower than 1 /2 then the chair cannot force her opinion using bundling even on a single issue.","cites":"6","conferencePercentile":"68.90909091"},{"venue":"AAAI","id":"d633a99c34548c293ee20ddcec8e0dffdd4e5e13","venue_1":"AAAI","year":"1992","title":"An On-Line Computational Model of Human Sentence Interpretation","authors":"Daniel Jurafsky","author_ids":"1746807","abstract":"Public reporting burden for the collection of information is estimated to average 1 hour per response, including the time for reviewing instructions, searching existing data sources, gathering and maintaining the data needed, and completing and reviewing the collection of information. Send comments regarding this burden estimate or any other aspect of this collection of information, including suggestions for reducing this burden, to Washington Headquarters Services, Directorate for Information Operations and Reports, 1215 Jefferson Davis Highway, Suite 1204, Arlington VA 22202-4302. Respondents should be aware that notwithstanding any other provision of law, no person shall be subject to a penalty for failing to comply with a collection of information if it does not display a currently valid OMB control number.","cites":"31","conferencePercentile":"51.78571429"},{"venue":"AAAI","id":"00af4fba4bc85262d381881848c3ad67536fcb6b","venue_1":"AAAI","year":"2015","title":"A Multivariate Timeseries Modeling Approach to Severity of Illness Assessment and Forecasting in ICU with Sparse, Heterogeneous Clinical Data","authors":"Marzyeh Ghassemi, Marco A. F. Pimentel, Tristan Naumann, Thomas Brennan, David A. Clifton, Peter Szolovits, Mengling Feng","author_ids":"2804918, 3346773, 2522240, 6788800, 1803625, 1679873, 2773476","abstract":"The ability to determine patient acuity (or severity of illness) has immediate practical use for clinicians. We evaluate the use of multivariate timeseries modeling with the multi-task Gaussian process (GP) models using noisy, incomplete, sparse, heterogeneous and unevenly-sampled clinical data, including both physiological signals and clinical notes. The learned multi-task GP (MTGP) hyperparameters are then used to assess and forecast patient acuity. Experiments were conducted with two real clinical data sets acquired from ICU patients: firstly, estimating cerebrovascular pressure reactivity, an important indicator of secondary damage for traumatic brain injury patients, by learning the interactions between intracranial pressure and mean arterial blood pressure signals, and secondly, mortality prediction using clinical progress notes. In both cases, MTGPs provided improved results: an MTGP model provided better results than single-task GP models for signal interpolation and forecasting (0.91 vs 0.69 RMSE), and the use of MTGP hyperparameters obtained improved results when used as additional classification features (0.812 vs 0.788 AUC).","cites":"11","conferencePercentile":"93.85826772"},{"venue":"AAAI","id":"3f1cdb1702301ccb2499d30ab26baf903b61ada9","venue_1":"AAAI","year":"1993","title":"Understanding Linkages","authors":"Howard E. Shrobe","author_ids":"1716356","abstract":"Mechanical linkages are used to transmit and transform motion. In this paper we investigate what it might mean to \"understand\" a linkage, i.e. how one would explain the functioning of the system. We present a system capable of understanding a variety of relatively simple linkage mechanisms found in standard references. Our system extracts its understanding by analyzing the results of a numerical simulation of the mechanism. It proceeds through several stages: The simulator builds a trace of its reasoning which is parsed and analyzed, leading to a structuring of the mechanism into driving and driven components. The trajectories of the coupling points are then analyzed to find interesting qualitative features, aa are the curves representing the histories of angular deflections of rocker arms. Next the system looks for symbolic relationships between the features and conjectures a causal relationship between them. Finally, this causal relationship is verified by geometric reasoning. This process produces explanations very much like those in standard texts. 1 Motivation Mechanical linkages are used to transmit and transform motion. In this paper we investigate what it might mean to \"understand\" a linkage, i.e. how one would explain the functioning of the system. We constrain ourselves to simple mechanisms with a single degree of freedom. Figure 11 shows a \"dwell mechanism \"~ with its explanation reproduced from [1]. (We have highlighted parts of this explanation). This paper presents a system which can \"un-derstand\" this linkage. For those not familiar with linkages, we note that the set of links 1,2, and 3 together with the fixed frame, is a \"four-bar linkage\" (with joints A,B,C and D) and that the pair of links 4 and 5 (with joints F and G) is a \"dyad\". Link 2 is the \"coupler\" of the four-bar linkage; since point z In this picture, the links are draw as bars, except that link 2 has a long finger projecting from it to point E making it look link u inverted T. Circles are used to indicate the joints between the links. The \"ground\" symbols are used to indicate that link AB is rigidly connected to the fixed frame and that joint G connects link 5 to the fixed frame. ~A dwell mecbanllm is one in which some part moves (in this case oscillates) most of the time, but for some period of time stands still (i.e. dwells). AD = 6AB, GD-8.4AB and AG = 1lAB. Link …","cites":"9","conferencePercentile":"23.64864865"},{"venue":"AAAI","id":"1e1ba5c017a2b087e53b771c18bda273a39920e9","venue_1":"AAAI","year":"1993","title":"Supporting and Optimizing Full Unification in a Forward Chaining Rule System","authors":"Howard E. Shrobe","author_ids":"1716356","abstract":"The Rete and Treat algorithms are considered the most efficient implementation techniques for Forward Chaining rule systems. These algorithms support a language of limited expressive power. Assertions are not allowed to contain variables, making universal quantification impossible to express except as a rule. In this paper we show how to support full unification in these algorithms. We also show that: Supporting full unification is costly; Full unification is not used frequently; A combination of compile time and run time checks can determine when full unification is not needed. We present data to show that the cost of supporting full unification can be reduced in proportion to the degree that it isn't employed and that for many practical systems this cost is negligible.","cites":"0","conferencePercentile":"2.027027027"},{"venue":"AAAI","id":"d514b1725430e72cea9d8cb2399332e28a56fadf","venue_1":"AAAI","year":"2015","title":"PD Disease State Assessment in Naturalistic Environments Using Deep Learning","authors":"Nils Y. Hammerla, James Fisher, Peter Andras, Lynn Rochester, Richard Walker, Thomas Plötz","author_ids":"3128867, 4979384, 1682170, 2242456, 2801535, 7606729","abstract":"Management of Parkinson's Disease (PD) could be improved significantly if reliable, objective information about fluctuations in disease severity can be obtained in ecologically valid surroundings such as the private home. Although automatic assessment in PD has been studied extensively, so far no approach has been devised that is useful for clinical practice. Analysis approaches common for the field lack the capability of exploiting data from realistic environments, which represents a major barrier towards practical assessment systems. The very unreliable and infrequent labelling of ambiguous, low resolution movement data collected in such environments represents a very challenging analysis setting, where advances would have significant societal impact in our ageing population. In this work we propose an assessment system that abides practical usability constraints and applies deep learning to differentiate disease state in data collected in naturalistic settings. Based on a large data-set collected from 34 people with PD we illustrate that deep learning outperforms other approaches in generalisation performance, despite the unreliable labelling characteristic for this problem setting, and how such systems could improve current clinical practice.","cites":"16","conferencePercentile":"96.61417323"},{"venue":"AAAI","id":"ba3437093cdb98b718f704beefd47047f7c84ecb","venue_1":"AAAI","year":"2006","title":"Comparative Experiments on Sentiment Classification for Online Product Reviews","authors":"Hang Cui, Vibhu O. Mittal, Mayur Datar","author_ids":"3129614, 1751139, 1703747","abstract":"Evaluating text fragments for positive and negative subjective expressions and their strength can be important in applications such as single-or multi-document sum-marization, document ranking, data mining, etc. This paper looks at a simplified version of the problem: classifying online product reviews into positive and negative classes. We discuss a series of experiments with different machine learning algorithms in order to experimentally evaluate various trade-offs, using approximately 100K product reviews from the web.","cites":"108","conferencePercentile":"98.27089337"},{"venue":"AAAI","id":"b6298d0c3756001527f5f85deba7953f214c19fa","venue_1":"AAAI","year":"2015","title":"Incentive Networks","authors":"Yuezhou Lv, Thomas Moscibroda","author_ids":"1710143, 1715172","abstract":"In a basic economic system, each participant receives a (financial) reward according to his own contribution to the system. In this work, we study an alternative approach – Incentive Networks – in which a participant's reward depends not only on his own contribution; but also in part on the contributions made by his social contacts or friends. We show that the key parameter effecting the efficiency of such an Incentive Network-based economic system depends on the participant's degree of directed altruism. Directed altruism is the extent to which someone is willing to work if his work results in a payment to his friend, rather than to himself. Specifically, we characterize the condition under which an Incentive Network-based economy is more efficient than the basic \" pay-for-your-contribution \" economy. We quantify by how much incentive networks can reduce the total reward that needs to be paid to the participants in order to achieve a certain overall contribution. Finally, we study the impact of the network topology and various exogenous parameters on the efficiency of incentive networks. Our results suggest that in many practical settings, Incentive Network-based reward systems or compensation structures could be more efficient than the ubiquitous 'pay-for-your-contribution' schemes.","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"480e34860b1e458502db6a464e1ce9e8c0e3cc81","venue_1":"AAAI","year":"2006","title":"An Efficient Algorithm for Local Distance Metric Learning","authors":"Liu Yang, Rong Jin, Rahul Sukthankar, Yi Liu","author_ids":"1745614, 1718400, 1694199, 1691635","abstract":"Learning application-specific distance metrics from labeled data is critical for both statistical classification and information retrieval. Most of the earlier work in this area has focused on finding metrics that simultaneously optimize compactness and separability in a global sense. Specifically, such distance metrics attempt to keep all of the data points in each class close together while ensuring that data points from different classes are separated. However, particularly when classes exhibit multimodal data distributions, these goals conflict and thus cannot be simultaneously satisfied. This paper proposes a Local Distance Metric (LDM) that aims to optimize local compactness and local separability. We present an efficient algorithm that employs eigenvector analysis and bound optimization to learn the LDM from training data in a probabilistic framework. We demonstrate that LDM achieves significant improvements in both classification and retrieval accuracy compared to global distance learning and kernel-based KNN.","cites":"63","conferencePercentile":"93.51585014"},{"venue":"AAAI","id":"159e19d9dc23ccc345dec740ef2c994f0de33027","venue_1":"AAAI","year":"2006","title":"Semi-supervised Multi-label Learning by Constrained Non-negative Matrix Factorization","authors":"Yi Liu, Rong Jin, Liu Yang","author_ids":"1691635, 1718400, 1745614","abstract":"We present a novel framework for multi-label learning that explicitly addresses the challenge arising from the large number of classes and a small size of training data. The key assumption behind this work is that two examples tend to have large overlap in their assigned class memberships if they share high similarity in their input patterns. We capitalize this assumption by first computing two sets of similarities, one based on the input patterns of examples, and the other based on the class memberships of the examples. We then search for the optimal assignment of class memberships to the unlabeled data that minimizes the difference between these two sets of similarities. The optimization problem is formulated as a constrained Non-negative Matrix Factorization (NMF) problem, and an algorithm is presented to efficiently find the solution. Compared to the existing approaches for multi-label learning, the proposed approach is advantageous in that it is able to explore both the unlabeled data and the correlation among different classes simultaneously. Experiments with text categorization show that our approach performs significantly better than several state-of-the-art classification techniques when the number of classes is large and the size of training data is small.","cites":"88","conferencePercentile":"96.25360231"},{"venue":"AAAI","id":"ce29db10680a9f29413319561f21134557907b9b","venue_1":"AAAI","year":"2015","title":"A Neural Probabilistic Model for Context Based Citation Recommendation","authors":"Wenyi Huang, Zhaohui Wu, Liang Chen, Prasenjit Mitra, C. Lee Giles","author_ids":"1869202, 1687635, 1692551, 1714911, 1749125","abstract":"Automatic citation recommendation can be very useful for authoring a paper and is an AI-complete problem due to the challenge of bridging the semantic gap between citation context and the cited paper. It is not always easy for knowledgeable researchers to give an accurate citation context for a cited paper or to find the right paper to cite given context. To help with this problem , we propose a novel neural probabilistic model that jointly learns the semantic representations of citation contexts and cited papers. The probability of citing a paper given a citation context is estimated by training a multi-layer neural network. We implement and evaluate our model on the entire CiteSeer dataset, which at the time of this work consists of 10,760,318 citation contexts from 1,017,457 papers. We show that the proposed model significantly outperforms other state-of-the-art models in recall, MAP, MRR, and nDCG.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"a33ac390bf7dc0602d803f27a08199ff7b9cb239","venue_1":"AAAI","year":"2015","title":"Sense-Aaware Semantic Analysis: A Multi-Prototype Word Representation Model Using Wikipedia","authors":"Zhaohui Wu, C. Lee Giles","author_ids":"1687635, 1749125","abstract":"Human languages are naturally ambiguous, which makes it difficult to automatically understand the semantics of text. Most vector space models (VSM) treat all occurrences of a word as the same and build a single vector to represent the meaning of a word, which fails to capture any ambiguity. We present sense-aware semantic analysis (SaSA), a multi-prototype VSM for word representation based on Wikipedia, which could account for homonymy and polysemy. The \" sense-specific \" prototypes of a word are produced by clustering Wikipedia pages based on both local and global contexts of the word in Wikipedia. Experimental evaluation on semantic relatedness for both isolated words and words in senten-tial contexts and word sense induction demonstrate its effectiveness.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"5cca89cf43f7fac240a621bec16c2c4c6743c57d","venue_1":"AAAI","year":"2010","title":"Non-Negative Matrix Factorization with Constraints","authors":"Haifeng Liu, Zhaohui Wu","author_ids":"1678964, 1687635","abstract":"Non-negative matrix factorization (NMF), as a useful decomposition method for multivariate data, has been widely used in pattern recognition, information retrieval and computer vision. NMF is an effective algorithm to find the latent structure of the data and leads to a parts-based representation. However, NMF is essentially an unsupervised method and can not make use of label information. In this paper, we propose a novel semi-supervised matrix decomposition method, called Constrained Non-negative Matrix Factorization, which takes the label information as additional constraints. Specifically, we require that the data points sharing the same label have the same coordinate in the new representation space. This way, the learned representations can have more discriminating power. We demonstrate the effectiveness of this novel algorithm through a set of evaluations on real world applications.","cites":"11","conferencePercentile":"54.94880546"},{"venue":"AAAI","id":"bfc6765e7ff3c5d8f9ba5ba0c6bdbb0bfc0f20f6","venue_1":"AAAI","year":"2011","title":"Self-Aware Traffic Route Planning","authors":"David Wilkie, Jur P. van den Berg, Ming C. Lin, Dinesh Manocha","author_ids":"2293889, 1764300, 1709625, 1699159","abstract":"One of the most ubiquitous AI applications is vehicle route planning. While state-of-the-art systems take into account current traffic conditions or historic traffic data, current planning approaches ignore the impact of their own plans on the future traffic conditions. We present a novel algorithm for self-aware route planning that uses the routes it plans for current vehicle traffic to more accurately predict future traffic conditions for subsequent cars. Our planner uses a roadmap with stochastic, time-varying traffic densities that are defined by a combination of historical data and the densities predicted by the planned routes for the cars ahead of the current traffic. We have applied our algorithm to large-scale traffic route planning, and demonstrated that our self-aware route planner can more accurately predict future traffic conditions, which results in a reduction of the travel time for those vehicles that use our algorithm.","cites":"8","conferencePercentile":"60.82474227"},{"venue":"AAAI","id":"79db4fef0091d37db681ead0941a4c33378d4ae6","venue_1":"AAAI","year":"2007","title":"On Capturing Semantics in Ontology Mapping","authors":"Bo Hu, Srinandan Dasmahapatra, Paul H. Lewis, Nigel Shadbolt","author_ids":"7137080, 2336372, 1773066, 1705314","abstract":"Semantic interoperability between disparate systems in open, distributed environments has become the quest of many practitioners in a variety of fields. One way to achieve such a goal is through ontology mapping. The perspective users of such technology, however, are faced with a number of challenges including ambiguity of the meaning of mappings, difficulties of capturing semantics, choice of the right ontology mapping tools, verification and validation of results and operationalisation in the beneficiary semantic web application. In this paper we present a formalisation of ontologies and a triangle model for the ontology mapping problems. This formal-isation of ontology mapping reflects the engineering steps needed to materialise a versatile mapping system in order to faithfully recapture the semantics embodied in ontologies which is the fundamental requirements posed by the semantic web environment. We further accommodate this formalisation with a series of specialist algorithms targeting at particular aspects of semantic capturing. Finally, we evaluated the proposed algorithms by way of ontology mapping benchmark tests.","cites":"8","conferencePercentile":"46.29080119"},{"venue":"AAAI","id":"1cea0162dd80c017db662f43cb8c0659f07680dc","venue_1":"AAAI","year":"2016","title":"Seeing the Unseen Network: Inferring Hidden Social Ties from Respondent-Driven Sampling","authors":"Lin Chen, Forrest W. Crawford, Amin Karbasi","author_ids":"3407460, 3123440, 1697131","abstract":"Learning about the social structure of hidden and hard-to-reach populations — such as drug users and sex workers — is a major goal of epidemiological and public health research on risk behaviors and disease prevention. Respondent-driven sampling (RDS) is a peer-referral process widely used by many health organizations, where research subjects recruit other subjects from their social network. In such surveys, researchers observe who recruited whom, along with the time of recruitment and the total number of acquaintances (network degree) of respondents. However, due to privacy concerns , the identities of acquaintances are not disclosed. In this work, we show how to reconstruct the underlying network structure through which the subjects are recruited. We formulate the dynamics of RDS as a continuous-time diffusion process over the underlying graph and derive the likelihood of the recruitment time series under an arbitrary inter-recruitment time distribution. We develop an efficient stochastic optimization algorithm called RENDER (REspoNdent-Driven nEtwork Reconstruction) that finds the network that best explains the collected data. We support our analytical results through an exhaustive set of experiments on both synthetic and real data.","cites":"2","conferencePercentile":"61.31756757"},{"venue":"AAAI","id":"c6c2f5e3f7769bcfb175e02a910ff18990970cd7","venue_1":"AAAI","year":"2016","title":"Jointly Modeling Topics and Intents with Global Order Structure","authors":"Bei Chen, Jun Zhu, Nan Yang, Tian Tian, Ming Zhou, Bo Zhang","author_ids":"2571156, 1748711, 1823973, 3382824, 5962676, 1696318","abstract":"Modeling document structure is of great importance for discourse analysis and related applications. The goal of this research is to capture the document intent structure by modeling documents as a mixture of topic words and rhetorical words. While the topics are relatively unchanged through one document , the rhetorical functions of sentences usually change following certain orders in discourse. We propose GMM-LDA, a topic modeling based Bayesian unsupervised model, to analyze the document intent structure cooperated with order information. Our model is flexible that has the ability to combine the annotations and do supervised learning. Additionally , entropic regularization can be introduced to model the significant divergence between topics and intents. We perform experiments in both unsupervised and supervised settings , results show the superiority of our model over several state-of-the-art baselines.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"c7b634bd95d2dfa12fbf2989370a942e15911260","venue_1":"AAAI","year":"1991","title":"A Minimal Encoding Approach to Feature Discovery","authors":"Mark Derthick","author_ids":"2987887","abstract":"This paper discusses unsupervised learning of orthogonal concepts on relational data. Relational predicates, while formally equivalent to the features of the concept-learning literature, are not a good basis for deen-ing concepts. Hence the current t a s k d e m a n d s a m uch larger search space than traditional concept learning algorithms, the sort of space explored by connectionist algorithms. However the intended application, using the discovered concepts in the Cyc knowledge base, requires that the concepts be interpretable by a h uman, an ability not yet realized with connection-ist algorithms. Interpretability is aided by including a characterization of simplicity in the evaluation function. For Hinton's Family Relations data, we do nd cleaner, more intuitive features. Yet when the solutions are not known in advance, the diiculty o f i n terpreting even features meeting the simplicity criteria calls into question the usefulness of any reformula-tion algorithm that creates radically new primitives in a knowledge-based setting. At the very least, much more sophisticated explanation tools are needed. This paper discusses conceptual clustering using the Minimum Description Length principle in a domain of family relationships rst solved by H i n ton using back-propagation. This problem is unsuitable for algorithms such as ID3 because the features used in the problem description are very far removed from those present i n a n i n tuitive theory of family relationships. The algorithm described here, like back-propagation, uses constructive induction to discover a new set of features. The goal is then to use them in rules in the Cyc knowledge base to capture some of the domain regularities. Hence the features must be interpretable by a h uman. This requires maintaining the power of connectionist systems to discover completely new features while enhancing interpretability, w h i c h is accomplished by including a characterization of feature simplicity in the feature evaluation function. Indeed no other algorithm has discovered such clean intuitive features for problems, like F amily Relations, in which the original data is not naturally represented as feature-vectors. Yet this success has pointed out the diiculty o f i n terpreting even very good features, and calls into question the usefulness of any representation discovery algorithm that creates radically new primitives in a knowledge-based setting. At the very least, much more sophisticated explanation tools are needed.","cites":"9","conferencePercentile":"25"},{"venue":"AAAI","id":"024fb7a47f121d93415f8e2be6343c5975db90de","venue_1":"AAAI","year":"1993","title":"Learning Object Models from Appearance","authors":"Hiroshi Murase, Shree K. Nayar","author_ids":"1725612, 1750470","abstract":"We address the problem of automatically learning object models for recognition and pose estimation. In contrast to the traditional approach, we formulate the recognition problem as one of matching visual appearance rather than shape. The appearance of an object in a two-dimensional image depends on its shape, pose in the scene, reflectance properties, and the illumination conditions. While shape and reflectance are intrinsic properties of an object and are constant, pose and illumination vary from scene to scene. We present a new compact representation of object appearance that is parametrized by pose and illumination. For each object of interest, a large set of images is obtained by automatically varying pose and illumination. This large image set is compressed to obtain a low-dimensional subspace, called the eigenspace, in which the object is represented as a hypersur-face. Given an unknown input image, the recognition system projects the image onto the eigenspace. The object is recognized based on the hypersurface it lies on. The exact position of the projection on the hypersurface determines the object's pose in the image. We have conducted experiments using several objects with complex appearance characteristics. These results suggest the proposed appearance representation to be a valuable variety of machine vision applications.","cites":"34","conferencePercentile":"67.56756757"},{"venue":"AAAI","id":"57564680a3f6fb5c25ca86a7fbcef50e096e74a8","venue_1":"AAAI","year":"2015","title":"Sparse Deep Stacking Network for Image Classification","authors":"Jun Li, Heyou Chang, Jian Yang","author_ids":"1681426, 1918862, 1704854","abstract":"Sparse coding can learn good robust representation to noise and model more higher-order representation for image classification. However, the inference algorithm is computationally expensive even though the supervised signals are used to learn compact and discriminative dictionaries in sparse coding techniques. Luckily, a simplified neural network module (SNNM) has been proposed to directly learn the discriminative dictionaries for avoiding the expensive inference. But the SNNM module ignores the sparse representations. Therefore, we propose a sparse SNNM module by adding the mixed-norm regularization (l1/l2 norm). The sparse SNNM modules are further stacked to build a sparse deep stacking network (S-DSN). In the experiments, we evaluate S-DSN with four databases, including Extended YaleB, AR, 15 scene and Caltech101. Experimental results show that our model outperforms related classification methods with only a linear classifier. It is worth noting that we reach 98.8% recognition accuracy on 15 scene.","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"7eaecd108e3e4a8d9fcdfa7ba4d09be72a20af68","venue_1":"AAAI","year":"2008","title":"Another Look at Search-Based Drama Management","authors":"Mark J. Nelson, Michael Mateas","author_ids":"1763490, 1780919","abstract":"A drama manager (DM) monitors an interactive experience, such as a computer game, and intervenes to shape the global experience so it satisfies the author's expressive goals without decreasing a player's interactive agency. In declarative optimization-based drama management (DODM), the author declaratively specifies desired properties of the experience; the DM optimizes its interventions to maximize that metric. The initial DODM approach used online search to optimize an experience-quality function. Subsequent work questioned whether online search could perform well in general, and proposed alternative optimization frameworks such as reinforcement learning. Recent work on targeted trajectory distribution Markov decision processes (TTD-MDPs) replaced the experience-quality metric with a metric and associated algorithm based on targeting experience distributions. We argue that optimizing an experience-quality function does not destroy interactive agency, as has been claimed, and that in fact it can capture that goal directly. We further show that, though apparently quite different on the surface, the original search approach and TTD-MDPs actually use variants of the same underlying search algorithm, and that offline cached search, as is done by the TTD-MDP algorithm, allows the search-based systems to achieve similar results to TTD-MDPs.","cites":"5","conferencePercentile":"37.65822785"},{"venue":"AAAI","id":"1bb3dd1e7795f08156db4e4b13900b76d35db962","venue_1":"AAAI","year":"2006","title":"Targeting Specific Distributions of Trajectories in MDPs","authors":"David L. Roberts, Mark J. Nelson, Charles Lee Isbell, Michael Mateas, Michael L. Littman","author_ids":"5797583, 1763490, 1787816, 1780919, 1735162","abstract":"We define TTD-MDPs, a novel class of Markov decision processes where the traditional goal of an agent is changed from finding an optimal trajectory through a state space to realizing a specified distribution of trajectories through the space. After motivating this formulation, we show how to convert a traditional MDP into a TTD-MDP. We derive an algorithm for finding non-deterministic policies by constructing a trajectory tree that allows us to compute locally-consistent policies. We specify the necessary conditions for solving the problem exactly and present a heuristic algorithm for constructing policies when an exact answer is impossible or impractical. We present empirical results for our algorithm in two domains: a synthetic grid world and stories in an interactive drama or game.","cites":"44","conferencePercentile":"85.73487032"},{"venue":"AAAI","id":"1bee4af1a7ad61c9472eb7cea593fa78517f5e3b","venue_1":"AAAI","year":"2014","title":"Dramatis: A Computational Model of Suspense","authors":"Brian O'Neill, Mark O. Riedl","author_ids":"8399663, 2757194","abstract":"We introduce Dramatis, a computational model of suspense based on a reformulation of a psychological definition of the suspense phenomenon. In this reformulation, suspense is correlated with the audience's ability to generate a plan for the protagonist to avoid an impending negative outcome. Dramatis measures the suspense level by generating such a plan and determining its perceived likelihood of success. We report on three evaluations of Dramatis, including a comparison of Dramatis output to the suspense reported by human readers, as well as ablative tests of Dramatis components. In these studies, we found that Dramatis output corresponded to the suspense ratings given by human readers for stories in three separate domains.","cites":"5","conferencePercentile":"67.5"},{"venue":"AAAI","id":"013458b043b5f1c02178c937fe46148a6bb9364b","venue_1":"AAAI","year":"2010","title":"Collaborative Filtering Meets Mobile Recommendation: A User-Centered Approach","authors":"Vincent Wenchen Zheng, Bin Cao, Yu Zheng, Xing Xie, Qiang Yang","author_ids":"3113725, 1693204, 1713117, 1687677, 1733090","abstract":"With the increasing popularity of location tracking services such as GPS, more and more mobile data are being accumulated. Based on such data, a potentially useful service is to make timely and targeted recommendations for users on places where they might be interested to go and activities that they are likely to conduct. For example , a user arriving in Beijing might wonder where to visit and what she can do around the Forbidden City. A key challenge for such recommendation problems is that the data we have on each individual user might be very limited, while to make useful and accurate recommendations , we need extensive annotated location and activity information from user trace data. In this paper , we present a new approach, known as user-centered collaborative location and activity filtering (UCLAF), to pull many users' data together and apply collaborative filtering to find like-minded users and like-patterned activities at different locations. We model the user-location-activity relations with a tensor representation, and propose a regularized tensor and matrix decomposition solution which can better address the sparse data problem in mobile information retrieval. We empirically evaluate UCLAF using a real-world GPS dataset collected from 164 users over 2.5 years, and showed that our system can outperform several state-of-the-art solutions to the problem.","cites":"97","conferencePercentile":"99.31740614"},{"venue":"AAAI","id":"8e2726d00b22a04456b411e282aedbd818b8f473","venue_1":"AAAI","year":"2014","title":"Modeling and Mining Spatiotemporal Patterns of Infection Risk from Heterogeneous Data for Active Surveillance Planning","authors":"Bo Yang, Hua Guo, Yi Yang, Benyun Shi, Xiao-Nong Zhou, Jiming Liu","author_ids":"3199880, 2163229, 1698559, 2854616, 2545070, 1695157","abstract":"Active surveillance is a desirable way to prevent the spread of infectious diseases in that it aims to timely discover individual incidences through an active searching for patients. However, in practice active surveillance is difficult to implement especially when monitoring space is large but available resources are limited. Therefore, it is extremely important for public health authorities to know how to distribute their very sparse resources to high-priority regions so as to maximize the outcomes of active surveillance. In this paper, we raise the problem of active surveillance planning and provide an effective method to address it via modeling and mining spatiotemporal patterns of infection risks from heterogeneous data sources. Taking malaria as an example, we perform an empirical study on real-world data to validate our method and provide our new findings.","cites":"1","conferencePercentile":"25.90909091"},{"venue":"AAAI","id":"ad56fb987e7125a9a110ada1a620bdeb231bf4a3","venue_1":"AAAI","year":"2013","title":"Supervised Nonnegative Tensor Factorization with Maximum-Margin Constraint","authors":"Fei Wu, Xu Tan, Yi Yang, Dacheng Tao, Siliang Tang, Yueting Zhuang","author_ids":"1695826, 1803075, 1698559, 7761803, 1774936, 1755711","abstract":"Non-negative tensor factorization (NTF) has attracted great attention in the machine learning community. In this paper, we extend traditional non-negative ten-sor factorization into a supervised discriminative decomposition , referred as Supervised Non-negative Ten-sor Factorization with Maximum-Margin Constraint (SNTFM 2). SNTFM 2 formulates the optimal discrim-inative factorization of non-negative tensorial data as a coupled least-squares optimization problem via a maximum-margin method. As a result, SNTFM 2 not only faithfully approximates the tensorial data by additive combinations of the basis, but also obtains a strong generalization power to discriminative analysis (in particular for classification in this paper). The experimental results show the superiority of our proposed model over state-of-the-art techniques on both toy and real world data sets.","cites":"4","conferencePercentile":"55.45454545"},{"venue":"AAAI","id":"0139eb62a87649bf7d259542b5afc6be121b094b","venue_1":"AAAI","year":"2012","title":"Unsupervised Feature Selection Using Nonnegative Spectral Analysis","authors":"Zechao Li, Yi Yang, Jing Liu, Xiaofang Zhou, Hanqing Lu","author_ids":"3233021, 1698559, 5661757, 1720932, 1694235","abstract":"In this paper, a new unsupervised learning algorithm, namely Nonnegative Discriminative Feature Selection (NDFS), is proposed. To exploit the discriminative information in unsupervised scenarios, we perform spectral clustering to learn the cluster labels of the input samples, during which the feature selection is performed simultaneously. The joint learning of the cluster labels and feature selection matrix enables NDFS to select the most discriminative features. To learn more accurate cluster labels, a nonnegative constraint is explicitly imposed to the class indicators. To reduce the redundant or even noisy features, 2,1-norm minimization constraint is added into the objective function, which guarantees the feature selection matrix sparse in rows. Our algorithm exploits the discriminative information and feature correlation simultaneously to select a better feature subset. A simple yet efficient iterative algorithm is designed to optimize the proposed objective function. Experimental results on different real world datasets demonstrate the encouraging performance of our algorithm over the state-of-the-arts.","cites":"48","conferencePercentile":"98.17073171"},{"venue":"AAAI","id":"16cbbc687ae27e901b86df6fdf844823e5045632","venue_1":"AAAI","year":"2006","title":"Sensor-Based Understanding of Daily Life via Large-Scale Use of Common Sense","authors":"William Pentney, Ana-Maria Popescu, Shiaokai Wang, Henry A. Kautz, Matthai Philipose","author_ids":"2945977, 1752145, 2713538, 1690271, 3041721","abstract":"The use of large quantities of common sense has long been thought to be critical to the automated understanding of the world. To this end, various groups have collected repositories of common sense in machine-readable form. However, efforts to apply these large bodies of knowledge to enable correspondingly large-scale sensor-based understanding of the world have been few. Challenges have included semantic gaps between facts in the repositories and phenomena detected by sensors, fragility of reasoning in the face of noise, in-completeness of repositories, and slowness of reasoning with these large repositories. We show how to address these problems with a combination of novel sensors, probabilistic representation, web-scale information retrieval and approximate reasoning. In particular, we show how to use the 50,000-fact hand-entered Open-Mind Indoor Common Sense database to interpret sensor traces of day-today activities with 88% accuracy (which is easy) and 32/53% precision/recall (which is not).","cites":"38","conferencePercentile":"83.57348703"},{"venue":"AAAI","id":"0ddc8b224bf0a9b04292aa1bfa6e77152afdfce8","venue_1":"AAAI","year":"2005","title":"Recovery Planning for Ambiguous Cases in Perceptual Anchoring","authors":"Mathias Broxvall, Silvia Coradeschi, Lars Karlsson, Alessandro Saffiotti","author_ids":"2835621, 1734889, 4620262, 1815138","abstract":"An autonomous robot using symbolic reasoning, sensing and acting in a real environment needs the ability to create and maintain the connection between symbols representing objects in the world and the corresponding perceptual representations given by its sensors. This connection has been named perceptual anchoring. In complex environments, anchoring is not always easy to establish: the situation may often be ambiguous as to which percept actually corresponds to a given symbol. In this paper, we extend perceptual anchoring to deal robustly with ambiguous situations by providing general methods for detecting them and recovering from them. We consider different kinds of ambiguous situations and present planning-based methods to recover from them. We illustrate our approach by showing experiments involving a mobile robot equipped with a color camera and an electronic nose.","cites":"14","conferencePercentile":"56.99300699"},{"venue":"AAAI","id":"35910cc046b9d8701c14012a09cba3731c49918c","venue_1":"AAAI","year":"1992","title":"A Belief-Function Logic","authors":"Alessandro Saffiotti","author_ids":"1815138","abstract":"We present BFL, a hybrid logic for representing uncertain knowledge. BFL attaches a quantified notion of belief-based on Dempster-Shafer's theory of belief functions-to classical first-order logic. The language of BFL is composed of objects of the form F:[a,b], where F is a first-order sentence, and Q and b are numbers in the [O,l] interval (with c&b). Intuitively, a measures the strength of our belief in the truth of F, and (l-b) that in its falseness. A number of properties of first-order logic nicely generalize to BFL; in return, BFL gives us a new perspective on some important points of Dempster-Shafer theory (e.g., the role of Dempster's combination rule).","cites":"13","conferencePercentile":"23.21428571"},{"venue":"AAAI","id":"302d89d29c1351dbc046a684211b02af992a3ac5","venue_1":"AAAI","year":"2015","title":"Structured Embedding via Pairwise Relations and Long-Range Interactions in Knowledge Base","authors":"Fei Wu, Jun Song, Yi Yang, Xi Li, Zhongfei Zhang, Yueting Zhuang","author_ids":"1695826, 5381761, 1698559, 1742869, 1720488, 1755711","abstract":"We consider the problem of embedding entities and relations of knowledge bases into low-dimensional continuous vector spaces (distributed representations). Unlike most existing approaches, which are primarily efficient for modelling pairwise relations between entities, we attempt to explicitly model both pairwise relations and long-range interactions between entities, by interpreting them as linear operators on the low-dimensional embeddings of the entities. Therefore, in this paper we introduces path ranking to capture the long-range interactions of knowledge graph and at the same time preserve the pairwise relations of knowledge graph; we call it structured embedding via pairwise relation and long-range interactions (referred to as SePLi). Comparing with the-state-of-the-art models, SePLi achieves better performances of embeddings.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"8faa10a27725cbeb1a0e810e60cbad0e4c4eef9d","venue_1":"AAAI","year":"2012","title":"Threats and Trade-Offs in Resource Critical Crowdsourcing Tasks Over Networks","authors":"Swaprava Nath, Pankaj Dayama, Dinesh Garg, Y. Narahari, James Y. Zou","author_ids":"2543930, 2745442, 1705626, 1681789, 4933221","abstract":"In recent times, crowdsourcing over social networks has emerged as an active tool for complex task execution. In this paper, we address the problem faced by a planner to incen-tivize agents in the network to execute a task and also help in recruiting other agents for this purpose. We study this mechanism design problem under two natural resource optimization settings: (1) cost critical tasks, where the planner's goal is to minimize the total cost, and (2) time critical tasks, where the goal is to minimize the total time elapsed before the task is executed. We define a set of fairness properties that should be ideally satisfied by a crowdsourcing mechanism. We prove that no mechanism can satisfy all these properties simultaneously. We relax some of these properties and define their approximate counterparts. Under appropriate approximate fairness criteria, we obtain a non-trivial family of payment mechanisms. Moreover, we provide precise characterizations of cost critical and time critical mechanisms.","cites":"3","conferencePercentile":"30.79268293"},{"venue":"AAAI","id":"a31b7535db0f9753fdf3c5b30c2e538233b07e2e","venue_1":"AAAI","year":"2010","title":"Tolerable Manipulability in Dynamic Assignment without Money","authors":"James Y. Zou, Sujit Gujar, David C. Parkes","author_ids":"4933221, 1999022, 1702994","abstract":"We study a problem of dynamic allocation without money. Agents have arrivals and departures and strict preferences over items. Strategyproofness requires the use of an arrival-priority serial-dictatorship (APSD) mechanism, which is ex post Pareto efficient but has poor ex ante efficiency as measured through average rank efficiency. We introduce the scoring-rule (SR) mechanism, which biases in favor of allocating items that an agent values above the population consensus. The SR mechanism is not strategyproof but has tolerable manipulability in the sense that: (i) if every agent optimally manipulates, it reduces to APSD, and (ii) it significantly outperforms APSD for rank efficiency when only a fraction of agents are strategic. The performance of SR is also robust to mistakes by agents that manipulate on the basis of inaccurate information about the popularity of items.","cites":"9","conferencePercentile":"48.63481229"},{"venue":"AAAI","id":"b780b9145473058b99314e178a5c581aff783bf4","venue_1":"AAAI","year":"2014","title":"To Share or Not to Share? The Single Agent in a Team Decision Problem","authors":"Ofra Amir, Barbara J. Grosz, Roni Stern","author_ids":"2212554, 1692242, 2106020","abstract":"This paper defines the \" Single Agent in a Team Decision \" (SATD) problem. SATD differs from prior multi-agent communication problems in the assumptions it makes about team-mates' knowledge of each other's plans and possible observations. The paper proposes a novel integrated logical-decision-theoretic approach to solving SATD problems, called MDP-PRT. Evaluation of MDP-PRT shows that it outperforms a previously proposed communication mechanism that did not consider the timing of communication and compares favorably with a coordinated Dec-POMDP solution that uses knowledge about all possible observations.","cites":"8","conferencePercentile":"81.25"},{"venue":"AAAI","id":"f1b9b40c71d775fd08e078da1f9b9c5a3140bf01","venue_1":"AAAI","year":"2016","title":"Achieving Stable and Fair Profit Allocation with Minimum Subsidy in Collaborative Logistics","authors":"Lucas Agussurja, Hoong Chuin Lau, Shih-Fen Cheng","author_ids":"2026742, 1809379, 2089330","abstract":"With the advent of e-commerce, logistics providers are faced with the challenge of handling fluctuating and sparsely distributed demand, which raises their operational costs significantly. As a result, horizontal cooperation are gaining momentum around the world. One of the major impediments, however, is the lack of stable and fair profit sharing mechanism. In this paper, we address this problem using the framework of computational cooperative games. We first present cooperative vehicle routing game as a model for collabora-tive logistics operations. Using the axioms of Shapley value as the conditions for fairness, we show that a stable, fair and budget balanced allocation does not exist in many instances of the game. By relaxing budget balance, we then propose an allocation scheme based on the normalized Shapley value. We show that this scheme maintains stability and fairness while requiring minimum subsidy. Finally, using numerical experiments we demonstrate the feasibility of the scheme under various settings.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"4680f19e14d47417bc8402fcf647238f48cd5242","venue_1":"AAAI","year":"2008","title":"Yoopick: A Combinatorial Sports Prediction Market","authors":"Sharad Goel, David M. Pennock, Daniel M. Reeves, Cong Yu","author_ids":"3184636, 1766638, 4622298, 1746900","abstract":"We describe Yoopick, a combinatorial sports prediction market that implements a flexible betting language, and in turn facilitates fine-grained probabilistic estimation of outcomes.","cites":"15","conferencePercentile":"68.82911392"},{"venue":"AAAI","id":"f49914a08aefa0d205a573421234c55563b60ba4","venue_1":"AAAI","year":"2005","title":"Building Applications Using End to End Composition of Web Services","authors":"Vikas Agarwal, Girish Chafle, Koustuv Dasgupta, Neeran M. Karnik, Arun Kumar, Ashish Kundu, Anupam Mediratta, Sumit Mittal, Biplav Srivastava","author_ids":"1692917, 1852678, 1765942, 1718256, 1750615, 3045045, 2078229, 1968937, 1681873","abstract":"Description Web services have received much interest in industry due to their potential in facilitating seamless business-to-business or enterprise application integration (S. Staab et al. 2003; Srivastava & Koehler 2003). Web services offer standardized interface description, discovery (using a registry like UDDI) and messaging mechanisms. Also, the programming tools and runtime environments for web services have now matured. A component-oriented software development approach where each piece of software is wrapped as a web service would offer substantial benefits in application integration and we demonstrate this for a mobile service provider scenario. Given the intense competition in the telecom sector, mobile telephony service providers need to continually develop compelling applications to attract and retain end-users, with quick time-to-market. Often, if a competitor introduces a new service, the service provider must offer a similar or better service within days/weeks, to avoid losing customers. Also, a service provider can attract enterprise customers by offering custom-developed value-added services that leverage its telecom and IT infrastructure. Enterprise customers typically offer significantly higher margins than consumers, and are thus more attractive. Service providers therefore need tools and standards-based runtime platforms to quickly develop and deploy interesting applications for their clients. This would assist in their transition towards \" on demand \" , responsive businesses. Mobile user applications often rely on several, relatively simple building blocks – user profile look-ups, address books, location-tracking services, accounting and billing services, etc. Many of these building blocks are already in place, but they are not easy to reuse and integrate into new applications because they are not built using standardized frameworks or component models. This leads to high development costs, and substantial time-to-market for new services. This could be alleviated by building applications using the service-oriented architecture (SOA) paradigm, using web services as the underlying abstraction. Two different approaches have been taken to standardize and compose web services. The business world has adopted a distributed systems approach in which web service instances are described using WSDL, composed into flows with a language like BPEL,and invoked with the SOAP protocol. Academia has propounded the AI approach of formally representing web service capabilities in ontologies, and reasoning about their functional composition using goal-oriented inferencing techniques from planning (McIlraith, Son, & Zeng 2001). These approaches by themselves are piecemeal, and insufficient. The former has focused on the execution aspects of composite web services, without much consideration for requirements capture and the development process. …","cites":"0","conferencePercentile":"4.195804196"},{"venue":"AAAI","id":"0f97cad5983be8d1ce14246ee2cd6cc359fa9663","venue_1":"AAAI","year":"2006","title":"From Pigeons to Humans: Grounding Relational Learning in Concrete Examples","authors":"Marc T. Tomlinson, Bradley C. Love","author_ids":"3313444, 2408794","abstract":"We present a cognitive model that bridges work in analogy and category learning. The model, Building Relations through Instance Driven Gradient Error Shifting (BRIDGES), extends ALCOVE, an exemplar-based connectionist model of human category learning (Kruschke, 1992). Unlike ALCOVE which is limited to featural or spatial representations, BRIDGES can appreciate analogical relationships between stimuli and stored predicate representations of exemplars. Like ALCOVE, BRIDGES learns to shift attention over the course of learning to reduce error and, in the process, alters its notion of similarity. A shift toward relational sources of similarity allows BRIDGES to display what appears to be an understanding of abstract domains, when in fact performance is driven by similarity-based structural alignment (i.e., analogy) to stored exemplars. Supportive simulations of animal, infant, and adult learning are provided. We end by considering possible extensions of BRIDGES suitable for computa-tionally demanding applications.","cites":"10","conferencePercentile":"52.3054755"},{"venue":"AAAI","id":"115b3e47f6d3a752621f89ef748d8d89939ef556","venue_1":"AAAI","year":"2005","title":"Toward Affective Cognitive Robots for Human-Robot Interaction","authors":"Matthias Scheutz, James F. Kramer, Christopher Middendorff, Paul W. Schermerhorn, Michael Heilman, David Anderson, P. Bui","author_ids":"1793014, 2609362, 2541719, 2510893, 2618874, 5993792, 1851161","abstract":"We present an architecture for complex affective robots for human-robot interaction. After describing our rationale for using affect as a means of \" architectural integration \" , we give a quick conceptual example of how affect can play an organizational role in a complex agent and then describe our proposed affective architecture, its functionality and implementation, and results from experimental evaluations on an autonomous robot.","cites":"16","conferencePercentile":"61.53846154"},{"venue":"AAAI","id":"f8b38249ed0a0701dcda33af0a7c3f0f966103dd","venue_1":"AAAI","year":"2005","title":"A Learning and Reasoning System for Intelligence Analysis","authors":"Mihai Boicu, Gheorghe Tecuci, Cindy Ayers, Dorin Marcu, Cristina Boicu, Marcel Barbulescu, Bogdan Stanescu, William Wagner, Vu Le, Denitsa Apostolova, Adrian Ciubotariu","author_ids":"1796463, 1754513, 2699404, 1765194, 1757071, 2419217, 8064336, 8732684, 6875900, 2287531, 2829566","abstract":"This paper presents a personal cognitive assistant, called Disciple-LTA, that can acquire expertise in intelligence analysis directly from intelligence analysts, can train new analysts, and can help analysts find solutions to complex problems through mixed-initiative reasoning, making possible the synergistic integration of a human's experience and creativity with an automated agent's knowledge and speed, and facilitating the collaboration with complementary experts and their agents. Disciple-LTA builds on Disciple-RKF (Tecuci et al., 2002) and advances the Disciple approach to the development of knowledge-based agents by subject matter experts (Tecuci, 1998) with respect to the application to intelligence analysis, and the tutoring, problem solving and learning capabilities, as discussed below. One of the most important contributions of Disciple-LTA is the developing and implementation of a systematic approach to intelligence analysis which is both natural for the human analyst and appropriate for an automated agent. This approach is based on the general task-reduction/solution-composition paradigm of problem solving, and consists of the following steps: 1) A complex intelligence analysis task T is successively reduced to simpler tasks that either have known solutions, or can be solved through evidence analysis. 2) Potentially relevant pieces of evidence for each unsolved task are identified. 3) The identified pieces of evidence are analyzed using the task reduction paradigm and a solution for each unsolved task is obtained. 4) The solutions of the simplest tasks are successively combined to obtain the solution of the initial task T. The reductions and the compositions are guided by questions and answers, as if the analyst or the agent would be thinking aloud, asking themselves how to reduce the current task or to compose the current solutions. Evidence analysis (steps 2 and 3), which is inspired by the theory of evidence developed by Schum (2001), identifies different types of evidence (tangible, unequivocal testimonial, equivocal testimonial, missing tangible or testimonial, and authoritative records) and defines analyses procedures that are specific to each type. To illustrate our approach, let us consider a report from Person-Z who claims to have repeatedly seen Person-E, a known explosive expert, in the vicinity of Location-A. This piece of evidence is potentially relevant to the tasks \" Assess whether there are explosive experts in the vicinity of Location-A. \" In Schum's terminology, this is unequivocal testimonial evidence on a direct observation of Person-Z. Consequently, one has to assess three aspects: 1) the relevance of this evidence with respect to the …","cites":"4","conferencePercentile":"23.25174825"},{"venue":"AAAI","id":"6671a43a727f13a6fef69dfacc787f72db3f267b","venue_1":"AAAI","year":"1993","title":"Generating Explanations of Device Behavior Using Compositional Modeling and Causal Ordering","authors":"Patrice O. Gautier, Thomas R. Gruber","author_ids":"2430443, 1737170","abstract":"Generating explanations of device behavior is a long-standing goal of AI research in reasoning about physical systems. Much of the relevant work has concentrated on new methods for modeling and simulation, such as qualitative physics, or on sophisti cated natural language genera tion, in which the device models are specially crafted for explanatory purposes. We show how two techniques from the mod-eling research—compositional model ing and causal order-ing—can be effec tively combined to generate natural language explanations of device behavior from engineering models. The explana tions offer three advances over the data displays produced by conventional simulation software: (1) causal interpretations of the data, (2) summaries at ap-propri ate levels of abstraction (physical mechanisms and component operating modes), and (3) query-driven, natural language summaries. Furthermore, combining the composi-tional modeling and causal ordering techniques allows models that are more scalable and less brittle than models designed solely for explanation. However, these techniques produce models with detail that can be distracting in explanations and would be removed in hand-crafted models (e.g., intermediate variables). We present domain-independent filtering and aggregation techniques that overcome these problems.","cites":"27","conferencePercentile":"58.78378378"},{"venue":"AAAI","id":"7eed2ae164b68b40fb6dd0b91452444660adc59f","venue_1":"AAAI","year":"2008","title":"Pervasive Diagnosis: The Integration of Diagnostic Goals into Production Plans","authors":"Lukas D. Kuhn, Bob Price, Johan de Kleer, Minh Binh Do, Rong Zhou","author_ids":"2977404, 2737074, 3238472, 2739979, 1805700","abstract":"In model-based control, a planner uses a system description to create a plan that achieves production goals (Fikes & Nilsson 1971). The same description can be used by model-based diagnosis to infer the condition of components in a system from partially informative sensors. Prior work has demonstrated that diagnosis can be used to adapt the control of a system to changes in its components. However diagnosis must either make inferences from passive observations of production, or production must be halted to take diagnostic actions. We observe that the declarative nature of model-based control allows the planner to achieve production goals in multiple ways. This flexibility can be exploited with a novel paradigm we call pervasive diagnosis which produces diagnostic production plans that simultaneously achieve production goals while uncovering additional information about component health. We present an efficient heuristic search for these diagnostic production plans and show through experiments on a model of an industrial digital printing press that the theoretical increase in information can be realized on practical real-time systems. We obtain higher long-run productivity than a decoupled combination of planning and diagnosis.","cites":"11","conferencePercentile":"58.2278481"},{"venue":"AAAI","id":"08fa9cb56f9d21a493a943299991d4b495651169","venue_1":"AAAI","year":"2011","title":"Identifying Evaluative Sentences in Online Discussions","authors":"Zhongwu Zhai, Bing Liu, Lei Zhang, Hua Xu, Peifa Jia","author_ids":"1774830, 2201323, 2881749, 1718800, 2463381","abstract":"Much of opinion mining research focuses on product reviews because reviews are opinion-rich and contain little irrelevant information. However, this cannot be said about online discussions and comments. In such postings, the discussions can get highly emotional and heated with many emotional statements, and even personal attacks. As a result , many of the postings and sentences do not express positive or negative opinions about the topic being discussed. To find people's opinions on a topic and its different aspects , which we call evaluative opinions, those irrelevant sentences should be removed. The goal of this research is to identify evaluative opinion sentences. A novel unsupervised approach is proposed to solve the problem, and our experimental results show that it performs well.","cites":"13","conferencePercentile":"74.91408935"},{"venue":"AAAI","id":"09608b84f557793c8d70b3b9921571ac8ca14323","venue_1":"AAAI","year":"2010","title":"Discovering Long Range Properties of Social Networks with Multi-Valued Time-Inhomogeneous Models","authors":"Danny Wyatt, Tanzeem Choudhury, Jeff A. Bilmes","author_ids":"2173752, 1729948, 1748118","abstract":"The current methods used to mine and analyze temporal social network data make two assumptions: all edges have the same strength, and all parameters are time-homogeneous. We show that those assumptions may not hold for social networks and propose an alternative model with two novel aspects: (1) the modeling of edges as multi-valued variables that can change in intensity , and (2) the use of a curved exponential family framework to capture time-inhomogeneous properties while retaining a parsimonious and interpretable model. We show that our model outperforms traditional models on two real-world social network data sets.","cites":"10","conferencePercentile":"52.21843003"},{"venue":"AAAI","id":"05fe1ade4c745e46ce643ec958c44a8435130f3d","venue_1":"AAAI","year":"2008","title":"Learning Hidden Curved Exponential Family Models to Infer Face-to-Face Interaction Networks from Situated Speech Data","authors":"Danny Wyatt, Tanzeem Choudhury, Jeff A. Bilmes","author_ids":"2173752, 1729948, 1748118","abstract":"In this paper, we present a novel probabilistic framework for recovering global, latent social network structure from local, noisy observations. We extend curved exponential random graph models to include two types of variables: hidden variables that capture the structure of the network and observational variables that capture the behavior between actors in the network. We develop a novel combination of informative and intuitive conversational (local) and structural (global) features to specify our model. The model learns, in an unsupervised manner, the relationship between observable behavior and hidden social structure while simultaneously learning properties of the latent structure itself. We present empirical results on both synthetic data and a real world dataset of face-to-face conversations collected from 24 individuals using wearable sensors over the course of 6 months.","cites":"8","conferencePercentile":"49.52531646"},{"venue":"AAAI","id":"8c4f1461c85fcb2b57d52f43145f0aef27f73c39","venue_1":"AAAI","year":"2016","title":"A Proactive Sampling Approach to Project Scheduling under Uncertainty","authors":"Pradeep Varakantham, Na Fu, Hoong Chuin Lau","author_ids":"1718824, 8301146, 1809379","abstract":"Uncertainty in activity durations is a key characteristic of many real world scheduling problems in manufacturing, logistics and project management. RCPSP/max with dura-tional uncertainty is a general model that can be used to represent durational uncertainty in a wide variety of scheduling problems where there exist resource constraints. However, computing schedules or execution strategies for RCPSP/max with durational uncertainty is NP-hard and hence we focus on providing approximation methods in this paper. We provide a principled approximation approach based on Sample Average Approximation (SAA) to compute proactive schedules for RCPSP/max with durational uncertainty. We further contribute an extension to SAA for improving scala-bility significantly without sacrificing on solution quality. Not only is our approach able to compute schedules at comparable runtimes as existing approaches, it also provides lower α-quantile makespan (also referred to as α-robust makespan) values than the best known approach on benchmark problems from the literature.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"d81cbde8ba0309a59e9c3255de7e5c84ce38b32c","venue_1":"AAAI","year":"2013","title":"WordNet Based Multi-Way Concept Hierarchy Construction from Text Corpus","authors":"Ding Tu, Ling Chen, Gencai Chen","author_ids":"2932694, 1717165, 3025640","abstract":"In this paper, we propose an approach to build a multi-way concept hierarchy from a text corpus, which is based on WordNet and multi-way hierarchical clustering. In addition, a new evaluation metric is presented, and our approach is compared with 4 kinds of existing methods on the Amazon Customer Review data set.","cites":"0","conferencePercentile":"9.090909091"},{"venue":"AAAI","id":"3d75ecbac9df3c3cb1dcb08bb77af949c4bb3d7a","venue_1":"AAAI","year":"2014","title":"State Aggregation in Monte Carlo Tree Search","authors":"Jesse Hostetler, Alan Fern, Thomas G. Dietterich","author_ids":"1835871, 1791751, 1699720","abstract":"Monte Carlo tree search (MCTS) algorithms are a popular approach to online decision-making in Markov decision processes (MDPs). These algorithms can, however, perform poorly in MDPs with high stochastic branching factors. In this paper, we study state aggregation as a way of reducing stochastic branching in tree search. Prior work has studied formal properties of MDP state aggregation in the context of dynamic programming and reinforcement learning, but little attention has been paid to state aggregation in MCTS. Our main result is a performance loss bound for a class of value function-based state aggregation criteria in expectimax search trees. We also consider how to construct MCTS algorithms that operate in the abstract state space but require a simulator of the ground dynamics only. We find that trajectory sampling algorithms like UCT can be adapted easily, but that sparse sampling algorithms present difficulties. As a proof of concept , we experimentally confirm that state aggregation can improve the finite-sample performance of UCT.","cites":"5","conferencePercentile":"67.5"},{"venue":"AAAI","id":"6a152a6daf8585ace3cb5d6bf9d1f092247086c6","venue_1":"AAAI","year":"2012","title":"Exploiting Shared Resource Dependencies in Spectrum Based Plan Diagnosis","authors":"Shekhar Gupta, Nico Roos, Cees Witteveen, Bob Price, Johan de Kleer","author_ids":"1799520, 1678490, 1735401, 2737074, 3238472","abstract":"In case of a plan failure, plan-repair is a more promising solution than replanning from scratch. The effectiveness of plan-repair depends on knowledge of which plan action failed and why. Therefore, in this paper, we propose an Extended Spectrum Based Diagnosis approach that efficiently pinpoints failed actions. Unlike Model Based Diagnosis (MBD), it does not require the fault models and behavioral descriptions of actions. Our approach first computes the likelihood of an action being faulty and subsequently proposes optimal probe locations to refine the diagnosis. We also exploit knowledge of plan steps that are instances of the same plan operator to optimize the selection of the most informative diagnostic probes. In this paper, we only focus on diagnostic aspect of plan-repair process.","cites":"2","conferencePercentile":"22.40853659"},{"venue":"AAAI","id":"490e514049b778692f481de35021d71751dab628","venue_1":"AAAI","year":"2013","title":"PAC Optimal Planning for Invasive Species Management: Improved Exploration for Reinforcement Learning from Simulator-Defined MDPs","authors":"Thomas G. Dietterich, Majid Alkaee Taleghan, Mark Crowley","author_ids":"1699720, 2563916, 2143691","abstract":"Often the most practical way to define a Markov Decision Process (MDP) is as a simulator that, given a state and an action, produces a resulting state and immediate reward sampled from the corresponding distributions. Simulators in natural resource management can be very expensive to execute, so that the time required to solve such MDPs is dominated by the number of calls to the simulator. This paper presents an algorithm, DDV, that combines improved confidence intervals on the Q values (as in interval estimation) with a novel upper bound on the discounted state occupancy probabilities to intelligently choose state-action pairs to explore. We prove that this algorithm terminates with a policy whose value is within ε of the optimal policy (with probability 1 − δ) after making only polynomially-many calls to the simulator. Experiments on one benchmark MDP and on an MDP for inva-sive species management show very large reductions in the number of simulator calls required.","cites":"4","conferencePercentile":"55.45454545"},{"venue":"AAAI","id":"0a04ccc3d760310e646664ddc4143f7e54bf940e","venue_1":"AAAI","year":"2007","title":"Best-First Search for Treewidth","authors":"P. Alex Dow, Richard E. Korf","author_ids":"8586686, 1682627","abstract":"Finding the exact treewidth of a graph is central to many operations in a variety of areas, including probabilistic reasoning and constraint satisfaction. Treewidth can be found by searching over the space of vertex elimination orders. This search space differs from those where best-first search is typically applied, because a solution path is evaluated by its maximum edge cost instead of the sum of its edge costs. We show how to make best-first search admissible on max-cost problem spaces. We also employ breadth-first heuristic search to reduce the memory requirement while still eliminating all duplicate nodes in the search space. Our empirical results show that our algorithms find the exact treewidth an order of magnitude faster than the previous state-of-the-art algorithm on hard benchmark graphs.","cites":"12","conferencePercentile":"57.71513353"},{"venue":"AAAI","id":"1057dfcc4e92bf28766d7ad19d7263a8215b0337","venue_1":"AAAI","year":"2012","title":"Efficient Optimization of Control Libraries","authors":"Debadeepta Dey, Tian Yu Liu, Boris Sofman, J. Andrew Bagnell","author_ids":"1780951, 8484588, 2370815, 1756566","abstract":"A popular approach to high dimensional control problems in robotics uses a library of candidate \" maneuvers \" or \" trajectories \" [13, 28]. The library is either evaluated on a fixed number of candidate choices at runtime (e.g. path set selection for planning) or by iterating through a sequence of feasible choices until success is achieved (e.g. grasp selection). The performance of the library relies heavily on the content and order of the sequence of candidates. We propose a provably efficient method to optimize such libraries leveraging recent advances in optimizing sub-modular functions of sequences [29]. This approach is demonstrated on two important problems: mobile robot navigation and manipulator grasp set selection. In the first case, performance can be improved by choosing a subset of candidates which optimizes the metric under consideration (cost of traversal). In the second case, performance can be optimized by minimizing the depth the list is searched before a successful candidate is found. Our method can be used in both on-line and batch settings with provable performance guarantees, and can be run in an anytime manner to handle real-time constraints.","cites":"11","conferencePercentile":"71.34146341"},{"venue":"AAAI","id":"03c6059ad954b9e6206529d095a37f3bfb2f3b15","venue_1":"AAAI","year":"2011","title":"The Influence of Emotion Expression on Perceptions of Trustworthiness in Negotiation","authors":"Dimitrios Antos, Celso de Melo, Jonathan Gratch, Barbara J. Grosz","author_ids":"2665828, 1977901, 1730824, 1692242","abstract":"When interacting with computer agents, people make inferences about various characteristics of these agents, such as their reliability and trustworthiness. These perceptions are significant, as they influence people's behavior towards the agents, and may foster or inhibit repeated interactions between them. In this paper we investigate whether computer agents can use the expression of emotion to influence human perceptions of trust-worthiness. In particular, we study human-computer interactions within the context of a negotiation game, in which players make alternating offers to decide on how to divide a set of resources. A series of negotiation games between a human and several agents is then followed by a \" trust game. \" In this game people have to choose one among several agents to interact with, as well as how much of their resources they will trust to it. Our results indicate that, among those agents that displayed emotion, those whose expression was in accord with their actions (strategy) during the negotiation game were generally preferred as partners in the trust game over those whose emotion expressions and actions did not mesh. Moreover, we observed that when emotion does not carry useful new information, it fails to strongly influence human decision-making behavior in a negotiation setting.","cites":"0","conferencePercentile":"5.841924399"},{"venue":"AAAI","id":"4e5319d245f8f1c07b1ca1b0aa16025a5f3da296","venue_1":"AAAI","year":"2004","title":"Learning Social Preferences in Games","authors":"Ya'akov Gal, Avi Pfeffer, Francesca Marzo, Barbara J. Grosz","author_ids":"1721094, 1689364, 1891990, 1692242","abstract":"This paper presents a machine-learning approach to modeling human behavior in one-shot games. It provides a framework for representing and reasoning about the social factors that affect people's play. The model predicts how a human player is likely to react to different actions of another player, and these predictions are used to determine the best possible strategy for that player. Data collection and evaluation of the model were performed on a negotiation game in which humans played against each other and against computer models playing various strategies. A computer player trained on human data outplayed Nash equilibrium and Nash bargaining computer players as well as humans. It also generalized to play people and game situations it had not seen before.","cites":"46","conferencePercentile":"85.32934132"},{"venue":"AAAI","id":"47f74a059e8d683e1a309fa7fe43f702b9f2bd30","venue_1":"AAAI","year":"2010","title":"Coalitional Structure Generation in Skill Games","authors":"Yoram Bachrach, Reshef Meir, Kyomin Jung, Pushmeet Kohli","author_ids":"1698412, 1769579, 1731707, 1685185","abstract":"We consider optimizing the coalition structure in Coalitional Skill Games (CSGs), a succinct representation of coalitional games (Bachrach and Rosenschein 2008). In CSGs, the value of a coalition depends on the tasks its members can achieve. The tasks require various skills to complete them, and agents may have different skill sets. The optimal coalition structure is a partition of the agents to coalitions, that maximizes the sum of utilities obtained by the coalitions. We show that CSGs can represent any characteristic function, and consider optimal coalition structure generation in this representation. We provide hardness results, showing that in general CSGs, as well as in very restricted versions of them, computing the optimal coalition structure is hard. On the positive side, we show that the problem can be reformulated as constraint satisfaction on a hyper graph, and present an algorithm that finds the optimal coalition structure in polynomial time for instances with bounded tree-width and number of tasks.","cites":"25","conferencePercentile":"81.74061433"},{"venue":"AAAI","id":"b7f8eaf739b33115fd57e1b4051be9f2049668fa","venue_1":"AAAI","year":"2013","title":"A Fast Bandit Algorithm for Recommendation to Users With Heterogenous Tastes","authors":"Pushmeet Kohli, Mahyar Salek, Greg Stoddard","author_ids":"1685185, 3223663, 2352993","abstract":"We study recommendation in scenarios where there's no prior information about the quality of content in the system. We present an online algorithm that continually optimizes recommendation relevance based on behavior of past users. Our method trades weaker theoretical guarantees in asymptotic performance than the state-of-the-art for stronger theoretical guarantees in the online setting. We test our algorithm on real-world data collected from previous recommender systems and show that our algorithm learns faster than existing methods and performs equally well in the long-run.","cites":"11","conferencePercentile":"84.36363636"},{"venue":"AAAI","id":"6c2cabe6ccc48b2209bf00830a5a8663bac65691","venue_1":"AAAI","year":"2013","title":"Optimal Coalition Structure Generation in Cooperative Graph Games","authors":"Yoram Bachrach, Pushmeet Kohli, Vladimir Kolmogorov, Morteza Zadimoghaddam","author_ids":"1698412, 1685185, 1697050, 1724391","abstract":"Representation languages for coalitional games are a key research area in algorithmic game theory. There is an inherent tradeoff between how general a language is, allowing it to capture more elaborate games, and how hard it is com-putationally to optimize and solve such games. One prominent such language is the simple yet expressive Weighted Graph Games (WGGs) representation (Deng and Papadim-itriou 1994), which maintains knowledge about synergies between agents in the form of an edge weighted graph. We consider the problem of finding the optimal coalition structure in WGGs. The agents in such games are vertices in a graph, and the value of a coalition is the sum of the weights of the edges present between coalition members. The optimal coalition structure is a partition of the agents to coalitions, that maximizes the sum of utilities obtained by the coalitions. We show that finding the optimal coalition structure is not only hard for general graphs, but is also intractable for restricted families such as planar graphs which are amenable for many other combinatorial problems. We then provide algorithms with constant factor approximations for planar, minor-free and bounded degree graphs.","cites":"10","conferencePercentile":"82"},{"venue":"AAAI","id":"04478c02b1d16ef24b77d53372b918bbf4a4f7fc","venue_1":"AAAI","year":"2004","title":"Transport Logistics Planning with Service-Level Constraints","authors":"Hoong Chuin Lau, Kien Ming Ng, Xiaotao Wu","author_ids":"1809379, 1832965, 7916704","abstract":"In this paper, we study a logistics problem arising in military transport planning. A military organization operates a large fleet of vehicles in a depot to serve the requests of various operational units. Each request has a fixed start and end time, and is served by a prescribed number of vehicles. We address the following two problems: (1) how many vehicles are at least needed to meet a given service level of requests; and (2) suppose we allow each request to shift its start time by a constant duration, can all the requests be met? A Niche genetic algorithm, together with a hybridized variant, are applied to the problem.","cites":"4","conferencePercentile":"31.13772455"},{"venue":"AAAI","id":"0601e3ca24396c95fa98693b0646bba9f794ae77","venue_1":"AAAI","year":"2005","title":"Robust Supervised Learning","authors":"J. Andrew Bagnell","author_ids":"1756566","abstract":"Supervised machine learning techniques developed in the Probably Approximately Correct, Maximum A Pos-teriori, and Structural Risk Minimiziation frameworks typically make the assumption that the test data a learner is applied to is drawn from the same distribution as the training data. In various prominent applications of learning techniques, from robotics to medical diagnosis to process control, this assumption is violated. We consider a novel framework where a learner may influence the test distribution in a bounded way. From this framework, we derive an efficient algorithm that acts as a wrapper around a broad class of existing supervised learning algorithms while guarranteeing more robust behavior under changes in the input distribution.","cites":"6","conferencePercentile":"29.37062937"},{"venue":"AAAI","id":"3516a4ae1d602a2320b449598e73bbf82a25816f","venue_1":"AAAI","year":"2014","title":"Decentralized Multi-Agent Reinforcement Learning in Average-Reward Dynamic DCOPs","authors":"Duc Thien Nguyen, William Yeoh, Hoong Chuin Lau, Shlomo Zilberstein, Chongjie Zhang","author_ids":"1779016, 1805457, 1809379, 1707550, 1797369","abstract":"Researchers have introduced the Dynamic Distributed Constraint Optimization Problem (Dynamic DCOP) formulation to model dynamically changing multi-agent coordination problems, where a dynamic DCOP is a sequence of (static canonical) DCOPs, each partially different from the DCOP preceding it. Existing work typically assumes that the problem in each time step is decoupled from the problems in other time steps, which might not hold in some applications. In this paper, we introduce a new model, called Markovian Dynamic DCOPs (MD-DCOPs), where a DCOP is a function of the value assignments in the preceding DCOP. We also introduce a distributed reinforcement learning algorithm that balances exploration and exploitation to solve MD-DCOPs in an online manner.","cites":"4","conferencePercentile":"59.54545455"},{"venue":"AAAI","id":"d47ac6a22658aa950214af5dfb50d7fea2eb27db","venue_1":"AAAI","year":"2015","title":"Risk Based Optimization for Improving Emergency Medical Systems","authors":"Sandhya Saisubramanian, Pradeep Varakantham, Hoong Chuin Lau","author_ids":"3305291, 1718824, 1809379","abstract":"In emergency medical systems, arriving at the incident location a few seconds early can save a human life. Thus, this paper is motivated by the need to reduce the response time – time taken to arrive at the incident location after receiving the emergency call – of Emergency Response Vehicles, ERVs (ex: ambulances, fire rescue vehicles) for as many requests as possible. We expect to achieve this primarily by positioning the \" right \" number of ERVs at the \" right \" places and at the \" right \" times. Given the exponentially large action space (with respect to number of ERVs and their placement) and the stochasticity in location and timing of emergency incidents, this problem is computationally challenging. To that end, our contributions building on existing data-driven approaches are three fold: 1. Based on real world evaluation metrics, we provide a risk based optimization criterion to learn from past incident data. Instead of minimizing expected response time, we minimize the largest value of response time such that the risk of finding requests that have a higher value is bounded (ex: Only 10% of requests should have a response time greater than 8 minutes). 2. We develop a mixed integer linear optimization formulation to learn and compute an allocation from a set of input requests while considering the risk criterion. 3. To allow for \" live \" reallocation of ambulances, we provide a decomposition method based on Lagrangian Relaxation to significantly reduce the run-time of the optimization formulation. Finally, we provide an exhaustive evaluation on real-world datasets from two asian cities that demonstrates the improvement provided by our approach over current practice and the best known approach from literature.","cites":"4","conferencePercentile":"73.46456693"},{"venue":"AAAI","id":"8a802c9a8b7f6f47895ff9d771cc44908f500c37","venue_1":"AAAI","year":"2016","title":"Online Instrumental Variable Regression with Applications to Online Linear System Identification","authors":"Arun Venkatraman, Wen Sun, Martial Hebert, J. Andrew Bagnell, Byron Boots","author_ids":"1978198, 4537536, 1709305, 1756566, 3288815","abstract":"Instrumental variable regression (IVR) is a statistical technique utilized for recovering unbiased estimators when there are errors in the independent variables. Estimator bias in learned time series models can yield poor performance in applications such as long-term prediction and filtering where the recursive use of the model results in the accumulation of propagated error. However, prior work addressed the IVR objective in the batch setting, where it is necessary to store the entire dataset in memory-an infeasible requirement in large dataset scenarios. In this work, we develop Online Instrumental Variable Regression (OIVR), an algorithm that is capable of updating the learned estimator with streaming data. We show that the online adaptation of IVR enjoys a no-regret performance guarantee with respect the original batch setting by taking advantage of any no-regret online learning algorithm inside OIVR for the underlying update steps. We experimentally demonstrate the efficacy of our algorithm in combination with popular no-regret online algorithms for the task of learning predictive dynamical system models and on a prototypical econometrics instrumental variable regression problem.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"0f418f0acfe5d551d7e9d2851db4b6ec38973a1d","venue_1":"AAAI","year":"2015","title":"Learning to Manipulate Unknown Objects in Clutter by Reinforcement","authors":"Abdeslam Boularias, J. Andrew Bagnell, Anthony Stentz","author_ids":"2209847, 1756566, 1722938","abstract":"We present a fully autonomous robotic system for grasping objects in dense clutter. The objects are unknown and have arbitrary shapes. Therefore, we cannot rely on prior models. Instead, the robot learns online, from scratch, to manipulate the objects by trial and error. Grasping objects in clutter is significantly harder than grasping isolated objects, because the robot needs to push and move objects around in order to create sufficient space for the fingers. These pre-grasping actions do not have an immediate utility, and may result in unnecessary delays. The utility of a pre-grasping action can be measured only by looking at the complete chain of consecutive actions and effects. This is a sequential decision-making problem that can be cast in the reinforcement learning framework. We solve this problem by learning the stochastic transitions between the observed states, using nonparametric density estimation. The learned transition function is used only for recalculating the values of the executed actions in the observed states, with different policies. Values of new state-actions are obtained by regressing the values of the executed actions. The state of the system at a given time is a depth (3D) image of the scene. We use spectral clustering for detecting the different objects in the image. The performance of our system is assessed on a robot with real-world objects.","cites":"4","conferencePercentile":"73.46456693"},{"venue":"AAAI","id":"ab05a7ebef6cd971e5bcd2e61863b1fd43460593","venue_1":"AAAI","year":"2015","title":"Approximate MaxEnt Inverse Optimal Control and Its Application for Mental Simulation of Human Interactions","authors":"De-An Huang, Amir Massoud Farahmand, Kris M. Kitani, J. Andrew Bagnell","author_ids":"5977379, 2011924, 2908542, 1756566","abstract":"Maximum entropy inverse optimal control (MaxEnt IOC) is an effective means of discovering the underlying cost function of demonstrated human activity and can be used to predict human behavior over low-dimensional state spaces (i.e., forecasting of 2D trajectories). To enable inference in very large state spaces, we introduce an approximate MaxEnt IOC procedure to address the fundamental computational bottleneck stemming from calculating the partition function via dynamic programming. Approximate MaxEnt IOC is based on two components: approximate dynamic programming and Monte Carlo sampling. We analyze this approximation approach and provide a finite-sample error upper bound on its excess loss. We validate the proposed method in the context of analyzing dual-agent interactions from video, where we use approximate MaxEnt IOC to simulate mental images of a single agents body pose sequence (a high-dimensional image space). We experiment with sequences image data taken from RGB and RGBD data and show that it is possible to learn cost functions that lead to accurate predictions in high-dimensional problems that were previously intractable.","cites":"4","conferencePercentile":"73.46456693"},{"venue":"AAAI","id":"969b5a4d1bf6ead7fa5e4151c4444efd55de2083","venue_1":"AAAI","year":"2015","title":"Improving Multi-Step Prediction of Learned Time Series Models","authors":"Arun Venkatraman, Martial Hebert, J. Andrew Bagnell","author_ids":"1978198, 1709305, 1756566","abstract":"Most typical statistical and machine learning approaches to time series modeling optimize a single-step prediction error. In multiple-step simulation, the learned model is iteratively applied, feeding through the previous output as its new input. Any such pre-dictor however, inevitably introduces errors, and these compounding errors change the input distribution for future prediction steps, breaking the train-test i.i.d assumption common in supervised learning. We present an approach that reuses training data to make a no-regret learner robust to errors made during multi-step prediction. Our insight is to formulate the problem as imitation learning; the training data serves as a \" demonstrator \" by providing corrections for the errors made during multi-step prediction. By this reduction of multi-step time series prediction to imitation learning, we establish theoretically a strong performance guarantee on the relation between training error and the multi-step prediction error. We present experimental results of our method, DAD, and show significant improvement over the traditional approach in two notably different domains, dynamic system modeling and video texture prediction. Determining models for time series data is important in applications ranging from market prediction to the simulation of chemical processes and robotic systems. Many supervised learning approaches have been proposed for this task, (Ralaivola and D'Alche-Buc 2004). Common to most of these methods is that the objective being optimized is the single-step prediction loss. However , this criterion does not guarantee accurate multiple-step simulation accuracy in which the output of a prediction step is used as input for the next inference. The prevalence of single-step modeling approaches is a result of the difficulty in directly optimizing the multiple-step prediction error. As an example, consider fitting a simple linear dynamical system model for the multi-step error over the time horizon T from an initial condition x 0 , A * = arg min A T t=1 x t − A t x 0 2 2 (1) Even this squared-loss objective is difficult to optimize in two ways: it is non-convex in A, and though differentiable, the matrix power derivatives are non-trivial. In comparison, the single-step squared loss used in supervised learning, A * = arg min A T −1 t=0 x t+1 − Ax t 2 2 (2) is more appealing to solve as it has an easy, closed form solution. Abbeel et al. propose a generalization of (1) coined the \" lagged error \" criterion which penalizes deviations during forward simulation. However, …","cites":"7","conferencePercentile":"88.11023622"},{"venue":"AAAI","id":"0f5e1c864fe0ce368c77491328f165c1260e6bd3","venue_1":"AAAI","year":"2014","title":"Efficient Optimization for Autonomous Robotic Manipulation of Natural Objects","authors":"Abdeslam Boularias, J. Andrew Bagnell, Anthony Stentz","author_ids":"2209847, 1756566, 1722938","abstract":"Manipulating natural objects of irregular shapes, such as rocks, is an essential capability of robots operating in outdoor environments. Physics-based simulators are commonly used to plan stable grasps for man-made objects. However, planning is an expensive process that is based on simulating hand and object trajectories in different configurations, and evaluating the outcome of each trajectory. This problem is particularly concerning when the objects are irregular or cluttered, because the space of feasible grasps is significantly smaller, and more configurations need to be evaluated before finding a good one. In this paper, we first present a learning technique for fast detection of an initial set of potentially stable grasps in a cluttered scene. The best detected grasps are further optimized by fine-tuning the configuration of the hand in simulation. To reduce the computational burden of this last operation, we model the outcomes of the grasps as a Gaussian Process, and use an entropy-search method in order to focus the optimization on regions where the best grasp is most likely to be. This approach is tested on the task of clearing piles of real, unknown, rock debris with an autonomous robot. Empirical results show a clear advantage of the proposed approach when the time window for decision is short.","cites":"4","conferencePercentile":"59.54545455"},{"venue":"AAAI","id":"77d5dba89c34facc282e9fe30ad7fe6d2887975f","venue_1":"AAAI","year":"2015","title":"Algorithm Selection via Ranking","authors":"Richard Jayadi Oentaryo, Stephanus Daniel Handoko, Hoong Chuin Lau","author_ids":"2660470, 2423877, 1809379","abstract":"The abundance of algorithms developed to solve different problems has given rise to an important research question: How do we choose the best algorithm for a given problem? Known as algorithm selection, this issue has been prevailing in many domains, as no single algorithm can perform best on all problem instances. Traditional algorithm selection and portfolio construction methods typically treat the problem as a classification or regression task. In this paper, we present a new approach that provides a more natural treatment of algorithm selection and portfolio construction as a ranking task. Accordingly, we develop a Ranking-Based Algorithm Selection (RAS) method, which employs a simple polynomial model to capture the ranking of different solvers for different problem instances. We devise an efficient iterative algorithm that can gracefully optimize the polynomial coefficients by minimizing a ranking loss function, which is derived from a sound prob-abilistic formulation of the ranking problem. Experiments on the SAT 2012 competition dataset show that our approach yields competitive performance to that of more sophisticated algorithm selection methods.","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"4dfe757f38af2c7859b43674f922360ef87504a8","venue_1":"AAAI","year":"2012","title":"Collective Nominal Semantic Role Labeling for Tweets","authors":"Xiaohua Liu, Zhongyang Fu, Furu Wei, Ming Zhou","author_ids":"1900811, 2904393, 2517592, 5962676","abstract":"Tweets have become an increasingly popular source of fresh information. We investigate the task of Nominal Semantic Role Labeling (NSRL) for tweets, which aims to identify predicate-argument structures defined by nominals in tweets. Studies of this task can help fine-grained information extraction and retrieval from tweets. There are two main challenges in this task: 1) The lack of information in a single tweet, rooted in the short and noisy nature of tweets; and 2) recovery of implicit arguments. We propose jointly conducting NSRL on multiple similar tweets using a graphical model, leveraging the redundancy in tweets to tackle these challenges. Extensive evaluations on a human annotated data set demonstrate that our method outperforms two baselines with an absolute gain of 2.7% in F1.","cites":"1","conferencePercentile":"13.87195122"},{"venue":"AAAI","id":"26e3966c170b0d28141dd42111800c3622e22449","venue_1":"AAAI","year":"2008","title":"An Integrated Agent for Playing Real-Time Strategy Games","authors":"Joshua McCoy, Michael Mateas","author_ids":"2179071, 1780919","abstract":"We present a real-time strategy (RTS) game AI agent that integrates multiple specialist components to play a complete game. Based on an analysis of how skilled human players conceptualize RTS gameplay, we partition the problem space into domains of competence seen in expert human play. This partitioning helps us to manage and take advantage of the large amount of sophisticated domain knowledge developed by human players. We present results showing that incorporating expert high-level strategic knowledge allows our agent to consistently defeat established scripted AI players. In addition, this work lays the foundation to incorporate tactics and unit micro-management techniques developed by both man and machine.","cites":"29","conferencePercentile":"87.02531646"},{"venue":"AAAI","id":"73c784e2d84101a22b7befb0d9f56b9aefd7c966","venue_1":"AAAI","year":"2013","title":"The Automated Acquisition of Suggestions from Tweets","authors":"Li Dong, Furu Wei, Yajuan Duan, Xiaohua Liu, Ming Zhou, Ke Xu","author_ids":"4815698, 2517592, 2180009, 1900811, 5962676, 1691178","abstract":"This paper targets at automatically detecting and classifying user's suggestions from tweets. The short and informal nature of tweets, along with the imbalanced characteristics of suggestion tweets, makes the task extremely challenging. To this end, we develop a classification framework on Factorization Machines, which is effective and efficient especially in classification tasks with feature sparsity settings. Moreover, we tackle the imbalance problem by introducing cost-sensitive learning techniques in Factorization Machines. Extensively experimental studies on a manually annotated real-life data set show that the proposed approach significantly improves the baseline approach, and yields the precision of 71.06% and recall of 67.86%. We also investigate the reason why Factorization Machines perform better. Finally, we introduce the first manually annotated dataset for suggestion classification.","cites":"3","conferencePercentile":"47.09090909"},{"venue":"AAAI","id":"00fc90d405bb26605346107be54a4b0276a41be0","venue_1":"AAAI","year":"2006","title":"Behaviosites: Manipulation of Multiagent System Behavior through Parasitic Infection","authors":"Amit Shabtay, Zinovi Rabinovich, Jeffrey S. Rosenschein","author_ids":"1837003, 1756878, 1735970","abstract":"In this paper we present the Behaviosite Paradigm, a new approach to coordination and control of distributed agents in a multiagent system, inspired by biological parasites with behavior manipulation properties. Behaviosites are code modules that \" infect \" a system, attaching themselves to agents and altering the sensory activity and actions of those agents. These behavioral changes can be used to achieve altered, potentially improved, performance of the overall system; thus, Behaviosites provide a mechanism for distributed control over a distributed system. Behaviosites need to be designed so that they are intimately familiar with the internal workings of the environment and of the agents operating within it. To demonstrate our approach, we use behaviosites to control the behavior of a swarm of simple agents. With a relatively low infection rate, a few behaviosites can engender desired behavior over the swarm as a whole: keeping it in one place, leading it through checkpoints, or moving the swarm from one stable equilibrium to another. We contrast behaviosites as a distributed swarm control mechanism with alternatives, such as the use of group leaders, herders, or social norms.","cites":"0","conferencePercentile":"5.763688761"},{"venue":"AAAI","id":"07e42776cbc82506c3e4c8e16d054c25eade3dca","venue_1":"AAAI","year":"2006","title":"Mechanisms for Partial Information Elicitation: The Truth, but Not the Whole Truth","authors":"Aviv Zohar, Jeffrey S. Rosenschein","author_ids":"1782535, 1735970","abstract":"We examine a setting in which a buyer wishes to purchase probabilistic information from some agent. The seller must invest effort in order to gain access to the information, and must therefore be compensated appropriately. However, the information being sold is hard to verify and the seller may be tempted to lie in order to collect a higher payment. While it is generally easy to design information elicitation mechanisms that motivate the seller to be truthful, we show that if the seller has additional relevant information it does not want to reveal, the buyer must resort to elicitation mechanisms that work only some of the time. The optimal design of such mechanisms is shown to be computationally hard. We show two different algorithms to solve the mechanism design problem, each appropriate (from a complexity point of view) in different scenarios.","cites":"1","conferencePercentile":"14.4092219"},{"venue":"AAAI","id":"11210ac2c58075bf960f9feef9e3ca5bcb4b1a2c","venue_1":"AAAI","year":"2007","title":"Learning Voting Trees","authors":"Ariel D. Procaccia, Aviv Zohar, Yoni Peleg, Jeffrey S. Rosenschein","author_ids":"1689184, 1782535, 2017198, 1735970","abstract":"Binary voting trees provide a succinct representation for a large and prominent class of voting rules. In this paper, we investigate the PAC-learnability of this class of rules. We show that, while in general a learning algorithm would require an exponential number of samples, if the number of leaves is polynomial in the size of the set of alternatives then a polynomial training set suffices. We apply these results in an emerging theory: automated design of voting rules by learning.","cites":"12","conferencePercentile":"57.71513353"},{"venue":"AAAI","id":"0e01a90cfe4e502e2b07cef9c1481d0afe021d13","venue_1":"AAAI","year":"2008","title":"Multiagent Graph Coloring: Pareto Efficiency, Fairness and Individual Rationality","authors":"Yaad Blum, Jeffrey S. Rosenschein","author_ids":"2660792, 1735970","abstract":"We consider a multiagent extension of single-agent graph coloring. Multiple agents hold disjoint autonomous subgraphs of a global graph, and every color used by the agents in coloring the graph has associated cost. In this multiagent graph coloring scenario, we seek a minimum legal coloring of the global graph's vertices, such that the coloring is also Pareto efficient, socially fair, and individual rational. We analyze complexity of individual-rational solutions in special graph classes where classical coloring algorithms are known. Multiagent graph coloring has application to a wide variety of multiagent coordination problems, including multiagent scheduling.","cites":"0","conferencePercentile":"7.120253165"},{"venue":"AAAI","id":"7692d934664d627cdf0dc5d634f6c9b27124abb3","venue_1":"AAAI","year":"2008","title":"Strategyproof Classification under Constant Hypotheses: A Tale of Two Functions","authors":"Reshef Meir, Ariel D. Procaccia, Jeffrey S. Rosenschein","author_ids":"1769579, 1689184, 1735970","abstract":"We consider the following setting: a decision maker must make a decision based on reported data points with binary labels. Subsets of data points are controlled by different selfish agents, which might misreport the labels in order to sway the decision in their favor. We design mechanisms (both de-terministic and randomized) that reach an approximately optimal decision and are strategyproof, i.e., agents are best off when they tell the truth. We then recast our results into a classical machine learning classification framework, where the decision maker must make a decision (choose between the constant positive hypothesis and the constant negative hypothesis) based only on a sampled subset of the agents' points.","cites":"12","conferencePercentile":"61.86708861"},{"venue":"AAAI","id":"4c5d7e824a7cfbf2d896e58b6395ffc93e1a376e","venue_1":"AAAI","year":"2008","title":"Coordination and Multi-Tasking Using EMT","authors":"Zinovi Rabinovich, Nir Pochter, Jeffrey S. Rosenschein","author_ids":"1756878, 2965935, 1735970","abstract":"We introduce a multi-model variant of the EMT-based control algorithm. The new algorithm, MM-EMT, is capable of balancing several control tasks expressed using separate dynamic models with a common action space. Such multiple models are common in both single-agent environments, when the agent has multiple tasks to achieve, and in team activities, when agent actions affect both the local agent's task as well as the overall team's coordination. To demonstrate the behaviour that MM-EMT engenders, several experimental setups were devised. Simulation results support the effectiveness of the approach, which in the multi-agent scenario is expressed in the MM-EMT algorithm's ability to balance local and team-coordinated motion requirements .","cites":"0","conferencePercentile":"7.120253165"},{"venue":"AAAI","id":"59a999af705b233f7f7f438c2ed7152dd62a4807","venue_1":"AAAI","year":"2010","title":"Search Space Reduction Using Swamp Hierarchies","authors":"Nir Pochter, Aviv Zohar, Jeffrey S. Rosenschein, Ariel Felner","author_ids":"2965935, 1782535, 1735970, 2583880","abstract":"In various domains, such as computer games, robotics, and transportation networks, shortest paths may need to be found quickly. Search time can be significantly reduced if it is known which parts of the graph include \" swamps \" —areas that cannot lie on the only available shortest path, and can thus safely be pruned during search. We introduce an algorithm for detecting hierarchies of swamps, and exploiting them. Experiments support our claims of improved efficiency , showing significant reduction in search time.","cites":"13","conferencePercentile":"60.58020478"},{"venue":"AAAI","id":"6a918df25ef72410f62fb5e41764bac4721f0bc6","venue_1":"AAAI","year":"2011","title":"Exploiting Problem Symmetries in State-Based Planners","authors":"Nir Pochter, Aviv Zohar, Jeffrey S. Rosenschein","author_ids":"2965935, 1782535, 1735970","abstract":"Previous research in Artificial Intelligence has identified the possibility of simplifying planning problems via the identification and exploitation of symmetries. We advance the state of the art in algorithms that exploit symmetry in planning problems by generalizing previous approaches, and applying symmetry reductions to state-based planners. We suggest several algorithms for symmetry exploitation in state-based search, but also provide a comprehensive view through which additional algorithms can be developed and fine-tuned. We evaluate our approach to symmetry exploitation on instances from previous planning competitions, and demonstrate that our algorithms significantly improve the solution time of instances with symmetries.","cites":"19","conferencePercentile":"85.395189"},{"venue":"AAAI","id":"21f59386251478d441b488a73ba3fc535c1bedf5","venue_1":"AAAI","year":"2013","title":"Bounding the Cost of Stability in Games over Interaction Networks","authors":"Reshef Meir, Yair Zick, Edith Elkind, Jeffrey S. Rosenschein","author_ids":"1769579, 3061819, 1729566, 1735970","abstract":"We study the stability of cooperative games played over an interaction network, in a model that was introduced by My-erson (1977). We show that the cost of stability of such games (i.e., the subsidy required to stabilize the game) can be bounded in terms of natural parameters of their underlying interaction networks. Specifically, we prove that if the treewidth of the interaction network H is k, then the relative cost of stability of any game played over H is at most k + 1, and if the pathwidth of H is k , then the relative cost of stability is at most k. We show that these bounds are tight for all k ≥ 2 and all k ≥ 1, respectively.","cites":"4","conferencePercentile":"55.45454545"},{"venue":"AAAI","id":"65280d929cb2c5ad5856fbd3c8fefd3322cad537","venue_1":"AAAI","year":"2015","title":"Analysis of Equilibria in Iterative Voting Schemes","authors":"Zinovi Rabinovich, Svetlana Obraztsova, Omer Lev, Evangelos Markakis, Jeffrey S. Rosenschein","author_ids":"1756878, 1773297, 1785023, 1737120, 1735970","abstract":"Following recent studies of iterative voting and its effects on plurality vote outcomes, we provide characterisations and complexity results for three models of iterative voting under the plurality rule. Our focus is on providing a better understanding regarding the set of equilibria attainable by iterative voting processes. We start with the basic model of plurality voting. We first establish some useful properties of equilibria, reachable by iterative voting, which enable us to show that deciding whether a given profile is an iteratively reachable equilibrium is NP-complete. We then proceed to combine iterative voting with the concept of truth bias, a model where voters prefer to be truthful when they cannot affect the outcome. We fully characterise the set of attainable truth-biased equilibria, and show that it is possible to determine all such equilibria in polynomial time. Finally, we also examine the model of lazy voters, in which a voter may choose to abstain from the election. We establish convergence of the iterative process, albeit not necessarily to a Nash equilibrium. As in the case with truth bias, we also provide a polynomial time algorithm to find all the attainable equilibria.","cites":"12","conferencePercentile":"94.72440945"},{"venue":"AAAI","id":"17de673280a7d2bb84f397462044390b2083c2b6","venue_1":"AAAI","year":"2015","title":"The Pricing War Continues: On Competitive Multi-Item Pricing","authors":"Omer Lev, Joel Oren, Craig Boutilier, Jeffrey S. Rosenschein","author_ids":"1785023, 2990004, 2105432, 1735970","abstract":"We study a game with strategic vendors (the agents) who own multiple items and a single buyer with a submodular valuation function. The goal of the vendors is to maximize their revenue via pricing of the items, given that the buyer will buy the set of items that maximizes his net payoff. We show this game may not always have a pure Nash equilibrium , in contrast to previous results for the special case where each vendor owns a single item. We do so by relating our game to an intermediate, discrete game in which the vendors only choose the available items, and their prices are set exogenously afterwards. We further make use of the intermediate game to provide tight bounds on the price of anarchy for the subset games that have pure Nash equilibria; we find that the optimal PoA reached in the previous special cases does not hold, but only a logarithmic one. Finally, we show that for a special case of submod-ular functions, efficient pure Nash equilibria always exist.","cites":"2","conferencePercentile":"51.65354331"},{"venue":"AAAI","id":"073032c3450ca7faaeac5d2accd963939e0f2a9c","venue_1":"AAAI","year":"1992","title":"A Probabilistic Parser Applied to Software Testing Documents","authors":"Mark A. Jones, Jason Eisner","author_ids":"8081350, 1689429","abstract":"We describe an approach to training a statistical parser from a bracketed corpus, and demonstrate its use in a software testing application that translates English speciications into an automated testing language. A grammar is not explicitly speciied; the rules and contextual probabilities of occurrence are automatically generated from the corpus. The parser is extremely successful at producing and identifying the correct parse, and nearly deterministic in the number of parses that it produces. To compensate for undertrain-ing, the parser also uses general, linguistic sub-theories which aid in guessing some types of novel structures.","cites":"15","conferencePercentile":"33.92857143"},{"venue":"AAAI","id":"16e2a69ec94d08ceee3edbee304d16ac748979e2","venue_1":"AAAI","year":"2016","title":"Strategyproof Peer Selection: Mechanisms, Analyses, and Experiments","authors":"Haris Aziz, Omer Lev, Nicholas Mattei, Jeffrey S. Rosenschein, Toby Walsh","author_ids":"2382536, 1785023, 2080249, 1735970, 1733716","abstract":"We study an important crowdsourcing setting where agents evaluate one another and, based on these evaluations, a subset of agents are selected. This setting is ubiquitous when peer review is used for distributing awards in a team, allocating funding to scientists, and selecting publications for conferences. The fundamental challenge when applying crowd-sourcing in these settings is that agents may misreport their reviews of others to increase their chances of being selected. We propose a new strategyproof (impartial) mechanism called Dollar Partition that satisfies desirable axiomatic properties. We then show, using a detailed experiment with parameter values derived from target real world domains, that our mechanism performs better on average, and in the worst case, than other strategyproof mechanisms in the literature.","cites":"2","conferencePercentile":"61.31756757"},{"venue":"AAAI","id":"1850623e3dc871fbfb86f913f897648370fdd2f9","venue_1":"AAAI","year":"2016","title":"An Axiomatic Framework for Ex-Ante Dynamic Pricing Mechanisms in Smart Grid","authors":"Sambaran Bandyopadhyay, Ramasuri Narayanam, Pratyush Kumar, Sarvapali D. Ramchurn, Vijay Arya, Iskandarbin Petra","author_ids":"3023820, 3196118, 2976756, 1805612, 1745768, 3382002","abstract":"In electricity markets, the choice of the right pricing regime is crucial for the utilities because the price they charge to their consumers, in anticipation of their demand in real-time, is a key determinant of their profits and ultimately their survival in competitive energy markets. Among the existing pricing regimes, in this paper, we consider ex-ante dynamic pricing schemes as (i) they help to address the peak demand problem (a crucial problem in smart grids), and (ii) they are transparent and fair to consumers as the cost of electricity can be calculated before the actual consumption. In particular, we propose an axiomatic framework that establishes the conceptual underpinnings of the class of ex-ante dynamic pricing schemes. We first propose five key axioms that reflect the criteria that are vital for energy utilities and their relationship with consumers. We then prove an impossibility theorem to show that there is no pricing regime that satisfies all the five axioms simultaneously. We also study multiple cost functions arising from various pricing regimes to examine the subset of axioms that they satisfy. We believe that our proposed framework in this paper is first of its kind to evaluate the class of ex-ante dynamic pricing schemes in a manner that can be op-erationalised by energy utilities.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"4d3592667e8ab06d3eec45cdbb1dcbc99fab1d67","venue_1":"AAAI","year":"2015","title":"Crowdsourcing Complex Workflows under Budget Constraints","authors":"Long Tran-Thanh, Trung Dong Huynh, Avi Rosenfeld, Sarvapali D. Ramchurn, Nicholas R. Jennings","author_ids":"2757815, 1791030, 1955991, 1805612, 1786650","abstract":"We consider the problem of task allocation in crowdsourc-ing systems with multiple complex workflows, each of which consists of a set of interdependent micro-tasks. We propose Budgeteer, an algorithm to solve this problem under a budget constraint. In particular, our algorithm first calculates an efficient way to allocate budget to each workflow. It then determines the number of interdependent micro-tasks and the price to pay for each task within each workflow, given the corresponding budget constraints. We empirically evaluate it on a well-known crowdsourcing-based text correction workflow using Amazon Mechanical Turk, and show that Budgeteer can achieve similar levels of accuracy to current benchmarks, but is on average 45% cheaper.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"246598c5ecc13611f33331b0ebbe83e441e09b66","venue_1":"AAAI","year":"2006","title":"Robust Mechanisms for Information Elicitation","authors":"Aviv Zohar, Jeffrey S. Rosenschein","author_ids":"1782535, 1735970","abstract":"We study information elicitation mechanisms in which a principal agent attempts to elicit the private information of other agents using a carefully selected payment scheme based on proper scoring rules. Scoring rules, like many other mechanisms set in a probabilistic environment, assume that all participating agents share some common belief about the underlying probability of events. In real-life situations however, underlying distributions are not known precisely, and small differences in beliefs about these distributions may alter agent behavior under the prescribed mechanism.We propose designing elicitation mechanisms in a manner that will be robust to small changes in belief. We show how to algorithmically design such mechanisms in polynomial time using tools of stochastic programming and convex programming, and discuss implementation issues for multiagent scenarios.","cites":"10","conferencePercentile":"52.3054755"},{"venue":"AAAI","id":"358bcd9f3b3b3030e28274f7eade8e5307d0d666","venue_1":"AAAI","year":"1994","title":"Emergent Coordination through the Use of Cooperative State-Changing Rules","authors":"Claudia V. Goldman, Jeffrey S. Rosenschein","author_ids":"1728547, 1735970","abstract":"Researchers in Distributed &tificial Intelligence have suggested that it would be worthwhile to isolate \" aspects of cooperative behavior, \" general rules that cause agents to act in ways conducive to cooperation. One kind of cooperative behavior is when agents independently alter the environment to make it easier for everyone to function effectively. Cooperative behavior of this kind might be to put away a hammer that one finds lying on the floor, knowing that another agent will be able to find it more easily later on. We examine the effect a specific \" cooperation rule \" has on agents in the multi-agent Tileworld domain. Agents are encouraged to increase tiles' degrees of freedom, even when the tile is not involved in an agent's own primary plan. The amount of extra work an agent is willing to do is captured in the agent's cooperation level. Results from simulations are presented. We present a way of characterizing domains as multi-agent deterministic finite automata, and characterizing cooperative rules as transformations of these au-tomata. We also discuss general characteristics of cooperative state-changing rules. It is shown that a relatively simple, easily calculated rule can sometimes improve global system performance in the Tileworld. Coordination emerges from agents who use this rule of cooperation, without any explicit coordination or negotiation.","cites":"40","conferencePercentile":"80.39647577"},{"venue":"AAAI","id":"300538cf5de8c7c64dd38c2ae842047bae3895e9","venue_1":"AAAI","year":"2006","title":"Learning Basis Functions in Hybrid Domains","authors":"Branislav Kveton, Milos Hauskrecht","author_ids":"1681967, 1731761","abstract":"Markov decision processes (MDPs) with discrete and continuous state and action components can be solved efficiently by hybrid approximate linear programming (HALP). The main idea of the approach is to approximate the optimal value function by a set of basis functions and optimize their weights by linear programming. The quality of this approximation naturally depends on its basis functions. However, basis functions leading to good approximations are rarely known in advance. In this paper, we propose a new approach that discovers these functions automatically. The method relies on a class of para-metric basis function models, which are optimized using the dual formulation of a relaxed HALP. We demonstrate the performance of our method on two hybrid optimization problems and compare it to manually selected basis functions.","cites":"8","conferencePercentile":"46.39769452"},{"venue":"AAAI","id":"0c686c714ba64bb8c1210c0a0a7560bceafac920","venue_1":"AAAI","year":"2010","title":"Latent Variable Model for Learning in Pairwise Markov Networks","authors":"Saeed Amizadeh, Milos Hauskrecht","author_ids":"1961237, 1731761","abstract":"Pairwise Markov Networks (PMN) are an important class of Markov networks which, due to their simplicity, are widely used in many applications such as image analysis, bioinformatics, sensor networks, etc. However, learning of Markov networks from data is a challenging task; there are many possible structures one must consider and each of these structures comes with its own parameters making it easy to overfit the model with limited data. To deal with the problem, recent learning methods build upon the L1 regularization to express the bias towards sparse network structures. In this paper, we propose a new and more flexible framework that let us bias the structure, that can, for example, encode the preference to networks with certain local substructures which as a whole exhibit some special global structure. We experiment with and show the benefit of our framework on two types of problems: learning of modular networks and learning of traffic networks models.","cites":"4","conferencePercentile":"27.1331058"},{"venue":"AAAI","id":"12cd541ac7dc49c750c54d79e6aacd0c2d1401e9","venue_1":"AAAI","year":"2014","title":"Robust Non-Negative Dictionary Learning","authors":"Qihe Pan, Deguang Kong, Chris H. Q. Ding, Bin Luo","author_ids":"2962611, 8720637, 1737469, 1737124","abstract":"Dictionary learning plays an important role in machine learning , where data vectors are modeled as a sparse linear combinations of basis factors (i.e., dictionary). However, how to conduct dictionary learning in noisy environment has not been well studied. Moreover, in practice, the dictionary (i.e., the lower rank approximation of the data matrix) and the sparse representations are required to be nonnegative, such as applications for image annotation, document summarization, microarray analysis. In this paper, we propose a new formulation for non-negative dictionary learning in noisy environment , where structure sparsity is enforced on sparse representation. The proposed new formulation is also robust for data with noises and outliers, due to a robust loss function used. We derive an efficient multiplicative updating algorithm to solve the optimization problem, where dictionary and sparse representation are updated iteratively. We prove the convergence and correctness of proposed algorithm rigorously. We show the differences of dictionary at different level of spar-sity constraint. The proposed algorithm can be adapted for clustering and semi-supervised learning.","cites":"2","conferencePercentile":"38.63636364"},{"venue":"AAAI","id":"bfa80c869ba4272d525f2132205c412abb6d19e3","venue_1":"AAAI","year":"2014","title":"Source Free Transfer Learning for Text Classification","authors":"Zhongqi Lu, Yin Zhu, Sinno Jialin Pan, Evan Wei Xiang, Yujing Wang, Qiang Yang","author_ids":"1693122, 6002814, 1790541, 1687976, 2895012, 1733090","abstract":"Transfer learning uses relevant auxiliary data to help the learning task in a target domain where labeled data is usually insufficient to train an accurate model. Given appropriate auxiliary data, researchers have proposed many transfer learning models. How to find such auxiliary data, however, is of little research so far. In this paper , we focus on the problem of auxiliary data retrieval, and propose a transfer learning framework that effectively selects helpful auxiliary data from an open knowledge space (e.g. the World Wide Web). Because there is no need of manually selecting auxiliary data for different target domain tasks, we call our framework Source Free Transfer Learning (SFTL). For each target domain task, SFTL framework iteratively queries for the helpful auxiliary data based on the learned model and then updates the model using the retrieved auxiliary data. We highlight the automatic constructions of queries and the robustness of the SFTL framework. Our experiments on 20NewsGroup dataset and a Google search snippets dataset suggest that the framework is capable of achieving comparable performance to those state-of-the-art methods with dedicated selections of auxiliary data.","cites":"3","conferencePercentile":"49.43181818"},{"venue":"AAAI","id":"e06057fdab9204fb6df09d5d7641ed9b415df4cb","venue_1":"AAAI","year":"2014","title":"Hybrid Heterogeneous Transfer Learning through Deep Learning","authors":"Joey Tianyi Zhou, Sinno Jialin Pan, Ivor W. Tsang, Yan Yan","author_ids":"2235660, 1790541, 1807998, 1703972","abstract":"Most previous heterogeneous transfer learning methods learn a cross-domain feature mapping between heterogeneous feature spaces based on a few cross-domain instance-correspondences, and these corresponding instances are assumed to be representative in the source and target domains respectively. However, in many real-world scenarios, this assumption may not hold. As a result, the constructed feature mapping may not be precise due to the bias issue of the correspondences in the target or (and) source domain(s). In this case, a classifier trained on the labeled transformed-source-domain data may not be useful for the target domain. In this paper, we present a new transfer learning framework called Hybrid Heterogeneous Transfer Learning (HHTL), which allows the corresponding instances across domains to be biased in either the source or target domain. Specifically, we propose a deep learning approach to learn a feature mapping between cross-domain heterogeneous features as well as a better feature representation for mapped data to reduce the bias issue caused by the cross-domain correspondences. Extensive experiments on several multilingual sentiment classification tasks verify the effectiveness of our proposed approach compared with some baseline methods.","cites":"13","conferencePercentile":"92.5"},{"venue":"AAAI","id":"0cb649e89bb58b151567bb0124422bbea296f0b2","venue_1":"AAAI","year":"2013","title":"Active Transfer Learning for Cross-System Recommendation","authors":"Lili Zhao, Sinno Jialin Pan, Evan Wei Xiang, Erheng Zhong, Zhongqi Lu, Qiang Yang","author_ids":"1718117, 1790541, 1687976, 1762818, 1693122, 1733090","abstract":"Recommender systems, especially the newly launched ones, have to deal with the data-sparsity issue, where little existing rating information is available. Recently, transfer learning has been proposed to address this problem by leveraging the knowledge from related recom-mender systems where rich collaborative data are available. However, most previous transfer learning models assume that entity-correspondences across different systems are given as input, which means that for any entity (e.g., a user or an item) in a target system, its corresponding entity in a source system is known. This assumption can hardly be satisfied in real-world scenarios where entity-correspondences across systems are usually unknown, and the cost of identifying them can be expensive. For example, it is extremely difficult to identify whether a user A from Facebook and a user B from Twitter are the same person. In this paper, we propose a framework to construct entity correspondence with limited budget by using active learning to facilitate knowledge transfer across recommender systems. Specifically, for the purpose of maximizing knowledge transfer, we first iteratively select entities in the target system based on our proposed criterion to query their correspondences in the source system. We then plug the actively constructed entity-correspondence mapping into a general transferred collaborative-filtering model to improve recommendation quality. We perform extensive experiments on real world datasets to verify the effectiveness of our proposed framework for this cross-system recommendation problem.","cites":"16","conferencePercentile":"92.18181818"},{"venue":"AAAI","id":"2069c9389df8bb29b7fedf2c2ccfe7aaf82b2832","venue_1":"AAAI","year":"2011","title":"Heterogeneous Transfer Learning for Image Classification","authors":"Yin Zhu, Yuqiang Chen, Zhongqi Lu, Sinno Jialin Pan, Gui-Rong Xue, Yong Yu, Qiang Yang","author_ids":"6002814, 2756531, 1693122, 1790541, 1701421, 3578922, 1733090","abstract":"Transfer learning as a new machine learning paradigm has gained increasing attention lately. In situations where the training data in a target domain are not sufficient to learn pre-dictive models effectively, transfer learning leverages auxiliary source data from other related source domains for learning. While most of the existing works in this area only fo-cused on using the source data with the same structure as the target data, in this paper, we push this boundary further by proposing a heterogeneous transfer learning framework for knowledge transfer between text and images. We observe that for a target-domain classification problem, some annotated images can be found on many social Web sites, which can serve as a bridge to transfer knowledge from the abundant text documents available over the Web. A key question is how to effectively transfer the knowledge in the source data even though the text can be arbitrarily found. Our solution is to enrich the representation of the target images with semantic concepts extracted from the auxiliary source data through a novel matrix factorization method. By using the latent semantic features generated by the auxiliary data, we are able to build a better integrated image classifier. We empirically demonstrate the effectiveness of our algorithm on the Caltech-256 image dataset.","cites":"42","conferencePercentile":"97.25085911"},{"venue":"AAAI","id":"a795873690b0f99946192f1a62701e390d2ba3a7","venue_1":"AAAI","year":"2010","title":"Adaptive Transfer Learning","authors":"Bin Cao, Sinno Jialin Pan, Yu Zhang, Dit-Yan Yeung, Qiang Yang","author_ids":"1693204, 1790541, 1729700, 1739816, 1733090","abstract":"Transfer learning aims at reusing the knowledge in some source tasks to improve the learning of a target task. Many transfer learning methods assume that the source tasks and the target task be related, even though many tasks are not related in reality. However, when two tasks are unrelated, the knowledge extracted from a source task may not help, and even hurt, the performance of a target task. Thus, how to avoid negative transfer and then ensure a \" safe transfer \" of knowledge is crucial in transfer learning. In this paper, we propose an Adaptive Transfer learning algorithm based on Gaussian Processes (AT-GP), which can be used to adapt the transfer learning schemes by automatically estimating the similarity between a source and a target task. The main contribution of our work is that we propose a new semi-parametric transfer kernel for transfer learning from a Bayesian perspective, and propose to learn the model with respect to the target task, rather than all tasks as in multi-task learning. We can formulate the transfer learning problem as a unified Gaussian Process (GP) model. The adaptive transfer ability of our approach is verified on both synthetic and real-world datasets.","cites":"21","conferencePercentile":"77.64505119"},{"venue":"AAAI","id":"4d1479a4e610e69adf0c5a580d97bdee074e986f","venue_1":"AAAI","year":"2008","title":"Transferring Localization Models across Space","authors":"Sinno Jialin Pan, Dou Shen, Qiang Yang, James T. Kwok","author_ids":"1790541, 1680850, 1733090, 1776349","abstract":"abstract Machine learning approaches to indoor WiFi localiza-tion involve an offline phase and an online phase. In the offline phase, data are collected from an environment to build a localization model, which will be applied to new data collected in the online phase for location estimation. However, collecting the labeled data across an entire building would be too time consuming. In this paper, we present a novel approach to transferring the learning model trained on data from one area of a building to another. We learn a mapping function between the signal space and the location space by solving an optimization problem based on manifold learning techniques. A low-dimensional manifold is shared between data collected in different areas in an environment as a bridge to propagate the knowledge across the whole environment. With the help of the transferred knowledge, we can significantly reduce the amount of labeled data which are required for building the localization model. We test the effectiveness of our proposed solution in a real indoor WiFi environment.","cites":"14","conferencePercentile":"66.61392405"},{"venue":"AAAI","id":"1cb2907141f65acb6ae685fad80fa8c8080f2304","venue_1":"AAAI","year":"2015","title":"Sharing Rides with Friends: A Coalition Formation Algorithm for Ridesharing","authors":"Filippo Bistaffa, Alessandro Farinelli, Sarvapali D. Ramchurn","author_ids":"1711291, 1690281, 1805612","abstract":"We consider the Social Ridesharing (SR) problem, where a set of commuters, connected through a social network, arrange one-time rides at short notice. In particular, we focus on the associated optimisation problem of forming cars to minimise the travel cost of the overall system modelling such problem as a graph constrained coalition formation (GCCF) problem, where the set of feasible coalitions is restricted by a graph (i.e., the social network). Moreover, we significantly extend the state of the art algorithm for GCCF, i.e., the CFSS algorithm, to solve our GCCF model of the SR problem. Our empirical evaluation uses a real dataset for both spatial (Geo-Life) and social data (Twitter), to validate the applicability of our approach in a realistic application scenario. Empirical results show that our approach computes optimal solutions for systems of medium scale (up to 100 agents) providing significant cost reductions (up to −36.22%). Moreover, we can provide approximate solutions for very large systems (i.e., up to 2000 agents) and good quality guarantees (i.e., with an approximation ratio of 1.41 in the worst case) within minutes (i.e., 100 seconds).","cites":"4","conferencePercentile":"73.46456693"},{"venue":"AAAI","id":"033472178174f153607148e5781d9b9be8f2bfcc","venue_1":"AAAI","year":"2008","title":"Transfer Learning via Dimensionality Reduction","authors":"Sinno Jialin Pan, James T. Kwok, Qiang Yang","author_ids":"1790541, 1776349, 1733090","abstract":"Transfer learning addresses the problem of how to utilize plenty of labeled data in a source domain to solve related but different problems in a target domain, even when the training and testing problems have different distributions or features. In this paper, we consider transfer learning via dimensionality reduction. To solve this problem, we learn a low-dimensional latent feature space where the distributions between the source domain data and the target domain data are the same or close to each other. Onto this latent feature space, we project the data in related domains where we can apply standard learning algorithms to train classification or regression models. Thus, the latent feature space can be treated as a bridge of transferring knowledge from the source domain to the target domain. The main contribution of our work is that we propose a new di-mensionality reduction method to find a latent space, which minimizes the distance between distributions of the data in different domains in a latent space. The effectiveness of our approach to transfer learning is verified by experiments in two real world applications: indoor WiFi localization and binary text classification.","cites":"127","conferencePercentile":"99.05063291"},{"venue":"AAAI","id":"2a4a7fd878a6c28c46899adbddc0f68cbdebfee4","venue_1":"AAAI","year":"2007","title":"Online Co-Localization in Indoor Wireless Networks by Dimension Reduction","authors":"Jeffrey Junfeng Pan, Qiang Yang, Sinno Jialin Pan","author_ids":"1730133, 1733090, 1790541","abstract":"This paper addresses the problem of recovering the locations of both mobile devices and access points from radio signals that come in a stream manner, a problem which we call online co-localization, by exploiting both labeled and unlabeled data from mobile devices and access points. Many tracking systems function in two phases: an offline training phase and an online localiza-tion phase. In the training phase, models are built from a batch of data that are collected offline. Many of them can not cope with a dynamic environment in which calibration data may come sequentially. In such case, these systems may gradually become inaccurate without a manually costly re-calibration. To solve this problem, we proposed an online co-localization method that can deal with labeled and unlabeled data stream based on semi-supervised manifold-learning techniques. Experiments conducted in wireless local area networks show that we can achieve high accuracy with less calibration effort as compared to several previous systems. Furthermore , our method can deal with online stream data relatively faster than its two-phase counterpart.","cites":"6","conferencePercentile":"38.4272997"},{"venue":"AAAI","id":"b24da8854019436cbc763a26c5a448023caaec6e","venue_1":"AAAI","year":"2016","title":"Multivariate Conditional Outlier Detection and Its Clinical Application","authors":"Charmgil Hong, Milos Hauskrecht","author_ids":"2889409, 1731761","abstract":"This paper overviews and discusses our recent work on a multivariate conditional outlier detection framework for clinical applications.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"e306e0b1702faed407753697a4be36355b881e93","venue_1":"AAAI","year":"2016","title":"Learning Adaptive Forecasting Models from Irregularly Sampled Multivariate Clinical Data","authors":"Zitao Liu, Milos Hauskrecht","author_ids":"3195628, 1731761","abstract":"Building accurate predictive models of clinical multivariate time series is crucial for understanding of the patient condition, the dynamics of a disease, and clinical decision making. A challenging aspect of this process is that the model should be flexible and adaptive to reflect well patient-specific temporal behaviors and this also in the case when the available patient-specific data are sparse and short span. To address this problem we propose and develop an adaptive two-stage forecasting approach for modeling multivariate, irregularly sampled clinical time series of varying lengths. The proposed model (1) learns the population trend from a collection of time series for past patients; (2) captures individual-specific short-term multivariate variability; and (3) adapts by automatically adjusting its predictions based on new observations. The proposed forecasting model is evaluated on a real-world clinical time series dataset. The results demonstrate the benefits of our approach on the prediction tasks for multivariate, irregularly sampled clinical time series, and show that it can outperform both the population based and patient-specific time series prediction models in terms of prediction accuracy.","cites":"1","conferencePercentile":"40.70945946"},{"venue":"AAAI","id":"df0f85297e875c650a20ee7ef0a3aebb38fc9488","venue_1":"AAAI","year":"2015","title":"Multivariate Conditional Anomaly Detection and Its Clinical Application","authors":"Charmgil Hong, Milos Hauskrecht","author_ids":"2889409, 1731761","abstract":"Motivation • Reports from medical/clinical surveys • The occurrence of medical errors remains a persistent and critical problem • Medical errors that correspond to preventable adverse events are estimated to be up to 440k patients each year [James 2013] • This is the third leading cause of death in America 2 Captured from:","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"757dc51464407c1c999e9de05c4c4b40f8447ba1","venue_1":"AAAI","year":"2015","title":"A Regularized Linear Dynamical System Framework for Multivariate Time Series Analysis","authors":"Zitao Liu, Milos Hauskrecht","author_ids":"3195628, 1731761","abstract":"Linear Dynamical System (LDS) is an elegant mathematical framework for modeling and learning Multivariate Time Series (MTS). However, in general, it is difficult to set the dimension of an LDS's hidden state space. A small number of hidden states may not be able to model the complexities of a MTS, while a large number of hidden states can lead to overfitting. In this paper, we study learning methods that impose various regularization penalties on the transition matrix of the LDS model and propose a regularized LDS learning framework (rLDS) which aims to (1) automatically shut down LDSs' spurious and unnecessary dimensions, and consequently, address the problem of choosing the optimal number of hidden states; (2) prevent the overfitting problem given a small amount of MTS data; and (3) support accurate MTS forecasting. To learn the regularized LDS from data we incorporate a second order cone program and a generalized gradient descent method into the Maximum a Posteriori framework and use Expectation Maximization to obtain a low-rank transition matrix of the LDS model. We propose two priors for modeling the matrix which lead to two instances of our rLDS. We show that our rLDS is able to recover well the intrinsic dimensionality of the time series dynamics and it improves the predictive performance when compared to baselines on both synthetic and real-world MTS datasets.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"47553d0bb79c24b51cea3582f39a34be296a19de","venue_1":"AAAI","year":"2015","title":"Obtaining Well Calibrated Probabilities Using Bayesian Binning","authors":"Mahdi Pakdaman Naeini, Gregory F. Cooper, Milos Hauskrecht","author_ids":"1739626, 1726406, 1731761","abstract":"Learning probabilistic predictive models that are well calibrated is critical for many prediction and decision-making tasks in artificial intelligence. In this paper we present a new non-parametric calibration method called Bayesian Binning into Quantiles (BBQ) which addresses key limitations of existing calibration methods. The method post processes the output of a binary classification algorithm; thus, it can be readily combined with many existing classification algorithms. The method is computationally tractable, and empirically accurate, as evidenced by the set of experiments reported here on both real and simulated datasets.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"195ad95c54cd7f3ac9c437845965f1bc18feab01","venue_1":"AAAI","year":"2013","title":"Conditional Outlier Approach for Detection of Unusual Patient Care Actions","authors":"Milos Hauskrecht, Shyam Visweswaran, Gregory F. Cooper, Gilles Clermont","author_ids":"1731761, 1765482, 1726406, 2212354","abstract":"Developing methods that can identify important patterns in complex large-scale temporal datasets is one of the key challenges in machine learning and data mining research. Our work focuses on the development of methods that can, based on past data, identify unusual patient-management actions in the Electronic Medical Record (EMR) of the current patient and raise alerts if such actions are encountered. We developed and evaluated a conditional-outlier detection approach for identifying clinical actions such as omissions of medication orders or laboratory orders in the intensive care unit (ICU) that are unusual with respect to past patient care. We used data from 24,658 ICU patient admissions to first learn the outlier models and then to generate 240 medication and laboratory omission alerts. The alerts were evaluated by a group of 18 intensive care physicians. The results show the true positive alert rate for all study alerts ranged from 0.42 to 0.53, which is promising and compares favorably to the positive alert rates of existing clinical alerting systems.","cites":"1","conferencePercentile":"25.09090909"},{"venue":"AAAI","id":"4398c25bcea058c7006a741a5d613da8506d52e5","venue_1":"AAAI","year":"2007","title":"Adaptive Localization in a Dynamic WiFi Environment through Multi-view Learning","authors":"Sinno Jialin Pan, James T. Kwok, Qiang Yang, Jeffrey Junfeng Pan","author_ids":"1790541, 1776349, 1733090, 1730133","abstract":"Accurately locating users in a wireless environment is an important task for many pervasive computing and AI applications , such as activity recognition. In a WiFi environment, a mobile device can be localized using signals received from various transmitters, such as access points (APs). Most lo-calization approaches build a map between the signal space and the physical location space in a offline phase, and then using the received-signal-strength (RSS) map to estimate the location in an online phase. However, the map can be outdated when the signal-strength values change with time due to environmental dynamics. It is infeasible or expensive to repeat data calibration for reconstructing the RSS map. In such a case, it is important to adapt the model learnt in one time period to another time period without too much re-calibration. In this paper, we present a location-estimation approach based on Manifold co-Regularization, which is a machine learning technique for building a mapping function between data. We describe LeManCoR, a system for adapting the mapping function between the signal space and physical location space over different time periods based on Manifold Co-Regularization. We show that LeManCoR can effectively transfer the knowledge between two time periods without requiring too much new calibration effort.We illustrate LeMan-CoR's effectiveness in a real 802.11 WiFi environment.","cites":"35","conferencePercentile":"85.90504451"},{"venue":"AAAI","id":"a262efe088b881037c7e7d57774fdeee8c47208d","venue_1":"AAAI","year":"2015","title":"Balanced Trade Reduction for Dual-Role Exchange Markets","authors":"Dengji Zhao, Sarvapali D. Ramchurn, Enrico Gerding, Nicholas R. Jennings","author_ids":"2127683, 1805612, 2985154, 1786650","abstract":"We consider dual-role exchange markets, where traders can offer to both buy and sell the same commodity in the exchange but, if they transact, they can only be either a buyer or a seller, which is determined by the market mechanism. To design desirable mechanisms for such exchanges, we show that existing solutions may not be incentive compatible, and more importantly, cause the market maker to suffer a significant deficit. Hence, to combat this problem, following McAfee's trade reduction approach, we propose a new trade reduction mechanism , called balanced trade reduction, that is incentive compatible and also provides flexible trade-offs between efficiency and deficit.","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"3e3612686e6fa05a443208e9e548922b54a6f860","venue_1":"AAAI","year":"2012","title":"Delivering the Smart Grid: Challenges for Autonomous Agents and Multi-Agent Systems Research","authors":"Alex Rogers, Sarvapali D. Ramchurn, Nicholas R. Jennings","author_ids":"1793672, 1805612, 1786650","abstract":"Restructuring electricity grids to meet the increased demand caused by the electrification of transport and heating , while making greater use of intermittent renewable energy sources, represents one of the greatest engineering challenges of our day. This modern electricity grid, in which both electricity and information flow in two directions between large numbers of widely distributed suppliers and generators — commonly termed the 'smart grid' — represents a radical reengineering of infrastructure which has changed little over the last hundred years. However, the autonomous behaviour expected of the smart grid, its distributed nature, and the existence of multiple stakeholders each with their own incentives and interests, challenges existing engineering approaches. In this challenge paper, we describe why we believe that artificial intelligence, and particularly, the fields of autonomous agents and multi-agent systems are essential for delivering the smart grid as it is envisioned. We present some recent work in this area and describe many of the challenges that still remain.","cites":"11","conferencePercentile":"71.34146341"},{"venue":"AAAI","id":"5aaaa7c18b7703021ed959dbe4dba15b35fd0d8a","venue_1":"AAAI","year":"2012","title":"Competing with Humans at Fantasy Football: Team Formation in Large Partially-Observable Domains","authors":"Tim Matthews, Sarvapali D. Ramchurn, Georgios Chalkiadakis","author_ids":"2472289, 1805612, 3169479","abstract":"We present the first real-world benchmark for sequentially-optimal team formation, working within the framework of a class of online football prediction games known as Fantasy Football. We model the problem as a Bayesian reinforcement learning one, where the action space is exponential in the number of players and where the decision maker's beliefs are over multiple characteristics of each footballer. We then exploit domain knowledge to construct computationally tractable solution techniques in order to build a competitive automated Fantasy Football manager. Thus, we are able to establish the baseline performance in this domain, even without complete information on footballers' performances (accessible to human managers), showing that our agent is able to rank at around the top percentile when pitched against 2.5M human players.","cites":"9","conferencePercentile":"64.02439024"},{"venue":"AAAI","id":"97aa26db674a05aedc609fa5123ad301c810d0ea","venue_1":"AAAI","year":"2006","title":"Using the Semantic Web to Integrate Ecoinformatics Resources","authors":"Cynthia Sims Parr, Andriy Parafiynyk, Joel Sachs, Rong Pan, Lushan Han, Li Ding, Timothy W. Finin, David Wang","author_ids":"8594851, 2243555, 3074520, 1710684, 3050089, 1709049, 1770852, 2214071","abstract":"We demonstrate an end-to-end use case of the semantic web's utility for synthesizing ecological and environmental data. ELVIS (the Ecosystem Location Visualization and Information System) is a suite of tools for constructing food webs for a given location. ELVIS functionality is exposed as a collection of web services, and all input and output data is expressed in OWL, thereby enabling its integration with other semantic web resources. In particular, we describe using a Triple Shop application to answer SPARQL queries from a collection of semantic web documents.","cites":"3","conferencePercentile":"26.5129683"},{"venue":"AAAI","id":"2985d838d4a7c1ac7ce39534426bc1caa7a86ea3","venue_1":"AAAI","year":"2013","title":"Verbal IQ of a Four-Year Old Achieved by an AI System","authors":"Stellan Ohlsson, Robert H. Sloan, György Turán, Aaron Urasky","author_ids":"2995788, 1792015, 1767680, 1898418","abstract":"One view of common-sense reasoning ability is that it is the ability to perform those tasks with verbal inputs and outputs that have traditionally been difficult for computer systems, but are easy for fairly young children. We administered the verbal part of the Wechsler Preschool and Primary Scale of Intelligence (WPPSI-III, Third Edition) to the ConceptNet 4 system. The IQ test's questions (e.g., \" Why do we shake hands? \" or \" What do apples and bananas have in common \") were translated into ConceptNet 4 inputs using a combination of the simple natural language processing tools that come with ConceptNet together with short Python programs that we wrote. The question-answering primarily used the part of the ConceptNet system that represents the knowledge as a matrix based on spectral methods (AnalogySpace). We found that the system has a Verbal IQ that is average for a four-year-old child, but below average for 5, 6, and 7 year-olds. Large variations from subtest to subtest indicate potential areas of improvement. In particular, results were strongest for the Vocabulary and Similarities subtests, intermediate for the Information subtest, and lowest for the Comprehension and Word Reasoning subtests. Comprehension is the subtest most strongly associated with common sense. Children's verbal IQ tests offer a new, objective, third-party metric for the evaluation and comparison of common-sense AI systems.","cites":"3","conferencePercentile":"47.09090909"},{"venue":"AAAI","id":"05fd8715c5cc8285ed94e8c9e0b18ef16e3c455b","venue_1":"AAAI","year":"1994","title":"Experimentally Evaluating Communicative Strategies: The Effect of the Task","authors":"Marilyn A. Walker","author_ids":"1760530","abstract":"Effective problem solving among multiple agents requires a better understanding of the role of communication in collaboration. In this paper we show that there are communicative strategies that greatly improve the performance of resource-bounded agents, but that these strategies are highly sensitive to the task requirements, situation parameters and agents' resource limitations. We base our argument on two sources of evidence: (1) an analysis of a corpus of 55 problem solving dialogues, and (2) experimental simulations of collaborative problem solving dialogues in an experimental world, Design-World, where we parameterize task requirements, agents' resources and communicative strategies.","cites":"7","conferencePercentile":"36.56387665"},{"venue":"AAAI","id":"e8b0bc84e4529e9eb419ec38a17740792f794478","venue_1":"AAAI","year":"2007","title":"Real-Time Identification of Operating Room State from Video","authors":"Beenish Bhatia, Tim Oates, Yan Xiao, Peter Fu-Ming Hu","author_ids":"2182273, 1756624, 4166958, 2705068","abstract":"Managers of operating rooms (ORs) and of units upstream (e.g., ambulatory surgery) and downstream (e.g., intensive care and post-anesthesia care) of the OR require real-time information about OR occupancy. Which ORs are in use, and when will each ongoing operation end? This information is used to make decisions about how to assign staff, when to prepare patients for the OR, when to schedule add-on cases, when to move cases, and how to prioritize room cleanups (Dexter et al. 2004). It is typically gathered by OR managers manually, by walking to each OR and estimating the time to case completion. This paper presents a system for determining the state of an ongoing operation automatically from video. Support vector machines are trained to identify relevant image features, and hidden Markov models are trained to use these features to compute a sequence of OR states from the video. The system was tested on video captured over a 24 hour period in one of the 19 operating rooms in Baltimore's R. Adams Crowley Shock Trauma Center. It was found to be more accurate and have less delay while providing more fine-grained state information than the current state-of-the-art system based on patient vital signs used by the Shock Trauma Center.","cites":"8","conferencePercentile":"46.29080119"},{"venue":"AAAI","id":"0eb11da1130aae58914fdd6388f556cf59ce4859","venue_1":"AAAI","year":"2015","title":"Microblog Sentiment Classification with Contextual Knowledge Regularization","authors":"Fangzhao Wu, Yangqiu Song, Yongfeng Huang","author_ids":"2397264, 1809614, 1731776","abstract":"Microblog sentiment classification is an important research topic which has wide applications in both academia and industry. Because microblog messages are short, noisy and contain masses of acronyms and informal words, microblog sentiment classification is a very challenging task. Fortunately, collectively the con-textual information about these idiosyncratic words provide knowledge about their sentiment orientations. In this paper, we propose to use the microblogs' contex-tual knowledge mined from a large amount of unlabeled data to help improve microblog sentiment classification. We define two kinds of contextual knowledge: word-word association and word-sentiment association. The contextual knowledge is formulated as regularization terms in supervised learning algorithms. An efficient optimization procedure is proposed to learn the model. Experimental results on benchmark datasets show that our method can consistently and significantly outper-form the state-of-the-art methods.","cites":"2","conferencePercentile":"51.65354331"},{"venue":"AAAI","id":"5d5c9454af83a45df10f386024a2024c0213d740","venue_1":"AAAI","year":"2007","title":"Authorial Idioms for Target Distributions in TTD-MDPs","authors":"David L. Roberts, Sooraj Bhat, Kenneth St. Clair, Charles Lee Isbell","author_ids":"5797583, 1771512, 2765659, 1787816","abstract":"In designing Markov Decision Processes (MDP), one must define the world, its dynamics, a set of actions, and a reward function. MDPs are often applied in situations where there is a clear choice of reward functions and in these cases significant care must be taken to construct a reward function that induces the desired behavior. In this paper, we consider an analogous design problem: crafting a target distribution in Targeted Trajectory Distribution MDPs (TTD-MDPs). TTD-MDPs produce probabilistic policies that minimize divergence from a target distribution of trajectories from an underlying MDP. They are an extension of MDPs that provide variety of experience during repeated execution. Here, we present a brief overview of TTD-MDPs with approaches for constructing target distributions. Then we present a novel au-thorial idiom for creating target distributions using prototype trajectories. We evaluate these approaches on a drama manager for an interactive game.","cites":"12","conferencePercentile":"57.71513353"},{"venue":"AAAI","id":"082979ce49f40c09271f253455cf1cfd9f50d583","venue_1":"AAAI","year":"2006","title":"On the Difficulty of Modular Reinforcement Learning for Real-World Partial Programming","authors":"Sooraj Bhat, Charles Lee Isbell, Michael Mateas","author_ids":"1771512, 1787816, 1780919","abstract":"In recent years there has been a great deal of interest in \" modular reinforcement learning \" (MRL). Typically, problems are decomposed into concurrent subgoals, allowing increased scalability and state abstraction. An arbitrator combines the subagents' preferences to select an action. In this work, we contrast treating an MRL agent as a set of sub-agents with the same goal with treating an MRL agent as a set of subagents who may have different, possibly conflicting goals. We argue that the latter is a more realistic description of real-world problems, especially when building partial programs. We address a range of algorithms for single-goal MRL, and leveraging social choice theory, we present an impossibility result for applications of such algorithms to multi-goal MRL. We suggest an alternative formulation of arbitration as scheduling that avoids the assumptions of comparability of preference that are implicit in single-goal MRL. A notable feature of this formulation is the explicit codification of the tradeoffs between the subproblems. Finally, we introduce A 2 BL, a language that encapsulates many of these ideas.","cites":"11","conferencePercentile":"54.61095101"},{"venue":"AAAI","id":"69797e341f94d78a6b2b7edcf653aa76bf41c188","venue_1":"AAAI","year":"2006","title":"Temporal Preference Optimization as Weighted Constraint Satisfaction","authors":"Michael D. Moffitt, Martha E. Pollack","author_ids":"3254446, 1801194","abstract":"We present a new efficient algorithm for obtaining utilitarian optimal solutions to Disjunctive Temporal Problems with Preferences (DTPPs). The previous state-of-the-art system achieves temporal preference optimization using a SAT formulation, with its creators attributing its performance to advances in SAT solving techniques. We depart from the SAT encoding and instead introduce the Valued DTP (VDTP). In contrast to the traditional semiring-based formalism that annotates legal tuples of a constraint with preferences , our framework instead assigns elementary costs to the constraints themselves. After proving that the VDTP can express the same set of utilitarian optimal solutions as the DTPP with piecewise-constant preference functions, we develop a method for achieving weighted constraint satisfaction within a meta-CSP search space that has traditionally been used to solve DTPs without preferences. This allows us to directly incorporate several powerful techniques developed in previous decision-based DTP literature. Finally, we present empirical results demonstrating that an implementation of our approach consistently outperforms the SAT-based solver by orders of magnitude.","cites":"12","conferencePercentile":"57.20461095"},{"venue":"AAAI","id":"c7de715f3387d752a3f89eb972a01ac34515e007","venue_1":"AAAI","year":"2006","title":"Using Semantic Web Technologies for Policy Management on the Web","authors":"Lalana Kagal, Tim Berners-Lee, Dan Connolly, Daniel J. Weitzner","author_ids":"1735243, 1796130, 2379763, 3152129","abstract":"With policy management becoming popular as a means of providing flexible Web security, the number of policy languages being proposed for the Web is constantly increasing. We recognize the importance of policies for securing the Web and believe that the future will only bring more policy languages. We do not, however, believe that users should be forced to conform the description of their policy relationships to a single standard policy language. Instead there should be a way of encompassing different policy languages and supporting heterogeneous policy systems. As a step in this direction , we propose Rein, a policy framework grounded in Semantic Web technologies, which leverages the distributed nature and linkability of the Web to provide Web-based policy management. Rein provides ontologies for describing policy domains in a decentralized manner and provides an engine for reasoning over these descriptions, both of which can be used to develop domain and policy language specific security systems. We describe the Rein policy framework and discuss how a Rein policy management systems can be developed for access control in an online photo sharing application.","cites":"48","conferencePercentile":"88.90489914"},{"venue":"AAAI","id":"0041616736f5fb2cac94098177a360e534fb45d3","venue_1":"AAAI","year":"2013","title":"Cost-Optimal Planning by Self-Interested Agents","authors":"Raz Nissim, Ronen I. Brafman","author_ids":"1686774, 1680506","abstract":"As our world becomes better connected and autonomous agents no longer appear to be science fiction, a natural need arises for enabling groups of selfish agents to cooperate in generating plans for diverse tasks that none of them can perform alone in a cost-effective manner. While most work on planning for/by selfish agents revolves around finding stable solutions (e.g., Nash Equilibrium), this work combines techniques from mechanism design with a recently introduced method for distributed planning, in order to find cost optimal (and, thus, social welfare maximizing) solutions. Based on the Vickrey-Clarke-Groves mechanisms, we present both a centralized, and a privacy-preserving distributed mechanism.","cites":"6","conferencePercentile":"68.90909091"},{"venue":"AAAI","id":"e17102afd21d90b0fa33aaf30fc0dd0038041263","venue_1":"AAAI","year":"2013","title":"Qualitative Planning under Partial Observability in Multi-Agent Domains","authors":"Ronen I. Brafman, Guy Shani, Shlomo Zilberstein","author_ids":"1680506, 1719532, 1707550","abstract":"Decentralized POMDPs (Dec-POMDPs) provide a rich, attractive model for planning under uncertainty and partial ob-servability in cooperative multi-agent domains with a growing body of research. In this paper we formulate a qualitative , propositional model for multi-agent planning under uncertainty with partial observability, which we call Qualitative Dec-POMDP (QDec-POMDP). We show that the worst-case complexity of planning in QDec-POMDPs is similar to that of Dec-POMDPs. Still, because the model is more \" classical \" in nature, it is more compact and easier to specify. Furthermore , it eases the adaptation of methods used in classical and contingent planning to solve problems that challenge current Dec-POMDPs solvers. In particular, in this paper we describe a method based on compilation to classical planning, which handles multi-agent planning problems significantly larger than those handled by current Dec-POMDP algorithms.","cites":"5","conferencePercentile":"62.54545455"},{"venue":"AAAI","id":"e11eb7e775b0842009a3e59bf08b76eef29886b5","venue_1":"AAAI","year":"2012","title":"Lifted MEU by Weighted Model Counting","authors":"Udi Apsel, Ronen I. Brafman","author_ids":"2008036, 1680506","abstract":"Recent work in the field of probabilistic inference demonstrated the efficiency of weighted model counting (WMC) engines for exact inference in propositional and, very recently, first order models. To date, these methods have not been applied to decision making models , propositional or first order, such as influence diagrams , and Markov decision networks (MDN). In this paper we show how this technique can be applied to such models. First, we show how WMC can be used to solve (propositional) MDNs. Then, we show how this can be extended to handle a first-order model – the Markov Logic Decision Network (MLDN). WMC offers two central benefits: it is a very simple and very efficient technique. This is particularly true for the first-order case, where the WMC approach is simpler conceptually , and, in many cases, more effective computa-tionally than the existing methods for solving MLDNs via first-order variable elimination, or via proposition-alization. We demonstrate the above empirically.","cites":"3","conferencePercentile":"30.79268293"},{"venue":"AAAI","id":"38d674ca16c40a72eb9716da758e2f7af14b9046","venue_1":"AAAI","year":"2012","title":"A Multi-Path Compilation Approach to Contingent Planning","authors":"Ronen I. Brafman, Guy Shani","author_ids":"1680506, 1719532","abstract":"We describe a new sound and complete method for compiling contingent planning problems with sensing actions into classical planning. Our method encodes conditional plans within a linear, classical plan. This allows our planner, MPSR, to reason about multiple future outcomes of sensing actions, and makes it less susceptible to dead-ends. MPRS, however, generates very large classical planning problems. To overcome this, we use an incomplete variant of the method, based on state sampling, within an online replanner. On most current domains, MPSR finds plans faster, although its plans are often longer. But on a new challenging variant of Wumpus with dead-ends, it finds smaller plans, faster, and scales better.","cites":"9","conferencePercentile":"64.02439024"},{"venue":"AAAI","id":"1a99c020d355d2b110f32a04fce9278325053c8a","venue_1":"AAAI","year":"2011","title":"Planning for Operational Control Systems with Predictable Exogenous Events","authors":"Ronen I. Brafman, Carmel Domshlak, Yagil Engel, Zohar Feldman","author_ids":"1680506, 1735824, 2259790, 2136401","abstract":"Various operational control systems (OCS) are naturally modeled as Markov Decision Processes. OCS often enjoy access to predictions of future events that have substantial impact on their operations. For example, reliable forecasts of extreme weather conditions are widely available, and such events can affect typical request patterns for customer response management systems, the flight and service time of airplanes, or the supply and demand patterns for electricity. The space of exogenous events impacting OCS can be very large, prohibiting their modeling within the MDP; moreover, for many of these exogenous events there is no useful pre-dictive, probabilistic model. Realtime predictions, however, possibly with a short lead-time, are often available. In this work we motivate a model which combines offline MDP infinite horizon planning with realtime adjustments given specific predictions of future exogenous events, and suggest a framework in which such predictions are captured and trigger real-time planning problems. We propose a number of variants of existing MDP solution algorithms, adapted to this context, and evaluate them empirically.","cites":"2","conferencePercentile":"24.05498282"},{"venue":"AAAI","id":"2ccce6c42e24d8adea02e37a860081d64f3a00f5","venue_1":"AAAI","year":"2015","title":"The Dynamic Chinese Restaurant Process via Birth and Death Processes","authors":"Rui Huang, Fengyuan Zhu, Pheng-Ann Heng","author_ids":"1731703, 2943795, 1714602","abstract":"We develop the Dynamic Chinese Restaurant Process (DCRP) which incorporates time-evolutionary feature in dependent Dirichlet Process mixture models. This model can capture the dynamic change of mixture components , allowing clusters to emerge, vanish and vary over time. All these macroscopic changes are controlled by tracing the birth and death of every single element. We investigate the properties of dependent Dirichlet Process mixture model based on DCRP and develop corresponding Gibbs Sampler for posterior inference. We also conduct simulation and empirical studies to compare this model with traditional CRP and related models. The results show that this model can provide better results for sequential data, especially for data with heterogeneous lifetime distribution.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"08473ba29269ead259d8d1d1f4c3ceba9f7c9e3c","venue_1":"AAAI","year":"2011","title":"The Next Best Solution","authors":"Ronen I. Brafman, Enrico Pilotto, Francesca Rossi, Domenico Salvagnin, Kristen Brent Venable, Toby Walsh","author_ids":"1680506, 2368099, 1700163, 1810099, 1712010, 1733716","abstract":"We study the computational complexity of finding the next most preferred solution in some common formalisms for representing constraints and preferences. The problem is computationally intractable for CSPs, but is polynomial for tree-shaped CSPs and tree-shaped fuzzy CSPs. On the other hand, it is intractable for weighted CSPs, even under restrictions on the constraint graph. For CP-nets, the problem is polynomial when the CP-net is acyclic. This remains so if we add (soft) constraints that are tree-shaped and topologically compatible with the CP-net.","cites":"1","conferencePercentile":"16.15120275"},{"venue":"AAAI","id":"4d97756740076d551ad36ec5a064489b4642a4da","venue_1":"AAAI","year":"2014","title":"A Relevance-Based Compilation Method for Conformant Probabilistic Planning","authors":"Ran Taig, Ronen I. Brafman","author_ids":"1897268, 1680506","abstract":"Conformant probabilistic planning (CPP) differs from conformant planning (CP) by two key elements: the initial belief state is probabilistic, and the conformant plan must achieve the goal with probability ≥ θ, for some 0 < θ ≤ 1. In earlier work we observed that one can reduce CPP to CP by finding a set of initial states whose probability ≥ θ, for which a conformant plan exists. In previous solvers we used the underlying planner to select this set of states and to plan for them simultaneously. Here we suggest an alternative approach: start with relevance analysis to determine a promising set of initial states on which to focus. Then, call an off-the-shelf conformant planner to solve the resulting problem. This approach has a number of advantages. First, instead of depending on the heuristic function to select the set of initial states, we can introduce specific, efficient relevance reasoning techniques. Second, we can benefit from optimizations used by conformant planners that are unsound when applied to the original CPP. Finally, we are free to use any existing (or new) CP solver. Consequently, the new planner dominates previous solvers on almost all domains and scales to instances that were not solved before.","cites":"2","conferencePercentile":"38.63636364"},{"venue":"AAAI","id":"822012c14d30a376aef0f3cab29ade4b54ed7c9f","venue_1":"AAAI","year":"2014","title":"Pairwise-Covariance Linear Discriminant Analysis","authors":"Deguang Kong, Chris H. Q. Ding","author_ids":"8720637, 1737469","abstract":"In machine learning, linear discriminant analysis (LDA) is a popular dimension reduction method. In this paper, we first provide a new perspective of LDA from an information theory perspective. From this new perspective, we propose a new formulation of LDA, which uses the pairwise averaged class covariance instead of the globally averaged class covariance used in standard LDA. This pairwise (averaged) covariance describes data distribution more accurately. The new perspective also provides a natural way to properly weigh different pairwise distances, which emphasizes the pairs of class with small distances, and this leads to the proposed pairwise co-variance properly weighted LDA (pcLDA). The kernel version of pcLDA is presented to handle nonlinear projections. Efficient algorithms are presented to efficiently compute the proposed models.","cites":"1","conferencePercentile":"25.90909091"},{"venue":"AAAI","id":"3dbb1ee1ebabaea8d6b73889579f4b6215e58729","venue_1":"AAAI","year":"2005","title":"Augmenting Disjunctive Temporal Problems with Finite-Domain Constraints","authors":"Michael D. Moffitt, Bart Peintner, Martha E. Pollack","author_ids":"3254446, 2123347, 1801194","abstract":"We present a general framework for augmenting instances of the Disjunctive Temporal Problem (DTP) with finite-domain constraints. In this new formalism, the bounds of the temporal constraints become conditional on the finite-domain assignment. This hybridization makes it possible to reason simultaneously about temporal relationships between events as well as their nontemporal properties. We provide a special case of this hybridization that allows reasoning about a limited form of spatial constraints; namely, the travel time induced by the locations of a set of activities. We develop a least-commitment algorithm for efficiently finding solutions to this combined constraint system and provide empirical results demonstrating the effectiveness of our approach.","cites":"19","conferencePercentile":"66.08391608"},{"venue":"AAAI","id":"0cc8621a94cf6144a14a92c273e5c5ac7edb708a","venue_1":"AAAI","year":"2004","title":"Low-cost Addition of Preferences to DTPs and TCSPs","authors":"Bart Peintner, Martha E. Pollack","author_ids":"2123347, 1801194","abstract":"We present an efficient approach to adding soft constraints, in the form of preferences, to Disjunctive Temporal Problems (DTPs) and their subclass Temporal Constraint Satisfaction Problems (TCSPs). Specifically, we describe an algorithm for checking the consistency of and finding optimal solutions to such problems. The algorithm borrows concepts from previous algorithms for solving TCSPs and Simple Temporal Problems with Preferences (STPPs), in both cases using techniques for projecting and solving component sub-problems. We show that adding preferences to DTPs and TCSPs requires only slightly more time than corresponding algorithms for TCSPs and DTPs without preferences. Thus, for problems where DTPs and TCSPs make sense, adding preferences provides a substantial gain in expressiveness for a marginal cost.","cites":"40","conferencePercentile":"82.03592814"},{"venue":"AAAI","id":"0132cafe4c66ef013c8294808a274425acb5f533","venue_1":"AAAI","year":"2011","title":"A Distributed Anytime Algorithm for Dynamic Task Allocation in Multi-Agent Systems","authors":"Kathryn S. Macarthur, Ruben Stranders, Sarvapali D. Ramchurn, Nicholas R. Jennings","author_ids":"2151666, 2446693, 1805612, 1786650","abstract":"We introduce a novel distributed algorithm for multi-agent task allocation problems where the sets of tasks and agents constantly change over time. We build on an existing anytime algorithm (fast-max-sum), and give it significant new capabilities: namely, an online pruning procedure that simplifies the problem, and a branch-and-bound technique that reduces the search space. This allows us to scale to problems with hundreds of tasks and agents. We empirically evaluate our algorithm against established benchmarks and find that, even in such large environments, a solution is found up to 31% faster, and with up to 23% more utility, than state-of-the-art approximation algorithms. In addition, our algorithm sends up to 30% fewer messages than current approaches when the set of agents or tasks changes.","cites":"21","conferencePercentile":"88.65979381"},{"venue":"AAAI","id":"104a93dcb896ae10ef9fbe35873169bd8720ac03","venue_1":"AAAI","year":"2011","title":"Decentralised Control of Micro-Storage in the Smart Grid","authors":"Thomas Voice, Perukrishnen Vytelingum, Sarvapali D. Ramchurn, Alex Rogers, Nicholas R. Jennings","author_ids":"1769473, 1773389, 1805612, 1793672, 1786650","abstract":"In this paper, we propose a novel decentralised control mechanism to manage micro-storage in the smart grid. Our approach uses an adaptive pricing scheme that energy suppliers apply to home smart agents controlling micro-storage devices. In particular, we prove that the interaction between a supplier using our pricing scheme and the actions of selfish micro-storage agents forms a globally stable feedback loop that converges to an efficient equilibrium. We further propose a market strategy that allows the supplier to reduce wholesale purchasing costs without increasing the uncertainty and variance for its aggregate consumer demand. Moreover, we empirically evaluate our mechanism (based on the UK grid data) and show that it yields savings of up to 16% in energy cost for consumers using storage devices with average capacity 10 kWh. Furthermore, we show that it is robust against extreme system changes.","cites":"23","conferencePercentile":"89.86254296"},{"venue":"AAAI","id":"1694b6ee13fab0d3775de66469afae89493c9c75","venue_1":"AAAI","year":"2007","title":"Anytime Optimal Coalition Structure Generation","authors":"Talal Rahwan, Sarvapali D. Ramchurn, Viet Dung Dang, Andrea Giovannucci, Nicholas R. Jennings","author_ids":"1775071, 1805612, 2210655, 2561399, 1786650","abstract":"A key problem when forming effective coalitions of autonomous agents is determining the best groupings, or the optimal coalition structure, to select to achieve some goal. To this end, we present a novel, anytime algorithm for this task that is significantly faster than current solutions. Specifically, we empirically show that we are able to find solutions that are optimal in 0.082% of the time taken by the state of the art dynamic programming algorithm (for 27 agents), using much less memory (O(2 n) instead of O(3 n) for n agents). Moreover , our algorithm is the first to be able to find solutions for more than 17 agents in reasonable time (less than 90 minutes for 27 agents, as opposed to around 2 months for the best previous solution).","cites":"39","conferencePercentile":"87.38872404"},{"venue":"AAAI","id":"438250c5000a271d1584db7d271238ab022dbb31","venue_1":"AAAI","year":"2013","title":"Unsupervised Cluster Matching via Probabilistic Latent Variable Models","authors":"Tomoharu Iwata, Tsutomu Hirao, Naonori Ueda","author_ids":"2664600, 1776807, 1735221","abstract":"We propose a probabilistic latent variable model for un-supervised cluster matching, which is the task of finding correspondences between clusters of objects in different domains. Existing object matching methods find one-to-one matching. The proposed model finds many-to-many matching, and can handle multiple domains with different numbers of objects. The proposed model assumes that there are an infinite number of latent vectors that are shared by all domains, and that each object is generated using one of the latent vectors and a domain-specific linear projection. By inferring a latent vector to be used for generating each object, objects in different domains are clustered in shared groups, and thus we can find matching between clusters in an unsu-pervised manner. We present efficient inference procedures for the proposed model based on a stochastic EM algorithm. The effectiveness of the proposed model is demonstrated with experiments using synthetic and real data sets.","cites":"4","conferencePercentile":"55.45454545"},{"venue":"AAAI","id":"2452d5ce9dc467f44676893a99d14ee9f8a0da84","venue_1":"AAAI","year":"2006","title":"Learning Systems of Concepts with an Infinite Relational Model","authors":"Charles Kemp, Joshua B. Tenenbaum, Thomas L. Griffiths, Takeshi Yamada, Naonori Ueda","author_ids":"1746851, 5119093, 1799860, 1724904, 1735221","abstract":"Relationships between concepts account for a large proportion of semantic knowledge. We present a nonpara-metric Bayesian model that discovers systems of related concepts. Given data involving several sets of entities, our model discovers the kinds of entities in each set and the relations between kinds that are possible or likely. We apply our approach to four problems: clustering objects and features, learning ontologies, discovering kin-ship systems, and discovering structure in political data. Philosophers, psychologists and computer scientists have proposed that semantic knowledge is best understood as a system of relations. Two questions immediately arise: how can these systems be represented, and how are these representations acquired? Researchers who start with the first question often devise complex representational schemes (e.g. Minsky's (1975) classic work on frames), but explaining how these representations are learned is a challenging problem. We take the opposite approach. We consider only simple relational systems, but show how these systems can be acquired by unsupervised learning. The systems we wish to discover are simple versions of the \" domain theories \" discussed by cognitive scientists and AI researchers (Davis 1990). Suppose that a domain includes several types, or sets of entities. One role of a domain theory is to specify the kinds of entities that exist in each set, and the possible or likely relationships between those kinds. Consider the domain of medicine, and a single type defined as the set of terms that might appear on a medical chart. A theory of this domain might specify that cancer and diabetes are both disorders, asbestos and arsenic are both chemicals, and that chemicals can cause disorders. Our model assumes that each entity belongs to exactly one kind, or cluster, and simultaneously discovers the clusters and the relationships between clusters that are best supported by the data. A key feature of our approach is that it does not require the number of clusters to be fixed in advance. The number of clusters used by a theory should be able to grow as more and more data are encountered, but a theory-learner should introduce no more clusters than are necessary to explain the data. Our approach automatically chooses an appropriate number of clusters using a prior that favors small numbers of clusters , but has access to a countably infinite collection of clusters. We therefore call our approach the infinite relational model (IRM). Previous infinite models (Rasmussen 2000; Antoniak 1974) …","cites":"304","conferencePercentile":"99.42363112"},{"venue":"AAAI","id":"1e834157de8b7a090747842359fbb7060680c45a","venue_1":"AAAI","year":"2005","title":"A Hybrid Generative/Discriminative Approach to Semi-Supervised Classifier Design","authors":"Akinori Fujino, Naonori Ueda, Kazumi Saito","author_ids":"2230249, 1735221, 1727070","abstract":"Semi-supervised classifier design that simultaneously utilizes both labeled and unlabeled samples is a major research issue in machine learning. Existing semi-supervised learning methods belong to either genera-tive or discriminative approaches. This paper focuses on probabilistic semi-supervised classifier design and presents a hybrid approach to take advantage of the gen-erative and discriminative approaches. Our formulation considers a generative model trained on labeled samples and a newly introduced bias correction model. Both models belong to the same model family. The proposed hybrid model is constructed by combining both genera-tive and bias correction models based on the maximum entropy principle. The parameters of the bias correction model are estimated by using training data, and combination weights are estimated so that labeled samples are correctly classified. We use naive Bayes models as the generative models to apply the hybrid approach to text classification problems. In our experimental results on three text data sets, we confirmed that the proposed method significantly outperformed pure generative and discriminative methods when the classification performances of the both methods were comparable.","cites":"35","conferencePercentile":"83.04195804"},{"venue":"AAAI","id":"78515ff75593b82180598a834b54af2bdf41c9a3","venue_1":"AAAI","year":"2015","title":"Towards Knowledge-Driven Annotation","authors":"Yassine Mrabet, Claire Gardent, Muriel Foulonneau, Elena Paslaru Bontas Simperl, Eric Ras","author_ids":"1711712, 1794075, 2686056, 2927032, 2637699","abstract":"While the Web of data is attracting increasing interest and rapidly growing in size, the major support of information on the surface Web are still multimedia documents. Semantic annotation of texts is one of the main processes that are intended to facilitate meaning-based information exchange between computational agents. However, such annotation faces several challenges such as the heterogeneity of natural language expressions, the heterogeneity of documents structure and context dependencies. While a broad range of annotation approaches rely mainly or partly on the target textual context to disambiguate the extracted entities, in this paper we present an approach that relies mainly on formalized-knowledge expressed in RDF datasets to categorize and disambiguate noun phrases. In the proposed method, we represent the reference knowledge bases as co-occurrence matrices and the disambigua-tion problem as a 0-1 Integer Linear Programming (ILP) problem. The proposed approach is unsupervised and can be ported to any RDF knowledge base. The system implementing this approach, called KODA, shows very promising results w.r.t. state-of-the-art annotation tools in cross-domain experimentations.","cites":"4","conferencePercentile":"73.46456693"},{"venue":"AAAI","id":"32d56afda3ee0d6b60be2432bc2a7f756db14d08","venue_1":"AAAI","year":"2005","title":"Anytime, Complete Algorithm for Finding Utilitarian Optimal Solutions to STPPs","authors":"Bart Peintner, Martha E. Pollack","author_ids":"2123347, 1801194","abstract":"We present a simple greedy algorithm and a novel complete algorithm for finding utilitarian optimal solutions to Simple Temporal Problems with Preferences. Unlike previous algorithms , ours does not restrict preference functions to be convex. We present experimental results showing that (1) a single iteration of the greedy algorithm produces high-quality solutions, (2) multiple iterations, bounded by the square of the number of constraints, produce near-optimal solutions, and (3) our complete, memory-boundable algorithm has compelling anytime properties and outperforms a branch-and-bound algorithm.","cites":"8","conferencePercentile":"36.18881119"},{"venue":"AAAI","id":"d73b3904f06ee18113c83ef649192782cddc8fde","venue_1":"AAAI","year":"2008","title":"Make3D: Depth Perception from a Single Still Image","authors":"Ashutosh Saxena, Min Sun, Andrew Y. Ng","author_ids":"1681995, 1711801, 1701538","abstract":"Humans have an amazing ability to perceive depth from a single still image; however, it remains a challenging problem for current computer vision systems. In this paper, we will present algorithms for estimating depth from a single still image. There are numerous monocular cues—such as texture variations and gradients, defocus, color/haze, etc.—that can be used for depth perception. Taking a supervised learning approach to this problem, in which we begin by collecting a training set of single images and their corresponding ground-truth depths, we learn the mapping from image features to the depths. We then apply these ideas to create 3-d models that are visually-pleasing as well as quantitatively accurate from individual images. We also discuss applications of our depth perception algorithm in robotic navigation, in improving the performance of stereovision, and in creating large-scale 3-d models given only a small number of images.","cites":"16","conferencePercentile":"71.20253165"},{"venue":"AAAI","id":"372dbeb37535ae591067425ee3c41927bca02bc9","venue_1":"AAAI","year":"2005","title":"A Knowledge-Based Approach to Network Security: Applying Cyc in the Domain of Network Risk Assessment","authors":"Blake Shepard, Cynthia Matuszek, C. Bruce Fraser, William Wechtenhiser, David Crabbe, Zelal Güngördü, John Jantos, Todd Hughes, Larry Lefkowitz, Michael J. Witbrock, Douglas B. Lenat, Erik Larson","author_ids":"2872722, 2674440, 3160975, 3024320, 2491639, 2410892, 2412515, 1877423, 2270694, 2819135, 1704635, 7332346","abstract":"CycSecure TM is a network risk assessment and network monitoring application that relies on knowledge-based artificial intelligence technologies to improve on traditional network vulnerability assessment. CycSecure integrates public reports of software faults from online databases, data gathered automatically from computers on a network and hand-ontologized information about computers and computer networks. This information is stored in the Cyc ® knowledge base (KB) and reasoned about by the Cyc inference engine and planner to provide detailed analyses of the security (and vulnerability) of networks.","cites":"14","conferencePercentile":"56.99300699"},{"venue":"AAAI","id":"16b0058e31f8f0e7cc9e83acf2ff9654d7cf66c5","venue_1":"AAAI","year":"2005","title":"Searching for Common Sense: Populating Cyc™ from the Web","authors":"Cynthia Matuszek, Michael J. Witbrock, Robert C. Kahlert, John Cabral, David Schneider, Purvesh Shah, Douglas B. Lenat","author_ids":"2674440, 2819135, 2412533, 2582677, 3465914, 2206184, 1704635","abstract":"The Cyc project is predicated on the idea that effective machine learning depends on having a core of knowledge that provides a context for novel learned information – what is known informally as \" common sense. \" Over the last twenty years, a sufficient core of common sense knowledge has been entered into Cyc to allow it to begin effectively and flexibly supporting its most important task: increasing its own store of world knowledge. In this paper, we present initial work on a method of using a combination of Cyc and the World Wide Web, accessed via Google, to assist in entering knowledge into Cyc. The long-term goal is automating the process of building a consistent, formalized representation of the world in the Cyc knowledge base via machine learning. We present preliminary results of this work and describe how we expect the knowledge acquisition process to become more accurate, faster, and more automated in the future.","cites":"71","conferencePercentile":"94.75524476"},{"venue":"AAAI","id":"1f3a2cdbd1a27485bb76dd666f6fd3baf5bb1ab5","venue_1":"AAAI","year":"2008","title":"A Fast Data Collection and Augmentation Procedure for Object Recognition","authors":"Benjamin Sapp, Ashutosh Saxena, Andrew Y. Ng","author_ids":"1720675, 1681995, 1701538","abstract":"Goal of this talk  Data  Training data quality/quantity has a significant impact on the performance of learning algorithms.  Often, even an inferior learning algorithm will outperform a superior one, if given more data to learn from.","cites":"14","conferencePercentile":"66.61392405"},{"venue":"AAAI","id":"6ad3ccaf8429be7e22f9ff6349f5deba8e928157","venue_1":"AAAI","year":"2008","title":"Learning Grasp Strategies with Partial Shape Information","authors":"Ashutosh Saxena, Lawson L. S. Wong, Andrew Y. Ng","author_ids":"1681995, 2260904, 1701538","abstract":"We consider the problem of grasping novel objects in cluttered environments. If a full 3-d model of the scene were available, one could use the model to estimate the stability and robustness of different grasps (formalized as form/force-closure, etc); in practice, however, a robot facing a novel object will usually be able to perceive only the front (visible) faces of the object. In this paper, we propose an approach to grasping that estimates the stability of different grasps, given only noisy estimates of the shape of visible portions of an object, such as that obtained from a depth sensor. By combining this with a kinematic description of a robot arm and hand, our algorithm is able to compute a specific positioning of the robot's fingers so as to grasp an object. We test our algorithm on two robots (with very different arms/manipulators, including one with a multi-fingered hand). We report results on the task of grasping objects of significantly different shapes and appearances than ones in the training set, both in highly cluttered and in uncluttered environments. We also apply our algorithm to the problem of unloading items from a dishwasher.","cites":"71","conferencePercentile":"96.36075949"},{"venue":"AAAI","id":"760b8efc52271fd453f92132de847e9bebd81636","venue_1":"AAAI","year":"2006","title":"Efficient L1 Regularized Logistic Regression","authors":"Su-In Lee, Honglak Lee, Pieter Abbeel, Andrew Y. Ng","author_ids":"2609062, 1697141, 1689992, 1701538","abstract":"L 1 regularized logistic regression is now a workhorse of machine learning: it is widely used for many classification problems, particularly ones with many features. L 1 regularized logistic regression requires solving a convex optimization problem. However, standard algorithms for solving convex optimization problems do not scale well enough to handle the large datasets encountered in many practical settings. In this paper, we propose an efficient algorithm for L 1 regularized logistic regression. Our algorithm iteratively approximates the objective function by a quadratic approximation at the current point, while maintaining the L 1 constraint. In each iteration , it uses the efficient LARS (Least Angle Regression) algorithm to solve the resulting L 1 constrained quadratic optimization problem. Our theoretical results show that our algorithm is guaranteed to converge to the global optimum. Our experiments show that our algorithm significantly outperforms standard algorithms for solving convex optimization problems. Moreover, our algorithm outperforms four previously published algorithms that were specifically designed to solve the L1 regularized logistic regression problem.","cites":"135","conferencePercentile":"98.55907781"},{"venue":"AAAI","id":"1d4d14e78eb1536b84f6e851a67ecc5a6c0ae07f","venue_1":"AAAI","year":"2005","title":"Robust Textual Inference Via Learning and Abductive Reasoning","authors":"Rajat Raina, Andrew Y. Ng, Christopher D. Manning","author_ids":"2979876, 1701538, 1812612","abstract":"We present a system for textual inference (the task of inferring whether a sentence follows from another text) that uses learning and a logical-formula semantic representation of the text. More precisely, our system begins by parsing and then transforming sentences into a logical formula-like representation similar to the one used by (Harabagiu et al., 2000). An abductive theorem prover then tries to find the minimum \" cost \" set of assumptions necessary to show that one statement follows from the other. These costs reflect how likely different assumptions are, and are learned automatically using information from syntactic/semantic features and from linguistic resources such as WordNet. If one sentence follows from the other given only highly plausible, low cost assumptions , then we conclude that it can be inferred. Our approach can be viewed as combining statistical machine learning and classical logical reasoning, in the hope of marrying the ro-bustness and scalability of learning with the preciseness and elegance of logical theorem proving. We give experimental results from the recent PASCAL RTE 2005 challenge competition on recognizing textual inferences, where a system using this inference algorithm achieved the highest confidence weighted score.","cites":"43","conferencePercentile":"88.11188811"},{"venue":"AAAI","id":"2500ccb5c947953458c02b745c64c80eef2a7e15","venue_1":"AAAI","year":"1994","title":"Least-Cost Flaw Repair: A Plan Refinement Strategy for Partial-Order Planning","authors":"David Joslin, Martha E. Pollack","author_ids":"3203400, 1801194","abstract":"We describe the least-cost flaw repair (LCFR) strategy for performing flaw selection during partial-order causal link (POCL) planning. LCFR can be seen as a generalization of Peot and Smith's \" Delay Un-forced Threats \" (DUnf) strategy (Peot & Smith 1993); where DUnf treats threats differently from open conditions , LCFR has a uniform mechanism for handling all flaws. We provide experimental results that demonstrate that the power of DUnf does not come from delaying threat repairs per ue, but rather from the fact that this delay has the effect of imposing a partial preference for least-cost flaw selection. Our experiments also show that extending this to a complete preference for least-cost selection reduces search-space size even further. We consider the computational overhead of employing LCFR, and discuss techniques for reducing this overhead. In particular, we describe QLCFR, a strategy that reduces computational overhead by approximating repair c0sts.l","cites":"35","conferencePercentile":"75.99118943"},{"venue":"AAAI","id":"4a8b3d110b32e89489471247617c709e829f1e50","venue_1":"AAAI","year":"2005","title":"Social Tag: Finding the Person with the Pink Hat","authors":"Carl F. DiSalvo, Didac Font, Laura M. Hiatt, Nik A. Melchior, Marek P. Michalowski, Reid G. Simmons","author_ids":"1750905, 1902110, 1752471, 1686955, 1711135, 1719955","abstract":"At the AAAI 2005 Robot Exhibition, the robot GRACE (Graduate Robot Attending a ConferencE, Fig. 1) will be playing a game that involves human-robot social interaction, navigation, and interface design. The task is for Grace to locate and rendezvous with one of our team members, who will be wearing a pink hat. The game can be seen as a social version of \" tag \" or \" Marco Polo, \" where the the robot finds the target not through the modalities of sight or sound, but rather through social interactions with strangers in the environment. The task has four phases (Fig. 2), which are repeated until the pink hat is located visually: 1. Identification of approachable humans. 2. Approach toward a human with whom the robot would like to interact. 3. Asking for directions to the person with the pink hat. 4. Following those directions. In typical robot tasks involving detection of a visual target , distinctively colored objects such as pink hats are used to simplify the vision problem. However, in this case, the pink hat is as much for the benefit of other people as for Grace herself. The team member should be a prominent individual who is easily recognized and remembered by conference participants, so that it will be easy for them to help a wandering robot. Accordingly, it is not the completion of the goal (finding the pink hat) in which we are most interested , but rather in Grace's journey and her social interactions along the way. The phases of the task, as mentioned above, are described here. 1. Identification. Grace is equipped with a laser scanner near human knee-height and a camera near human face-height. The laser scanner clusters short range readings, labels those that appear to be human beings, and tracks those humans over time using a Kalman filter. The camera locates faces using appearance-based frontal face detectors and tracks them using skin color models. Data from these two sensors is combined to determine more reliably Figure 1: The robot GRACE. where there are people, and to determine whether a person is approachable based on the direction they are facing and their proximity to other people. 2. Approach. Grace moves toward the person and attempts to begin a conversation. She is equipped with an animated face and a text-to-speech engine that generates audible speech to greet the person she is approaching. During this …","cites":"2","conferencePercentile":"16.25874126"},{"venue":"AAAI","id":"003e0aa0cfdf011362d4cbc21c0b5f2f5281fdd2","venue_1":"AAAI","year":"2016","title":"Offline Evaluation of Online Reinforcement Learning Algorithms","authors":"Travis Mandel, Yun-En Liu, Emma Brunskill, Zoran Popovic","author_ids":"3212030, 3228636, 2563117, 1696595","abstract":"In many real-world reinforcement learning problems, we have access to an existing dataset and would like to use it to evaluate various learning approaches. Typically, one would prefer not to deploy a fixed policy, but rather an algorithm that learns to improve its behavior as it gains more experience. Therefore, we seek to evaluate how a proposed algorithm learns in our environment, meaning we need to evaluate how an algorithm would have gathered experience if it were run online. In this work, we develop three new evaluation approaches which guarantee that, given some history, algorithms are fed samples from the distribution that they would have encountered if they were run online. Additionally , we are the first to propose an approach that is provably unbiased given finite data, eliminating bias due to the length of the evaluation. Finally, we compare the sample-efficiency of these approaches on multiple datasets, including one from a real-world deployment of an educational game.","cites":"1","conferencePercentile":"40.70945946"},{"venue":"AAAI","id":"732939b3d249d5ccce30641ca934b712569c905b","venue_1":"AAAI","year":"2015","title":"The Queue Method: Handling Delay, Heuristics, Prior Data, and Evaluation in Bandits","authors":"Travis Mandel, Yun-En Liu, Emma Brunskill, Zoran Popovic","author_ids":"3212030, 3228636, 2563117, 1696595","abstract":"Current algorithms for the standard multi-armed bandit problem have good empirical performance and optimal regret bounds. However, real-world problems often differ from the standard formulation in several ways. First, feedback may be delayed instead of arriving immediately. Second, the real world often contains structure which suggests heuris-tics, which we wish to incorporate while retaining strong theoretical guarantees. Third, we may wish to make use of an arbitrary prior dataset without negatively impacting performance. Fourth, we may wish to efficiently evaluate algorithms using a previously collected dataset. Surprisingly, these seemingly-disparate problems can be addressed using algorithms inspired by a recently-developed queueing technique. We present the Stochastic Delayed Bandits (SDB) algorithm as a solution to these four problems, which takes black-box bandit algorithms (including heuristic approaches) as input while achieving good theoretical guarantees. We present empirical results from both synthetic simulations and real-world data drawn from an educational game. Our results show that SDB outperforms state-of-the-art approaches to handling delay, heuristics, prior data, and evaluation.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"1f03111bac5391f0b8326059d3807c3bbb6b03a2","venue_1":"AAAI","year":"2014","title":"Active Learning with Model Selection","authors":"Alnur Ali, Rich Caruana, Ashish Kapoor","author_ids":"2675438, 1790184, 7665582","abstract":"Most active learning methods avoid model selection by training models of one type (SVMs, boosted trees, etc.) using one pre-defined set of model hyperparameters. We propose an algorithm that actively samples data to simultaneously train a set of candidate models (different model types and/or different hyperparameters) and also select the best model from this set. The algorithm actively samples points for training that are most likely to improve the accuracy of the more promising candidate models, and also samples points for model selection— all samples count against the same labeling budget. This exposes a natural trade-off between the focused active sampling that is most effective for training models, and the unbiased sampling that is better for model selection. We empirically demonstrate on six test problems that this algorithm is nearly as effective as an active learning oracle that knows the optimal model in advance.","cites":"5","conferencePercentile":"67.5"},{"venue":"AAAI","id":"a34f49028eec5f00a4d597bddcbb85f6db8ba346","venue_1":"AAAI","year":"2008","title":"Expressive Banner Ad Auctions and Model-Based Online Optimization for Clearing","authors":"Craig Boutilier, David C. Parkes, Tuomas Sandholm, William E. Walsh","author_ids":"2105432, 1702994, 1732422, 3045456","abstract":"We present the design of a banner advertising auction which is considerably more expressive than current designs. We describe a general model of expressive ad contracts/bidding and an allocation model that can be executed in real time through the assignment of fractions of relevant ad channels to specific advertiser contracts. The uncertainty in channel supply and demand is addressed by the formulation of a stochastic com-binatorial optimization problem for channel allocation that is rerun periodically. We solve this in two different ways: fast deterministic optimization with respect to expectations; and a novel online sample-based stochastic optimization method— that can be applied to continuous decision spaces—which exploits the deterministic optimization as a black box. Experiments demonstrate the importance of expressive bidding and the value of stochastic optimization.","cites":"24","conferencePercentile":"82.75316456"},{"venue":"AAAI","id":"92017ab20a9eafaaf87c30ddb517dfd165c7f9ca","venue_1":"AAAI","year":"2008","title":"Economic Hierarchical Q-Learning","authors":"Erik G. Schultink, Ruggiero Cavallo, David C. Parkes","author_ids":"3099637, 2311690, 1702994","abstract":"Hierarchical state decompositions address the curse-of-dimensionality in Q-learning methods for reinforcement learning (RL) but can suffer from suboptimality. In addressing this, we introduce the Economic Hierarchical Q-Learning (EHQ) algorithm for hierarchical RL. The EHQ algorithm uses subsidies to align interests such that agents that would otherwise converge to a recursively optimal policy will instead be motivated to act hierarchically optimally. The essential idea is that a parent will pay a child for the relative value to the rest of the system for \" returning the world \" in one state over another state. The resulting learning framework is simple compared to other algorithms that obtain hierarchical op-timality. Additionally, EHQ encapsulates relevant information about value tradeoffs faced across the hierarchy at each node and requires minimal data exchange between nodes. We provide no theoretical proof of hierarchical optimality but are able demonstrate success with EHQ in empirical results.","cites":"4","conferencePercentile":"32.75316456"},{"venue":"AAAI","id":"114d910f04a7bc8730880bf74542035723792317","venue_1":"AAAI","year":"2008","title":"Value-Based Policy Teaching with Active Indirect Elicitation","authors":"Haoqi Zhang, David C. Parkes","author_ids":"3162562, 1702994","abstract":"Many situations arise in which an interested party's utility is dependent on the actions of an agent; e.g., a teacher is interested in a student learning effectively and a firm is interested in a consumer's behavior. We consider an environment in which the interested party can provide incentives to affect the agent's actions but cannot otherwise enforce actions. In value-based policy teaching, we situate this within the framework of sequential decision tasks modeled by Markov Decision Processes, and seek to associate limited rewards with states that induce the agent to follow a policy that maximizes the total expected value of the interested party. We show value-based policy teaching is NP-hard and provide a mixed integer program formulation. Focusing in particular on environments in which the agent's reward is unknown to the interested party, we provide a method for active indirect elic-itation wherein the agent's reward function is inferred from observations about its response to incentives. Experimental results suggest that we can generally find the optimal incentive provision in a small number of elicitation rounds.","cites":"23","conferencePercentile":"81.80379747"},{"venue":"AAAI","id":"1a2beb1a25b6df143f90cb15e29ca1c74461a935","venue_1":"AAAI","year":"2008","title":"Computing Reserve Prices and Identifying the Value Distribution in Real-world Auctions with Market Disruptions","authors":"William E. Walsh, David C. Parkes, Tuomas Sandholm, Craig Boutilier","author_ids":"3045456, 1702994, 1732422, 2105432","abstract":"Single-good ascending auctions, including the English Auction and its close variants (e.g. eBay), are the most widely used type of auction. Effective strategies for buyers and sellers in these auctions can have an enormous economic impact. We present a system that, relying on minimal assumptions, computes reserve prices for real-world ascending auctions by inferring the value distribution from past auction data. Our contributions include improvements on previous methods for estimating the bidder value distribution, and novel Bayesian methods for adapting to disruptions in market conditions. We demonstrate the effectiveness of our system in both simulated auctions and in real Internet auctions that we conducted in the domain of selling off returned merchandise.","cites":"10","conferencePercentile":"54.90506329"},{"venue":"AAAI","id":"88a9220f403be6a51372ebc240c77aa4c35ae7a7","venue_1":"AAAI","year":"2008","title":"Efficient Metadeliberation Auctions","authors":"Ruggiero Cavallo, David C. Parkes","author_ids":"2311690, 1702994","abstract":"Imagine a resource allocation scenario in which the interested parties can, at a cost, individually research ways of using the resource to be allocated, potentially increasing the value they would achieve from obtaining it. Each agent has a private model of its research process and obtains a private realization of its improvement in value, if any. From a social perspective it is optimal to coordinate research in a way that strikes the right tradeoff between value and cost, ultimately allocating the resource to one party– thus this is a problem of multi-agent metadeliberation. We provide a reduction of computing the optimal deliberation-allocation policy to computing Gittins indices in multi-armed bandit worlds, and apply a modification of the dynamic-VCG mechanism to yield truthful participation in an ex post equilibrium. Our mechanism achieves equilibrium implementation of the optimal policy even when agents have the capacity to deliberate about other agents' valuations, and thus addresses the problem of strategic deliberation.","cites":"11","conferencePercentile":"58.2278481"},{"venue":"AAAI","id":"8ddf2a34ff151534f99d5c142f5ec6ff3063c6e0","venue_1":"AAAI","year":"2008","title":"Partially Synchronized DEC-MDPs in Dynamic Mechanism Design","authors":"Sven Seuken, Ruggiero Cavallo, David C. Parkes","author_ids":"1884044, 2311690, 1702994","abstract":"In this paper, we combine for the first time the methods of dynamic mechanism design with techniques from decentralized decision making under uncertainty. Consider a multi-agent system with self-interested agents acting in an uncertain environment , each with private actions, states and rewards. There is also a social planner with its own actions, rewards, and states, acting as a coordinator and able to influence the agents via actions (e.g., resource allocations). Agents can only communicate with the center, but may become inaccessible, e.g., when their communication device fails. When accessible to the center, agents can report their local state (and models) and receive recommendations from the center about local policies to follow for the present period and also, should they become inaccessible, until becoming accessible again. Without self-interest, this poses a new problem class which we call partially-synchronized DEC-MDPs, and for which we establish some positive complexity results under reasonable assumptions. Allowing for self-interested agents, we are able to bridge to methods of dynamic mechanism design, aligning incentives so that agents truthfully report local state when accessible and choose to follow the prescribed \" emergency policies \" of the center.","cites":"6","conferencePercentile":"41.4556962"},{"venue":"AAAI","id":"05b774f06f84034f67018bd35c36a8a004b86f42","venue_1":"AAAI","year":"2010","title":"Hidden Market Design","authors":"Sven Seuken, Kamal Jain, David C. Parkes","author_ids":"1884044, 1800444, 1702994","abstract":"The next decade will see an abundance of new intelligent systems, many of which will be market-based. Soon, users will interact with many new markets, perhaps without even knowing it: when driving their car, when listening to a song, when backing up their files, or when surfing the web. We argue that these new systems can only be successful if a new approach is chosen towards designing them. In this paper we introduce the general problem of \" Hidden Market Design. \" The design of a \" weakly hidden \" market involves reducing some of the market complexities and providing a user interface (UI) that makes the interaction seamless for the user. A \" strongly hidden market \" is one where some semantic aspect of a market is hidden altogether (e.g., budgets, prices, combinatorial constraints). We show that the intersection of UI design and market design is of particular importance for this research agenda. To illustrate hidden market design, we give a series of potential applications. We hope that the problem of hidden market design will inspire other researchers and lead to new research in this direction, paving the way for more successful market-based systems in the future.","cites":"12","conferencePercentile":"58.02047782"},{"venue":"AAAI","id":"673ef0034d70ebe0a15cb56996a81c631dff1277","venue_1":"AAAI","year":"2008","title":"An Expressive Auction Design for Online Display Advertising","authors":"Sébastien Lahaie, David C. Parkes, David M. Pennock","author_ids":"1692293, 1702994, 1766638","abstract":"We propose an expressive auction design that allows advertisers to specify the kinds of demographics and websites they wish to target within an advertising network. The design allows the network to differentiate impressions according to relevant attributes (e.g., geographic location of the user, topic of the webpage). Advertisers can place bids for different kinds of impressions according to their attributes, and can also specify volume constraints to control exposure. The novelty of the design is a bidding language that admits scalable allocation and pricing algorithms. We discuss the incentive properties of different pricing approaches. We also propose a bidder feedback mechanism to mitigate the complexity of expressive bidding.","cites":"11","conferencePercentile":"58.2278481"},{"venue":"AAAI","id":"02bc50da4be7769f410ae0bdf2cc9a584aa224b2","venue_1":"AAAI","year":"2010","title":"Automated Channel Abstraction for Advertising Auctions","authors":"William E. Walsh, Craig Boutilier, Tuomas Sandholm, Rob Shields, George L. Nemhauser, David C. Parkes","author_ids":"3045456, 2105432, 1732422, 1965360, 1705564, 1702994","abstract":"The use of simple auction mechanisms like the GSP in on-line advertising can lead to significant loss of efficiency and revenue when advertisers have rich preferences—even simple forms of expressiveness like budget constraints can lead to suboptimal outcomes. While the optimal allocation of inventory can provide greater efficiency and revenue, natural formulations of the underlying optimization problems grow exponentially in the number of features of interest, presenting a key practical challenge. To address this problem, we propose a means for automatically partitioning inventory into abstract channels so that the least relevant features are ignored. Our approach, based on LP/MIP column and constraint generation, dramatically reduces the size of the problem , thus rendering optimization computationally feasible at practical scales. Our algorithms allow for principled trade-offs between tractability and solution quality. Numerical experiments demonstrate the computational practicality of our approach as well as the quality of the resulting abstractions.","cites":"14","conferencePercentile":"63.48122867"},{"venue":"AAAI","id":"0c48f8e41aa39b290d214e3af5c3f3a2b5ffb4ad","venue_1":"AAAI","year":"2011","title":"Incentive-Compatible Escrow Mechanisms","authors":"Jens Witkowski, Sven Seuken, David C. Parkes","author_ids":"2988421, 1884044, 1702994","abstract":"The most prominent way to establish trust between buyers and sellers on online auction sites are reputation mechanisms. Two drawbacks of this approach are the reliance on the seller being long-lived and the susceptibility to whitewashing. In this paper, we introduce so-called escrow mechanisms that avoid these problems by installing a trusted intermediary which forwards the payment to the seller only if the buyer acknowledges that the good arrived in the promised condition. We address the incentive issues that arise and design an escrow mechanism that is incentive compatible, efficient, interim individually rational and ex ante budget-balanced. In contrast to previous work on trust and reputation, our approach does not rely on knowing the sellers' cost functions or the distribution of buyer valuations.","cites":"10","conferencePercentile":"67.18213058"},{"venue":"AAAI","id":"0c680c92f6c0e11cf617fbfac79836399b300ef9","venue_1":"AAAI","year":"2011","title":"On Expressing Value Externalities in Position Auctions","authors":"Florin Constantin, Malvika Rao, Chien-Chung Huang, David C. Parkes","author_ids":"2545109, 2742959, 2226814, 1702994","abstract":"We introduce a bidding language for expressing negative value externalities in position auctions for online advertising. The unit-bidder constraints (UBC) language allows a bidder to condition a bid on its allocated slot and on the slots allocated to other bidders. We introduce a natural extension of the Generalized Second Price (GSP) auction, the expressive GSP (eGSP) auction, that induces truthful revelation of constraints for a rich subclass of unit-bidder types, namely downward-monotonic UBC. We establish the existence of envy-free Nash equilibrium in eGSP under a further restriction to a subclass of exclusion constraints, for which the standard GSP has no pure strategy Nash equilibrium. The equilibrium results are obtained by reduction to equilibrium analysis for reserve price GSP (Even-Dar et al. 2008). In considering the winner determination problem, which is NP-hard, we bound the approximation ratio for social welfare in eGSP and provide parameterized complexity results.","cites":"14","conferencePercentile":"76.28865979"},{"venue":"AAAI","id":"46d871ecc137c2ab98d0520c6a24071a26ab6ea2","venue_1":"AAAI","year":"2011","title":"Optimal Envy-Free Cake Cutting","authors":"Yuga J. Cohler, John K. Lai, David C. Parkes, Ariel D. Procaccia","author_ids":"2708524, 2021157, 1702994, 1689184","abstract":"We consider the problem of fairly dividing a heterogeneous divisible good among agents with different preferences. Previous work has shown that envy-free allocations, i.e., where each agent prefers its own allocation to any other, may not be efficient, in the sense of maximizing the total value of the agents. Our goal is to pinpoint the most efficient allocations among all envy-free allocations. We provide tractable algorithms for doing so under different assumptions regarding the preferences of the agents.","cites":"37","conferencePercentile":"96.39175258"},{"venue":"AAAI","id":"3c7fd44fa1116e3dfdf53ff5a671691ea92ed7a3","venue_1":"AAAI","year":"2012","title":"A Complexity-of-Strategic-Behavior Comparison between Schulze's Rule and Ranked Pairs","authors":"David C. Parkes, Lirong Xia","author_ids":"1702994, 1794126","abstract":"Schulze's rule and ranked pairs are two Condorcet methods that both satisfy many natural axiomatic properties. Schulze's rule is used in the elections of many organizations, including the Wikimedia Foundation, the Pirate Party of Sweden and Germany, the Debian project, and the Gento Project. Both rules are immune to control by cloning alternatives, but little is otherwise known about their strategic robustness, including resistance to manipulation by one or more voters, control by adding or deleting alternatives, adding or deleting votes, and bribery. Considering computational barriers, we show that these types of strategic behavior are NP-hard for ranked pairs (both constructive, in making an alternative a winner, and destructive , in precluding an alternative from being a winner). Schulze's rule, in comparison, remains vulnerable at least to constructive manipulation by a single voter and destructive manipulation by a coalition. As the first such polynomial-time rule known to resist all such manipulations, and considering also the broad axiomatic support, ranked pairs seems worthwhile to consider for practical applications.","cites":"17","conferencePercentile":"84.75609756"},{"venue":"AAAI","id":"1a380e0f2d3e760f0fcf618cd60fcea397ed5349","venue_1":"AAAI","year":"2012","title":"A Robust Bayesian Truth Serum for Small Populations","authors":"Jens Witkowski, David C. Parkes","author_ids":"2988421, 1702994","abstract":"Peer prediction mechanisms allow the truthful elicitation of private signals (e.g., experiences, or opinions) in regard to a true world state when this ground truth is unobservable. The original peer prediction method is incentive compatible for any number of agents n ≥ 2, but relies on a common prior, shared by all agents and the mechanism. The Bayesian Truth Serum (BTS) relaxes this assumption. While BTS still assumes that agents share a common prior, this prior need not be known to the mechanism. However, BTS is only incentive compatible for a large enough number of agents, and the particular number of agents required is uncertain because it depends on this private prior. In this paper, we present a robust BTS for the elicitation of binary information which is incentive compatible for every n ≥ 3, taking advantage of a particularity of the quadratic scoring rule. The robust BTS is the first peer prediction mechanism to provide strict incentive compatibility for every n ≥ 3 without relying on knowledge of the common prior. Moreover, and in contrast to the original BTS, our mechanism is numerically robust and ex post individually rational.","cites":"47","conferencePercentile":"97.56097561"},{"venue":"AAAI","id":"0ee0dc243079f836d1edba74eb0adc1c5c02b0c1","venue_1":"AAAI","year":"2013","title":"Dynamic Social Choice with Evolving Preferences","authors":"David C. Parkes, Ariel D. Procaccia","author_ids":"1702994, 1689184","abstract":"Social choice theory provides insights into a variety of collective decision making settings, but nowadays some of its tenets are challenged by Internet environments, which call for dynamic decision making under constantly changing preferences. In this paper we model the problem via Markov decision processes (MDP), where the states of the MDP coincide with preference profiles and a (deterministic, stationary) policy corresponds to a social choice function. We can therefore employ the axioms studied in the social choice literature as guidelines in the design of socially desirable policies. We present tractable algorithms that compute optimal policies under different prominent social choice constraints. Our machinery relies on techniques for exploiting symmetries and isomorphisms between MDPs.","cites":"9","conferencePercentile":"79.45454545"},{"venue":"AAAI","id":"7f8d44e7fd2605d580683e47bb185de7f9ea9e28","venue_1":"AAAI","year":"2016","title":"Predicting Personal Traits from Facial Images Using Convolutional Neural Networks Augmented with Facial Landmark Information","authors":"Yoad Lewenberg, Yoram Bachrach, Sukrit Shankar, Antonio Criminisi","author_ids":"2291654, 1698412, 1808862, 1716777","abstract":"We consider the task of predicting various traits of a person given an image of their face. We estimate both objective traits, such as gender, ethnic-ity and hair-color; as well as subjective traits, such as the emotion a person expresses or whether he is humorous or attractive. For sizeable experimentation , we contribute a new Face Attributes Dataset (FAD), having roughly 200,000 attribute labels for the above traits, for over 10,000 facial images. Due to the recent surge of research on Deep Con-volutional Neural Networks (CNNs), we begin by using a CNN architecture for estimating facial attributes and show that they indeed provide an impressive baseline performance. To further improve performance, we propose a novel approach that incorporates facial landmark information for input images as an additional channel, helping the CNN learn better attribute-specific features so that the landmarks across various training images hold correspondence. We empirically analyse the performance of our method, showing consistent improvement over the baseline across traits.","cites":"1","conferencePercentile":"40.70945946"},{"venue":"AAAI","id":"6d1571c6e08cefddd8a19b1325d29354a3ebda19","venue_1":"AAAI","year":"2010","title":"Accounting Mechanisms for Distributed Work Systems","authors":"Sven Seuken, Jie Tang, David C. Parkes","author_ids":"1884044, 1750766, 1702994","abstract":"In distributed work systems, individual users perform work for other users. A significant challenge in these systems is to provide proper incentives for users to contribute as much work as they consume, even when monitoring is not possible. We formalize the problem of designing incentive-compatible accounting mechanisms that measure the net contributions of users, despite relying on voluntary reports. We introduce the Drop-Edge Mechanism that removes any incentive for a user to manipulate via misreports about work contributed or consumed. We prove that Drop-Edge provides a good approximation to a user's net contribution, and is accurate in the limit as the number of users grows. We demonstrate very good welfare properties in simulation compared to an existing, manipulable mechanism. In closing, we discuss our ongoing work, including a real-world implementation and evaluation of the Drop-Edge Mechanism in a BitTorrent client.","cites":"10","conferencePercentile":"52.21843003"},{"venue":"AAAI","id":"0436137cd637094e886d1b9e276475c9a266851e","venue_1":"AAAI","year":"2015","title":"Congestion Games with Distance-Based Strict Uncertainty","authors":"Reshef Meir, David C. Parkes","author_ids":"1769579, 1702994","abstract":"We put forward a new model of congestion games where agents have uncertainty over the routes used by other agents. We take a non-probabilistic approach, assuming that each agent knows that the number of agents using an edge is within a certain range. Given this uncertainty, we model agents who either minimize their worst-case cost (WCC) or their worst-case regret (WCR), and study implications on equilibrium existence, convergence through adaptive play, and efficiency. Under the WCC behavior the game reduces to a modified congestion game, and welfare improves when agents have moderate uncertainty. Under WCR behavior the game is not, in general , a congestion game, but we show convergence and efficiency bounds for a simple class of games.","cites":"5","conferencePercentile":"80.31496063"},{"venue":"AAAI","id":"3e5249928a8a8374c232f1dcec54444e2b9bc422","venue_1":"AAAI","year":"2007","title":"An Ironing-Based Approach to Adaptive Online Mechanism Design in Single-Valued Domains","authors":"David C. Parkes, Quang Duong","author_ids":"1702994, 3075600","abstract":"Online mechanism design considers the problem of sequential decision making in a multi-agent system with self-interested agents. The agent population is dynamic and each agent has private information about its value for a sequence of decisions. We introduce a method (\" ironing\") to transform an algorithm for online stochastic optimization into one that is incentive-compatible. Ironing achieves this by canceling decisions that violate a form of monotonicity. The approach is applied to the CONSENSUS algorithm and experimental results in a resource allocation domain show that not many decisions need to be canceled and that the overhead of ironing is manageable.","cites":"33","conferencePercentile":"83.82789318"},{"venue":"AAAI","id":"64dc32f0ad2c28710ef4eb71c5eec5d05171ce74","venue_1":"AAAI","year":"2014","title":"Who Also Likes It? Generating the Most Persuasive Social Explanations in Recommender Systems","authors":"Beidou Wang, Martin Ester, Jiajun Bu, Deng Cai","author_ids":"2615789, 1766588, 8475311, 1745280","abstract":"Social explanation, the statement with the form of \" A and B also like the item \" , is widely used in almost all the major recommender systems in the web and effectively improves the persuasiveness of the recommendation results by convincing more users to try. This paper presents the first algorithm to generate the most persuasive social explanation by recommending the optimal set of users to be put in the explanation. New challenges like modeling persuasiveness of multiple users, different types of users in social network, sparsity of likes, are discussed in depth and solved in our algorithm. The extensive evaluation demonstrates the advantage of our proposed algorithm compared with traditional methods. With over 1.73 billion users around the world, social networking services 1 , like Facebook, Google Plus and Twit-ter, not only capture social relations among people, but also record our preferences towards various items based on our social network activities like post, retweet, like and +1. This kind of social information is crucial to recom-mender systems, as previous studies on social influence the-ories(Cialdini 2001) have already proved that our preferences can be easily impacted by the actions of those around us. For instance, if our friends keep recommending a movie, we are very likely to try it out. Due to this phenomenon, many recommender systems provide extra social information about other people who also like the item, to achieve better performance. Given an item i to be recommended to user u, we define a social explanation as a statement with the form of \" A and B also like the item \". Social explanations are widely used in different kinds of recommender systems, including the Face-book page recommendations, Twitter people you may like recommendations and even Google Adwords recommendations , with examples summarized in Figure 1. The major benefit of social explanation is the persuasive-ness it brings to the recommendation result. That's to say social explanations convince users to try or buy items(Tintarev and Masthoff 2007). For example, a trusted friend's recommendation may increase our interest to buy an item because we believe in our friend's judgement, or we may want to try something out because we want to talk about it with our friends. Previous studies already confirm that social explanations do help to increase the persuasiveness of the recommendation result (Sharma and Cosley 2013). Despite the wide use of social explanations in systems such as …","cites":"3","conferencePercentile":"49.43181818"},{"venue":"AAAI","id":"54652b948e25b302d174826087d408cb0a1426a7","venue_1":"AAAI","year":"2014","title":"Stochastic Privacy","authors":"Adish Singla, Eric Horvitz, Ece Kamar, Ryen W. White","author_ids":"1703727, 1688884, 1783184, 1734415","abstract":"Online services such as web search and e-commerce applications typically rely on the collection of data about users, including details of their activities on the web. Such personal data is used to maximize revenues via targeting of advertisements and longer engagements of users, and to enhance the quality of service via per-sonalization of content. To date, service providers have largely followed the approach of either requiring or requesting consent for collecting user data. Users may be willing to share private information in return for incentives , enhanced services, or assurances about the nature and extent of the logged data. We introduce stochastic privacy, an approach to privacy centering on the simple concept of providing people with a guarantee that the probability that their personal data will be shared does not exceed a given bound. Such a probability, which we refer to as the privacy risk, can be given by users as a preference or communicated as a policy by a service provider. Service providers can work to personalize and to optimize revenues in accordance with preferences about privacy risk. We present procedures , proofs, and an overall system for maximizing the quality of services, while respecting bounds on privacy risk. We demonstrate the methodology with a case study and evaluation of the procedures applied to web search personalization. We show how we can achieve near-optimal utility of accessing information with prov-able guarantees on the probability of sharing data.","cites":"0","conferencePercentile":"9.431818182"},{"venue":"AAAI","id":"d37297f9b5e17fcc851486af51c34afcebf685af","venue_1":"AAAI","year":"2015","title":"Mining Query Subtopics from Questions in Community Question Answering","authors":"Yu Wu, Wei Wu, Zhoujun Li, Ming Zhou","author_ids":"3495121, 2581478, 1707275, 5962676","abstract":"This paper proposes mining query subtopics from questions in community question answering (CQA). The subtopics are represented as a number of clusters of questions with keywords summarizing the clusters. The task is unique in that the subtopics from questions can not only facilitate user browsing in CQA search, but also describe aspects of queries from a question-answering perspective. The challenges of the task include how to group semantically similar questions and how to find keywords capable of summarizing the clusters. We formulate the subtopic mining task as a non-negative matrix factorization (NMF) problem and further extend the model of NMF to incorporate question similarity estimated from meta-data of CQA into learning. Compared with existing methods, our method can jointly optimize question clustering and keyword extraction and encourage the former task to enhance the latter. Experimental results on large scale real world CQA datasets show that the proposed method significantly outper-forms the existing methods in terms of keyword extraction, while achieving a comparable performance to the state-of-the-art methods for question clustering.","cites":"2","conferencePercentile":"51.65354331"},{"venue":"AAAI","id":"dde41829e45c695703ca73469ee2e33b1fe59860","venue_1":"AAAI","year":"2014","title":"Double Configuration Checking in Stochastic Local Search for Satisfiability","authors":"Chuan Luo, Shaowei Cai, Wei Wu, Kaile Su","author_ids":"1765668, 7884715, 2581478, 1776629","abstract":"Stochastic local search (SLS) algorithms have shown effectiveness on satisfiable instances of the Boolean satis-fiability (SAT) problem. However, their performance is still unsatisfactory on random k-SAT at the phase transition , which is of significance and is one of the empirically hardest distributions of SAT instances. In this paper, we propose a new heuristic called DCCA, which combines two configuration checking (CC) strategies with different definitions of configuration in a novel way. We use the DCCA heuristic to design an efficient SLS solver for SAT dubbed DCCASat. The experiments show that the DCCASat solver significantly outperforms a number of state-of-the-art solvers on extensive random k-SAT benchmarks at the phase transition. Moreover, DCCASat shows good performance on structured benchmarks, and a combination of DCCASat with a complete solver achieves state-of-the-art performance on structured benchmarks.","cites":"5","conferencePercentile":"67.5"},{"venue":"AAAI","id":"0737507872f8a2a18ad8d4a47f7ff8505deb5801","venue_1":"AAAI","year":"2011","title":"Multi-Task Learning in Square Integrable Space","authors":"Wei Wu, Hang Li, Yunhua Hu, Rong Jin","author_ids":"2581478, 3701964, 7741830, 1718400","abstract":"Several kernel based methods for multi-task learning have been proposed, which leverage relations among tasks as reg-ularization to enhance the overall learning accuracies. These methods assume that the tasks share the same kernel, which could limit their applications because in practice different tasks may need different kernels. The main challenge of introducing multiple kernels into multiple tasks is that models from different Reproducing Kernel Hilbert Spaces (RKHSs) are not comparable, making it difficult to exploit relations among tasks. This paper addresses the challenge by formalizing the problem in the Square Integrable Space (SIS). Specially , it proposes a kernel based method which makes use of a regularization term defined in the SIS to represent task relations. We prove a new representer theorem for the proposed approach in SIS. We further derive a practical method for solving the learning problem and conduct consistency analysis of the method. We discuss the relations between our method and an existing method. We also give an SVM based implementation of our method for multi-label classification. Experiments on two real-world data sets show that the proposed method performs better than the existing method.","cites":"1","conferencePercentile":"16.15120275"},{"venue":"AAAI","id":"595d4a939eaf6aba931d46f445af376e46216723","venue_1":"AAAI","year":"2012","title":"Learning to Learn: Algorithmic Inspirations from Human Problem Solving","authors":"Ashish Kapoor, Bongshin Lee, Desney S. Tan, Eric Horvitz","author_ids":"7665582, 1710078, 1719056, 1688884","abstract":"We harness the ability of people to perceive and interact with visual patterns in order to enhance the performance of a machine learning method. We show how we can collect evidence about how people optimize the parameters of an ensemble classification system using a tool that provides a visualization of misclassification costs. Then, we use these observations about human attempts to minimize cost in order to extend the performance of a state-of-the-art ensemble classification system. The study highlights opportunities for learning from evidence collected about human problem solving to refine and extend automated learning and inference.","cites":"4","conferencePercentile":"39.17682927"},{"venue":"AAAI","id":"43f501e3efbfa0df4f2929092278293822a136ab","venue_1":"AAAI","year":"2010","title":"Generalized Task Markets for Human and Machine Computation","authors":"Dafna Shahaf, Eric Horvitz","author_ids":"1805894, 1688884","abstract":"We discuss challenges and opportunities for developing generalized task markets where human and machine intelligence are enlisted to solve problems, based on a consideration of the competencies, availabilities, and pricing of different problem-solving resources. The approach couples human computation with machine learning and planning, and is aimed at optimizing the flow of subtasks to people and to computational problem solvers. We illustrate key ideas in the context of Lin-gua Mechanica, a project focused on harnessing human and machine translation skills to perform translation among languages. We present infrastructure and methods for enlisting and guiding human and machine computation for language translation, including details about the hardness of generating plans for assigning tasks to solvers. Finally, we discuss studies performed with machine and human solvers, focusing on components of a Lingua Mechanica prototype.","cites":"52","conferencePercentile":"94.88054608"},{"venue":"AAAI","id":"179851adb55bf899a6cdc2b1b1df68479f4f563b","venue_1":"AAAI","year":"2008","title":"A Utility-Theoretic Approach to Privacy and Personalization","authors":"Andreas Krause, Eric Horvitz","author_ids":"3421686, 1688884","abstract":"Online services such as web search, news portals, and e-commerce applications face the challenge of providing high-quality experiences to a large, heterogeneous user base. Recent efforts have highlighted the potential to improve performance by personalizing services based on special knowledge about users. For example, a user's location, demographics, and search and browsing history may be useful in enhancing the results offered in response to web search queries. However, reasonable concerns about privacy by both users, providers, and government agencies acting on behalf of citizens , may limit access to such information. We introduce and explore an economics of privacy in personalization, where people can opt to share personal information in return for enhancements in the quality of an online service. We focus on the example of web search and formulate realistic objective functions for search efficacy and privacy. We demonstrate how we can identify a near-optimal solution to the utility-privacy tradeoff. We evaluate the methodology on data drawn from a log of the search activity of volunteer participants. We separately assess users' preferences about privacy and utility via a large-scale survey, aimed at eliciting preferences about peoples' willingness to trade the sharing of personal data in returns for gains in search efficiency. We show that a significant level of personalization can be achieved using only a small amount of information about users.","cites":"37","conferencePercentile":"90.34810127"},{"venue":"AAAI","id":"a6feafed2ef7239b53a166376601df6f91f471cb","venue_1":"AAAI","year":"2004","title":"GROWRANGE: Anytime VCG-Based Mechanisms","authors":"David C. Parkes, Grant Schoenebeck","author_ids":"1702994, 1710013","abstract":"We introduce anytime mechanisms for distributed optimization with self-interested agents. Anytime mechanisms retain good incentive properties even when interrupted before the optimal solution is computed, and provide better quality solutions when given additional time. Anytime mechanisms can solve easy instances of a hard problem quickly and optimally, while providing approximate solutions on very hard instances. In a particular instantiation, GROWRANGE, we successively expand the range of outcomes considered, computing the optimal solution for each range. Truth-revelation remains a dominant strategy equilibrium with a stage-based interruption , and is a best-response with high probability when the interruption is time-based.","cites":"9","conferencePercentile":"45.50898204"},{"venue":"AAAI","id":"203feb2d895f71d038a8a9b2dcafd8ccef7fcec3","venue_1":"AAAI","year":"2006","title":"Trip Router with Individualized Preferences (TRIP): Incorporating Personalization into Route Planning","authors":"Julia Letchner, John Krumm, Eric Horvitz","author_ids":"2682352, 1690256, 1688884","abstract":"Popular route planning systems (Windows Live Local, Yahoo! Maps, Google Maps, etc.) generate driving directions using a static library of roads and road attributes. They ignore both the time at which a route is to be traveled and, more generally, the preferences of the drivers they serve. We present a set of methods for including driver preferences and time-variant traffic condition estimates in route planning. These methods have been incorporated into a working prototype named TRIP. Using a large database of GPS traces logged by drivers, TRIP learns time-variant traffic speeds for every road in a widespread metropolitan area. It also leverages a driver's past GPS logs when responding to future route queries to produce routes that are more suited to the driver's individual driving preferences. Using experiments with real driving data, we demonstrate that the routes produced by TRIP are measurably closer to those actually chosen by drivers than are the routes produced by routers that use static heuristics.","cites":"46","conferencePercentile":"87.46397695"},{"venue":"AAAI","id":"1f6a6aef56ca47c89c237bb1c077b37f1b59f020","venue_1":"AAAI","year":"2015","title":"Stable Model Counting and Its Application in Probabilistic Logic Programming","authors":"Rehan Abdul Aziz, Geoffrey Chu, Christian J. Muise, Peter J. Stuckey","author_ids":"3325356, 2502293, 2428160, 1682747","abstract":"Model counting is the problem of computing the number of models that satisfy a given propositional theory. It has recently been applied to solving inference tasks in probabilistic logic programming, where the goal is to compute the probability of given queries being true provided a set of mutually independent random variables, a model (a logic program) and some evidence. The core of solving this inference task involves translating the logic program to a propositional theory and using a model counter. In this paper, we show that for some problems that involve inductive definitions like reachability in a graph, the translation of logic programs to SAT can be expensive for the purpose of solving inference tasks. For such problems, direct implementation of stable model semantics allows for more efficient solving. We present two implementation techniques, based on unfounded set detection, that extend a propositional model counter to a stable model counter. Our experiments show that for particular problems, our approach can outperform a state-of-the-art probabilistic logic programming solver by several orders of magnitude in terms of running time and space requirements, and can solve instances of significantly larger sizes on which the current solver runs out of time or memory.","cites":"2","conferencePercentile":"51.65354331"},{"venue":"AAAI","id":"207db89bf4a203ff4641414cd6cadd8aac404ca1","venue_1":"AAAI","year":"1994","title":"A Modular Visual Tracking System","authors":"Mike Wessler","author_ids":"3114760","abstract":"I am currently building an active visual tracking system for a real world robot. The hardware is being built at MIT under the supervision of Professors Rod Brooks and Lynn Andrea Stein, and is humanoid in form. The software is also humanoid: I am basing its organization on models of early vision in the human brain. Most of the software is still in the design phase; what I describe here is the part of the system that is already up and running. The robot, named Cog, has roughly the same degrees of freedom in the waist, neck, arms and eyes as a human and is designed with similar proportions in mind. The eyes sport a simulated fovea-each eye consists of two cameras mounted in the same plate, one with a wide field of view, and one with a much narrower view. Both cameras produce 128 x 128 gray scale images. The narrow one is used for tracking, and can be used for object recognition, while the wider view will be used for motion detection and peripheral vision. I have written a visual tracking system that will eventually be hooked up to the motors in Cog's neck and eyes. For now, tracking is simulated by moving a small 16 x 16 \" attention window \" around the larger image from one of the cameras. On startup, the system memorizes the 16 x 16 segment in the center of the full image as a \" reference \" image. For the rest of the run, the system moves the window around to maintain whatever was initially present within its view. The tracking system runs as follows. Once a new frame is grabbed, the system makes a guess about where the new window location should be, based on its previous velocity. Next, a portion of the image slightly larger than the attention window is selected, and the derivative of this region is computed.' Finally, a simple correlation is performed between the memorized reference image and the nine 16 x 16 windows centered around the pixel position nearest the guess. The one Any opinions, findings, conclusions or recommendations expressed in this material are those of the author and do not necessarily reflect the views of the NSF. 10rigina.lly, I had taken two derivatives in the 3: and y directions, but it turns out that a single derivative runs twice as quickly, with very little decrease …","cites":"9","conferencePercentile":"44.49339207"},{"venue":"AAAI","id":"5260a706305c59c0fa2981bcdd86280c3c4a16b1","venue_1":"AAAI","year":"2016","title":"Learning the Preferences of Ignorant, Inconsistent Agents","authors":"Owain Evans, Andreas Stuhlmüller, Noah D. Goodman","author_ids":"6326072, 2214496, 1945655","abstract":"An important use of machine learning is to learn what people value. What posts or photos should a user be shown? Which jobs or activities would a person find rewarding? In each case, observations of people's past choices can inform our inferences about their likes and preferences. If we assume that choices are approximately optimal according to some utility function, we can treat preference inference as Bayesian inverse planning. That is, given a prior on utility functions and some observed choices, we invert an optimal decision-making process to infer a posterior distribution on utility functions. However, people often deviate from approximate optimality. They have false beliefs, their planning is sub-optimal, and their choices may be temporally inconsistent due to hyperbolic discounting and other biases. We demonstrate how to incorporate these deviations into algorithms for preference inference by constructing generative models of planning for agents who are subject to false beliefs and time inconsistency. We explore the inferences these models make about preferences , beliefs, and biases. We present a behavioral experiment in which human subjects perform preference inference given the same observations of choices as our model. Results show that human subjects (like our model) explain choices in terms of systematic deviations from optimal behavior and suggest that they take such deviations into account when inferring preferences .","cites":"4","conferencePercentile":"79.72972973"},{"venue":"AAAI","id":"8f2fa65cb08d76e9fd127bfea81e9665bc5e0829","venue_1":"AAAI","year":"2004","title":"AI Characters and Directors for Interactive Computer Games","authors":"Brian Magerko, John E. Laird, Mazin Assanie, Alex Kerfoot, Devvan Stokes","author_ids":"1691882, 1715438, 2781038, 3305736, 2363201","abstract":"We are creating an environment for investigating the role of advanced AI in interactive, story-based computer games. This environment is based on the Unreal Tournament (UT) game engine and the Soar AI engine. Unreal provides a 3D virtual environment, while Soar provides a flexible architecture for developing complex AI characters. This paper describes our progress to date, starting with our game, Haunt 2, which is designed so that complex AI characters will be critical to the success (or failure) of the game. It addresses design issues with constructing a plot for an interactive storytelling environment, creating synthetic characters for that environment, and using a story director agent to tell the story with those characters.","cites":"83","conferencePercentile":"93.41317365"},{"venue":"AAAI","id":"014ac1d3c0c8f68d1ae867e36f5a415dfbaa6f1b","venue_1":"AAAI","year":"2016","title":"Uncorrelated Group LASSO","authors":"Deguang Kong, Ji Liu, Bo Liu, Xuan Bao","author_ids":"8720637, 3256884, 3436080, 2418751","abstract":"2,1-norm is an effective regularization to enforce a simple group sparsity for feature learning. To capture some subtle structures among feature groups, we propose a new regular-ization called exclusive group 2,1-norm. It enforces the spar-sity at the intra-group level by using 2,1-norm, while encourages the selected features to distribute in different groups by using 2 norm at the inter-group level. The proposed exclusive group 2,1-norm is capable of eliminating the feature correlations in the context of feature selection, if highly correlated features are collected in the same groups. To solve the generic exclusive group 2,1-norm regularized problems, we propose an efficient iterative re-weighting algorithm and provide a rigorous convergence analysis. Experiment results on real world datasets demonstrate the effectiveness of the proposed new regularization and algorithm.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"3d13a3ab6a026cb45357844d7783fd73136c2bb8","venue_1":"AAAI","year":"2011","title":"Towards Large-Scale Collaborative Planning: Answering High-Level Search Queries Using Human Computation","authors":"Edith Law, Haoqi Zhang","author_ids":"2987829, 3162562","abstract":"Behind every search query is a high-level mission that the user wants to accomplish. While current search engines can often provide relevant information in response to well-specified queries, they place the heavy burden of making a plan for achieving a mission on the user. We take the alternative approach of tackling users' high-level missions directly by introducing a human computation system that generates simple plans, by decomposing a mission into goals and retrieving search results tailored to each goal. Results show that our system is able to provide users with diverse, actionable search results and useful roadmaps for accomplishing their missions.","cites":"26","conferencePercentile":"92.78350515"},{"venue":"AAAI","id":"14d7b0ee9466b0e539ea701d5e6781f5d56146e2","venue_1":"AAAI","year":"2011","title":"Composite Social Network for Predicting Mobile Apps Installation","authors":"Wei Pan, Nadav Aharony, Alex Pentland","author_ids":"4267785, 2384607, 1682773","abstract":"We have carefully instrumented a large portion of the population living in a university graduate dormitory by giving participants Android smart phones running our sensing software. In this paper, we propose the novel problem of predicting mobile application (known as \" apps \") installation using social networks and explain its challenge. Modern smart phones, like the ones used in our study, are able to collect different social networks using built-in sensors. (e.g. Bluetooth proximity network, call log network, etc) While this information is accessible to app market makers such as the iPhone AppStore, it has not yet been studied how app market makers can use these information for marketing research and strategy development. We develop a simple computational model to better predict app installation by using a composite network computed from the different networks sensed by phones. Our model also captures individual variance and exogenous factors in app adoption. We show the importance of considering all these factors in predicting app installations, and we observe the surprising result that app installation is indeed predictable. We also show that our model achieves the best results compared with generic approaches.","cites":"41","conferencePercentile":"96.90721649"},{"venue":"AAAI","id":"130a6ed7bd61e017ac7b67119d202f45dfce930c","venue_1":"AAAI","year":"2004","title":"The Backdoor Key: A Path to Understanding Problem Hardness","authors":"Yongshao Ruan, Henry A. Kautz, Eric Horvitz","author_ids":"1760493, 1690271, 1688884","abstract":"We introduce our work on the backdoor key, a concept that shows promise for characterizing problem hardness in back-tracking search algorithms. The general notion of backdoors was recently introduced to explain the source of heavy-tailed behaviors in backtracking algorithms (Williams, Gomes, & Selman 2003a; 2003b). We describe empirical studies that show that the key faction,i.e., the ratio of the key size to the corresponding backdoor size, is a good predictor of problem hardness of ensembles and individual instances within an ensemble for structure domains with large key fraction.","cites":"29","conferencePercentile":"75.74850299"},{"venue":"AAAI","id":"1031ff6de09ebb5cbbb6e5dc379050983ac519b8","venue_1":"AAAI","year":"2010","title":"Decomposed Utility Functions and Graphical Models for Reasoning about Preferences","authors":"Ronen I. Brafman, Yagil Engel","author_ids":"1680506, 2259790","abstract":"Recently, Brafman and Engel (2009) proposed new concepts of marginal and conditional utility that obey additive analogues of the chain rule and Bayes rule, which they employed to obtain a directed graphical model of utility functions that resembles Bayes nets. In this paper we carry this analogy a step farther by showing that the notion of utility independence , built on conditional utility, satisfies identical properties to those of probabilistic independence. This allows us to formalize the construction of graphical models for utility functions, directed and undirected, and place them on the firm foundations of Pearl and Paz's axioms of semi-graphoids. With this strong equivalence in place, we show how algorithms used for probabilistic reasoning such as Belief Propagation (Pearl 1988) can be replicated to reasoning about utilities with the same formal guarantees, and open the way to the adaptation of additional algorithms.","cites":"1","conferencePercentile":"11.09215017"},{"venue":"AAAI","id":"af50e9054ce9e6a9dcbfe6020384f024629cb448","venue_1":"AAAI","year":"1994","title":"A Dynamic Organization in Distributed Constraint Satisfaction","authors":"Katsutoshi Hirayama, Seiji Yamada, Jun'ichi Toyoda","author_ids":"3148762, 1679243, 3327603","abstract":"We present a novel dynamic organization to solve DC-SP(Distributed Constraint Satisfaction Problem). DCSP provides a formal framework for studying cooperative distributed problem solving[Yokoo 921. To solve DCSP, we have developed a simple algorithm using iterative improvement. This technique has had great success on certain CSP(Constraint Satisfaction Problems)[Minton 9O][Selman 921. In our algorithm each agent performs iterative improvement and also plural agents can do in parallel. However, one drawback of this technique is the possibility of getting caught in local minima(which are defined specifically in our algorithm). LMO is a technique for escaping from local minima. It is summarized as follows: When an agent(A1) gets caught in a local minimum, (step I) Al sends its CSP(variables, domains and constraints) to an agent(A2). Al selects A2 such that it shares violated constraints at that time. Ties are broken randomly. (step 2) AZ puts its CSP and Al's CSP together and searches for all possible assignments with simple back-tracking. After that, A2 performs iterative improvement. Besides escaping from local minima, LMO prevents agents from getting caught in the same local minima as before. Therefore our algorithm for DCSP is complete. LMO is also the algorithm for a dynamic organization since agents reassign the responsibilities of solving CSP based on a developing view of the problem. As a dynamic organization, LMO is characterized by grouping in response to the conflicts(i.e., local minima) that arise during problem solving. This produces the effect that the organization with LMO(we call it the LMO organization) makes groups depending on the number of local minima. That is, when there are few local minima in a problem, the LMO organization solves it in a distributed manner, and when there are many, it does in a centralized manner. To evaluate the performance of LMO, we have compared the LMO organization with the following ones. 1. Distributed organization: This organization always solves problems in a distributed manner. In this organization each agent performs iterative improvement. When one agent gets caught in a local minimum, all agents change their assignments randomly and continue to perform iterative improvement. 2. Centralized organization: This organization always solves problems in a centralized manner. In this organization , to begin with agents have to solve the leader election problem. Then all agents(but the leader) send their CSP to the leader. Finally the leader searches for one solution with simple backtraking(the method used in LMQ. Note that agents solve …","cites":"0","conferencePercentile":"6.387665198"},{"venue":"AAAI","id":"03f336aaa827ef85fae74aa3484448ad1d43be57","venue_1":"AAAI","year":"2014","title":"Fast Multi-Instance Multi-Label Learning","authors":"Sheng-Jun Huang, Wei Gao, Zhi-Hua Zhou","author_ids":"7649626, 1698396, 1692625","abstract":"In multi-instance multi-label learning (MIML), one object is represented by multiple instances and simultaneously associated with multiple labels. Existing MIML approaches have been found useful in many applications ; however, most of them can only handle moderate-sized data. To efficiently handle large data sets, we propose the MIMLfast approach, which first constructs a low-dimensional subspace shared by all labels, and then trains label specific linear models to optimize approximated ranking loss via stochastic gradient descent. Although the MIML problem is complicated, MIMLfast is able to achieve excellent performance by exploiting label relations with shared space and discovering sub-concepts for complicated labels. Experiments show that the performance of MIMLfast is highly competitive to state-of-the-art techniques, whereas its time cost is much less; particularly, on a data set with 30K bags and 270K instances, where none of existing approaches can return results in 24 hours, MIMLfast takes only 12 minutes. Moreover, our approach is able to identify the most representative instance for each label, and thus providing a chance to understand the relation between input patterns and output semantics.","cites":"9","conferencePercentile":"84.43181818"},{"venue":"AAAI","id":"70f7128149763af6eae2605ac82eb833a9bd9da4","venue_1":"AAAI","year":"2005","title":"Competence Driven Case-Base Mining","authors":"Rong Pan, Qiang Yang, Jeffrey Junfeng Pan, Lei Li","author_ids":"1710684, 1733090, 1730133, 4236221","abstract":"We present a novel algorithm for extracting a high-quality case base from raw data while preserving and sometimes improving the competence of case-based reasoning. We extend the framework of Smyth and Keane's case-deletion policy with two additional features. First, we build a case base using a statistical distribution that is mined from the input data so that the case-base competence can be preserved or even increased for future problems. Second, we introduce a nonlin-ear transformation of the data set so that the case-base sizes can be further reduced while ensuring that the competence be preserved and even increased. We show that Smyth and Keane's deletion-based algorithm is sensitive to noisy cases, and that our solution solves this problem more satisfactorily. We show the theoretical foundation and empirical evaluation on several data sets.","cites":"3","conferencePercentile":"20.45454545"},{"venue":"AAAI","id":"3160738b7a7bf17cc8bbd713bfd4dcc03b96ef46","venue_1":"AAAI","year":"2006","title":"A Manifold Regularization Approach to Calibration Reduction for Sensor-Network Based Tracking","authors":"Jeffrey Junfeng Pan, Qiang Yang, Hong Chang, Dit-Yan Yeung","author_ids":"1730133, 1733090, 1783542, 1739816","abstract":"The ability to accurately detect the location of a mobile node in a sensor network is important for many artificial intelligence (AI) tasks that range from robot-ics to context-aware computing. Many previous approaches to the location-estimation problem assume the availability of calibrated data. However, to obtain such data requires great effort. In this paper, we present a manifold regularization approach known as LeMan to calibration-effort reduction for tracking a mobile node in a wireless sensor network. We compute a subspace mapping function between the signal space and the physical space by using a small amount of labeled data and a large amount of unlabeled data. This mapping function can be used online to determine the location of mobile nodes in a sensor network based on the signals received. We use Crossbow MICA2 to setup the network and USB camera array to obtain the ground truth. Experimental results show that we can achieve a higher accuracy with much less calibration effort as compared to several previous systems.","cites":"21","conferencePercentile":"71.03746398"},{"venue":"AAAI","id":"797b2bcbedc2b650fff4622b88a3d0d13110c19b","venue_1":"AAAI","year":"2007","title":"Transferring Naive Bayes Classifiers for Text Classification","authors":"Wenyuan Dai, Gui-Rong Xue, Qiang Yang, Yong Yu","author_ids":"1752769, 1701421, 1733090, 3578922","abstract":"A basic assumption in traditional machine learning is that the training and test data distributions should be identical. This assumption may not hold in many situations in practice, but we may be forced to rely on a different-distribution data to learn a prediction model. For example, this may be the case when it is expensive to label the data in a domain of interest, although in a related but different domain there may be plenty of labeled data available. In this paper, we propose a novel transfer-learning algorithm for text classification based on an EM-based Naive Bayes classifiers. Our solution is to first estimate the initial probabilities under a distribution D ℓ of one labeled data set, and then use an EM algorithm to revise the model for a different distribution Du of the test data which are unlabeled. We show that our algorithm is very effective in several different pairs of domains, where the distances between the different distributions are measured using the Kullback-Leibler (KL) divergence. Moreover, KL-divergence is used to decide the trade-off parameters in our algorithm. In the experiment, our algorithm outperforms the traditional supervised and semi-supervised learning algorithms when the distributions of the training and test sets are increasingly different.","cites":"100","conferencePercentile":"98.51632047"},{"venue":"AAAI","id":"2cb31e61e20c4f02439cac049fdea8d7f4825ab6","venue_1":"AAAI","year":"2007","title":"Mining Web Query Hierarchies from Clickthrough Data","authors":"Dou Shen, Min Qin, Weizhu Chen, Qiang Yang, Zheng Chen","author_ids":"1680850, 2756826, 7307263, 1733090, 1705657","abstract":"In this paper, we propose to mine query hierarchies from clickthrough data, which is within the larger area of automatic acquisition of knowledge from the Web. When a user submits a query to a search engine and clicks on the returned Web pages, the user's understanding of the query as well as its relation to the Web pages is encoded in the clickthrough data. With millions of queries being submitted to search engines every day, it is both important and beneficial to mine the knowledge hidden in the queries and their intended Web pages. We can use this information in various ways, such as providing query suggestions and organizing the queries. In this paper, we plan to exploit the knowledge hidden in clickthrough logs by constructing query hierarchies, which can reflect the relationship among queries. Our proposed method consists of two stages: generating candidate queries and determining \" generalization/specialization \" relations between these queries in a hierarchy. We test our method on some labeled data sets and illustrate the effectiveness of our proposed solution empirically.","cites":"25","conferencePercentile":"76.2611276"},{"venue":"AAAI","id":"0116e12fd4dcbc7e71ee7d3a477b7bd8fc6220ae","venue_1":"AAAI","year":"2008","title":"Mining Translations of Web Queries from Web Click-through Data","authors":"Rong Hu, Weizhu Chen, Jian Hu, Yansheng Lu, Zheng Chen, Qiang Yang","author_ids":"3279297, 7307263, 4218854, 1691412, 1705657, 1733090","abstract":"Query translation for Cross-Lingual Information Retrieval (CLIR) has gained increasing attention in the research area. Previous work mainly used machine translation systems, bilingual dictionaries, or web corpora to perform query translation. However, most of these approaches require either expensive language resources or complex language models, and cannot achieve timely translation for new queries. In this paper, we propose a novel solution to automatically acquire query translation pairs from the knowledge hidden in the click-through data, that are represented by the URL a user clicks after submitting a query to a search engine. Our proposed solution consists of two stages: identifying bilingual URL pair patterns in the click-through data and matching query translation pairs based on user click behavior. Experimental results on a real dataset show that our method not only generates existing query translation pairs with high precision, but also generates many timely query translation pairs that could not be obtained by previous methods. A comparative study between our system and two commercial online translation systems shows the advantage of our proposed method.","cites":"0","conferencePercentile":"7.120253165"},{"venue":"AAAI","id":"ae7d5d50fc1d11aff59f910c3b37d7ee6415ee51","venue_1":"AAAI","year":"2010","title":"Visual Contextual Advertising: Bringing Textual Advertisements to Images","authors":"Yuqiang Chen, Ou Jin, Gui-Rong Xue, Jia Chen, Qiang Yang","author_ids":"2756531, 4057027, 1701421, 5562274, 1733090","abstract":"Advertising in the case of textual Web pages has been studied extensively by many researchers. However, with the increasing amount of multimedia data such as image, audio and video on the Web, the need for recommending advertisement for the multimedia data is becoming a reality. In this paper, we address the novel problem of visual contextual advertising, which is to directly advertise when users are viewing images which do not have any surrounding text. A key challenging issue of visual contextual advertising is that images and advertisements are usually represented in image space and word space respectively, which are quite different with each other inherently. As a result, existing methods for Web page advertising are inapplicable since they represent both Web pages and advertisement in the same word space. In order to solve the problem, we propose to exploit the social Web to link these two feature spaces together. In particular, we present a unified generative model to integrate advertisements, words and images. Specifically, our solution combines two parts in a prin-cipled approach: First, we transform images from a image feature space to a word space utilizing the knowledge from images with annotations from social Web. Then, a language model based approach is applied to estimate the relevance between transformed images and advertisements. Moreover, in this model, the probability of recommending an advertisement can be inferred efficiently given an image, which enables potential applications to online advertising.","cites":"5","conferencePercentile":"32.08191126"},{"venue":"AAAI","id":"9ab41801f516cf61c17bc88c5652f5d582da7279","venue_1":"AAAI","year":"2010","title":"Clickthrough Log Analysis by Collaborative Ranking","authors":"Bin Cao, Dou Shen, Kuansan Wang, Qiang Yang","author_ids":"1693204, 1680850, 3163131, 1733090","abstract":"Analyzing clickthrough log data is important for improving search performance as well as understanding user behaviors. In this paper, we propose a novel collaborative ranking model to tackle two difficulties in analyzing clickthrough log. First, previous studies have shown that users tend to click top-ranked results even they are less relevant. Therefore, we use pairwise ranking relation to avoid the position bias in clicks. Second, since click data are extremely sparse with respect to each query or user, we construct a collaboration model to eliminate the sparseness problem. We also find that the proposed model and previous popular used click-based models address different aspects of clickthrough log data. We further propose a hybrid model that can achieve significant improvement compared to the baselines on a large-scale real world dataset.","cites":"13","conferencePercentile":"60.58020478"},{"venue":"AAAI","id":"7c031939dbb05b566c5f2dbc797e689f320b20b7","venue_1":"AAAI","year":"2005","title":"Multiple-Goal Recognition from Low-Level Signals","authors":"Xiaoyong Chai, Qiang Yang","author_ids":"2059102, 1733090","abstract":"Researchers and practitioners from both the artificial intelligence and pervasive computing communities have been paying increasing attention to the task of inferring users' high-level goals from low-level sensor readings. A common assumption made by most approaches is that a user either has a single goal in mind, or achieves several goals sequentially. However, in real-world environments , a user often has multiple goals that are concurrently carried out, and a single action can serve as a common step towards multiple goals. In this paper, we formulate the multiple-goal recognition problem and exemplify it in an indoor environment where an RF-based wireless network is available. We propose a goal-recognition algorithm based on a dynamic model set and show how goal models evolve over time based on pre-defined states. Experiments with real data demonstrate that our method can accurately and efficiently recognize multiple interleaving goals in a user's trace.","cites":"11","conferencePercentile":"47.02797203"},{"venue":"AAAI","id":"56efce392172f53b71cfc3daf09db983629b60a5","venue_1":"AAAI","year":"2011","title":"A Whole Page Click Model to Better Interpret Search Engine Click Data","authors":"Weizhu Chen, Zhanglong Ji, Si Shen, Qiang Yang","author_ids":"7307263, 2972397, 2508784, 1733090","abstract":"Recent advances in click modeling have established it as an attractive approach to interpret search click data. These advances characterize users' search behavior either in advertisement blocks, or within an organic search block through probabilistic models. Yet, when searching for information on a search result page, one is often interacting with the search engine via an entire page instead of a single block. Consequently, previous works that exclusively modeled user behavior in a single block may sacrifice much useful user behavior information embedded in other blocks. To solve this problem, in this paper, we put forward a novel Whole Page Click (WPC) Model to characterize user behavior in multiple blocks. Specifically, WPC uses a Markov chain to learn the user transition probabilities among different blocks in the whole page. To compare our model with the best alternatives in the Web-Search literature, we run a large-scale experiment on a real dataset and demonstrate the advantage of the WPC model in terms of both the whole page and each block in the page. Especially, we find that WPC can achieve significant gain in interpreting the advertisement data, despite of the sparsity of the advertisement click data.","cites":"13","conferencePercentile":"74.91408935"},{"venue":"AAAI","id":"a0affa458a3a135731f3f098c892cccfd943ad54","venue_1":"AAAI","year":"2012","title":"Transfer Learning in Collaborative Filtering with Uncertain Ratings","authors":"Weike Pan, Evan Wei Xiang, Qiang Yang","author_ids":"1746462, 1687976, 1733090","abstract":"To solve the sparsity problem in collaborative filtering, researchers have introduced transfer learning as a viable approach to make use of auxiliary data. Most previous transfer learning works in collaborative filtering have focused on exploiting point-wise ratings such as numerical ratings, stars, or binary ratings of likes/dislikes. However, in many real-world recommender systems, many users may be unwilling or unlikely to rate items with precision. In contrast, practitioners can turn to various non-preference data to estimate a range or rating distribution of a user's preference on an item. Such a range or rating distribution is called an uncertain rating since it represents a rating spectrum of uncertainty instead of an accurate point-wise score. In this paper , we propose an efficient transfer learning solution for collaborative filtering, known as transfer by inte-grative factorization (TIF), to leverage such auxiliary uncertain ratings to improve the performance of recommendation. In particular, we integrate auxiliary data of uncertain ratings as additional constraints in the target matrix factorization problem, and learn an expected rating value for each uncertain rating automatically. The advantages of our proposed approach include the efficiency and the improved effectiveness of collaborative filtering, showing that incorporating the auxiliary data of uncertain ratings can really bring a benefit. Experimental results on two movie recommendation tasks show that our TIF algorithm performs significantly better over a state-of-the-art non-transfer learning method.","cites":"17","conferencePercentile":"84.75609756"},{"venue":"AAAI","id":"9c0b596be024d0e45d325f8fd549e575e7fbd12c","venue_1":"AAAI","year":"2012","title":"A Mouse-Trajectory Based Model for Predicting Query-URL Relevance","authors":"Hengjie Song, Ruoxue Liao, Xiangliang Zhang, Chunyan Miao, Qiang Yang","author_ids":"2688347, 2335728, 2928371, 1679209, 1733090","abstract":"For the learning to ranking algorithms used in commercial search engines, a conventional way to generate the training examples is to employ professional annotators to label the relevance of query url pairs. Since label quality depends on the expertise of annotators to a large extent, this process is time consuming and labor intensive. Automatically generating labels from click through data has been well studied to have comparable or better performance than human judges. Click through data present users' action and imply their satisfaction on search results, but exclude the interactions between users and search results beyond the page view level (e.g., eye and mouse movements). This paper proposes a novel approach to comprehensively consider the information underlying mouse trajectory and click through data so as to describe user behaviors more objectively and achieve a better understanding of the user experience. By integrating multi sources data, the proposed approach reveals that the relevance labels of query url pairs are related to positions of urls and users' behavioral features. Based on their correlations, query url pairs can be labeled more accurately and search results are more satisfactory to users. The experiments that are conducted on the most popular Chinese commercial search engine (Baidu) validated the rationality of our research motivation and proved that the proposed approach outperformed the state of the art methods.","cites":"1","conferencePercentile":"13.87195122"},{"venue":"AAAI","id":"858cdf1ad6822e644c53c7751f9b5bda40104262","venue_1":"AAAI","year":"2015","title":"RAIN: Social Role-Aware Information Diffusion","authors":"Yang Yang, Jie Tang, Cane Wing-ki Leung, Yizhou Sun, Qicong Chen, Juan-Zi Li, Qiang Yang","author_ids":"3432905, 1750766, 2142726, 1792614, 2030189, 8549842, 1733090","abstract":"Information diffusion, which studies how information is propagated in social networks, has attracted considerable research effort recently. However, most existing approaches do not distinguish social roles that nodes may play in the diffusion process. In this paper, we study the interplay between users' social roles and their influence on information diffusion. We propose a Role-Aware INformation diffusion model (RAIN) that integrates social role recognition and diffusion modeling into a unified framework. We develop a Gibbs-sampling based algorithm to learn the proposed model using historical diffusion data. The proposed model can be applied to different scenarios. For instance, at the micro-level, the proposed model can be used to predict whether an individual user will repost a specific message; while at the macro-level, we can use the model to predict the scale and the duration of a diffusion process. We evaluate the proposed model on a real social media data set. Our model performs much better in both micro-and macro-level prediction than several alternative methods.","cites":"10","conferencePercentile":"93.07086614"},{"venue":"AAAI","id":"40067509fc14381b79f484252609d1a4583fda0d","venue_1":"AAAI","year":"2015","title":"Spectral Label Refinement for Noisy and Missing Text Labels","authors":"Yangqiu Song, Chenguang Wang, Ming Zhang, Hailong Sun, Qiang Yang","author_ids":"1809614, 8205951, 1720939, 4880467, 1733090","abstract":"With the recent growth of online content on the Web, there have been more user generated data with noisy and missing labels, e.g., social tags and voted labels from Amazon's Mechanical Turks. Most of machine learning methods, which require accurate label sets, could not be trusted when the label sets were yet unreliable. In this paper, we provide a text label refinement algorithm to adjust the labels for such noisy and missing labeled datasets. We assume that the labeled sets can be refined based on the labels with certain confidence, and the similarity between data being consistent with the labels. We propose a label smoothness ratio criterion to measure the smoothness of the labels and the consistency between labels and data. We demonstrate the effectiveness of the label refining algorithm on eight labeled document datasets, and validate that the results are useful for generating better labels.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"6f8d57f3f91f7c896e70c5c8ae74f3c652f14acb","venue_1":"AAAI","year":"2016","title":"Multi-Domain Active Learning for Recommendation","authors":"Zihan Zhang, Xiaoming Jin, Lianghao Li, Guiguang Ding, Qiang Yang","author_ids":"3372967, 1730129, 2747826, 2270631, 1733090","abstract":"Recently, active learning has been applied to recommendation to deal with data sparsity on a single domain. In this paper, we propose an active learning strategy for recommendation to alleviate the data sparsity in a multi-domain scenario. Specifically, our proposed active learning strategy simultaneously consider both specific and independent knowledge over all domains. We use the expected entropy to measure the generalization error of the domain-specific knowledge and propose a variance-based strategy to measure the generalization error of the domain-independent knowledge. The proposed active learning strategy use a unified function to effectively combine these two measurements. We compare our strategy with five state-of-the-art baselines on five different multi-domain recommendation tasks, which are constituted by three real-world data sets. The experimental results show that our strategy performs significantly better than all the baselines and reduces human labeling efforts by at least 5.","cites":"1","conferencePercentile":"40.70945946"},{"venue":"AAAI","id":"958359369671ccf9a120e167a30c14ad7bb8cda3","venue_1":"AAAI","year":"2015","title":"Self-Paced Learning for Matrix Factorization","authors":"Qian Zhao, Deyu Meng, Lu Jiang, Qi Xie, Zongben Xu, Alexander G. Hauptmann","author_ids":"3648843, 7480838, 1697318, 1683127, 7814629, 7661726","abstract":"Matrix factorization (MF) has been attracting much attention due to its wide applications. However, since MF models are generally non-convex, most of the existing methods are easily stuck into bad local minima, especially in the presence of outliers and missing data. To alleviate this deficiency, in this study we present a new MF learning methodology by gradually including matrix elements into MF training from easy to complex. This corresponds to a recently proposed learning fashion called self-paced learning (SPL), which has been demonstrated to be beneficial in avoiding bad local minima. We also generalize the conventional binary (hard) weighting scheme for SPL to a more effective real-valued (soft) weighting manner. The effectiveness of the proposed self-paced MF method is substantiated by a series of experiments on synthetic, structure from motion and background subtraction data.","cites":"17","conferencePercentile":"97.16535433"},{"venue":"AAAI","id":"f2171ea6e028fb5c2eb1d0256639b4e732764ab4","venue_1":"AAAI","year":"2015","title":"OMNI-Prop: Seamless Node Classification on Arbitrary Label Correlation","authors":"Yuto Yamaguchi, Christos Faloutsos, Hiroyuki Kitagawa","author_ids":"2278685, 1702392, 1687013","abstract":"If we know most of Smith's friends are from Boston, what can we say about the rest of Smith's friends? In this paper, we focus on the node classification problem on networks, which is one of the most important topics in AI and Web communities. Our proposed algorithm which is referred to as OMNI-Prop has the following properties: (a) seamless and accurate; it works well on any label correlations (i.e., homophily, het-erophily, and mixture of them) (b) fast; it is efficient and guaranteed to converge on arbitrary graphs (c) quasi-parameter free; it has just one well-interpretable parameter with heuris-tic default value of 1. We also prove the theoretical connections of our algorithm to the semi-supervised learning (SSL) algorithms and to random-walks. Experiments on four real, different network datasets demonstrate the benefits of the proposed algorithm, where OMNI-Prop outperforms the top competitors.","cites":"2","conferencePercentile":"51.65354331"},{"venue":"AAAI","id":"522708b047d1496095237d3842fa803f818ba3b4","venue_1":"AAAI","year":"2011","title":"Transfer Learning by Structural Analogy","authors":"Hua-Yan Wang, Qiang Yang","author_ids":"3153736, 1733090","abstract":"Transfer learning allows knowledge to be extracted from auxiliary domains and be used to enhance learning in a target domain. For transfer learning to be successful , it is critical to find the similarity between auxiliary and target domains, even when such mappings are not obvious. In this paper, we present a novel algorithm for finding the structural similarity between two domains, to enable transfer learning at a structured knowledge level. In particular, we address the problem of how to learn a non-trivial structural similarity mapping between two different domains when they are completely different on the representation level. This problem is challenging because we cannot directly compare features across domains. Our algorithm extracts the structural features within each domain and then maps the features into the Reproducing Kernel Hilbert Space (RKHS), such that the \" structural dependencies \" of features across domains can be estimated by kernel matrices of the features within each domain. By treating the analogues from both domains as equivalent, we can transfer knowledge to achieve a better understanding of the domains and improved performance for learning. We validate our approach on a large number of transfer learning scenarios constructed from a real world dataset.","cites":"7","conferencePercentile":"55.67010309"},{"venue":"AAAI","id":"b5344d78b2d9eb05ad2d9c80b1a3f477414b923b","venue_1":"AAAI","year":"2016","title":"Risk Minimization in the Presence of Label Noise","authors":"Wei Gao, Lu Wang, Yu-Feng Li, Zhi-Hua Zhou","author_ids":"1698396, 3540438, 2634254, 1692625","abstract":"Matrix concentration inequalities have attracted much attention in diverse applications such as linear algebra, statistical estimation, combinatorial optimization, etc. In this paper, we present new Bernstein concentration inequalities depending only on the first moments of random matrices, whereas previous Bernstein inequalities are heavily relevant to the first and second moments. Based on those results, we analyze the empirical risk minimization in the presence of label noise. We find that many popular losses used in risk minimization can be decomposed into two parts, where the first part won't be affected and only the second part will be affected by noisy labels. We show that the influence of noisy labels on the second part can be reduced by our proposed LICS (Labeled Instance Centroid Smoothing) approach. The effectiveness of the LICS algorithm is justified both theoretically and empirically.","cites":"1","conferencePercentile":"40.70945946"},{"venue":"AAAI","id":"331306b0fed0a860e4c557e5c68c94acc4c8c305","venue_1":"AAAI","year":"2005","title":"Activity Recognition through Goal-Based Segmentation","authors":"Jie Yin, Dou Shen, Qiang Yang, Ze-Nian Li","author_ids":"3978641, 1680850, 1733090, 1689656","abstract":"A major issue in activity recognition in a sensor network is how to automatically segment the low-level signal sequences in order to optimize the probabilistic recognition models for goals and activities. Past efforts have relied on segmenting the signal sequences by hand, which is both time-consuming and error-prone. In our view, segments should correspond to atomic human activities that enable a goal-recognizer to operate optimally; the two are intimately related. In this paper, we present a novel method for building probabilistic activity models at the same time as we segment signal sequences into motion patterns. We model each motion pattern as a linear dynamic model and the transitions between motion patterns as a Markov process conditioned on goals. Our EM learning algorithm simultaneously learns the motion-pattern boundaries and probabilistic models for goals and activities, which in turn can be used to accurately recognize activities in an online phase. A major advantage of our algorithm is that it can reduce the human effort in segmenting and labeling signal sequences. We demonstrate the effectiveness of our algorithm using the data collected in a real wireless environment.","cites":"7","conferencePercentile":"32.69230769"},{"venue":"AAAI","id":"78147fed4bd451989c0b9a0a318810810158ee4a","venue_1":"AAAI","year":"1992","title":"The Expected Value of Hierarchical Problem-Solving","authors":"Fahiem Bacchus, Qiang Yang","author_ids":"1736882, 1733090","abstract":"In the best case using an abstraction hierarchy i n problem-solving can yield an exponential speed-up in search eeciency. S u c h a speed-up is predicted by v ar-ious analytical models developed in the literature, and eeciency gains of this order have been connrmed empirically. H o wever, these models assume that the Downward R eenement Property (DRP) holds. When this property holds, backtracking never need occur across abstraction levels. When it fails, search m a y h a ve t o consider many diierent abstract solutions before nd-ing one that can be reened to a concrete solution. In this paper we provide an analysis of the expected search complexity without assuming the DRP. W e nd that our model predicts a phase boundary where abstraction provides no beneet: if the probability that an abstract solution can be reened is very low o r v ery high, search with abstraction yields signiicant speed up. However, in the phase boundary area where the probability t a k es on an intermediate value search eciency is not necessarily improved. The phenomenon of a phase boundary where search is hardest agrees with recent empirical studies of Cheeseman et al. CKT91].","cites":"12","conferencePercentile":"18.75"},{"venue":"AAAI","id":"95762eb04f0c99b3b1428a670e054a5d8c6ec1fc","venue_1":"AAAI","year":"2015","title":"On Machine Learning towards Predictive Sales Pipeline Analytics","authors":"Junchi Yan, Chao Zhang, Hongyuan Zha, Min Gong, Changhua Sun, Jin Huang, Stephen M. Chu, Xiaokang Yang","author_ids":"3063894, 3671118, 1750350, 8451836, 1792329, 3579556, 1731014, 1795291","abstract":"Sales pipeline win-propensity prediction is fundamental to effective sales management. In contrast to using subjective human rating, we propose a modern machine learning paradigm to estimate the win-propensity of sales leads over time. A profile-specific two-dimensional Hawkes processes model is developed to capture the influence from seller's activities on their leads to the win outcome, coupled with lead's person-alized profiles. It is motivated by two observations: i) sellers tend to frequently focus their selling activities and efforts on a few leads during a relatively short time. This is evidenced and reflected by their concentrated interactions with the pipeline, including login, browsing and updating the sales leads which are logged by the system; ii) the pending opportunity is prone to reach its win outcome shortly after such temporally concentrated interactions. Our model is deployed and in continual use to a large, global, B2B multinational technology enter-prize (Fortune 500) with a case study. Due to the generality and flexibility of the model, it also enjoys the potential applicability to other real-world problems.","cites":"6","conferencePercentile":"84.80314961"},{"venue":"AAAI","id":"c90a6189df5f3e8075a3dd6f04763d92248d6fe6","venue_1":"AAAI","year":"2007","title":"Responding to Student Affect and Efficacy through Empathetic Companion Agents in Interactive Learning Environments","authors":"Scott W. McQuiggan","author_ids":"2779835","abstract":"Because many students experience frustration during learning, it is important to develop affective strategies to support students' coping with frustration in interactive learning environments. First, we must devise affect recognition models to detect student affect. Second, we need to determine when to intervene; these conditions are likely to be different for each student. To determine how much frustration a student can persist through, we should utilize models of student self-efficacy to predict a student's frustration threshold. Third, we should devise techniques for responding empathetically before the student reaches her threshold of frustration. We propose an approach to support students' coping with frustration in intelligent tutoring systems that utilizes induced models of affect, self-efficacy and empathetic behavior to effectively reason about precisely when and how to intervene in frustration-ridden learning situations.","cites":"0","conferencePercentile":"5.489614243"},{"venue":"AAAI","id":"e1c59e00458b4dee3f0e683ed265735f33187f77","venue_1":"AAAI","year":"2013","title":"Spectral Rotation versus K-Means in Spectral Clustering","authors":"Jin Huang, Feiping Nie, Heng Huang","author_ids":"3579556, 1688370, 1748032","abstract":"Spectral clustering has been a popular data clustering algorithm. This category of approaches often resort to other clustering methods, such as K-Means, to get the final cluster. The potential flaw of such common practice is that the obtained relaxed continuous spectral solution could severely deviate from the true discrete solution. In this paper, we propose to impose an additional orthonormal constraint to better approximate the optimal continuous solution to the graph cut objective functions. Such a method, called spectral rotation in literature , optimizes the spectral clustering objective functions better than K-Means, and improves the clustering accuracy. We would provide efficient algorithm to solve the new problem rigorously, which is not significantly more costly than K-Means. We also establish the connection between our method and K-Means to provide theoretical motivation of our method. Experimental results show that our algorithm consistently reaches better cut and meanwhile outperforms in clustering metrics than classic spectral clustering methods.","cites":"4","conferencePercentile":"55.45454545"},{"venue":"AAAI","id":"6a5fe819d2b72b6ca6565a0de117c2b3be448b02","venue_1":"AAAI","year":"2013","title":"Supervised and Projected Sparse Coding for Image Classification","authors":"Jin Huang, Feiping Nie, Heng Huang, Chris H. Q. Ding","author_ids":"3579556, 1688370, 1748032, 1737469","abstract":"Classic sparse representation for classification (SRC) method fails to incorporate the label information of training images, and meanwhile has a poor scalabil-ity due to the expensive computation for 1 norm. In this paper, we propose a novel subspace sparse coding method with utilizing label information to effectively classify the images in the subspace. Our new approach unifies the tasks of dimension reduction and supervised sparse vector learning, by simultaneously preserving the data sparse structure and meanwhile seeking the optimal projection direction in the training stage, therefore accelerates the classification process in the test stage. Our method achieves both flat and structured sparsity for the vector representations, therefore making our framework more discriminative during the sub-space learning and subsequent classification. The empirical results on 4 benchmark data sets demonstrate the effectiveness of our method.","cites":"4","conferencePercentile":"55.45454545"},{"venue":"AAAI","id":"08cf510175a0955c76bb9e998416af5149efa7c9","venue_1":"AAAI","year":"2012","title":"Modeling Context Aware Dynamic Trust Using Hidden Markov Model","authors":"Xin Liu, Anwitaman Datta","author_ids":"1749705, 1716678","abstract":"Modeling trust in complex dynamic environments is an important yet challenging issue since an intelligent agent may strategically change its behavior to maximize its profits. In this paper, we propose a context aware trust model to predict dynamic trust by using a Hidden Markov Model (HMM) to model an agent's interactions. Although HMMs have already been applied in the past to model an agent's dynamic behavior to greatly improve the traditional static probabilistic trust approaches, most HMM based trust models only focus on outcomes of the past interactions without considering interaction context, which we believe, reflects immensely on the dynamic behavior or intent of an agent. Interaction contextual information is comprehensively studied and integrated into the model to more precisely approximate an agent's dynamic behavior. Evaluation using real auction data and synthetic data demonstrates the efficacy of our approach in comparison with previous state-of-the-art trust mechanisms.","cites":"10","conferencePercentile":"67.83536585"},{"venue":"AAAI","id":"8a5e2d886f4026c6ce54b8726f4c8368697e6abe","venue_1":"AAAI","year":"2016","title":"Reading Scene Text in Deep Convolutional Sequences","authors":"Pan He, Weilin Huang, Yu Qiao, Chen Change Loy, Xiaoou Tang","author_ids":"1782072, 1739171, 1690077, 1717179, 1741901","abstract":"We develop a Deep-Text Recurrent Network (DTRN) that regards scene text reading as a sequence labelling problem. We leverage recent advances of deep convo-lutional neural networks to generate an ordered high-level sequence from a whole word image, avoiding the difficult character segmentation problem. Then a deep recurrent model, building on long short-term memory (LSTM), is developed to robustly recognize the generated CNN sequences, departing from most existing approaches recognising each character independently. Our model has a number of appealing properties in comparison to existing scene text recognition methods: (i) It can recognise highly ambiguous words by leverag-ing meaningful context information, allowing it to work reliably without either pre-or post-processing; (ii) the deep CNN feature is robust to various image distortions; (iii) it retains the explicit order information in word image , which is essential to discriminate word strings; (iv) the model does not depend on pre-defined dictionary, and it can process unknown words and arbitrary strings. It achieves impressive results on several benchmarks, advancing the-state-of-the-art substantially. Text recognition in natural image has received increasing attention in computer vision and machine intelligence, due to its numerous practical applications. This problem includes two sub tasks, namely text detection (Huang, Qiao, This work focuses on the latter that aims to retrieve a text string from a cropped word image. Though huge efforts have been devoted to this task, reading text in unconstrained environment is still extremely challenging, and remains an open problem, as substantiated in recent literature (Jaderberg et al. 2015b; Almazán et al. 2014). The main difficulty arises from the large diversity of text patterns (e.g. low resolution, low contrast, and blurring), and highly complicated background clutters. Consequently, individual character segmentation or separation is extremely challenging. Most previous studies focus on developing powerful char-* Authors contributed equally Figure 1: The word image recognition pipeline of the proposed Deep-Text Recurrent Networks (DTRN) model. acter classifiers, some of which are incorporated with a language model, leading to the state-of-the-art performance These approaches mainly follow the pipeline of conventional OCR techniques by first involving a character-level segmentation, then followed by an isolated character classifier and post-processing for recognition. They also adopt deep neural networks for representation learning, but the recognition is still confined to character-level classification. Thus their performance are severely harmed by the difficulty of character segmentation or separation. Importantly, recognizing each character independently discards meaningful context information of the words, significantly reducing its …","cites":"11","conferencePercentile":"95.60810811"},{"venue":"AAAI","id":"55966926e7c28b1eee1c7eb7a0b11b10605a1af0","venue_1":"AAAI","year":"2015","title":"Surpassing Human-Level Face Verification Performance on LFW with GaussianFace","authors":"Chaochao Lu, Xiaoou Tang","author_ids":"2312486, 1741901","abstract":"Optimization As discussed in the main text, learning the GaussianFace model can amount to minimizing the following marginal likelihood, L M odel = − log p(Z T , θ|X T) − βM. (1) For the model optimization, we first expand Equation (1) to obtain the following equation (ignoring the constant items)","cites":"40","conferencePercentile":"99.84251968"},{"venue":"AAAI","id":"3dfa7844672902774c76ec2db40458b06171cd34","venue_1":"AAAI","year":"2004","title":"High-Level Goal Recognition in a Wireless LAN","authors":"Jie Yin, Xiaoyong Chai, Qiang Yang","author_ids":"3978641, 2059102, 1733090","abstract":"Plan recognition has traditionally been developed for logically encoded application domains with a focus on logical reasoning. In this paper, we present an integrated plan-recognition model that combines low-level sensory readings with high-level goal inference. A two-level architecture is proposed to infer a user's goals in a complex indoor environment using an RF-based wireless network. The novelty of our work derives from our ability to infer a user's goals from sequences of signal trajectory, and the ability for us to make a trade-off between model accuracy and inference efficiency. The model relies on a dynamic Bayesian network to infer a user's actions from raw signals, and an N-gram model to infer the users' goals from actions. We present a method for constructing the model from the past data and demonstrate the effectiveness of our proposed solution through empirical studies using some real data that we have collected.","cites":"41","conferencePercentile":"82.93413174"},{"venue":"AAAI","id":"9c5694922ef65c38b120d5443db5e7d43a36de57","venue_1":"AAAI","year":"2013","title":"Robust Discrete Matrix Completion","authors":"Jin Huang, Feiping Nie, Heng Huang","author_ids":"3579556, 1688370, 1748032","abstract":"Most existing matrix completion methods seek the matrix global structure in the real number domain and produce predictions that are inappropriate for applications retaining discrete structure, where an additional step is required to post-process prediction results with either heuristic threshold parameters or complicated map-pings. Such an ad-hoc process is inefficient and impractical. In this paper, we propose a novel robust discrete matrix completion algorithm that produces the prediction from the collection of user specified discrete values by introducing a new discrete constraint to the matrix completion model. Our method achieves a high prediction accuracy, very close to the most optimal value of competitive methods with threshold values tuning. We solve the difficult integer programming problem via incorporating augmented Lagrangian method in an elegant way, which greatly accelerates the converge process of our method and provides the asymptotic convergence in theory. The proposed discrete matrix completion model is applied to solve three real-world applications , and all empirical results demonstrate the effectiveness of our method. Missing data occur in many applications for different reasons. Some questions in a survey might be left blank due to individual user's negligence or reluctance to answer, certain parts of a gene microarray could fail to yield measurements due to noise and manufacturing defects, clinical studies often contain time sequential missing medical observations after participants drop out. In this paper, we focus on the prediction of random missing values. In data mining community, a wide range of data sets are naturally organized in matrix form. Clearly recovering an arbitrary matrix M from partial entries is not a well-posed problem, therefore certain assumptions have to be imposed to the underlying matrix. The most common one is the low-rank of the matrix, which has been applied to factor-based models (Rennie and Srebro 2005; Srebro and Jaakkola 2003; Salakhutdinov and Mnih 2008). Training a linear factor model essentially seeks a low-rank matrix X that approximates M. There are other methods seeking low-rank approximation , including SVD (Billsus and Pazzani 1998), So far all the prediction methods mentioned above work well on the data with continuous attributes, but there are also many applications only retaining discrete values, such as binary images and document-term associations. However, imposing the discrete constraints on the prediction outcome in the objective function could often turn the optimization into a computationally expensive NP-hard integer programming problem (Bertsimas and Weismantel 2005). Solution methods for integer programming problems …","cites":"8","conferencePercentile":"76.54545455"},{"venue":"AAAI","id":"05582e59616c2e5a3aa56e949f6f3feaf95fd316","venue_1":"AAAI","year":"1994","title":"HTN Planning: Complexity and Expressivity","authors":"Kutluhan Erol, James A. Hendler, Dana S. Nau","author_ids":"1889509, 1701341, 1734158","abstract":"Most practical work on AI planning systems during the last fteen years has been based on hierarchical task network (HTN) decomposition, but until now, there has been very little analytical work on the properties of HTN planners. This paper describes how the complexity of HTN planning varies with various conditions on the task networks.","cites":"347","conferencePercentile":"98.23788546"},{"venue":"AAAI","id":"34a2e3fc43c84c561649d1e9c4b57fa28197cd9c","venue_1":"AAAI","year":"2007","title":"A Planning Approach for Message-Oriented Semantic Web Service Composition","authors":"Zhen Liu, Anand Ranganathan, Anton Riabov","author_ids":"1731300, 1783727, 1984577","abstract":"In this paper, we consider the problem of composing a set of web services, where the requirements are specified in terms of the input and output messages of the composite workflow. We propose a semantic model of messages using RDF graphs that encode OWL ABox assertions. We also propose a model of web service operations where the input message requirements and output message characteristics are modeled using RDF graph patterns. We formulate the message-oriented semantic web service composition problem and show how it can be translated into a planning problem. There are, however, significant challenges in scalably doing planning in this domain, especially since DL reasoning may be performed to check if an operation can be given a certain input message. We propose a two-phase planning algorithm that incorporates DLP reasoning and evaluate the performance of this planning algorithm. An important class of web services consists of those that either do data processing or provide information, i.e. they take in messages containing input data, process them in some manner, and produce messages containing output data or results. In this paper we propose a novel way of associating rich semantic information with messages and web service operations. Our model describes messages using RDF graphs that encode OWL ABox assertions. It also describes the input message requirement and the output message description of each operation using RDF graph patterns. The terms used in these patterns are defined in OWL ontologies that describe the application domain. The main motivation behind this model is to allow automatic composition of workflows that process, transform or analyze data to produce some desired information. In such workflows, it is necessary to have expressive models of messages and of the data processing capabilities of services so as to compose services that are semantically compatible and to create workflows that produce the desired information. We formulate the message oriented service composition problem as one of producing messages that satisfy certain semantic conditions, from certain initial input messages. We show how this problem can be cast as a planning problem. Many existing service models (like OWLS (Martin et al 2004)) do not allow expressions with variables in describing inputs and outputs. OWLS describes inputs and outputs using concepts in an ontology. Similarly, SA-WSDL (Akki-raju et al 2005), which allows linking semantic annotations to WSDL files, is also typically used to associate inputs and outputs with concepts in an ontology. Our …","cites":"13","conferencePercentile":"60.53412463"},{"venue":"AAAI","id":"9433dd34a7d1105a6c2cffb4e05405a33969a881","venue_1":"AAAI","year":"1994","title":"A User Interface for Knowledge Acquisition From Video","authors":"Henry Lieberman","author_ids":"1695083","abstract":"In conventional knowledge acquisition, a domain expert interacts with a knowledge engineer, who interviews the expert, and codes knowledge about the domain objects and procedures in a rule-based language, or other textual representation language. This indirect methodology can be tedious and error-prone, since the domain expert's verbal descriptions can be inaccurate or incomplete, and the knowledge engineer may not correctly interpret the expert's intent. We describe a user interface that allows a domain expert who is not a programmer to construct representations of objects and procedures directly from a video of a human performing an example procedure. The domain expert need not be fluent in the underlying representation language, since all interaction is through direct manipulation. Starting from digitized video, the user selects significant frames that illustrate before-and after-states of important operations. Then the user graphically annotates the contents of each selected frame, selecting portions of the image to represent each part, labeling the parts, and indicating part/whole relationships. Finally, programming by demonstration techniques describe the actions that represent the transition between frames. The result is object descriptions for each object in the domain, generalized procedural descriptions, and visual and natural language documentation of the procedure. We illustrate the system in the domain of documentation of operational and maintenance procedures for electrical devices. Video as a tool for procedural knowledge representation Conventional expert systems are often hampered by the knowledge acquisition bottleneck: the difficulty of communicating knowledge that a human expert has into computer-readable descriptions. Domain experts may already know how to perform a procedure when presented with a real-world example of the device, but they may not be capable of producing an accurate, complete, well-written description of the procedure, either in natural language, or in the form of frame descriptions and if-then rules. The role of a knowledge engineer is to interview the domain expert and perform the translation into a language that the domain expert typically does not know. However, this is difficult and","cites":"11","conferencePercentile":"47.57709251"},{"venue":"AAAI","id":"026bc764a8db4d7bfd28b80d543559be5b950344","venue_1":"AAAI","year":"2008","title":"AnalogySpace: Reducing the Dimensionality of Common Sense Knowledge","authors":"Robert Speer, Catherine Havasi, Henry Lieberman","author_ids":"3032806, 2232845, 1695083","abstract":"We are interested in the problem of reasoning over very large common sense knowledge bases. When such a knowledge base contains noisy and subjective data, it is important to have a method for making rough conclusions based on similarities and tendencies, rather than absolute truth. We present AnalogySpace, which accomplishes this by forming the ana-logical closure of a semantic network through dimensionality reduction. It self-organizes concepts around dimensions that can be seen as making distinctions such as \" good vs. bad \" or \" easy vs. hard \" , and generalizes its knowledge by judging where concepts lie along these dimensions. An evaluation demonstrates that users often agree with the predicted knowledge , and that its accuracy is an improvement over previous techniques.","cites":"103","conferencePercentile":"97.78481013"},{"venue":"AAAI","id":"fac44c789e942e3a0eeb8bfa91688e498ba817d7","venue_1":"AAAI","year":"2015","title":"Visualizing Inference","authors":"Henry Lieberman, Joe Henke","author_ids":"1695083, 2020340","abstract":"Graphical visualization has demonstrated enormous power in helping people to understand complexity in many branches of science. But, curiously, AI has been slow to pick up on the power of visualization. Alar is a visualization system intended to help people understand and control symbolic inference. Alar presents dynamically controllable node-and-arc graphs of concepts, and of assertions both supplied to the system and inferred. Alar is useful in quality assurance of knowledge bases (finding false, vague, or misleading statements; or missing assertions). It is also useful in tuning parameters of inference, especially how \" liberal vs. conservative \" the inference is (trading off the desire to maximize the power of inference versus the risk of making incorrect inferences). We present a typical scenario of using Alar to debug a knowledge base. We present Alar, a visualization system for a large com-monsense ontology and knowledge base, ConceptNet, and its associated heuristic inference technique, AnalogySpace [Speer et al 08]. Alar can visualize both graphs of concepts , and also graphs of assertions. Alar is based on display of dynamic node-and-arc graphs, dynamically adjusting using the force-directed layout of the visualization toolkit D3JS [Bostock 14]. In the Concept view, nodes represent Concepts (like elements of an ontology), and links represent similarity between concepts. Link thickness represents the degree of similarity, and lines exert a proportional spring-like \" force \" in the dynamic graph pulling its nodes closer (working against a repelling force that spaces out the nodes). Concepts with similar meanings will be seen to cluster together. Words with, say, more than one meaning, will find themselves pulled between clusters that represent each of their meaning contexts. ____________________________ In the Assertion view, nodes represent assertions, a triple of Concept-Relation-Concept (e.g. \" Fork UsedFor Eating \"). Links represent similarity of assertions (not necessarily that one assertion logically implies another, although for a link between an assertion in the knowledge base (black) and an inferred assertion (green), it is usually the case that it exerts a strong influence. The size of the dot indicates its truth value. We believe the visualization of assertion graphs to be particularly novel. Visualization of related sets of assertions can be a powerful tool in debugging knowledge bases and inference. The assumption is that the inference space has a kind of smoothness characteristic – inference about similar concepts should have similar truth values. When incorrect assertions are inferred, they are often …","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"545f376a63b6534d740b1eebd835e47a36472331","venue_1":"AAAI","year":"2004","title":"Error Detection and Impact-Sensitive Instance Ranking in Noisy Datasets","authors":"Xingquan Zhu, Xindong Wu, Ying Yang","author_ids":"1694121, 1720579, 1699160","abstract":"Given a noisy dataset, how to locate erroneous instances and attributes and rank suspicious instances based on their impacts on the system performance is an interesting and important research issue. We provide in this paper an Error Detection and Impact-sensitive instance Ranking (EDIR) mechanism to address this problem. Given a noisy dataset D, we first train a benchmark classifier T from D. The instances, that cannot be effectively classified by T are treated as suspicious and forwarded to a subset S. For each attribute A i , we switch A i and the class label C to train a classifier AP i for A i. Given an instance I k in S, we use AP i and the benchmark classifier T to locate the erroneous value of each attribute A i. To quantitatively rank instances in S, we define an impact measure based on the Information-gain Ratio (IR). We calculate IR i between attribute A i and C, and use IR i as the impact-sensitive weight of A i. The sum of impact-sensitive weights from all located erroneous attributes of I k indicates its total impact value. The experimental results demonstrate the effectiveness of our strategies.","cites":"25","conferencePercentile":"70.35928144"},{"venue":"AAAI","id":"21d255246cd7ddba24a651fd716950f893ea8eb2","venue_1":"AAAI","year":"2015","title":"Self-Paced Curriculum Learning","authors":"Lu Jiang, Deyu Meng, Qian Zhao, Shiguang Shan, Alexander G. Hauptmann","author_ids":"1697318, 7480838, 3648843, 1685914, 7661726","abstract":"Curriculum learning (CL) or self-paced learning (SPL) represents a recently proposed learning regime inspired by the learning process of humans and animals that gradually proceeds from easy to more complex samples in training. The two methods share a similar conceptual learning paradigm, but differ in specific learning schemes. In CL, the curriculum is predetermined by prior knowledge, and remain fixed thereafter. Therefore, this type of method heavily relies on the quality of prior knowledge while ignoring feedback about the learner. In SPL, the curriculum is dynamically determined to adjust to the learning pace of the leaner. However, SPL is unable to deal with prior knowledge, rendering it prone to overfitting. In this paper, we discover the missing link between CL and SPL, and propose a unified framework named self-paced curriculum leaning (SPCL). SPCL is formulated as a concise optimization problem that takes into account both prior knowledge known before training and the learning progress during training. In comparison to human education, SPCL is analogous to \" instructor-student-collaborative \" learning mode, as opposed to \" instructor-driven \" in CL or \" student-driven \" in SPL. Empirically, we show that the advantage of SPCL on two tasks. have been attracting increasing attention in the field of machine learning and artificial intelligence. Both the learning paradigms are inspired by the learning principle underlying the cognitive process of humans and animals, which generally start with learning easier aspects of a task, and then gradually take more complex examples into consideration. The intuition can be explained in analogous to human education in which a pupil is supposed to understand elementary algebra before he or she can learn more advanced algebra topics. This learning paradigm has been empirically demonstrated to be instrumental in avoiding bad local minima and in achieving A curriculum determines a sequence of training samples which essentially corresponds to a list of samples ranked in ascending order of learning difficulty. A major disparity between curriculum learning (CL) and self-paced learning (SPL) lies in the derivation of the curriculum. In CL, the curriculum is assumed to be given by an oracle beforehand, and remains fixed thereafter. In SPL, the curriculum is dynamically generated by the learner itself, according to what the learner has already learned. The advantage of CL includes the flexibility to incorporate prior knowledge from various sources. Its drawback stems from the fact that the curriculum design is determined independently of the …","cites":"27","conferencePercentile":"99.21259843"},{"venue":"AAAI","id":"5cfce742ded3cde8d7a12d7038a4ccc7cd7a5087","venue_1":"AAAI","year":"1993","title":"Massively Parallel Support for Computationally Effective Recognition Queries","authors":"Matthew P. Evett, James A. Hendler, William A. Andersen","author_ids":"2206828, 1701341, 2657914","abstract":"PARKA is a frame-based knowledge representation system implemented on the Connection Machine. PARKA provides a representation language consisting of concept descriptions (frames) and binary relations on those descriptions (slots). The system is designed explicitly to provide extremely fast property inheritance inference capabilities. In particular, PARKA can perform fast \"recognition\" queries of the form \"find all frames satisfying p property constraints\" in O(d+p) time-proportional only to the depth of the knowledge base (If, B), and independent of its size. For conjunctive queries of this type, PARKA's performance is measured in tenths of a second, even for KBs with 100,000+ frames. We show similar results for timings on the Cyc KB. Because PARKA's run-time performance is independent of KB size, it promises to scale up to arbitrarily larger domains. With such run-time performance, we believe PARKA to be a contender for the title of \"fastest knowledge representation system in the world\".","cites":"7","conferencePercentile":"18.91891892"},{"venue":"AAAI","id":"94ed83c08465af965d9dfcbab810fb68bc880b79","venue_1":"AAAI","year":"2010","title":"Transferable Utility Planning Games","authors":"Ronen I. Brafman, Carmel Domshlak, Yagil Engel, Moshe Tennenholtz","author_ids":"1680506, 1735824, 2259790, 1708847","abstract":"Connecting between standard AI planning constructs and a classical cooperative model of transferable-utility coalition games, we introduce the notion of transferable-utility (TU) planning games. The key representational property of these games is that coalitions are valued implicitly based on their ability to carry out efficient joint plans. On the side of the expressiveness, we show that existing succinct representations of monotonic TU games can be efficiently compiled into TU planning games. On the side of computation, TU planning games allow us to provide some of the strongest to date tractability results for core-existence and core-membership queries in succinct TU coalition games.","cites":"10","conferencePercentile":"52.21843003"},{"venue":"AAAI","id":"7ffc950372dfd0f6db915fa8317560a5f7ff455a","venue_1":"AAAI","year":"2007","title":"Near-Optimal Search in Continuous Domains","authors":"Samuel Ieong, Nicolas S. Lambert, Yoav Shoham, Ronen I. Brafman","author_ids":"1745593, 1784519, 1701353, 1680506","abstract":"We investigate search problems in continuous state and action spaces with no uncertainty. Actions have costs and can only be taken at discrete time steps (unlike the case with continuous control). Given an admissible heuristic function and a starting state, the objective is to find a minimum-cost plan that reaches a goal state. As the continuous domain does not allow the tight optimality results that are possible in the discrete case (for example by A*), we instead propose and analyze an approximate forward-search algorithm that has the following provable properties. Given a desired accuracy , and a bound d on the length of the plan, the algorithm computes a lower bound L on the cost of any plan. It either (a) returns a plan of cost L that is at most more than the optimal plan, or (b) if, according to the heuristic estimate, there may exist a plan of cost L of length > d, returns a partial plan that traces the first d steps of such plan. To our knowledge, this is the first algorithm that provides optimality guarantees in continuous domains with discrete control and without uncertainty.","cites":"1","conferencePercentile":"13.94658754"},{"venue":"AAAI","id":"0c4ef68d52eb5c424741657ea9e1db1162a22a6a","venue_1":"AAAI","year":"2007","title":"Scaling Up: Solving POMDPs through Value Based Clustering","authors":"Yan Virin, Guy Shani, Solomon Eyal Shimony, Ronen I. Brafman","author_ids":"1831042, 1719532, 1719613, 1680506","abstract":"Partially Observable Markov Decision Processes (POMDPs) provide an appropriately rich model for agents operating under partial knowledge of the environment. Since finding an optimal POMDP policy is intractable, approximation techniques have been a main focus of research, among them point-based algorithms, which scale up relatively well-up to thousands of states. An important decision in a point-based algorithm is the order of backup operations over belief states. Prioritization techniques for ordering the sequence of backup operations reduce the number of needed backups considerably , but involve significant overhead. This paper suggests a new way to order backups, based on a soft clustering of the belief space. Our novel soft clustering method relies on the solution of the underlying MDP. Empirical evaluation verifies that our method rapidly computes a good order of backups, showing orders of magnitude improvement in runtime over a number of benchmarks.","cites":"10","conferencePercentile":"53.85756677"},{"venue":"AAAI","id":"1b99acccee3676e7841b755a1096a6868e5ec10d","venue_1":"AAAI","year":"2007","title":"TableRank: A Ranking Algorithm for Table Search and Retrieval","authors":"Ying Liu, Kun Bai, Prasenjit Mitra, C. Lee Giles","author_ids":"8735949, 2520507, 1714911, 1749125","abstract":"Tables are ubiquitous in web pages and scientific documents. With the explosive development of the web, tables have become a valuable information repository. Therefore, effectively and efficiently searching tables becomes a challenge. Existing search engines do not provide satisfactory search results largely because the current ranking schemes are inadequate for table search and automatic table understanding and extraction are rather difficult in general. In this work, we design and evaluate a novel table ranking algorithm – TableRank to improve the performance of our table search engine Table-Seer. Given a keyword based table query, TableRank facilities TableSeer to return the most relevant tables by tailoring the classic vector space model. TableRank adopts an innovative term weighting scheme by aggregating multiple weight-ing factors from three levels: term, table and document. The experimental results show that our table search engine out-performs existing search engines on table search. In addition, incorporating multiple weighting factors can significantly improve the ranking results.","cites":"5","conferencePercentile":"34.71810089"},{"venue":"AAAI","id":"0f18d5f7f4244a054a5bc2498f0fbbcc752d4b9e","venue_1":"AAAI","year":"2011","title":"Across-Model Collective Ensemble Classification","authors":"Hoda Eldardiry, Jennifer Neville","author_ids":"3355952, 1715004","abstract":"Ensemble classification methods that independently construct component models (e.g., bagging) improve accuracy over single models by reducing the error due to variance. Some work has been done to extend ensemble techniques for classification in relational domains by taking relational data characteristics or multiple link types into account during model construction. However , since these approaches follow the conventional approach to ensemble learning, they improve performance by reducing the error due to variance in learning. We note however, that variance in inference can be an additional source of error in relational methods that use collective classification, since inferred values are propagated during inference. We propose a novel ensemble mechanism for collective classification that reduces both learning and inference variance, by incorporating prediction averaging into the collective inference process itself. We show that our proposed method significantly outperforms a straightforward relational ensemble baseline on both synthetic and real-world datasets.","cites":"24","conferencePercentile":"90.54982818"},{"venue":"AAAI","id":"143bf5e22794d5165e1f41a49713206d90ebe537","venue_1":"AAAI","year":"2015","title":"Efficient Task Sub-Delegation for Crowdsourcing","authors":"Han Yu, Chunyan Miao, Zhiqi Shen, Cyril Leung, Yiqiang Chen, Qiang Yang","author_ids":"4850269, 1679209, 1700911, 3337708, 4070304, 1733090","abstract":"Reputation-based approaches allow a crowdsourcing system to identify reliable workers to whom tasks can be delegated. In crowdsourcing systems that can be modeled as multi-agent trust networks consist of resource constrained trustee agents (i.e., workers), workers may need to further sub-delegate tasks to others if they determine that they cannot complete all pending tasks before the stipulated deadlines. Existing reputation-based decision-making models cannot help workers decide when and to whom to sub-delegate tasks. In this paper, we proposed a reputation aware task sub-delegation (RTS) approach to bridge this gap. By jointly considering a worker's reputation, workload, the price of its effort and its trust relationships with others, RTS can be implemented as an intelligent agent to help workers make sub-delegation decisions in a distributed manner. The resulting task allocation maximizes social welfare through efficient utilization of the collective capacity of a crowd, and provides provable performance guarantees. Experimental comparisons with state-of-the-art approaches based on the Epinions trust network demonstrate significant advantages of RTS under high workload conditions.","cites":"9","conferencePercentile":"91.96850394"},{"venue":"AAAI","id":"fb89978c92ea809d2e9d18a768285f61f2a4a465","venue_1":"AAAI","year":"2015","title":"Scalable and Interpretable Data Representation for High-Dimensional, Complex Data","authors":"Been Kim, Kayur Patel, Afshin Rostamizadeh, Julie A. Shah","author_ids":"3351164, 2760803, 2435268, 3497743","abstract":"The majority of machine learning research has been fo-cused on building models and inference techniques with sound mathematical properties and cutting edge performance. Little attention has been devoted to the development of data representation that can be used to improve a user's ability to interpret the data and machine learning models to solve real-world problems. In this paper, we quantitatively and qualitatively evaluate an efficient, accurate and scalable feature-compression method using latent Dirichlet allocation for discrete data. This representation can effectively communicate the characteristics of high-dimensional, complex data points. We show that the improvement of a user's interpretability through the use of a topic modeling-based compression technique is statistically significant, according to a number of metrics, when compared with other representations. Also, we find that this representation is scal-able — it maintains alignment with human classification accuracy as an increasing number of data points are shown. In addition, the learned topic layer can semantically deliver meaningful information to users that could potentially aid human reasoning about data characteristics in connection with compressed topic space.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"da82793bfc0435c21c010508e84638b93c7824bb","venue_1":"AAAI","year":"2014","title":"Decomposing Activities of Daily Living to Discover Routine Clusters","authors":"Onur Yürüten, Jiyong Zhang, Pearl Pu","author_ids":"1834949, 2606073, 1781996","abstract":"The modern sensor technology helps us collect time series data for activities of daily living (ADLs), which in turn can be used to infer broad patterns, such as common daily routines. Most of the existing approaches either rely on a model trained by a preselected and manually labeled set of activities, or perform micro-pattern analysis with manually selected length and number of micro-patterns. Since real life ADL datasets are massive , such approaches would be too costly to apply. Thus, there is a need to formulate unsupervised methods that can be applied to different time scales. We propose a novel approach to discover clusters of daily activity routines. We use a matrix decomposition method to isolate routines and deviations to obtain two different sets of clusters. We obtain the final memberships via the cross product of these sets. We validate our approach using two real-life ADL datasets and a well-known artificial dataset. Based on average silhouette width scores, our approach can capture strong structures in the underlying data. Furthermore, results show that our approach improves on the accuracy of the baseline algorithms by 12% with a statistical significance (p <0.05) using the Wilcoxon signed-rank comparison test.","cites":"1","conferencePercentile":"25.90909091"},{"venue":"AAAI","id":"3683d0021c36efde2d772a4486b9ad53ba610a55","venue_1":"AAAI","year":"2014","title":"Prediction of Helpful Reviews Using Emotions Extraction","authors":"Lionel Martin, Pearl Pu","author_ids":"1720103, 1781996","abstract":"Reviews keep playing an increasingly important role in the decision process of buying products and booking hotels. However, the large amount of available information can be confusing to users. A more succinct interface, gathering only the most helpful reviews, can reduce information processing time and save effort. To create such an interface in real time, we need reliable prediction algorithms to classify and predict new reviews which have not been voted but are potentially helpful. So far such helpfulness prediction algorithms have benefited from structural aspects, such as the length and readability score. Since emotional words are at the heart of our written communication and are powerful to trigger listeners' attention, we believe that emotional words can serve as important parameters for predicting helpfulness of review text. Using GALC, a general lexicon of emotional words associated with a model representing 20 different categories , we extracted the emotionality from the review text and applied supervised classification method to derive the emotion-based helpful review prediction. As the second contribution, we propose an evaluation framework comparing three different real-world datasets extracted from the most well-known product review web-sites. This framework shows that emotion-based methods are outperforming the structure-based approach, by up to 9%.","cites":"6","conferencePercentile":"72.84090909"},{"venue":"AAAI","id":"727e1893116f3e725f358270717ff969dbb46938","venue_1":"AAAI","year":"2006","title":"Evaluating Critiquing-based Recommender Agents","authors":"Li Chen, Pearl Pu","author_ids":"1725490, 1781996","abstract":"We describe a user study evaluating two critiquing-based recommender agents based on three criteria: decision accuracy, decision effort, and user confidence. Results show that user-motivated critiques were more frequently applied and the example critiquing system employing only this type of critiques achieved the best results. In particular, the example critiquing agent significantly improves users' decision accuracy with less cognitive effort consumed than the dynamic critiquing recommender with system-proposed critiques. Additionally, the former is more likely to inspire users' confidence of their choice and promote their intention to purchase and return to the agent for future use.","cites":"36","conferencePercentile":"82.5648415"},{"venue":"AAAI","id":"2b747165bc855ac413c4e0e91d09fa60b74e12dd","venue_1":"AAAI","year":"2007","title":"Probabilistic Community Discovery Using Hierarchical Latent Gaussian Mixture Model","authors":"Haizheng Zhang, C. Lee Giles, Henry C. Foley, John Yen","author_ids":"2330025, 1749125, 3131560, 1722074","abstract":"Complex networks exist in a wide array of diverse domains , ranging from biology, sociology, and computer science. These real-world networks, while disparate in nature, often comprise of a set of loose clusters(a.k.a communities), whose members are better connected to each other than to the rest of the network. Discovering such inherent community structures can lead to deeper understanding about the networks and therefore has raised increasing interests among researchers from various disciplines. This paper describes GWN-LDA(Generic weighted network-Latent Dirichlet Allocation) model, a hierarchical Bayesian model derived from the widely-received LDA model, for discovering probabilistic community profiles in social networks. In this model, communities are modeled as latent variables and defined as distributions over the social actor space. In addition, each social actor belongs to every community with different probability. This paper also proposes two different network encoding approaches and explores the impact of these two approaches to the community discovery performance. This model is evaluated on two research collaborative networks:CiteSeer and NanoSCI. The experimental results demonstrate that this approach is promising for discovering community structures in large-scale networks.","cites":"29","conferencePercentile":"80.26706231"},{"venue":"AAAI","id":"a797323e22f4eff299318dacfc3b9591e0d3465c","venue_1":"AAAI","year":"2004","title":"Exploring More Realistic Evaluation Measures for Collaborative Filtering","authors":"Giuseppe Carenini, Rita Sharma","author_ids":"1825424, 1743825","abstract":"Collaborative filtering is a popular technique for recommending items to people. Several methods for col-laborative filtering have been proposed in the literature and the quality of their predictions compared in empirical studies. In this paper, we argue that the measures of quality used in these studies are based on rather simple assumptions. We propose and apply additional measures for comparing the effectiveness of collabora-tive filtering methods which are grounded in decision-theory.","cites":"5","conferencePercentile":"35.32934132"},{"venue":"AAAI","id":"4ba0cd62006846a7fbdb48cc596c9d74a5c8cb17","venue_1":"AAAI","year":"2015","title":"Towards User-Adaptive Information Visualization","authors":"Cristina Conati, Giuseppe Carenini, Dereck Toker, Sébastien Lallé","author_ids":"1692714, 1825424, 2976229, 3019748","abstract":"This paper summarizes an ongoing multi-year project aiming to uncover knowledge and techniques for devising intelligent environments for user-adaptive visualizations. We ran three studies designed to investigate the impact of user and task characteristics on user performance and satisfaction in different visualization contexts. Eye-tracking data collected in each study was analyzed to uncover possible interactions between user/task characteristics and gaze behavior during visualization processing. Finally, we investigated user models that can assess user characteristics relevant for adaptation from eye tracking data.","cites":"2","conferencePercentile":"51.65354331"},{"venue":"AAAI","id":"cfba9d65e1dadb98907549a98350345b4268dd25","venue_1":"AAAI","year":"2015","title":"Dictionary Learning with Mutually Reinforcing Group-Graph Structures","authors":"Hongteng Xu, Licheng Yu, Dixin Luo, Hongyuan Zha, Yi Xu","author_ids":"2468306, 1714982, 2241974, 1750350, 1734114","abstract":"In this paper, we propose a novel dictionary learning method in the semi-supervised setting by dynamically coupling graph and group structures. To this end, samples are represented by sparse codes inheriting their graph structure while the labeled samples within the same class are represented with group sparsity, sharing the same atoms of the dictionary. Instead of statically combining graph and group structures, we take advantage of them in a mutually reinforcing way — in the dictionary learning phase, we introduce the unlabeled samples into groups by an entropy-based method and then update the corresponding local graph, resulting in a more structured and discriminative dictionary. We analyze the relationship between the two structures and prove the convergence of our proposed method. Focus-ing on image classification task, we evaluate our approach on several datasets and obtain superior performance compared with the state-of-the-art methods, especially in the case of only a few labeled samples and limited dictionary size.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"b87962ab2af96b7fc5e996228b1d974b6b9d0b5d","venue_1":"AAAI","year":"2014","title":"Large-Scale Optimistic Adaptive Submodularity","authors":"Victor Gabillon, Branislav Kveton, Zheng Wen, Brian Eriksson, S. Muthukrishnan","author_ids":"3038127, 1681967, 1740317, 2323731, 1711192","abstract":"Maximization of submodular functions has wide applications in artificial intelligence and machine learning. In this paper, we propose a scalable learning algorithm for maximizing an adaptive submodular function. The key structural assumption in our solution is that the state of each item is distributed according to a generalized linear model, which is conditioned on the feature vector of the item. Our objective is to learn the parameters of this model. We analyze the performance of our algorithm, and show that its regret is polylogarithmic in time and quadratic in the number of features. Finally, we evaluate our solution on two problems, preference elicitation and face detection, and show that high-quality policies can be learned sample efficiently.","cites":"5","conferencePercentile":"67.5"},{"venue":"AAAI","id":"902512292765742c6ad47baaaaa54ad1059193f9","venue_1":"AAAI","year":"2006","title":"Using Semantics to Identify Web Objects","authors":"Nathanael Chambers, James F. Allen, Lucian Galescu, Hyuckchul Jung, William Taysom","author_ids":"1729918, 1749025, 1686309, 1723398, 2434425","abstract":"Many common web tasks can be automated by algorithms that are able to identify web objects relevant to the user's needs. This paper presents a novel approach to web object identification that finds relationships between the user's actions and linguistic information associated with web objects. From a single training example involving demonstration and a natural language description, we create a parameterized object description. The approach performs as well as a popular web wrapper on a routine task, but it has the additional capability of performing in dynamic environments and the attractive property of being reusable in other domains without additional training.","cites":"9","conferencePercentile":"50"},{"venue":"AAAI","id":"45c747afee24401806cffaab38d092f0dc38e1cc","venue_1":"AAAI","year":"2006","title":"Fast Hierarchical Goal Schema Recognition","authors":"Nate Blaylock, James F. Allen","author_ids":"1748576, 1749025","abstract":"We present our work on using statistical, corpus-based machine learning techniques to simultaneously recognize an agent's current goal schemas at various levels of a hierarchical plan. Our recognizer is based on a novel type of graphical model, a Cascading Hidden Markov Model, which allows the algorithm to do exact inference and make predictions at each level of the hierarchy in time quadratic to the number of possible goal schemas. We also report results of our recognizer's performance on a plan corpus.","cites":"18","conferencePercentile":"67.4351585"},{"venue":"AAAI","id":"431e61648a59abcd05411503ead56de8aa97906b","venue_1":"AAAI","year":"2007","title":"PLOW: A Collaborative Task Learning Agent","authors":"James F. Allen, Nathanael Chambers, George Ferguson, Lucian Galescu, Hyuckchul Jung, Mary D. Swift, William Taysom","author_ids":"1749025, 1729918, 1752556, 1686309, 1723398, 2435536, 2434425","abstract":"To be effective, an agent that collaborates with humans needs to be able to learn new tasks from humans they work with. This paper describes a system that learns executable task models from a single collaborative learning session consisting of demonstration, explanation and dialogue. To accomplish this, the system integrates a range of AI technologies: deep natural language understanding, knowledge representation and reasoning, dialogue systems, plan-ning/agent-based systems and machine learning. A formal evaluation shows the approach has great promise.","cites":"90","conferencePercentile":"97.92284866"},{"venue":"AAAI","id":"910600d751a2964f9db4b0ac139805011de54987","venue_1":"AAAI","year":"2012","title":"Real-Time Collaborative Planning with the Crowd","authors":"Walter S. Lasecki, Jeffrey P. Bigham, James F. Allen, George Ferguson","author_ids":"2598433, 1744846, 1749025, 1752556","abstract":"Planning is vital to a wide range of domains, including robotics, military strategy, logistics, itinerary generation and more, that both humans and computers find difficult. Collaborative planning holds the promise of greatly improving performance on these tasks by lever-aging the strengths of both humans and automated planners. However, this requires formalizing the problem domain and input, which must be done by hand, a pri-ori, restricting its use in general real-world domains. We propose using a real-time crowd of workers to simultaneously solve the planning problem, formalize the domain , and train an automated system. As plans are developed , the system is able to learn the domain, and contribute larger segments of work.","cites":"4","conferencePercentile":"39.17682927"},{"venue":"AAAI","id":"0acc05350ba5ee7ca8e496c83808e920dd192a09","venue_1":"AAAI","year":"2008","title":"CIGAR: Concurrent and Interleaving Goal and Activity Recognition","authors":"Derek Hao Hu, Qiang Yang","author_ids":"1811433, 1733090","abstract":"In artificial intelligence and pervasive computing research, inferring users' high-level goals from activity sequences is an important task. A major challenge in goal recognition is that users often pursue several high-level goals in a concurrent and interleaving manner, where the pursuit of goals may spread over different parts of an activity sequence and may be pursued in parallel. Existing approaches to recognizing multiple goals often formulate this problem either as a single-goal recognition problem or in a deterministic way, ignoring uncertainty. In this paper, we propose CIGAR (Concurrent and Interleaving Goal and Activity Recognition)-a novel and simple two-level probabilistic framework for multiple-goal recognition where we can recognize both concurrent and in-terleaving goals. We use skip-chain conditional random fields (SCCRF) for modeling interleaving goals and we model concurrent goals by adjusting inferred probabilities through a correlation graph, which is a major advantage in that we are able to reason about goal interactions explicitly through the correlation graph. The two-level framework also avoids the high training complexity when modeling concurrency and in-terleaving together in a unified CRF model. Experimental results show that our method can effectively improve recognition accuracies on several real-world datasets collected from various wireless and sensor networks.","cites":"44","conferencePercentile":"92.56329114"},{"venue":"AAAI","id":"d9d9cd400cdd42f470c0298bf455b37017160cf0","venue_1":"AAAI","year":"2012","title":"Learning Names for RFID-Tagged Objects in Activity Videos","authors":"Ian E. Perera, James F. Allen","author_ids":"1937619, 1749025","abstract":"We describe a method for determining the names of RFID-tagged objects in activity videos using descriptions which have been parsed to provide anaphoric reference resolution and ontological categorization.","cites":"1","conferencePercentile":"13.87195122"},{"venue":"AAAI","id":"5521421ddf96c0980d80fd244b33598f2903b2c6","venue_1":"AAAI","year":"2008","title":"Hierarchical Location and Topic Based Query Expansion","authors":"Shu Huang, Qiankun Zhao, Prasenjit Mitra, C. Lee Giles","author_ids":"6077893, 2178224, 1714911, 1749125","abstract":"In this paper, we propose a novel approach to expand queries by exploring both location information and topic information of the queries. Users at different locations tend to have different vocabularies, while the different expressions coming from different vocabularies may relate to the same topics. Thus these expressions are identified as location sensitive and can be used for query expansion. We propose a hierarchical query expansion model, which employs a two-level SVM classification model to classify queries as location sensitive or location non-sensitive, where the former are further classified into same location sensitive and different location sensitive. For the location sensitive queries, we propose an LDA based topic-level query similarity measure to rank the list of similar queries. Experiments with 2G raw log data from CiteSeer and Excite 1 show that our hierarchical classification model predicts the query location sensitivity with more than 80% precision and that the final search result is significantly better than existing query expansion methods.","cites":"3","conferencePercentile":"28.16455696"},{"venue":"AAAI","id":"2e4ccf5445490a176dabdf77a5e39cb11f88970c","venue_1":"AAAI","year":"2012","title":"Table Header Detection and Classification","authors":"Jing Fang, Prasenjit Mitra, Zhi Tang, C. Lee Giles","author_ids":"1693576, 1714911, 7172330, 1749125","abstract":"In digital libraries, a table, as a specific document component as well as a condensed way to present structured and relational data, contains rich information and often the only source of .that information. In order to explore, retrieve, and reuse that data, tables should be identified and the data extracted. Table recognition is an old field of research. However, due to the diversity of table styles, the results are still far from satisfactory, and not a single algorithm performs well on all different types of tables. In this paper, we randomly take samples from the CiteSeer X to investigate diverse table styles for automatic table extraction. We find that table headers are one of the main characteristics of complex table styles. We identify a set of features that can be used to segregate headers from tabular data and build a classifier to detect table headers. Our empirical evaluation on PDF documents shows that using a Random Forest classifier achieves an accuracy of 92%.","cites":"9","conferencePercentile":"64.02439024"},{"venue":"AAAI","id":"52ba699fe3b2b8a02f15a94e4853e7f31341724f","venue_1":"AAAI","year":"2013","title":"Sparse Multi-Task Learning for Detecting Influential Nodes in an Implicit Diffusion Network","authors":"Yingze Wang, Guang Xiang, Shi-Kuo Chang","author_ids":"2523069, 8720304, 1679040","abstract":"How to identify influential nodes is a central research topic in information diffusion analysis. Many existing methods rely on the assumption that the network structure is completely known by the model. However, in many applications, such a network is either unavailable or insufficient to explain the underlying information diffusion phenomena. To address this challenge, we develop a multi-task sparse linear influence model (MSLIM), which can simultaneously predict the volume for each contagion and automatically identify sets of the most influential nodes for different contagions. Our method is based on the linear influence model with two main advantages: 1) it does not require the network structure; 2) it can detect different sets of the most influential nodes for different contagions. To solve the corresponding convex optimization problem for learning the model, we adopt the accelerated gradient method (AGM) framework and show that there is an exact closed-form solution for the proximal mapping. Therefore , the optimization procedure achieves the optimal first-order convergence rate and can be scaled to very large datasets. The proposed model is validated on a set of 2.6 millions tweets from 1000 users of Twitter. We show that MSLIM can efficiently select the most influential users for specific contagions. We also present several interesting patterns of the selected influential users.","cites":"3","conferencePercentile":"47.09090909"},{"venue":"AAAI","id":"8932d95161208690deac3865eb5520e98f6c549d","venue_1":"AAAI","year":"2008","title":"Intelligence in Wikipedia","authors":"Daniel S. Weld, Fei Wu, Eytan Adar, Saleema Amershi, James Fogarty, Raphael Hoffmann, Kayur Patel, Michael Skinner","author_ids":"1780531, 2212713, 2630700, 1719124, 1738171, 3100993, 2760803, 5299672","abstract":"The Intelligence in Wikipedia project at the University of Washington is combining self-supervised information extraction (IE) techniques with a mixed initiative interface designed to encourage communal content creation (CCC). Since IE and CCC are each powerful ways to produce large amounts of structured information, they have been studied extensively — but only in isolation. By combining the two methods in a virtuous feedback cycle, we aim for substantial synergy. While previous papers have described the details of individual aspects of our endeavor [25, 26, 24, 13], this report provides an overview of the project's progress and vision .","cites":"39","conferencePercentile":"90.98101266"},{"venue":"AAAI","id":"a14066ad6fe314773224a4ba550a09073eac4d49","venue_1":"AAAI","year":"2006","title":"Laughing with HAHAcronym, a Computational Humor System","authors":"Oliviero Stock, Carlo Strapparava","author_ids":"1714320, 1723976","abstract":"Computational humor is a challenge with implications for many classical fields in AI such as, for example, natural language processing, intelligent human-computer interaction, reasoning, not to mention cognitive science, linguistics and psychology. In this paper we summarize our experience in developing HAHAcronym, a system devoted to produce humorous acronyms, and we discuss some concrete prospects for this field.","cites":"6","conferencePercentile":"40.20172911"},{"venue":"AAAI","id":"1f258d4110df16342a020dfd12b404ec4a1c1ba7","venue_1":"AAAI","year":"1994","title":"Social Interaction: Multimodal Conversation with Social Agents","authors":"Katashi Nagao, Akikazu Takeuchi","author_ids":"1725615, 1742326","abstract":"including robotics, artificial life, and artificial ecosystems. We present a new approach to human-computer interaction, called so&Z interaction. Its main characteristics are summarized by the following three points. First, interactions are realized as multimodal (verbal and nonverbal) conversation using spoken language, facial expressions , and so on. Second, the conversants are a group of humans and social agents that are autonomous and social. Autonomy is an important property that allows agents to decide how to act in an ever-changing environment. So-cialness is also an important property that allows agents to behave both cooperatively and col-laboratively. Generally, conversation is a joint work and ill-structured. Its participants are required to be social as well as autonomous. Third, conversants often encounter communication mismatches (misunderstanding others' intentions and beliefs) and fail to achieve their joint goals. The social agents, therefore, are always concerned with detecting communication mismatches. We realize a social agent that hears human-to-human conversation and informs what is causing the misunderstanding. It can also interact with humans by voice with facial displays and head (and eye) movement. However, is autonomy itself sufficient for social ser-vices? Although autonomy is vital to survive in the real world, it is only concerned with \" self. \" It is selfish by nature. It seems that it does not work well in human society, since it includes socially constructed artifacts such as laws, customs, culture. Social services provided by computer systems have to incorporate with these artifacts. Socialness is a higher-level concept defined above the concept of an individual, and is the style of interaction between the individuals in a group. Socialness can be applied to the interaction between humans and computers , and possibly to that between multiple computers. In this paper, we study socialness of conversational interaction between humans and computers. Conversation is no doubt, a social activity, especially when more than two participants are involved in it. However , conversation research to date has been biased to problem-solving. Question-answering systems are typical examples. All conversation research based on this view has the following features.","cites":"50","conferencePercentile":"84.5814978"},{"venue":"AAAI","id":"2858c69e5d9432c8b9529e3d97017d3909eb0b9c","venue_1":"AAAI","year":"2008","title":"Semi-Supervised Ensemble Ranking","authors":"Steven C. H. Hoi, Rong Jin","author_ids":"1741126, 1718400","abstract":"Ranking plays a central role in many Web search and information retrieval applications. Ensemble ranking, sometimes called meta-search, aims to improve the retrieval performance by combining the outputs from multiple ranking algorithms. Many ensemble ranking approaches employ supervised learning techniques to learn appropriate weights for combining multiple rankers. The main shortcoming with these approaches is that the learned weights for ranking algorithms are query independent. This is suboptimal since a ranking algorithm could perform well for certain queries but poorly for others. In this paper, we propose a novel semi-supervised ensemble ranking (SSER) algorithm that learns query-dependent weights when combining multiple rankers in document retrieval. The proposed SSER algorithm is formulated as an SVM-like quadratic program (QP), and therefore can be solved efficiently by taking advantage of optimization techniques that were widely used in existing SVM solvers. We evaluated the proposed technique on a standard document retrieval testbed and observed encouraging results by comparing to a number of state-of-the-art techniques.","cites":"20","conferencePercentile":"77.84810127"},{"venue":"AAAI","id":"612e302d1238b0b4f3f847b04c523195321cab31","venue_1":"AAAI","year":"2012","title":"Online Kernel Selection: Algorithms and Evaluations","authors":"Tianbao Yang, Mehrdad Mahdavi, Rong Jin, Jinfeng Yi, Steven C. H. Hoi","author_ids":"1704606, 1694826, 1718400, 2882166, 1741126","abstract":"Kernel methods have been successfully applied to many machine learning problems. Nevertheless, since the performance of kernel methods depends heavily on the type of kernels being used, identifying good kernels among a set of given kernels is important to the success of kernel methods. A straightforward approach to address this problem is cross-validation by training a separate classifier for each kernel and choosing the best kernel classifier out of them. Another approach is Multiple Kernel Learning (MKL), which aims to learn a single kernel classifier from an optimal combination of multiple kernels. However, both approaches suffer from a high computational cost in computing the full kernel matrices and in training, especially when the number of kernels or the number of training examples is very large. In this paper, we tackle this problem by proposing an efficient online kernel selection algorithm. It incrementally learns a weight for each kernel classifier. The weight for each kernel classifier can help us to select a good kernel among a set of given kernels. The proposed approach is efficient in that (i) it is an online approach and therefore avoids computing all the full kernel matrices before training; (ii) it only updates a single kernel classifier each time by a sampling technique and therefore saves time on updating kernel classifiers with poor performance; (iii) it has a theoretically guaranteed performance compared to the best kernel predictor. Empirical studies on image classification tasks demonstrate the effectiveness of the proposed approach for selecting a good kernel among a set of kernels.","cites":"1","conferencePercentile":"13.87195122"},{"venue":"AAAI","id":"8c057dfec76d1f1995d2baababd9e632045bf4ae","venue_1":"AAAI","year":"2014","title":"Learning Relative Similarity by Stochastic Dual Coordinate Ascent","authors":"Pengcheng Wu, Yi Ding, Peilin Zhao, Chunyan Miao, Steven C. H. Hoi","author_ids":"8327053, 3941316, 1714894, 1679209, 1741126","abstract":"Learning relative similarity from pairwise instances is an important problem in machine learning and has a wide range of applications. Despite being studied for years, some existing methods solved by Stochastic Gradient Descent (SGD) techniques generally suffer from slow convergence. In this paper, we investigate the application of Stochastic Dual Coordinate Ascent (SDCA) technique to tackle the optimization task of relative similarity learning by extending from vector to matrix parameters. Theoretically, we prove the optimal linear convergence rate for the proposed SDCA algorithm, beating the well-known sublinear convergence rate by the previous best metric learning algorithms. Empirically , we conduct extensive experiments on both standard and large-scale data sets to validate the effectiveness of the proposed algorithm for retrieval tasks.","cites":"2","conferencePercentile":"38.63636364"},{"venue":"AAAI","id":"8e431acd2d4d327882ea1fa55a90755e8689c0b6","venue_1":"AAAI","year":"2008","title":"Automatic Extraction of Data Points and Text Blocks from 2-Dimensional Plots in Digital Documents","authors":"Saurabh Kataria, William Browuer, Prasenjit Mitra, C. Lee Giles","author_ids":"1697274, 3199564, 1714911, 1749125","abstract":"Two dimensional plots (2-D) in digital documents on the web are an important source of information that is largely under-utilized. In this paper, we outline how data and text can be extracted automatically from these 2-D plots, thus eliminating a time consuming manual process. Our information extraction algorithm identifies the axes of the figures, extracts text blocks like axes-labels and legends and identifies data points in the figure. It also extracts the units appearing in the axes labels and segments the legends to identify the different lines in the legend, the different symbols and their associated text explanations. Our algorithm also performs the challenging task of separating out overlapping text and data points effectively. Our experiments indicate that these techniques are computationally efficient and provide acceptable accuracy.","cites":"17","conferencePercentile":"73.41772152"},{"venue":"AAAI","id":"29cc8a4bf867ef99d22166785c6110042ba98f64","venue_1":"AAAI","year":"2014","title":"SOML: Sparse Online Metric Learning with Application to Image Retrieval","authors":"Xingyu Gao, Steven C. H. Hoi, Yongdong Zhang, Ji Wan, Jintao Li","author_ids":"1732399, 1741126, 1699819, 2622533, 8722263","abstract":"Image similarity search plays a key role in many mul-timedia applications, where multimedia data (such as images and videos) are usually represented in high-dimensional feature space. In this paper, we propose a novel Sparse Online Metric Learning (SOML) scheme for learning sparse distance functions from large-scale high-dimensional data and explore its application to image retrieval. In contrast to many existing distance metric learning algorithms that are often designed for low-dimensional data, the proposed algorithms are able to learn sparse distance metrics from high-dimensional data in an efficient and scalable manner. Our experimental results show that the proposed method achieves better or at least comparable accuracy performance than the state-of-the-art non-sparse distance metric learning approaches, but enjoys a significant advantage in computational efficiency and sparsity, making it more practical for real-world applications.","cites":"9","conferencePercentile":"84.43181818"},{"venue":"AAAI","id":"7c81c8addd57c23560f2c2961b86697c33ad20fb","venue_1":"AAAI","year":"2008","title":"Linking Social Networks on the Web with FOAF: A Semantic Web Case Study","authors":"Jennifer Golbeck, Matthew Rothstein","author_ids":"1713898, 2489438","abstract":"One of the core goals of the Semantic Web is to store data in distributed locations, and use ontologies and reasoning to aggregate it. Social networking is a large movement on the web, and social networking data using the Friend of a Friend (FOAF) vocabulary makes up a significant portion of all data on the Semantic Web. Many traditional web-based social networks share their members' information in FOAF format. While this is by far the largest source of FOAF online, there is no information about whether the social network models from each network overlap to create a larger unified social network, or whether they are simply isolated components. If there are intersections, it is evidence that Semantic Web representations and technologies are being used to create interesting , useful data models. In this paper, we present a study of the intersection of FOAF data found in many online social networks. Using the semantics of the FOAF ontology and applying Semantic Web reasoning techniques, we show that a significant percentage of profiles can be merged from multiple networks. We present results on how this affects network structure and what it says about the success of the Semantic Web.","cites":"45","conferencePercentile":"93.03797468"},{"venue":"AAAI","id":"8f1b3f5be3be83fa1d1fd03236d2c4e354436d44","venue_1":"AAAI","year":"2007","title":"SUNNY: A New Algorithm for Trust Inference in Social Networks Using Probabilistic Confidence Models","authors":"Ugur Kuter, Jennifer Golbeck","author_ids":"1721385, 1713898","abstract":"In many computing systems, information is produced and processed by many people. Knowing how much a user trusts a source can be very useful for aggregating, filtering, and ordering of information. Furthermore, if trust is used to support decision making, it is important to have an accurate estimate of trust when it is not directly available, as well as a measure of confidence in that estimate. This paper describes a new approach that gives an explicit probabilistic interpretation for confidence in social networks. We describe SUNNY, a new trust inference algorithm that uses a probabilistic sampling technique to estimate our confidence in the trust information from some designated sources. SUNNY computes an estimate of trust based on only those information sources with high confidence estimates. In our experiments, SUNNY produced more accurate trust estimates than the well known trust inference algorithm TIDALTRUST (Golbeck 2005), demonstrating its effectiveness.","cites":"86","conferencePercentile":"97.62611276"},{"venue":"AAAI","id":"c747dde903f507b38addce5448ae93e53f0896a8","venue_1":"AAAI","year":"2006","title":"Social Network-based Trust in Prioritized Default Logic","authors":"Yarden Katz, Jennifer Golbeck","author_ids":"1741241, 1713898","abstract":"A drawback of traditional default logic is that there is no general mechanism for preferring one default rule over another. To remedy this problem, numerous default logics augmented with priority relations have been introduced. In this paper, we show how trust values, derived from web-based social networks, can be used to prioritize defaults. We provide a coupling between the method for computing trust values in social networks and the prioritized Reiter defaults of (Baader & Hollun-der 1995), where specificity of terminological concepts is used to prioritize defaults. We compare our approach with specificity-based prioritization, and discuss how the two can be combined. Finally, we show how our approach can be applied to other variants of prioritized default logic.","cites":"34","conferencePercentile":"81.70028818"},{"venue":"AAAI","id":"f33fcdd5a0a5fd8b29e81748463836cad07d5e8c","venue_1":"AAAI","year":"2013","title":"Ranking Scientific Articles by Exploiting Citations, Authors, Journals, and Time Information","authors":"Yujing Wang, Yunhai Tong, Ming Zeng","author_ids":"2895012, 8230405, 8063369","abstract":"Ranking scientific articles is an important but challenging task, partly due to the dynamic nature of the evolving publication network. In this paper, we mainly focus on two problems: (1) how to rank articles in the heterogeneous network; and (2) how to use time information in the dynamic network in order to obtain a better ranking result. To tackle the problems, we propose a graph-based ranking method, which utilizes citations, authors, journals/conferences and the publication time information collaboratively. The experiments were carried out on two public datasets. The result shows that our approach is practical and ranks scientific articles more accurately than the state-of-art methods.","cites":"5","conferencePercentile":"62.54545455"},{"venue":"AAAI","id":"15551fb3eaf0440c3bf555b877816cd30b33fc30","venue_1":"AAAI","year":"2011","title":"Ensemble Classification for Relational Domains","authors":"Hoda Eldardiry","author_ids":"3355952","abstract":"Ensemble classification methods have been shown to produce more accurate predictions than the base component models (Bauer and Kohavi 1999). Due to their effectiveness, ensemble approaches have been applied in a wide range of domains to improve classification. The expected prediction error of classification models can be decomposed into bias and variance (Friedman 1997). Ensemble methods that independently construct component models (e.g., bagging) can improve performance by reducing the error due to variance, while methods that dependently construct component models (e.g., boosting) can improve performance by reducing the error due to bias and variance. Although ensemble methods were initially developed for classification of independent and identically distributed (i.i.d.) data, they can be directly applied for relational data by using a relational classifier as the base component model. This straightforward approach can improve classification for network data, but suffers from a number of limitations. First, relational data characteristics will only be exploited by the base relational classifier, and not by the ensemble algorithm itself. We note that explicitly accounting for the structured nature of relational data by the ensemble mechanism can significantly improve ensemble classification. Second, ensemble learning methods that assume i.i.d. data can fail to preserve the relational structure of non-i.i.d. data, which will (1) prevent the relational base classifiers from exploiting these structures, and (2) fail to accurately capture properties of the dataset, which can lead to inaccurate models and classifications. Third, ensemble mechanisms that assume i.i.d. data are limited to reducing errors associated with i.i.d. models and fail to reduce additional sources of error associated with more powerful (e.g., collective classification (Sen et al. 2008)) models. Our key observation is that collective classification methods have error due to variance in inference (Neville and Jensen 2008). This has been overlooked by current ensemble methods that assume exact inference methods and only focus on the typical goal of reducing errors due to learning, even if the methods explicitly consider relational data (Preisach and Schmidt-Thieme 2006). Here we study the problem of ensemble classification for relational domains by focusing on the reduction of error due to variance. We propose a relational ensemble framework that explicitly accounts for the structured nature of rela-tional data during both learning and inference. Our proposed framework consists of two components. (1) A method for learning accurate ensembles from relational data, focusing on the reduction of error due to variance in learning, while preserving the relational characteristics …","cites":"0","conferencePercentile":"5.841924399"},{"venue":"AAAI","id":"91ccd2d983a50a248f2796616c3cfe79021986c9","venue_1":"AAAI","year":"2014","title":"CiteSeerX: AI in a Digital Library Search Engine","authors":"Jian Wu, Kyle Williams, Hung-Hsuan Chen, Madian Khabsa, Cornelia Caragea, Alexander Ororbia, Douglas Jordan, C. Lee Giles","author_ids":"1734550, 3517951, 2365770, 2072010, 1690656, 3038767, 3056037, 1749125","abstract":"CiteSeerX is a digital library search engine that provides access to more than 4 million academic documents with nearly a million users and millions of hits per day. Artificial intelligence (AI) technologies are used in many components of CiteSeerX e.g. to accurately extract metadata, intelligently crawl the web, and ingest documents. We present key AI technologies used in the following components: document classification and deduplication, document and citation clustering, automatic metadata extraction and indexing, and author disambiguation. These AI technologies have been developed by CiteSeerX group members over the past 5–6 years. We also show the usage status, payoff, development challenges, main design concepts, and deployment and maintenance requirements. While it is challenging to rebuild a system like CiteSeerX from scratch, many of these AI technologies are transferable to other digital libraries and/or search engines.","cites":"12","conferencePercentile":"91.47727273"},{"venue":"AAAI","id":"96c189d267ed217e3eb62a24e509479275ae9be8","venue_1":"AAAI","year":"2012","title":"Name-Ethnicity Classification and Ethnicity-Sensitive Name Matching","authors":"Pucktada Treeratpituk, C. Lee Giles","author_ids":"1695761, 1749125","abstract":"Personal names are important and common information in many data sources, ranging from social networks and news articles to patient records and scientific documents. They are often used as queries for retrieving records and also as key information for linking documents from multiple sources. Matching personal names can be challenging due to variations in spelling and various formatting of names. While many approximated name matching techniques have been proposed, most are generic string-matching algorithms. Unlike other types of proper names, personal names are highly cultural. Many ethnicities have their own unique naming systems and identifiable characteristics. In this paper we explore such relationships between ethnicities and personal names to improve the name matching performance. First, we propose a name-ethnicity classifier based on the multinomial logistic regression. Our model can effectively identify name-ethnicity from personal names in Wikipedia, which we use to define name-ethnicity, to within 85% accuracy. Next, we propose a novel alignment-based name matching algorithm, based on Smith–Waterman algorithm and logistic regression. Different name matching models are then trained for different name-ethnicity groups. Our preliminary experimental result on DBLP's disambiguated author dataset yields a performance of 99% precision and 89% recall. Surprisingly, tex-tual features carry more weight than phonetic ones in name-ethnicity classification.","cites":"8","conferencePercentile":"59.45121951"},{"venue":"AAAI","id":"7de9e052e084704cdaf19cefd26a340dc548f5fa","venue_1":"AAAI","year":"2015","title":"An Adaptive Gradient Method for Online AUC Maximization","authors":"Yi Ding, Peilin Zhao, Steven C. H. Hoi, Yew-Soon Ong","author_ids":"3941316, 1714894, 1741126, 1721346","abstract":"Learning for maximizing AUC performance is an important research problem in machine learning. Unlike traditional batch learning methods for maximizing AUC which often suffer from poor scalability, recent years have witnessed some emerging studies that attempt to maximize AUC by single-pass online learning approaches. Despite their encouraging results reported, the existing online AUC maximization algorithms often adopt simple stochastic gradient descent approaches, which fail to exploit the geometry knowledge of the data observed in the online learning process, and thus could suffer from relatively slow convergence. To overcome the limitation of the existing studies, in this paper, we propose a novel algorithm of Adaptive Online AUC Maximization (AdaOAM), by applying an adaptive gradient method for exploiting the knowledge of historical gradients to perform more informative online learning. The new adaptive updating strategy by AdaOAM is less sensitive to parameter settings due to its natural effect of tuning the learning rate. In addition, the time complexity of the new algorithm remains the same as the previous non-adaptive algorithms. To demonstrate the effectiveness of the proposed algorithm, we analyze its theoretical bound, and further evaluate its empirical performance on both public benchmark datasets and anomaly detection datasets. The encouraging empirical results clearly show the effectiveness and efficiency of the proposed algorithm.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"2252cdc61c68409b187d30c9eab69c1fbaa146a1","venue_1":"AAAI","year":"2006","title":"Integrating Joint Intention Theory, Belief Reasoning, and Communicative Action for Generating Team-Oriented Dialogue","authors":"Rajah Annamalai Subramanian, Sanjeev Kumar, Philip R. Cohen","author_ids":"2147323, 1800853, 2305444","abstract":"The goal of this research is to develop an architecture that can guide an agent during collaborative teamwork. The architecture should generate communication and dialogue during the performance of collaborative multi-agent tasks as a byproduct of the agent's rationally pursuing its intentions. This paper describes how a joint intention interpreter that is integrated with a reasoner over beliefs and communicative acts can form the core of a dialogue engine. As an interpreter of joint actions, the architecture enables agent programmers to describe a domain declaratively, specifying an agent's individual and joint intentions, plans and actions at a high level. The interpreter attempts to fulfill the agent's individual and joint intentions, subject to its beliefs and mutual beliefs. As a consequence, the system engages in dialogue through the planning and execution of communicative acts necessary to attain the collaborative task at hand. The dialogue engine is general enough to be applicable to both agent-agent and agent-human teams. The system has been implemented in a combination of Java and Prolog, and can be shown to obey the predictions of joint intention.","cites":"7","conferencePercentile":"43.08357349"},{"venue":"AAAI","id":"afe987d36438efaa2b5116c444b5fc47462f11d9","venue_1":"AAAI","year":"2013","title":"SALL-E: Situated Agent for Language Learning","authors":"Ian E. Perera, James F. Allen","author_ids":"1937619, 1749025","abstract":"We describe ongoing research towards building a cog-nitively plausible system for near one-shot learning of the meanings of attribute words and object names, by grounding them in a sensory model. The system learns incrementally from human demonstrations recorded with the Microsoft Kinect, in which the demonstrator can use unrestricted natural language descriptions. We achieve near-one shot learning of simple objects and attributes by focusing solely on examples where the learning agent is confident, ignoring the rest of the data. We evaluate the system's learning ability by having it generate descriptions of presented objects, including objects it has never seen before, and comparing the system response against collected human descriptions of the same objects. We propose that our method of retrieving object examples with a k-nearest neighbor classifier using Mahalanobis distance corresponds to a cognitively plausible representation of objects. Our initial results show promise for achieving rapid, near one-shot, incremental learning of word meanings.","cites":"5","conferencePercentile":"62.54545455"},{"venue":"AAAI","id":"117b8e8dcf2cd3ff7f0e7e71f073864c355d1880","venue_1":"AAAI","year":"2013","title":"Integrating Programming by Example and Natural Language Programming","authors":"Mehdi Manshadi, Daniel Gildea, James F. Allen","author_ids":"2744932, 1793218, 1749025","abstract":"We motivate the integration of programming by example and natural language programming by developing a system for specifying programs for simple text editing operations based on regular expressions. The programs are described with un-constrained natural language instructions, and providing one or more examples of input/output. We show that natural language allows the system to deduce the correct program much more often and much faster than is possible with the in-put/output example(s) alone, showing that natural language programming and programming by example can be combined in a way that overcomes the ambiguities that both methods suffer from individually and, at the same time, provides a more natural interface to the user.","cites":"4","conferencePercentile":"55.45454545"},{"venue":"AAAI","id":"51657ed77a8db4f002817e0a8aed3ee09efb1a44","venue_1":"AAAI","year":"2006","title":"Lookahead Pathology in Real-Time Path-Finding","authors":"Vadim Bulitko, Mitja Lustrek","author_ids":"1884952, 1723535","abstract":"Large real-time search problems such as path-finding in computer games and robotics limit the applicability of complete search methods such as A*. As a result, real-time heuris-tic methods are becoming more widespread in practice. These algorithms typically conduct a limited-depth looka-head search and evaluate the states at the frontier using a heuristic. Actions selected by such methods can be subop-timal due to the incompleteness of their search and inaccuracies in the heuristic. Lookahead pathologies occur when a deeper search decreases the chances of selecting a better action. Over the last two decades research on lookahead pathologies has focused on minimax search and small synthetic examples in single-agent search. As real-time search methods gain ground in applications, the importance of understanding and remedying lookahead pathologies increases. This paper, for the first time, conducts a large scale investigation of lookahead pathologies in the domain of real-time path-finding. We use maps from commercial computer games to show that deeper search often not only consumes additional in-game CPU cycles but also decreases path quality. As a second contribution, we suggest three explanations for such pathologies and support them empirically. Finally, we propose a remedy to lookahead pathologies via a method for dynamic lookahead depth selection. This method substantially improves on-line performance and, as an added benefit, spares the user from having to tune a control parameter.","cites":"22","conferencePercentile":"71.61383285"},{"venue":"AAAI","id":"14437c37b7f621ab1cb6374ad7e485a89f7f2826","venue_1":"AAAI","year":"2004","title":"Spatial Aggregation for Qualitative Assessment of Scientific Computations","authors":"Chris Bailey-Kellogg, Naren Ramakrishnan","author_ids":"1799123, 1755938","abstract":"Qualitative assessment of scientific computations is an emerging application area that applies a data-driven approach to characterize, at a high level, phenomena including conditioning of matrices, sensitivity to various types of error propagation , and algorithmic convergence behavior. This paper develops a spatial aggregation approach that formalizes such analysis in terms of model selection utilizing spatial structures extracted from matrix perturbation datasets. We focus in particular on the characterization of matrix eigenstruc-ture, both analyzing sensitivity of computations with spectral portraits and determining eigenvalue multiplicity with Jordan portraits. Our approach employs spatial reasoning to overcome noise and sparsity by detecting mutually reinforcing interpretations , and to guide subsequent data sampling. It enables quantitative evaluation of properties of a scientific computation in terms of confidence in a model, explainable in terms of the sampled data and domain knowledge about the underlying mathematical structure. Not only is our methodology more rigorous than the common approach of visual inspection , but it also is often substantially more efficient, due to well-defined stopping criteria. Results show that the mechanism efficiently samples perturbation space and successfully uncovers high-level properties of matrices.","cites":"0","conferencePercentile":"5.089820359"},{"venue":"AAAI","id":"20ab9046a4f99aa08661e1ea28a531e4700d01de","venue_1":"AAAI","year":"2005","title":"Redescription Mining: Structure Theory and Algorithms","authors":"Laxmi Parida, Naren Ramakrishnan","author_ids":"1718465, 1755938","abstract":"We introduce a new data mining problem—redescription mining—that unifies considerations of conceptual clustering, constructive induction, and logical formula discovery. Re-description mining begins with a collection of sets, views it as a propositional vocabulary, and identifies clusters of data that can be defined in at least two ways using this vocabulary. The primary contributions of this paper are conceptual and theoretical: (i) we formally study the space of redescriptions underlying a dataset and characterize their intrinsic structure, (ii) we identify impossibility as well as strong possibility results about when mining redescriptions is feasible, (iii) we present several scenarios of how we can custom-build re-description mining solutions for various biases, and (iv) we outline how many problems studied in the larger machine learning community are really special cases of redescription mining. By highlighting its broad scope and relevance, we aim to establish the importance of redescription mining and make the case for a thrust in this new line of research.","cites":"19","conferencePercentile":"66.08391608"},{"venue":"AAAI","id":"16ba522057811c5c02ef8809df8f1de662411c76","venue_1":"AAAI","year":"2011","title":"Discovering Life Cycle Assessment Trees from Impact Factor Databases","authors":"Naren Sundaravaradan, Debprakash Patnaik, Naren Ramakrishnan, Manish Marwah, Amip Shah","author_ids":"2847441, 2681048, 1755938, 2733065, 1954017","abstract":"In recent years, environmental sustainability has received widespread attention due to continued depletion of natural resources and degradation of the environment. Life cycle assessment (LCA) is a methodology for quantifying multiple environmental impacts of a product, across its entire life cycle – from creation to use to discard. The key object of interest in LCA is the inventory tree, with the desired product as the root node and the materials and processes used across its life cycle as the children. The total impact of the parent in any environmental category is a linear combination of the impacts of the children in that category. LCA has generally been used in 'forward' mode: given an inventory tree and impact factors of its children, the task is to compute the impact factors of the root, i.e., the product being modeled. We propose a data mining approach to solve the inverse problem, where the task is to infer inventory trees from a database of environmental factors. This is an important problem with applications in not just understanding what parts and processes constitute a product but also in designing and developing more sustainable alternatives. Our solution methodology is one of feature selection but set in the context of a non-negative least squares problem. It organizes numerous non-negative least squares fits over the impact factor database into a set of pairwise membership relations which are then summarized into candidate trees in turn yielding a consensus tree. We demonstrate the applicability of our approach over real LCA datasets obtained from a large computer manufacturer.","cites":"5","conferencePercentile":"42.43986254"},{"venue":"AAAI","id":"434c80f498d5aa9ebc35ef5507529f2c183a40d0","venue_1":"AAAI","year":"2012","title":"Fine-Grained Photovoltaic Output Prediction Using a Bayesian Ensemble","authors":"Prithwish Chakraborty, Manish Marwah, Martin F. Arlitt, Naren Ramakrishnan","author_ids":"2457896, 2733065, 2185810, 1755938","abstract":"Local and distributed power generation is increasingly reliant on renewable power sources, e.g., solar (pho-tovoltaic or PV) and wind energy. The integration of such sources into the power grid is challenging, however , due to their variable and intermittent energy output. To effectively use them on a large scale, it is essential to be able to predict power generation at a fine-grained level. We describe a novel Bayesian ensemble methodology involving three diverse predictors. Each predictor estimates mixing coefficients for integrating PV generation output profiles but captures fundamentally different characteristics. Two of them employ classical parameterized (naive Bayes) and non-parametric (nearest neighbor) methods to model the relationship between weather forecasts and PV output. The third pre-dictor captures the sequentiality implicit in PV generation and uses motifs mined from historical data to estimate the most likely mixture weights using a stream prediction methodology. We demonstrate the success and superiority of our methods on real PV data from two locations that exhibit diverse weather conditions. Predictions from our model can be harnessed to optimize scheduling of delay tolerant workloads, e.g., in a data center.","cites":"9","conferencePercentile":"64.02439024"},{"venue":"AAAI","id":"5c552dc2d488912691da1e80dff68382e602ac20","venue_1":"AAAI","year":"2013","title":"Clustering with Complex Constraints - Algorithms and Applications","authors":"Weifeng Zhi, Xiang Wang, Buyue Qian, Patrick Butler, Naren Ramakrishnan, Ian Davidson","author_ids":"1838782, 1702287, 1752249, 3092974, 1755938, 1712716","abstract":"Clustering with constraints is an important and developing area. However, most work is confined to conjunctions of simple together and apart constraints which limit their usability. In this paper, we propose a new formulation of constrained clustering that is able to incorporate not only existing types of constraints but also more complex logical combinations beyond conjunctions. We first show how any statement in conjunctive normal form (CNF) can be represented as a linear inequality. Since existing clustering formulations such as spectral clustering cannot easily incorporate these linear inequalities , we propose a quadratic programming (QP) clustering formulation to accommodate them. This new formulation allows us to have much more complex guidance in clustering. We demonstrate the effectiveness of our approach in two applications on text and personal information management. We also compare our algorithm against existing constrained spectral clustering algorithm to show its efficiency in computational time.","cites":"5","conferencePercentile":"62.54545455"},{"venue":"AAAI","id":"745b09783b9854127036b070269fc781bf0b0655","venue_1":"AAAI","year":"2013","title":"A Temporal Motif Mining Approach to Unsupervised Energy Disaggregation: Applications to Residential and Commercial Buildings","authors":"Huijuan Shao, Manish Marwah, Naren Ramakrishnan","author_ids":"2584665, 2733065, 1755938","abstract":"Non-intrusive appliance load monitoring has emerged as an attractive approach to study energy consumption patterns without instrumenting every device in a building. The ensuing computational problem is to disaggregate total energy usage into usage by specific devices, to gain insight into consumption patterns. We exploit the temporal ordering implicit in on/off events of devices to uncover motifs (episodes) corresponding to the operation of individual devices. Extracted motifs are then subjected to a sequence of constraint checks to ensure that the resulting episodes are interpretable. Our results reveal that motif mining is adept at distinguishing devices with multiple power levels and at disentangling the combinatorial operation of devices. With suitably configured processing steps, we demonstrate the applicability of our method to both residential and commercial buildings.","cites":"10","conferencePercentile":"82"},{"venue":"AAAI","id":"084b9b895cc309970b185aba79992965c69b2f83","venue_1":"AAAI","year":"2014","title":"Avoiding Plagiarism in Markov Sequence Generation","authors":"Alexandre Papadopoulos, Pierre Roy, François Pachet","author_ids":"2049870, 2844033, 1986454","abstract":"Markov processes are widely used to generate sequences that imitate a given style, using random walk. Random walk generates sequences by iteratively con-catenating states to prefixes of length equal or less than the given Markov order. However, at higher orders, Markov chains tend to replicate chunks of the corpus with a size possibly higher than the order, a primary form of plagiarism. The Markov order defines a maximum length for training but not for generation. In the framework of constraint satisfaction (CSP), we introduce MAXORDER. This global constraint ensures that generated sequences do not include chunks larger than a given maximum order. We exhibit an automaton that recognises the solution set, with a size linear in the size of the corpus. We propose a linear-time procedure to generate this automaton from a corpus and a given max order. We then use this automaton to achieve gener-alised arc consistency for the MAXORDER constraint, holding on a sequence of size n, in O(n.T) time, where T is the size of the automaton. We illustrate our approach by generating text sequences from text corpora with a maximum order guarantee, effectively controlling plagiarism.","cites":"8","conferencePercentile":"81.25"},{"venue":"AAAI","id":"5968541124b94f2bc30b06f4a9cf2775ad02fc17","venue_1":"AAAI","year":"2015","title":"Planned Protest Modeling in News and Social Media","authors":"Sathappan Muthiah, Bert Huang, Jaime Arredondo, David Mares, Lise Getoor, Graham Katz, Naren Ramakrishnan","author_ids":"2740193, 2033484, 2779103, 2864325, 1746034, 1747585, 1755938","abstract":"Civil unrest (protests, strikes, and \" occupy \" events) is a common occurrence in both democracies and authoritarian regimes. The study of civil unrest is a key topic for political scientists as it helps capture an important mechanism by which citizenry express themselves. In countries where civil unrest is lawful, qualitative analysis has revealed that more than 75% of the protests are planned, organized, and/or announced in advance; therefore detecting future time mentions in relevant news and social media is a direct way to develop a protest forecasting system. We develop such a system in this paper, using a combination of key phrase learning to identify what to look for, probabilistic soft logic to reason about location occurrences in extracted results, and time normalization to resolve future tense mentions. We illustrate the application of our system to 10 countries in Venezuela. Results demonstrate our successes in capturing significant societal unrest in these countries with an average lead time of 4.08 days. We also study the selective superiorities of news media versus social media (Twitter, Facebook) to identify relevant tradeoffs. Civil unrest (protests, strikes, and \" occupy \" events) is a common happening in both democracies and authoritarian regimes. Although we typically associate civil unrest with disruptions and instability, for a social scientist civil unrest reflects the democratic process by which citizenry communicate their views and preferences to those in authority. The advent of social media has afforded citizenry new mechanisms for organization and mobilization, and online news sources and social networking sites like Facebook and Twit-ter can provide a window into civil unrest happenings in a particular country. Why study and forecast protests? Our region of interest is Latin America and protest is an important topic of study here, as many countries here are democracies struggling to consolidate themselves. The combination of weak channels of communication between citizen and government, and a citizenry that still has not grasped the desirability of elections as the means to affect politics means that public protest will be an especially attractive option. To illustrate the power of protest in Latin America we need only recall that between 1985 and 2011, 17 presidents resigned or were impeached under pressure from demonstrations, usually violent, in the streets. Protests have also resulted in the rollback of price increases for public services, such as during the 'Brazilian Spring' of June 2013. Forecasting protests is an important capability in …","cites":"8","conferencePercentile":"90.23622047"},{"venue":"AAAI","id":"17c0d47692c2543d69b662563735c212288485df","venue_1":"AAAI","year":"2016","title":"Inferring Multi-Dimensional Ideal Points for US Supreme Court Justices","authors":"Mohammad Raihanul Islam, K. S. M. Tozammel Hossain, Siddharth Krishnan, Naren Ramakrishnan","author_ids":"1815815, 2182555, 3385913, 1755938","abstract":"In Supreme Court parlance and the political science literature , an ideal point positions a justice in a continuous space and can be interpreted as a quantification of the justice's policy preferences. We present an automated approach to infer such ideal points for justices of the US Supreme Court. This approach combines topic modeling over case opinions with the voting (and endorsing) behavior of justices. Furthermore, given a topic of interest, say the Fourth Amendment, the topic model can be optionally seeded with supervised information to steer the inference of ideal points. Application of this methodology over five years of cases provides interesting perspectives into the leaning of justices on crucial issues, coalitions underlying specific topics, and the role of swing justices in deciding the outcomes of cases.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"23ab11da13aab50dadcceada0e62bf58436091d9","venue_1":"AAAI","year":"2007","title":"Active Imitation Learning","authors":"Aaron P. Shon, Deepak Verma, Rajesh P. N. Rao","author_ids":"2507160, 6047537, 1777466","abstract":"Imitation learning, also called learning by watching or programming by demonstration, has emerged as a means of accelerating many reinforcement learning tasks. Previous work has shown the value of imitation in domains where a single mentor demonstrates execution of a known optimal policy for the benefit of a learning agent. We consider the more general scenario of learning from mentors who are themselves agents seeking to maximize their own rewards. We propose a new algorithm based on the concept of transferable utility for ensuring that an observer agent can learn efficiently in the context of a selfish, not necessarily helpful, mentor. We also address the questions of when an imitative agent should request help from a mentor, and when the mentor can be expected to acknowledge a request for help. In analogy with other types of active learning, we call the proposed approach active imitation learning.","cites":"9","conferencePercentile":"50.44510386"},{"venue":"AAAI","id":"0b8baa454394332ca04fe331138a13c3fc13b8af","venue_1":"AAAI","year":"2007","title":"KA-CAPTCHA: An Opportunity for Knowledge Acquisition on the Web","authors":"Bruno Norberto da Silva, Ana Cristina Bicharra Garcia","author_ids":"2018445, 1715457","abstract":"Any Web user is a potential knowledge contributor, but it remains a challenge to make them devote their time contributing to some purpose. In order to align individual with social interests, we selected the CAPTCHA Web resource protection application to embed knowledge elicitation within the users' main task of accessing a Web resource. Consequently, unlike previous knowledge acquisition approaches, no extra effort is expected from users since they are already willing to use a CAPTCHA to perform some particular task. We present an application where we extract pictorial knowledge from Web users, and experiments suggest that our approach enables knowledge acquisition while still satisfying CAPTCHA's security requirements.","cites":"6","conferencePercentile":"38.4272997"},{"venue":"AAAI","id":"5ead901a08fe2de03527892261e2c1b34ec52948","venue_1":"AAAI","year":"2016","title":"TGSum: Build Tweet Guided Multi-Document Summarization Dataset","authors":"Ziqiang Cao, Chengyao Chen, Wenjie Li, Sujian Li, Furu Wei, Ming Zhou","author_ids":"2314396, 2059995, 1749930, 1695451, 2517592, 5962676","abstract":"The development of summarization research has been significantly hampered by the costly acquisition of reference summaries. This paper proposes an effective way to automatically collect large scales of news-related multi-document summaries with reference to social me-dia's reactions. We utilize two types of social labels in tweets, i.e., hashtags and hyper-links. Hashtags are used to cluster documents into different topic sets. Also, a tweet with a hyper-link often highlights certain key points of the corresponding document. We synthesize a linked document cluster to form a reference summary which can cover most key points. To this aim, we adopt the ROUGE metrics to measure the coverage ratio, and develop an Integer Linear Programming solution to discover the sentence set reaching the upper bound of ROUGE. Since we allow summary sentences to be selected from both documents and high-quality tweets, the generated reference summaries could be abstractive. Both informativeness and readability of the collected summaries are verified by manual judgment. In addition, we train a Support Vector Regression summarizer on DUC generic multi-document summa-rization benchmarks. With the collected data as extra training resource, the performance of the summarizer improves a lot on all the test sets. We release this dataset for further research 1 .","cites":"5","conferencePercentile":"86.31756757"},{"venue":"AAAI","id":"0ce17d4d41b1291e942ec3bf6c102f3ae3034b3d","venue_1":"AAAI","year":"2015","title":"Ranking with Recursive Neural Networks and Its Application to Multi-Document Summarization","authors":"Ziqiang Cao, Furu Wei, Li Dong, Sujian Li, Ming Zhou","author_ids":"2314396, 2517592, 4815698, 1695451, 5962676","abstract":"We develop a Ranking framework upon Recursive Neural Networks (R2N2) to rank sentences for multi-document sum-marization. It formulates the sentence ranking task as a hierarchical regression process, which simultaneously measures the salience of a sentence and its constituents (e.g., phrases) in the parsing tree. This enables us to draw on word-level to sentence-level supervisions derived from reference summaries. In addition, recursive neural networks are used to automatically learn ranking features over the tree, with hand-crafted feature vectors of words as inputs. Hierarchical regressions are then conducted with learned features concatenating raw features. Ranking scores of sentences and words are utilized to effectively select informative and non-redundant sentences to generate summaries. Experiments on the DUC 2001, 2002 and 2004 multi-document summariza-tion datasets show that R2N2 outperforms state-of-the-art ex-tractive summarization approaches.","cites":"17","conferencePercentile":"97.16535433"},{"venue":"AAAI","id":"4d06b6d3bf332316446d35817cb4b481a716bf90","venue_1":"AAAI","year":"2014","title":"Adaptive Multi-Compositionality for Recursive Neural Models with Applications to Sentiment Analysis","authors":"Li Dong, Furu Wei, Ming Zhou, Ke Xu","author_ids":"4815698, 2517592, 5962676, 1691178","abstract":"Recursive neural models have achieved promising results in many natural language processing tasks. The main difference among these models lies in the composition function, i.e., how to obtain the vector representation for a phrase or sentence using the representations of words it contains. This paper introduces a novel Adaptive Multi-Compositionality (AdaMC) layer to re-cursive neural models. The basic idea is to use more than one composition functions and adaptively select them depending on the input vectors. We present a general framework to model each semantic composition as a distribution over these composition functions. The composition functions and parameters used for adap-tive selection are learned jointly from data. We integrate AdaMC into existing recursive neural models and conduct extensive experiments on the Stanford Sentiment Treebank. The results illustrate that AdaMC significantly outperforms state-of-the-art sentiment classification methods. It helps push the best accuracy of sentence-level negative/positive classification from 85.4% up to 88.5%.","cites":"16","conferencePercentile":"94.65909091"},{"venue":"AAAI","id":"54abe32b2689510d2f262174563ae49a81f8c886","venue_1":"AAAI","year":"2013","title":"Co-Training Based Bilingual Sentiment Lexicon Learning","authors":"Dehong Gao, Furu Wei, Wenjie Li, Xiaohua Liu, Ming Zhou","author_ids":"4115877, 2517592, 1749930, 1900811, 5962676","abstract":"In this paper, we address the issue of bilingual sentiment lexicon learning(BSLL) which aims to automatically and simultaneously generate sentiment words for two languages. The underlying motivation is that sentiment information from two languages can perform iterative mutual-teaching in the learning procedure. We propose to develop two classifiers to determine the sentiment polarities of words under a co-training framework, which makes full use of the two-view sentiment information from the two languages. The word alignment derived from the parallel corpus is leveraged to design effective features and to bridge the learning of the two classifiers. The experimental results on English and Chinese languages show the effectiveness of our approach in BSLL.","cites":"3","conferencePercentile":"47.09090909"},{"venue":"AAAI","id":"c0389bf74e124dd742fc63b722fbbc1fc936ffa9","venue_1":"AAAI","year":"2016","title":"Wikipedia in the Tourism Industry: Forecasting Demand and Modeling Usage Behavior","authors":"Pejman Khadivi, Naren Ramakrishnan","author_ids":"2867746, 1755938","abstract":"Due to the economic and social impacts of tourism, both private and public sectors are interested in precisely forecasting the tourism demand volume in a timely manner. With recent advances in social networks, more people use online resources to plan their future trips. In this paper we explore the application of Wikipedia usage trends (WUTs) in tourism analysis. We propose a framework that deploys WUTs for forecasting the tourism demand of Hawaii. We also propose a data-driven approach, using WUTs, to estimate the behavior of tourists when they plan their trips.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"1dc8532ece6fefcae81ce053bbae31fafea41a79","venue_1":"AAAI","year":"2007","title":"AURA: Enabling Subject Matter Experts to Construct Declarative Knowledge Bases from Science Textbooks","authors":"Ken Barker, Vinay K. Chaudhri, Shaw Yi Chaw, Peter Clark, Daniel Hansch, Bonnie E. John, Sunil Mishra, John Pacheco, Bruce W. Porter, Aaron Spaulding, Moritz Weiten","author_ids":"8630056, 2810613, 3031050, 6232140, 2377400, 1688844, 4317051, 3123697, 2612461, 2946400, 2808279","abstract":"The long-term goal of Project Halo is to build an application called Digital Aristotle that can answer questions on a variety of science topics and provide user and domain appropriate explanations. As a near-term goal, we are focusing on enabling Subject Matter Experts (SMEs) to construct declarative knowledge bases (KBs) from 50 pages of a science textbook in the domains of Physics (Giancoli 2004), Chemistry (Brown et al. 2003) and Biology (Campbell et al. 2001) in a way that the system can answer questions similar to those on an Advanced Placement (AP) exam. We will demonstrate the current state of a system called AURA that we have been developing as a contributing technology toward the goal of Digital Aristotle. The innovative features of AURA are that it supports knowledge formulation for a mixture of textual and nontextual knowledge, and question formulation using an interactive dialog based on simplified English. The nontextual knowledge may contain tables, chemical reactions, and mathematical equations. In an extensive usability testing of AURA, we have established the basic viability of the approach.","cites":"1","conferencePercentile":"13.94658754"},{"venue":"AAAI","id":"4418354db97102b0057967a1519be16f621657ad","venue_1":"AAAI","year":"2013","title":"Enforcing Meter in Finite-Length Markov Sequences","authors":"Pierre Roy, François Pachet","author_ids":"2844033, 1986454","abstract":"Markov processes are increasingly used to generate finite-length sequences that imitate a given style. However , Markov processes are notoriously difficult to control. Recently, Markov constraints have been introduced to give users some control on generated sequences. Markov constraints reformulate finite-length Markov sequence generation in the framework of constraint satisfaction (CSP). However, in practice, this approach is limited to local constraints and its performance is low for global constraints, such as cardinality or arithmetic constraints. This limitation prevents generated sequences to satisfy structural properties which are independent of the style, but inherent to the domain, such as meter. In this article, we introduce meter, a constraint that ensures a sequence is 1) Markovian with regards to a given corpus and 2) follows metrical rules expressed as cumulative cost functions. Additionally, meter can simultaneously enforce cardinality constraints. We propose a domain consistency algorithm whose complexity is pseudo-polynomial. This result is obtained thanks to a theorem on the growth of sumsets by Khovanskii. We illustrate our constraint on meter-constrained music generation problems that were so far not solvable by any other technique. Statistical style imitation techniques are increasingly used for content generation applications. From a corpus of finite-length sequences considered as representative of the style of an author, a statistical model of the style is built. Then new sequences can be generated from the model that \" look \" like or \" sound \" like the originals. In the context of Markov processes , models exploit the Markov hypothesis, which states that the future state of a sequence depends only on the last state, i. The Markovian aspects of musical sequences have long been acknowledged, see e.g., (Brooks et al. 1992). Many attempts to model musical style have therefore exploited Markov chains in various ways (Nierhaus 2009), notably sequence generation. The same is true, to some extent, for text, and toy text generators can easily be implemented to illustrate this point. However, putting these ideas in practice raises difficult control problems: users generally want to enforce specific, domain-dependent properties on the sequences to generate. Unfortunately, Markov models, as most statistical models, do not offer natural handles to enforce such properties. The reason is that semantically interesting properties often establish long-range correlations between non contiguous items in the sequence, which is incompatible with the Markov hypothesis of limited dependency. A general solution to this problem, called Markov constraints , was introduced in (Pachet …","cites":"13","conferencePercentile":"89.27272727"},{"venue":"AAAI","id":"ed71da11bf309c49a4e4ea6a85bdfee9b66e5cee","venue_1":"AAAI","year":"2015","title":"Two Weighting Local Search for Minimum Vertex Cover","authors":"Shaowei Cai, Jinkun Lin, Kaile Su","author_ids":"7884715, 2010236, 1776629","abstract":"Minimum Vertex Cover (MinVC) is a well known NP-hard combinatorial optimization problem, and local search has been shown to be one of the most effective approaches to this problem. State-of-the-art MinVC local search algorithms employ edge weighting techniques and prefer to select vertices with higher weighted score. These algorithms are not robust and especially have poor performance on instances with structures which defeat greedy heuristics. In this paper, we propose a vertex weighting scheme to address this shortcoming, and combine it within the current best MinVC local search algorithm NuMVC, leading to a new algorithm called TwMVC. Our experiments show that TwMVC outperforms NuMVC on the standard benchmarks namely DIMACS and BHOSLIB. To the best of our knowledge, TwMVC is the first MinVC algorithm that attains the best known solution for all instances in both benchmarks. Further, TwMVC shows superiority on a benchmark of real-world networks.","cites":"4","conferencePercentile":"73.46456693"},{"venue":"AAAI","id":"c98e35429c1d5fc041f7c2e28af8ec312fd3ece7","venue_1":"AAAI","year":"2016","title":"Business-Aware Visual Concept Discovery from Social Media for Multimodal Business Venue Recognition","authors":"Bor-Chun Chen, Yan-Ying Chen, Francine Chen, Dhiraj Joshi","author_ids":"1827312, 1809974, 1800347, 6163828","abstract":"Image localization is important for marketing and recommendation of local business; however, the level of granu-larity is still a critical issue. Given a consumer photo and its rough GPS information, we are interested in extracting the fine-grained location information, i.e. business venues, of the image. To this end, we propose a novel framework for business venue recognition. The framework mainly contains three parts. First, business-aware visual concept discovery: we mine a set of concepts that are useful for business venue recognition based on three guidelines including business awareness, visually detectable, and discriminative power. We define concepts that satisfy all of these three criteria as business-aware visual concept. Second, business-aware concept detection by convolutional neural networks (BA-CNN): we propose a new network configuration that can incorporate semantic signals mined from business reviews for extracting semantic concept features from a query image. Third, multimodal business venue recognition: we extend visually detected concepts to multimodal feature representations that allow a test image to be associated with business reviews and images from social media for business venue recognition. The experiments results show the visual concepts detected by BA-CNN can achieve up to 22.5% relative improvement for business venue recognition compared to the state-of-the-art convolutional neural network features. Experiments also show that by leveraging multimodal information from social media we can further boost the performance, especially when the database images belonging to each business venue are scarce.","cites":"1","conferencePercentile":"40.70945946"},{"venue":"AAAI","id":"c3348741bf8beba6109cbbf7e43737e4b2894570","venue_1":"AAAI","year":"2015","title":"Complex Event Detection via Event Oriented Dictionary Learning","authors":"Yan Yan, Yi Yang, Haoquan Shen, Deyu Meng, Gaowen Liu, Alexander G. Hauptmann, Nicu Sebe","author_ids":"1703972, 1698559, 2104633, 7480838, 3056447, 7661726, 1703601","abstract":"Complex event detection is a retrieval task with the goal of finding videos of a particular event in a large-scale unconstrained internet video archive, given example videos and text descriptions. Nowadays, different multimodal fusion schemes of low-level and high-level features are extensively investigated and evaluated for the complex event detection task. However, how to effectively select the high-level semantic meaningful concepts from a large pool to assist complex event detection is rarely studied in the literature. In this paper, we propose two novel strategies to automatically select semantic meaningful concepts for the event detection task based on both the events-kit text descriptions and the concepts high-level feature descriptions. Moreover, we introduce a novel event oriented dictionary representation based on the selected semantic concepts. Towards this goal, we leverage training samples of selected concepts from the Semantic Indexing (SIN) dataset with a pool of 346 concepts, into a novel supervised multi-task dictionary learning framework. Extensive experimental results on TRECVID Multimedia Event Detection (MED) dataset demonstrate the efficacy of our proposed method.","cites":"7","conferencePercentile":"88.11023622"},{"venue":"AAAI","id":"a0bf2bffb127c94c0830d6998ed90b27f1872fdc","venue_1":"AAAI","year":"2010","title":"Bidirectional Integration of Pipeline Models","authors":"Xiaofeng Yu, Wai Lam","author_ids":"1789443, 1717078","abstract":"Traditional information extraction systems adopt pipeline strategies, which are highly ineffective and suffer from several problems such as error propagation. Typically, pipeline models fail to produce highly-accurate final output. On the other hand, there has been growing interest in integrated or joint models which explore mutual benefits and perform multiple subtasks simultaneously to avoid problems caused by pipeline models. However, building such systems usually increases computational complexity and requires considerable engineering. This paper presents a general, strongly-coupled, and bidirectional architecture based on discriminatively trained factor graphs for information extraction. First we introduce joint factors connecting variables of relevant subtasks to capture dependencies and interactions between them. We then propose a strong bidirectional MCMC sampling inference algorithm which allows information to flow in both directions to find the approximate MAP solution for all subtasks. Extensive experiments on entity identification and relation extraction using real-world data illustrate the promise of our approach.","cites":"4","conferencePercentile":"27.1331058"},{"venue":"AAAI","id":"be8896eafaafc804fb18ef854f81de76cc2c21d0","venue_1":"AAAI","year":"2008","title":"Hidden Dynamic Probabilistic Models for Labeling Sequence Data","authors":"Xiaofeng Yu, Wai Lam","author_ids":"1789443, 1717078","abstract":"We propose a new discriminative framework, namely Hidden Dynamic Conditional Random Fields (HD-CRFs), for building probabilistic models which can capture both internal and external class dynamics to label sequence data. We introduce a small number of hidden state variables to model the sub-structure of a observation sequence and learn dynamics between different class labels. An HDCRF offers several advantages over previous discriminative models and is attractive both, conceptually and computationally. We performed experiments on three well-established sequence labeling tasks in natural language, including part-of-speech tagging , noun phrase chunking, and named entity recognition. The results demonstrate the validity and competitiveness of our model. In addition, our model compares favorably with current state-of-the-art sequence labeling approach, Conditional Random Fields (CRFs), which can only model the external dynamics.","cites":"7","conferencePercentile":"45.41139241"},{"venue":"AAAI","id":"2ea97802beb7b543395262111e602e0eab066481","venue_1":"AAAI","year":"2012","title":"Decision Support for Agent Populations in Uncertain and Congested Environments","authors":"Pradeep Varakantham, Shih-Fen Cheng, Geoffrey J. Gordon, Asrar Ahmed","author_ids":"1718824, 2089330, 1736834, 2412208","abstract":"This research is motivated by large scale problems in urban transportation and labor mobility where there is congestion for resources and uncertainty in movement. In such domains, even though the individual agents do not have an identity of their own and do not explicitly interact with other agents, they effect other agents. While there has been much research in handling such implicit effects, it has primarily assumed de-terministic movements of agents. We address the issue of decision support for individual agents that are identical and have involuntary movements in dynamic environments. For instance, in a taxi fleet serving a city, when a taxi is hired by a customer, its movements are uncontrolled and depend on (a) the customers requirement; and (b) the location of other taxis in the fleet. Towards addressing decision support in such problems, we make two key contributions: (a) A framework to represent the decision problem for selfish individuals in a dynamic population, where there is transitional uncertainty (involuntary movements); and (b) Two techniques (Fictitious Play for Symmetric Agent Populations, FP-SAP and Soft-max based Flow Update, SMFU) that converge to equilibrium solutions. We show that our techniques (apart from providing equilibrium strategies) outperform \" driver \" strategies with respect to overall availability of taxis and the revenue obtained by the taxi drivers. We demonstrate this on a real world data set with 8,000 taxis and 83 zones (representing the entire area of Singapore).","cites":"10","conferencePercentile":"67.83536585"},{"venue":"AAAI","id":"d32d37d148ebbf347460513244e435882b1f27fe","venue_1":"AAAI","year":"2005","title":"Approximate Strategic Reasoning through Hierarchical Reduction of Large Symmetric Games","authors":"Michael P. Wellman, Daniel M. Reeves, Kevin M. Lochner, Shih-Fen Cheng, Rahul Suri","author_ids":"1796536, 4622298, 2221369, 2089330, 2386418","abstract":"To deal with exponential growth in the size of a game with the number of agents, we propose an approximation based on a hierarchy of reduced games. The reduced game achieves savings by restricting the number of agents playing any strategy to fixed multiples. We validate the idea through experiments on randomly generated local-effect games. An extended application to strategic reasoning about a complex trading scenario motivates the approach, and demonstrates methods for game-theoretic reasoning over incompletely-specified games at multiple levels of granularity.","cites":"42","conferencePercentile":"87.23776224"},{"venue":"AAAI","id":"adf6280e1c8bcbaea6279a634eb13e1026dad018","venue_1":"AAAI","year":"2011","title":"Collaborative Users' Brand Preference Mining across Multiple Domains from Implicit Feedbacks","authors":"Jian Tang, Jun Yan, Lei Ji, Ming Zhang, Shaodan Guo, Ning Liu, Xianfang Wang, Zheng Chen","author_ids":"1690273, 1712810, 1766637, 1720939, 2274825, 1680152, 1769114, 1705657","abstract":"Advanced e-applications require comprehensive knowledge about their users' preferences in order to provide accurate personalized services. In this paper, we propose to learn users' preferences to product brands from their implicit feedbacks such as their searching and browsing behaviors in user Web browsing log data. The user brand preference learning problem is challenge since (1) the users' implicit feedbacks are extremely sparse in various product domains; and (2) we can only observe positive feedbacks from users' behaviors. In this paper, we propose a latent factor model to collaboratively mine users' brand preferences across multiple domains simultaneously. By collective learning, the learning processes in all the domains are mutually enhanced and hence the problem of data scarcity in each single domain can be effectively addressed. On the other hand, we learn our model with an adaption of the Bayesian personalized ranking (BPR) optimization criterion which is a general learning framework for collaborative filtering from implicit feedbacks. Experiments with both synthetic and real world datasets show that our proposed model significantly outperforms the baselines.","cites":"3","conferencePercentile":"29.3814433"},{"venue":"AAAI","id":"d378e6cae0c6fc86718a41fd89efb8426c3ae718","venue_1":"AAAI","year":"2014","title":"A Knowledge Representation that Models Memory in Narrative Comprehension","authors":"Rogelio Enrique Cardona-Rivera, Robert Michael Young","author_ids":"2787237, 1937688","abstract":"We present work toward computationally defining a model of narrative comprehension vis-` a-vis memory of narrative events, via an automated planning knowledge representation, capable of being used in a narrative generation context. There has been much recent research on computationally analyzing and generating narratives (e.g. Mani 2012). Key to these efforts is the modeling of the mind as it makes sense of stories. As people perceive narrative, their story comprehension faculties are active in the projection of a fictional world (Gerrig 2013), such that the story context in which they are embedded plays a key role in how they expect the future of the narrative to unfold. Authors accordingly design stories to affect their audience in specific ways (Bordwell 1989). A generative computational model of narrative must go beyond story structure, because the fundamental design criteria for a narrative artifact rest in the cognitive and af-fective responses they prompt in their human consumers. In this paper, we present work toward a computational model of narrative, which begins to account for the human consumer by modeling the person's memory for previously experienced narrative events relative to the most recently experienced event of the same narrative. Early approaches to computationally modeling narratives fo-cused primarily on the structural properties of stories, e.g. as a collection of forward-chained scripts (Schank and Abel-son 1975). Automated Planning has enjoyed success in supporting narrative content generation, due to its flexibility in representing the causal, and temporal structures typically present in structural analyses of narrative plot (Young 1999). For example, Riedl and Young's (2010) FABULIST system modeled narrative through an extended partial-order causal link (POCL) planning paradigm, capable of modeling the intentional nature of story characters. There has recently been a call to go beyond story structure and account for the effect of stories on the minds of systems that account for the cognitive effects of stories have extended the aforementioned structural approaches to model individual psychonarratological phenomena, such as suspense (O'Neill 2013), or inference-making (Niehaus and Young 2010). The work we present here is the start of both a unification of the work on modeling psychonarratological phenomena, and an extension of structural approaches to narrative generation: we expand a POCL planning knowledge representation with information that allows us to compute the relative recallability between steps in the plan. The recallabil-ity of a narrative event indicates how recallable the event is in a person's mind, and correspondingly, the …","cites":"0","conferencePercentile":"9.431818182"},{"venue":"AAAI","id":"1127a44dcaff28fd67bde9a83f1f86838a6bbe53","venue_1":"AAAI","year":"2007","title":"OPTIMOL: A Framework for Online Picture Collection via Incremental Model Learning","authors":"Li-Jia Li, Juan Carlos Niebles, Li Fei-Fei","author_ids":"2451991, 1751383, 3216322","abstract":"OPTIMOL (a framework for Online Picture collecTion via Incremental MOdel Learning) is a novel, automatic dataset collecting and model learning system for object categoriza-tion. Our algorithm mimics the human learning process in such a way that, starting from a few training examples, the more confident data you incorporate in the training data, the more reliable models can be learnt. Our system uses the Internet as the (nearly) unlimited resource for images. The learning and image collection processes are done via an iterative and incremental scheme. The goal of this work is to use this tremendous web resource to learn robust object category models in order to detect and search for objects in real-world scenes.","cites":"2","conferencePercentile":"19.43620178"},{"venue":"AAAI","id":"d58686d04a5ca83510ee749603825bbc0db1af6f","venue_1":"AAAI","year":"2013","title":"A Kernel Density Estimate-Based Approach to Component Goodness Modeling","authors":"Nuno Cardoso, Rui Abreu","author_ids":"1780002, 8689649","abstract":"Intermittent fault localization approaches account for the fact that faulty components may fail intermittently by considering a parameter (known as goodness) that quantifies the probability that faulty components may still exhibit correct behavior. Current, state-of-the-art approaches (1) assume that this goodness probability is context independent and (2) do not provide means for integrating past diagnosis experience in the diagnostic mechanism. In this paper, we present a novel approach , coined Non-linear Feedback-based Goodness Estimate (NFGE), that uses kernel density estimations (KDE) to address such limitations. We evaluated the approach with both synthetic and real data, yielding lower estimation errors, thus increasing the diagnosis performance.","cites":"2","conferencePercentile":"37.09090909"},{"venue":"AAAI","id":"25238cb0825924e891e0f724c993941ddc52ccb9","venue_1":"AAAI","year":"2011","title":"Spectrum-Based Sequential Diagnosis","authors":"Alberto González-Sanchez, Rui Abreu, Hans-Gerhard Groß, Arjan J. C. van Gemund","author_ids":"2373471, 8689649, 2577221, 1686060","abstract":"Often multiple observations are required to achieve acceptable diagnostic certainty. We present a spectrum-based sequential diagnosis approach coined SEQUOIA, that greedily selects tests out of a suite of tests to narrow down the set of diagnostic candidates with a minimum number of tests. SEQUOIA handles multiple faults, that can be intermittent, at polynomial time and space complexity. This is due to a novel, approximate diagnostic entropy estimation approach, which is based on a relatively small subset of diagnoses that cover almost all Bayesian posterior probability mass. Synthetic data shows, that the dynamic selection of the next best test based on the test results measured so far, allows SEQUOIA to achieve much better decay of diagnostic uncertainty compared to random test sequencing. Real programs, taken from the Siemens set, also show that SEQUOIA has better performance, except in a few cases where the diagnosis includes large fault sets, which affects the entropy estimation quality. 1 INTRODUCTION In fault diagnosis an important performance metric is the accuracy of the multiple-fault diagnosis D returned by a diagnostic algorithm (DA). In many cases diagnostic accuracy is insufficient (D comprises too many candidates). Diagnostic uncertainty can be reduced by supplying more modeling information, and more observation information. Observation information can be in spatial sense (more probing points), and in temporal sense (more tests), the latter of which is the focus of this paper. Ignoring the computational cost of the DA itself, the diagnostic process may be viewed as (1) expending costs to generate observation input to the DA (testing cost C t), and (2) expending costs to find the","cites":"10","conferencePercentile":"67.18213058"},{"venue":"AAAI","id":"683cde1cca4f0c00bc2727188505e59d712db8b3","venue_1":"AAAI","year":"1994","title":"Towards More Creative Case-Based Design Systems","authors":"Linda M. Wills, Janet L. Kolodner","author_ids":"1695824, 1814794","abstract":"Case-based reasoning (CBR) has a great deal to ooer in supporting creative design, particularly processes that rely heavily on previous design experience , such as framing the problem and evaluating design alternatives. However, most existing CBR systems are not living up to their potential. They tend to adapt and reuse old solutions in routine ways, producing robust but uninspired results. Little research eeort has been directed towards the kinds of situation assessment, evaluation , and assimilation processes that facilitate the exploration of ideas and the elaboration and redeenition of problems that are crucial to creative design. Also, their typically rigid control structures do not facilitate the kinds of strategic control and opportunism inherent in creative reasoning. In this paper, we describe the types of behavior we would like case-based design systems to support, based on a study of designers working on a mechanical engineering problem. We show how the standard CBR framework should be extended and we describe an architecture we are developing to experiment with these ideas. 1","cites":"27","conferencePercentile":"67.40088106"},{"venue":"AAAI","id":"accec07921c8701016c74d9c9c2e76ba0d87a924","venue_1":"AAAI","year":"2004","title":"SEM-Ether: Semantic Web Based Pervasive Computing Framework - Integrating Web, Devices and People","authors":"Sushil Puradkar, Sachin Singh, Chintan Patel, Kartik Vishwanath, Rahul Gupta, Yugyung Lee","author_ids":"2281502, 2093471, 1756071, 2676753, 4414000, 1787659","abstract":"Pervasive computing aims to build an aggregated environment around a user by knitting diverse computing and communicating devices and software services into a single homogeneous unit. Our work is to develop a Pervasive computing framework which harnesses the power of Semantic Web and Web Services, facilitating the development of effective and intelligent Pervasive environments. This paper presents a high level view of the framework and how different Pervasive services can be built on this framework","cites":"0","conferencePercentile":"5.089820359"},{"venue":"AAAI","id":"0dc41e1ca77dfdef6d682ed5b188f7153bd64584","venue_1":"AAAI","year":"2007","title":"Centralized, Distributed or Something Else? Making Timely Decisions in Multi-Agent Systems","authors":"Tim Harbers, Rajiv T. Maheswaran, Pedro A. Szekely","author_ids":"2287173, 1747887, 2628881","abstract":"In multi-agent systems, agents need to share information in order to make good decisions. Who does what in order to achieve this matters a lot. The assignment of responsibility influences delay and consequently affects agents' abilities to make timely decisions. It is often unclear which approaches are best. We develop a model where one can easily test the impact of different assignments and information sharing protocols by focusing only on the delays caused by computation and communication. Using the model, we obtain interesting results that provide insight about the types of assignments that perform well in various domains and how slight variations in protocols can make great differences in feasibility.","cites":"4","conferencePercentile":"31.00890208"},{"venue":"AAAI","id":"b9a72f9f75eb7aa51ecfa01c975c1c4f35c416ab","venue_1":"AAAI","year":"2013","title":"Basis Adaptation for Sparse Nonlinear Reinforcement Learning","authors":"Sridhar Mahadevan, Stephen Giguere, Nicholas Jacek","author_ids":"1850503, 1837707, 2248640","abstract":"This paper presents a new approach to representation discovery in reinforcement learning (RL) using basis adaptation. We introduce a general framework for basis adaptation as nonlinear separable least-squares value function approximation based on finding Fréchet gradients of an error function using variable projection func-tionals. We then present a scalable proximal gradient-based approach for basis adaptation using the recently proposed mirror-descent framework for RL. Unlike traditional temporal-difference (TD) methods for RL, mirror descent based RL methods undertake proximal gradient updates of weights in a dual space, which is linked together with the primal space using a Legendre transform involving the gradient of a strongly convex function. Mirror descent RL can be viewed as a proximal TD algorithm using Bregman divergence as the distance generating function. We present a new class of regular-ized proximal-gradient based TD methods, which combine feature selection through sparse L 1 regularization and basis adaptation. Experimental results are provided to illustrate and validate the approach.","cites":"2","conferencePercentile":"37.09090909"},{"venue":"AAAI","id":"5c6eeffe821342e49f5a6af48f38207115fcdab9","venue_1":"AAAI","year":"2008","title":"On the Progression of Situation Calculus Basic Action Theories: Resolving a 10-year-old Conjecture","authors":"Stavros Vassos, Hector J. Levesque","author_ids":"1728186, 1796525","abstract":"In a seminal paper, Lin and Reiter introduced a model-theoretic definition for the progression of the initial knowledge base of a basic action theory. This definition comes with a strong negative result, namely that for certain kinds of action theories, first-order logic is not expressive enough to correctly characterize this form of progression, and second-order axioms are necessary. However, Lin and Reiter also considered an alternative definition for progression which is always first-order definable. They conjectured that this alternative definition is incorrect in the sense that the progressed theory is too weak and may sometimes lose information. This conjecture, and the status of first-order definable progression, has remained open since then. In this paper we present two significant results about this alternative definition of progression. First, we prove the Lin and Reiter conjecture by presenting a case where the progressed theory indeed does lose information. Second, we prove that the alternative definition is nonetheless correct for reasoning about a large class of sentences , including some that quantify over situations. In this case the alternative definition is a preferred option due to its simplicity and the fact that it is always first-order.","cites":"10","conferencePercentile":"54.90506329"},{"venue":"AAAI","id":"2bbba193ee3c5391566506d2d9e5e796616b39ce","venue_1":"AAAI","year":"2015","title":"Pathway Graphical Lasso","authors":"Maxim Grechkin, Maryam Fazel, Daniela M. Witten, Su-In Lee","author_ids":"1892750, 1737171, 2115376, 2609062","abstract":"Graphical models provide a rich framework for summarizing the dependencies among variables. The graphical lasso approach attempts to learn the structure of a Gaussian graphical model (GGM) by maximizing the log likelihood of the data, subject to an l1 penalty on the elements of the inverse co-variance matrix. Most algorithms for solving the graphical lasso problem do not scale to a very large number of variables. Furthermore, the learned network structure is hard to interpret. To overcome these challenges, we propose a novel GGM structure learning method that exploits the fact that for many real-world problems we have prior knowledge that certain edges are unlikely to be present. For example, in gene regulatory networks, a pair of genes that does not participate together in any of the cellular processes, typically referred to as pathways, is less likely to be connected. In computer vision applications in which each variable corresponds to a pixel, each variable is likely to be connected to the nearby variables. In this paper, we propose the pathway graphical lasso, which learns the structure of a GGM subject to pathway-based constraints. In order to solve this problem, we decompose the network into smaller parts, and use a message-passing algorithm in order to communicate among the subnetworks. Our algorithm has orders of magnitude improvement in run time compared to the state-of-the-art optimization methods for the graphical lasso problem that were modified to handle pathway-based constraints.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"15ff9562a7b3f88d3ed774bb2f532cdecc2a5db6","venue_1":"AAAI","year":"2012","title":"Exacting Social Events for Tweets Using a Factor Graph","authors":"Xiaohua Liu, Xiangyang Zhou, Zhongyang Fu, Furu Wei, Ming Zhou","author_ids":"1900811, 2760627, 2904393, 2517592, 5962676","abstract":"Social events are events that occur between people where at least one person is aware of the other and of the event taking place. Extracting social events can play an important role in a wide range of applications, such as the construction of social network. In this paper, we introduce the task of social event extraction for tweets, an important source of fresh events. One main challenge is the lack of information in a single tweet, which is rooted in the short and noise-prone nature of tweets. We propose to collectively extract social events from multiple similar tweets using a novel factor graph, to harvest the redundance in tweets, i.e., the repeated occurrences of a social event in several tweets. We evaluate our method on a human annotated data set, and show that it out-performs all baselines, with an absolute gain of 21% in F1.","cites":"7","conferencePercentile":"55.18292683"},{"venue":"AAAI","id":"18662b940e02b02448cc425e3c6cb3d64d533927","venue_1":"AAAI","year":"2012","title":"Learning from Demonstration for Goal-Driven Autonomy","authors":"Ben George Weber, Michael Mateas, Arnav Jhala","author_ids":"1802429, 1780919, 1763814","abstract":"Goal-driven autonomy (GDA) is a conceptual model for creating an autonomous agent that monitors a set of expectations during plan execution, detects when discrepancies occur, builds explanations for the cause of failures , and formulates new goals to pursue when planning failures arise. While this framework enables the development of agents that can operate in complex and dynamic environments, implementing the logic for each of the subtasks in the model requires substantial domain engineering. We present a method using case-based reasoning and intent recognition in order to build GDA agents that learn from demonstrations. Our approach reduces the amount of domain engineering necessary to implement GDA agents and learns expectations, explanations , and goals from expert demonstrations. We have applied this approach to build an agent for the real-time strategy game StarCraft. Our results show that integrating the GDA conceptual model into the agent greatly improves its win rate.","cites":"16","conferencePercentile":"83.23170732"},{"venue":"AAAI","id":"2bf92ce44afaf49ecd4574e5284853cadb6389eb","venue_1":"AAAI","year":"2008","title":"A Demonstration of the RADAR Personal Assistant","authors":"Andrew Faulring, Brad A. Myers, Ken Mohnkern, Michael Freed","author_ids":"2287103, 1707801, 2637272, 1678912","abstract":"Email clients were not designed to serve as a task management tools, but a high volume of task-relevant information in email leads many people to use email clients for this purpose. Such usage aggravates a user's experience of email overload and reduces productivity. Prior research systems have sought to address this problem by experimentally adding task management capabilities to email client software. RADAR (Reflective Agents with Distributed Adaptive Reasoning) takes a different approach in which a software agent acts like a trusted human assistant. Many RADAR components employ machine learning to improve their performance. Human participant studies showed a clear impact of learning on user performance metrics.","cites":"0","conferencePercentile":"7.120253165"},{"venue":"AAAI","id":"12dbbc1f31d302b528e7d260b6a51fb280112ab3","venue_1":"AAAI","year":"2010","title":"Temporal Information Extraction","authors":"Xiao Ling, Daniel S. Weld","author_ids":"3280311, 1780531","abstract":"Research on information extraction (IE) seeks to distill re-lational tuples from natural language text, such as the contents of the WWW. Most IE work has focussed on identifying static facts, encoding them as binary relations. This is unfortunate, because the vast majority of facts are fluents, only holding true during an interval of time. It is less helpful to extract PresidentOf(Bill-Clinton, USA) without the temporal scope 1/20/93-1/20/01. This paper presents TIE, a novel, information-extraction system, which distills facts from text while inducing as much temporal information as possible. In addition to recognizing temporal relations between times and events, TIE performs global inference , enforcing transitivity to bound the start and ending times for each event. We introduce the notion of temporal en-tropy as a way to evaluate the performance of temporal IE systems and present experiments showing that TIE outperforms three alternative approaches.","cites":"65","conferencePercentile":"96.92832765"},{"venue":"AAAI","id":"56c3c82077885275fd91c768b4d963d1bf1bf013","venue_1":"AAAI","year":"2010","title":"Decision-Theoretic Control of Crowd-Sourced Workflows","authors":"Peng Dai, Mausam, Daniel S. Weld","author_ids":"2666496, 2674444, 1780531","abstract":"Crowd-sourcing is a recent framework in which human intelligence tasks are outsourced to a crowd of unknown people (\" workers \") as an open call (e.g., on Amazon's Mechanical Turk). Crowd-sourcing has become immensely popular with hoards of employers (\" requesters \"), who use it to solve a wide variety of jobs, such as dictation transcription, content screening, etc. In order to achieve quality results, requesters often subdivide a large task into a chain of bite-sized subtasks that are combined into a complex, iterative workflow in which workers check and improve each other's results. This paper raises an exciting question for AI — could an autonomous agent control these workflows without human intervention, yielding better results than today's state of the art, a fixed control program? We describe a planner, TURKONTROL, that formulates work-flow control as a decision-theoretic optimization problem, trading off the implicit quality of a solution artifact against the cost for workers to achieve it. We lay the mathematical framework to govern the various decisions at each point in a popular class of workflows. Based on our analysis we implement the workflow control algorithm and present experiments demonstrating that TURKONTROL obtains much higher utilities than popular fixed policies.","cites":"87","conferencePercentile":"98.46416382"},{"venue":"AAAI","id":"15eb39e8ed2c85db3e0cc9458b7f765c7f259224","venue_1":"AAAI","year":"2011","title":"Artificial Intelligence for Artificial Artificial Intelligence","authors":"Peng Dai, Mausam, Daniel S. Weld","author_ids":"2666496, 2674444, 1780531","abstract":"Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TURKONTROL, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TURKONTROL's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money.","cites":"34","conferencePercentile":"95.87628866"},{"venue":"AAAI","id":"2610c7c6d5ed4065798d88cf81a6880ba11f8a7e","venue_1":"AAAI","year":"2012","title":"Ontological Smoothing for Relation Extraction with Minimal Supervision","authors":"Congle Zhang, Raphael Hoffmann, Daniel S. Weld","author_ids":"1799338, 3100993, 1780531","abstract":"Relation extraction, the process of converting natural language text into structured knowledge, is increasingly important. Most successful techniques use supervised machine learning to generate extractors from sentences that have been manually labeled with the relations' arguments. Unfortunately , these methods require numerous training examples, which are expensive and time-consuming to produce. This paper presents ontological smoothing, a semi-supervised technique that learns extractors for a set of minimally-labeled relations. Ontological smoothing has three phases. First, it generates a mapping between the target relations and a background knowledge-base. Second, it uses distant supervision to heuristically generate new training examples for the target relations. Finally, it learns an extractor from a combination of the original and newly-generated examples. Experiments on 65 relations across three target domains show that ontological smoothing can dramatically improve precision and recall, even rivaling fully supervised performance in many cases.","cites":"12","conferencePercentile":"74.54268293"},{"venue":"AAAI","id":"0b51daba5492353196c382a463138df26585063a","venue_1":"AAAI","year":"2012","title":"Dynamically Switching between Synergistic Workflows for Crowdsourcing","authors":"Christopher H. Lin, Mausam, Daniel S. Weld","author_ids":"1999020, 2674444, 1780531","abstract":"To ensure quality results from unreliable crowdsourced workers , task designers often construct complex workflows and aggregate worker responses from redundant runs. Frequently, they experiment with several alternative workflows to accomplish the task, and eventually deploy the one that achieves the best performance during early trials. Surprisingly, this seemingly natural design paradigm does not achieve the full potential of crowdsourcing. In particular , using a single workflow (even the best) to accomplish a task is suboptimal. We show that alternative workflows can compose synergistically to yield much higher quality output. We formalize the insight with a novel probabilistic graphi-cal model. Based on this model, we design and implement AGENTHUNT, a POMDP-based controller that dynamically switches between these workflows to achieve higher returns on investment. Additionally, we design offline and online methods for learning model parameters. Live experiments on Amazon Mechanical Turk demonstrate the superiority of AGENTHUNT for the task of generating NLP training data, yielding up to 50% error reduction and greater net utility compared to previous methods.","cites":"35","conferencePercentile":"96.03658537"},{"venue":"AAAI","id":"0bd16bae8a0d4fdf39923944ca0d3d634166098e","venue_1":"AAAI","year":"2012","title":"LRTDP Versus UCT for Online Probabilistic Planning","authors":"Andrey Kolobov, Mausam, Daniel S. Weld","author_ids":"1778652, 2674444, 1780531","abstract":"UCT, the premier method for solving games such as Go, is also becoming the dominant algorithm for probabilistic planning. Out of the five solvers at the International Probabilistic Planning Competition (IPPC) 2011, four were based on the UCT algorithm. However, while a UCT-based planner, PROST, won the contest, an LRTDP-based system, GLUTTON, came in a close second, outperforming other systems derived from UCT. These results raise a question: what are the strengths and weaknesses of LRTDP and UCT in practice? This paper starts answering this question by contrasting the two approaches in the context of finite-horizon MDPs. We demonstrate that in such scenarios, UCT's lack of a sound termination condition is a serious practical disadvantage. In order to handle an MDP with a large finite horizon under a time constraint, UCT forces an expert to guess a non-myopic lookahead value for which it should be able to converge on the encountered states. Mistakes in setting this parameter can greatly hurt UCT's performance. In contrast, LRTDP's convergence criterion allows for an iterative deepening strategy. Using this strategy, LRTDP automatically finds the largest lookahead value feasible under the given time constraint. As a result, LRTDP has better performance and stronger theoretical properties. We present an online version of GLUTTON, named GOURMAND, that illustrates this analysis and outperforms PROST on the set of IPPC-2011 problems.","cites":"8","conferencePercentile":"59.45121951"},{"venue":"AAAI","id":"559e47c03297bc423c4ee866d042790ea056365c","venue_1":"AAAI","year":"2012","title":"Fine-Grained Entity Recognition","authors":"Xiao Ling, Daniel S. Weld","author_ids":"3280311, 1780531","abstract":"Entity Recognition (ER) is a key component of relation extraction systems and many other natural-language processing applications. Unfortunately, most ER systems are restricted to produce labels from to a small set of entity classes, e.g., person, organization, location or miscellaneous. In order to intelligently understand text and extract a wide range of information , it is useful to more precisely determine the semantic classes of entities mentioned in unstructured text. This paper defines a fine-grained set of 112 tags, formulates the tagging problem as multi-class, multi-label classification, describes an unsupervised method for collecting training data, and presents the FIGER implementation. Experiments show that the system accurately predicts the tags for entities. Moreover , it provides useful information for a relation extraction system, increasing the F1 score by 93%. We make FIGER and its data available as a resource for future work.","cites":"58","conferencePercentile":"98.7804878"},{"venue":"AAAI","id":"5f8da82f5d5deefac0660e898b0bac29fc0f8356","venue_1":"AAAI","year":"2010","title":"SixthSense: Fast and Reliable Recognition of Dead Ends in MDPs","authors":"Andrey Kolobov, Mausam, Daniel S. Weld","author_ids":"1778652, 2674444, 1780531","abstract":"The results of the latest International Probabilistic Planning Competition (IPPC-2008) indicate that the presence of dead ends, states with no trajectory to the goal, makes MDPs hard for modern probabilistic planners. Implicit dead ends, states with executable actions but no path to the goal, are particularly challenging; existing MDP solvers spend much time and memory identifying these states. As a first attempt to address this issue, we propose a machine learning algorithm called SIXTHSENSE. SIXTHSENSE helps existing MDP solvers by finding nogoods, conjunctions of literals whose truth in a state implies that the state is a dead end. Importantly, our learned nogoods are sound, and hence the states they identify are true dead ends. SIXTHSENSE is very fast, needs little training data, and takes only a small fraction of total planning time. While IPPC problems may have millions of dead ends, they may typically be represented with only a dozen or two no-goods. Thus, nogood learning efficiently produces a quick and reliable means for dead-end recognition. Our experiments show that the nogoods found by SIXTHSENSE routinely reduce planning space and time on IPPC domains, enabling some planners to solve problems they could not previously handle.","cites":"12","conferencePercentile":"58.02047782"},{"venue":"AAAI","id":"5670f4e460ccb7e6021b15d50d879a98a7a7b01c","venue_1":"AAAI","year":"2016","title":"Re-Active Learning: Active Learning with Relabeling","authors":"Christopher H. Lin, Mausam, Daniel S. Weld","author_ids":"1999020, 2674444, 1780531","abstract":"Active learning seeks to train the best classifier at the lowest annotation cost by intelligently picking the best examples to label. Traditional algorithms assume there is a single an-notator and disregard the possibility of requesting additional independent annotations for a previously labeled example. However, relabeling examples is important, because all an-notators make mistakes — especially crowdsourced workers, who have become a common source of training data. This paper seeks to understand the difference in marginal value between decreasing the noise of the training set via relabel-ing and increasing the size and diversity of the (noisier) training set by labeling new examples. We use the term re-active learning to denote this generalization of active learning. We show how traditional active learning methods perform poorly at re-active learning, present new algorithms designed for this important problem, formally characterize their behavior, and empirically show that our methods effectively make this tradeoff.","cites":"1","conferencePercentile":"40.70945946"},{"venue":"AAAI","id":"ed4170603c8027f753578b5033b237ce1a3dc400","venue_1":"AAAI","year":"2007","title":"PhotoSlap: A Multi-player Online Game for Semantic Annotation","authors":"Chien-Ju Ho, Tsung-Hsiang Chang, Jane Yung-jen Hsu","author_ids":"3351958, 2337269, 1717095","abstract":"Multimedia content presents special challenges for the search engines, and could benefit from semantic annotation of images. Unfortunately, manual labeling is too tedious and time-consuming for humans, whereas automatic image annotation is too difficult for the computers. In this paper, we explore the power of human computation by designing a multi-player online game, PhotoSlap, to achieve the task of annotating metadata for a collection of digital photos. PhotoSlap engages users in an interactive game that capitalizes on human ability in deciphering quickly whether the same person shows up in two consecutive images presented by the computer. The game mechanism supports the objection and trap actions to encourage truthful input from the players. This research extends human computation research in two aspects: game-theoretic design principles and quantitative evaluation metrics. In particular, Pho-toSlap can be shown to reach subgame perfect equilibrium with the target strategy when players are rational and without collusion. Experiments involving four focus groups have been conducted, and the preliminary results demonstrated the game to be fun and effective in annotating people metadata for photo collections.","cites":"21","conferencePercentile":"72.55192878"},{"venue":"AAAI","id":"4187643a3cbe5a2d9760580eea438110924356bf","venue_1":"AAAI","year":"2007","title":"The PhotoSlap Game: Play to Annotate","authors":"Tsung-Hsiang Chang, Chien-Ju Ho, Jane Yung-jen Hsu","author_ids":"2337269, 3351958, 1717095","abstract":"This paper presents PhotoSlap, an intelligent system for semantic annotation of photos. The system contains a semi-automatic face detector, a bulk annotation tool, and a multi-player online game, PhotoSlap. By exploring the design principles of gameplay and applying game theoretic analysis, PhotoSlap is designed as a fun and productive game, which adapts itself to different players to produce the desired output. Experiments involving four focus groups showed the game to be fun and effective in annotating people metadata for personal photo collections.","cites":"3","conferencePercentile":"25.22255193"},{"venue":"AAAI","id":"3798f3adcdcfda9a63e22579dd1af9ba19f5e564","venue_1":"AAAI","year":"2006","title":"Predicting Task-Specific Webpages for Revisiting","authors":"Arwen Twinkle Lettkeman, Simone Stumpf, Jed Irvine, Jonathan L. Herlocker","author_ids":"2157840, 2121662, 2079303, 2658798","abstract":"With the increased use of the web has come a corresponding increase in information overload that users face when trying to locate specific webpages, especially as a majority of visits to webpages are revisits. While automatically created browsing history lists offer a potential low-cost solution to relocating webpages, even short browsing sessions generate a glut of webpages that do not relate to the user's information need or have no revisit value. We address how we can better support web users who want to return to information on a webpage that they have previously visited by building more useful history lists. The paper reports on a combination technique that semi-automatically segments the webpage browsing history list into tasks, applies heuristics to remove webpages that carry no intrinsic revisit value, and uses a learning model, sensitive to individual users and tasks, that predicts which webpages are likely to be revisited again. We present results from an empirical evaluation that report the likely revisit need of users and that show that adequate overall prediction accuracy can be achieved. This approach can be used to increase utility of history lists by removing information overload to users when revisiting webpages.","cites":"8","conferencePercentile":"46.39769452"},{"venue":"AAAI","id":"f63fe90030f6a85ac340ef24343e9b12a0e0916a","venue_1":"AAAI","year":"1991","title":"Global Symbolic Maps from Local Navigation","authors":"David P. Miller, Marc G. Slack","author_ids":"1793794, 1799854","abstract":"In order to navigate autonomously, most robot systems are provided with some sort of global terrain map. To make storage practical, these maps usually have a high-level symbolic representation of the terrain. The robot's symbolic map is then used to plan a local path. This paper describes a system which uses the reverse (and perhaps more natural) process. This system processes local sensor data in such a way as to allow efficient , reactive local navigation. A byproduct of this navigation process is an abstraction of the terrain information which forms a global symbolic terrain map of the terrain through which the robot has passed. Since this map is in the same format as that used by the local navigation system, the map is easy for the system to use, augment, or correct. Compared with the data from which the maps are created, the maps are very space efficient, and can be modified, or used for navigation in real-time. Experiments with this system, both in simulation, and with a real robot operating in natural terrain, are described.","cites":"15","conferencePercentile":"39.77272727"},{"venue":"AAAI","id":"faab5dcd857d80e5cfe96c3ff2fc382916163d0a","venue_1":"AAAI","year":"1992","title":"Reactive Navigation through Rough Terrain: Experimental Results","authors":"David P. Miller, Rajiv S. Desai, Erann Gat, Robert Ivlev, John Loch","author_ids":"1793794, 2517861, 1698190, 2776171, 3229902","abstract":"This paper describes a series of experiments that were performed on the Rocky III robot. 1 Rocky III is a small autonomous rover capable of navigating through rough outdoor terrain to a predesignated area, searching that area for soft soil, acquiring a soil sample, and depositing the sample in a container at its home base. The robot is programmed according to a reactive behavior-control paradigm using the ALFA programming language. This style of programming produces robust autonomous performance while requiring significantly less computational resources than more traditional mobile robot control systems. The code for Rocky III runs on an 8-bit processor and uses about 10k of memory.","cites":"33","conferencePercentile":"55.35714286"},{"venue":"AAAI","id":"80082ce044b275f4c701a3caaebffcd6876e2e2f","venue_1":"AAAI","year":"1993","title":"Comprehensibility Improvement of Tabular Knowledge Bases","authors":"Atsushi Sugiura, Maximilian Riesenhuber, Yoshiyuki Koseki","author_ids":"1805436, 1996960, 1772335","abstract":"This paper discusses the important issue of knowledge base comprehensibility and describes a technique for comprehensibility improvement. Com-prehensibility is often measured by simplicity of concept description. Even in the simplest form, however, there will be a number of dierent DNF (Disjunctive Normal Form) descriptions possible to represent the same concept, and each of these will have a dierent degree of comprehensibility. In other words, simplication does not necessarily guarantee improved comprehensibility. In this paper , the authors introduce three new comprehen-sibility criteria, similarity, continuity, and conformity , for use with tabular knowledge bases. In addition, they propose an algorithm to convert a decision table with poor comprehensibility to one with high comprehensibility, while preserving logical equivalency. In experiments, the algorithm generated either the same or similar tables to those generated by humans.","cites":"3","conferencePercentile":"9.459459459"},{"venue":"AAAI","id":"a0cc9f66d2b1d1f87b0967602703f386aa858eb4","venue_1":"AAAI","year":"2014","title":"Improving Semi-Supervised Target Alignment via Label-Aware Base Kernels","authors":"Qiaojun Wang, Kai Zhang, Guofei Jiang, Ivan Marsic","author_ids":"2939773, 4420840, 1791767, 1707841","abstract":"Semi-supervised kernel design is an essential step for obtaining good predictive performance in semi-supervised learning tasks. In the current literatures, a large family of algorithms builds the new kernel by using the weighted average of pre-defined base kernels. While optimal weighting schemes have been studied extensively, the choice of base kernels received much less attention. Many methods simply adopt the empirical kernel matrices or its eigenvectors. Such base kernels are computed irrespective of class labels and may not always reflect useful structures in the data. As a result, in case of poor base kernels, the generalization performance can be degraded however hard their weights are tuned. In this paper, we propose to construct high-quality base kernels with the help of label information to globally improve the final target alignment. In particular, we devise label-aware kernel eigenvec-tors under the framework of semi-supervised eigenfunction extrapolation, which span base kernels that are more useful for learning. Such base kernels are individually better aligned to the learning target, so their mixture will more likely generate a good classifier. Our approach is computationally efficient , and demonstrates encouraging performance in semi-supervised classification and regression.","cites":"0","conferencePercentile":"9.431818182"},{"venue":"AAAI","id":"001ea2418661ab6a22ca1758ec84ca8c1e756b71","venue_1":"AAAI","year":"2014","title":"Semantical Clustering of Morphologically Related Chinese Words","authors":"Chia-Ling Lee, Ya-Ning Chang, Chao-Lin Liu, Chia-Ying Lee, Jane Yung-jen Hsu","author_ids":"1909823, 7312715, 1689269, 1706365, 1717095","abstract":"A Chinese character embedded in different compound words may carry different meanings. In this paper, we aim at semantic clustering of a given family of morphologically related Chinese words. In Experiment 1, we employed linguistic features at the word, syntactic, semantic , and contextual levels in aggregated computational linguistics methods to handle the clustering task. In Experiment 2, we recruited adults and children to perform the clustering task. Experimental results indicate that our computational model achieved a similar level of performance as children.","cites":"0","conferencePercentile":"9.431818182"},{"venue":"AAAI","id":"88180436465597501ba74392af48208bc210a6d3","venue_1":"AAAI","year":"2013","title":"Information Sharing for Care Coordination","authors":"Ofra Amir","author_ids":"2212554","abstract":"Teamwork and care coordination are of increasing importance to health care delivery and patient safety and health. My research aims at developing agents that are able to make intelligent information sharing decisions to support a diverse, evolving team of care providers in constructing and maintaining a shared plan that operates in uncertain environments.","cites":"0","conferencePercentile":"9.090909091"},{"venue":"AAAI","id":"5f74529fe7708b52dac23559a5ea481fb770aa2f","venue_1":"AAAI","year":"2008","title":"Partitioned External-Memory Value Iteration","authors":"Peng Dai, Mausam, Daniel S. Weld","author_ids":"2666496, 2674444, 1780531","abstract":"Dynamic programming methods (including value iteration, LAO*, RTDP, and derivatives) are popular algorithms for solving Markov decision processes (MDPs). Unfortunately, however, these techniques store the MDP model extension-ally in a table and thus are limited by the amount of main memory available. Since the required space is exponential in the number of domain features, these dynamic programming methods are ineffective for large problems. To address this problem, Edelcamp et al. devised the external memory value iteration (EMVI) algorithm, which uses a clever sorting scheme to efficiently move parts of the model between disk and main memory. While EMVI can handle larger problems than previously addressed, the need to repeatedly perform external sorts still limits scalability. This paper proposes a new approach. We partition an MDP into smaller pieces (blocks), keeping just the relevant blocks in memory and performing Bellman backups block by block. Experiments show that our algorithm is able to solve large MDPs an order of magnitude faster than EMVI.","cites":"3","conferencePercentile":"28.16455696"},{"venue":"AAAI","id":"28460f94ab04ab288295822d0bf0f71b314a5fbf","venue_1":"AAAI","year":"2005","title":"Extending Continuous Time Bayesian Networks","authors":"Karthik Gopalratnam, Henry A. Kautz, Daniel S. Weld","author_ids":"2854178, 1690271, 1780531","abstract":"Continuous-time Bayesian networks (CTBNs) (Nodelman, Shelton, & Koller 2002; 2003), are an elegant modeling language for structured stochastic processes that evolve over continuous time. The CTBN framework is based on homogeneous Markov processes, and defines two distributions with respect to each local variable in the system, given its parents: an exponential distribution over when the variable transitions, and a multinomial over what is the next value. In this paper, we present two extensions to the framework that make it more useful in modeling practical applications. The first extension models arbitrary transition time distributions using Erlang-Coxian approximations, while maintaining tractable learning. We show how the censored data problem arises in learning the distribution, and present a solution based on expectation-maximization initialized by the Kaplan-Meier estimate. The second extension is a general method for reasoning about negative evidence, by introducing updates that assert no observable events occur over an interval of time. Such updates were not defined in the original CTBN framework, and we show show that their inclusion can significantly improve the accuracy of filtering and prediction. We illustrate and evaluate these extensions in two real-world domains, email use and GPS traces of a person traveling about a city.","cites":"18","conferencePercentile":"64.86013986"},{"venue":"AAAI","id":"5970ca773725a8fa655fb17cf2fb10e4d4879977","venue_1":"AAAI","year":"2007","title":"Computing Optimal Subsets","authors":"Maxim Binshtok, Ronen I. Brafman, Solomon Eyal Shimony, Ajay Mani, Craig Boutilier","author_ids":"3258018, 1680506, 1719613, 2395506, 2105432","abstract":"Various tasks in decision making and decision support require selecting a preferred subset of items from a given set of feasible items. Recent work in this area considered methods for specifying such preferences based on the attribute values of individual elements within the set. Of these, the approach of (Brafman et al. 2006) appears to be the most general. In this paper, we consider the problem of computing an optimal subset given such a specification. The problem is shown to be NP-hard in the general case, necessitating heuristic search methods. We consider two algorithm classes for this problem: direct set construction, and implicit enumeration as solutions to appropriate CSPs. New algorithms are presented in each class and compared empirically against previous results.","cites":"9","conferencePercentile":"50.44510386"},{"venue":"AAAI","id":"6f5969cd6365bf9938d8b68cdfb47086900d8c3f","venue_1":"AAAI","year":"2006","title":"Factored Planning: How, When, and When Not","authors":"Ronen I. Brafman, Carmel Domshlak","author_ids":"1680506, 1735824","abstract":"Automated domain factoring, and planning methods that utilize them, have long been of interest to planning researchers. Recent work in this area yielded new theoretical insight and algorithms, but left many questions open: How to decompose a domain into factors? How to work with these fac-tors? And whether and when decomposition-based methods are useful? This paper provides theoretical analysis that answers many of these questions: it proposes a novel approach to factored planning; proves its theoretical superiority over previous methods; provides insight into how to factor domains ; and uses its novel complexity results to analyze when factored planning is likely to perform well, and when not. It also establishes the key role played by the domain's causal graph in the complexity analysis of planning algorithms.","cites":"75","conferencePercentile":"95.96541787"},{"venue":"AAAI","id":"05cd246da501f1a14c42ff9855c12d9f7a11c7a0","venue_1":"AAAI","year":"2006","title":"Preferences over Sets","authors":"Ronen I. Brafman, Carmel Domshlak, Solomon Eyal Shimony, Y. Silver","author_ids":"1680506, 1735824, 1719613, 1921203","abstract":"Typically, work on preference elicitation and reasoning about preferences has focused on the problem of specifying, modeling, and optimizing with preference over outcomes corresponding to single objects of interest. In a number of applications, however, the \" outcomes \" of interest are really sets of such atomic outcomes. For instance, when trying to form coalitions or committees, we need to select an optimal combination of individuals. In this paper we describe some initial work on specifying preferences over sets of objects, and selecting an optimal subset from a given set of objects. In particular , we show how TCP-nets can be used to handle this problem, and how an existing algorithm for preference-based constrained optimization can be adapted to the problem of optimal subset selection.","cites":"13","conferencePercentile":"59.51008646"},{"venue":"AAAI","id":"7af2cb072d6f8685beb10ff685d84a32c2bfdce4","venue_1":"AAAI","year":"2005","title":"Optimal Efficient Learning Equilibrium: Imperfect Monitoring in Symmetric Games","authors":"Ronen I. Brafman, Moshe Tennenholtz","author_ids":"1680506, 1708847","abstract":"Efficient Learning Equilibrium (ELE) is a natural solution concept for multi-agent encounters with incomplete information. It requires the learning algorithms themselves to be in equilibrium for any game selected from a set of (initially unknown) games. In an optimal ELE, the learning algorithms would efficiently obtain the surplus the agents would obtain in an optimal Nash equilibrium of the initially unknown game which is played. The crucial part is that in an ELE deviations from the learning algorithms would become non-beneficial after polynomial time, although the game played is initially unknown. While appealing conceptually, the main challenge for establishing learning algorithms based on this concept is to isolate general classes of games where an ELE exists. Unfortunately , it has been shown that while an ELE exists for the setting in which each agent can observe all other agents' actions and payoffs, an ELE does not exist in general when the other agents' payoffs cannot be observed. In this paper we provide the first positive results on this problem, constructively proving the existence of an optimal ELE for the class of symmetric games where an agent can not observe other agents' payoffs.","cites":"9","conferencePercentile":"39.86013986"},{"venue":"AAAI","id":"45d8776353608aa55bc82ceccf5c1c2be5db5665","venue_1":"AAAI","year":"1993","title":"Towards Knowledge-Level Analysis of Motion Planning","authors":"Ronen I. Brafman, Jean-Claude Latombe, Yoav Shoham","author_ids":"1680506, 1694248, 1701353","abstract":"Inspired by the success of the distributed computing community in applying logics of knowledge and time to reasoning about distributed protocols, we aim for a similarly powerful and high-level abstraction when reasoning about control problems involving uncertainty. Here we concentrate on robot motion planning, with uncertainty in both control and sensing. This problem has already been well studied within the robotics community. Our contributions include the following: We deene a new, natural problem in this domain: obtaining a sound and complete termination condition, given initial and goal locations. We consider a speciic class of (simple) motion plans in R n from the literature, and provide necessary and suucient conditions for the existence of sound and complete termination conditions for plans in that class. We deene a high-level language, a logic of time and knowledge, to reason about motion plans in the presence of uncertainty, and use them to provide general conditions for the existence of sound and complete termination conditions for a broader class of motion plans.","cites":"11","conferencePercentile":"30.40540541"},{"venue":"AAAI","id":"0f7f1b3b7b8660ca2cb04a8890ae921326fd0edb","venue_1":"AAAI","year":"2004","title":"Text Classification by Labeling Words","authors":"Bing Liu, Xiaoli Li, Wee Sun Lee, Philip S. Yu","author_ids":"2201323, 2617520, 1740222, 1703117","abstract":"Traditionally, text classifiers are built from labeled training examples. Labeling is usually done manually by human experts (or the users), which is a labor intensive and time consuming process. In the past few years, researchers investigated various forms of semi-supervised learning to reduce the burden of manual labeling. In this paper, we propose a different approach. Instead of labeling a set of documents, the proposed method labels a set of representative words for each class. It then uses these words to extract a set of documents for each class from a set of unlabeled documents to form the initial training set. The EM algorithm is then applied to build the classifier. The key issue of the approach is how to obtain a set of representative words for each class. One way is to ask the user to provide them, which is difficult because the user usually can only give a few words (which are insufficient for accurate learning). We propose a method to solve the problem. It combines clustering and feature selection. The technique can effectively rank the words in the unlabeled set according to their importance. The user then selects/labels some words from the ranked list for each class. This process requires less effort than providing words with no help or manual labeling of documents. Our results show that the new method is highly effective and promising.","cites":"89","conferencePercentile":"94.61077844"},{"venue":"AAAI","id":"33e7c15599f8e73a3df84debd615c03b1ec45b15","venue_1":"AAAI","year":"2011","title":"Integrating Community Question and Answer Archives","authors":"Wei Wei, Gao Cong, Xiaoli Li, See-Kiong Ng, Guohui Li","author_ids":"1725923, 1737379, 2617520, 1794527, 2023936","abstract":"Question and answer pairs in Community Question Answering (CQA) services are organized into hierarchical structures or taxonomies to facilitate users to find the answers for their questions conveniently. We observe that different CQA services have their own knowledge focus and used different tax-onomies to organize their question and answer pairs in their archives. As there are no simple semantic mappings between the taxonomies of the CQA services, the integration of CQA services is a challenging task. The existing approaches on integrating taxonomies ignore the hierarchical structures of the source taxonomy. In this paper, we propose a novel approach that is capable of incorporating the parent-child and sibling information in the hierarchical structures of the source taxon-omy for accurate taxonomy integration. Our experimental results with real world CQA data demonstrate that the proposed method significantly outperforms state-of-the-art methods.","cites":"5","conferencePercentile":"42.43986254"},{"venue":"AAAI","id":"891cf6d6f599944fcd4740368fa7f0bf35a133bd","venue_1":"AAAI","year":"2006","title":"Probabilistic Temporal Planning with Uncertain Durations","authors":"Mausam, Daniel S. Weld","author_ids":"2674444, 1780531","abstract":"Few temporal planners handle both concurrency and uncertain durations, but these features commonly co-occur in real-world domains. In this paper, we discuss the challenges caused by concurrent, durative actions whose durations are uncertain. We present five implemented algorithms, including ∆DUR prun, a planner guaranteed to find the optimal policy. An empirical comparison reveals that ∆DURexp, our fastest planner, obtains orders of magnitude speed-up compared to ∆DURprun— with little loss in solution quality. Importantly , our algorithms can handle probabilistic effects in addition to stochastic durations, and they are effective even when duration distributions are multi-modal.","cites":"17","conferencePercentile":"65.56195965"},{"venue":"AAAI","id":"55ce907d81337f01aea97b99cbefac2b8fbdfee9","venue_1":"AAAI","year":"2012","title":"ET-LDA: Joint Topic Modeling for Aligning Events and their Twitter Feedback","authors":"Yuheng Hu, Ajita John, Fei Wang, Subbarao Kambhampati","author_ids":"2731506, 2984639, 1723185, 1740315","abstract":"During broadcast events such as the Superbowl, the U.S. Presidential and Primary debates, etc., Twitter has become the de facto platform for crowds to share perspectives and commentaries about them. Given an event and an associated large-scale collection of tweets, there are two fundamental research problems that have been receiving increasing attention in recent years. One is to extract the topics covered by the event and the tweets; the other is to segment the event. So far these problems have been viewed separately and studied in isolation. In this work, we argue that these problems are in fact interdependent and should be addressed together. We develop a joint Bayesian model that performs topic modeling and event segmentation in one unified framework. We evaluate the proposed model both quantitatively and qualitatively on two large-scale tweet datasets associated with two events from different domains to show that it improves significantly over baseline models.","cites":"28","conferencePercentile":"93.59756098"},{"venue":"AAAI","id":"6d60a75db8de1e657eb7f65c5b9d448d4c534259","venue_1":"AAAI","year":"2013","title":"From Interest to Function: Location Estimation in Social Media","authors":"Yan Chen, Jichang Zhao, Xia Hu, Xiaoming Zhang, Zhoujun Li, Tat-Seng Chua","author_ids":"1700696, 8648757, 1687568, 1679013, 1707275, 1684968","abstract":"Recent years have witnessed the tremendous development of social media, which attracts a vast number of Internet users. The high-dimension content generated by these users provides an unique opportunity to understand their behavior deeply. As one of the most fundamental topics, location estimation attracts more and more research efforts. Different from the previous literature , we find that user's location is strongly related to user interest. Based on this, we first build a detection model to mine user interest from short text. We then establish the mapping between location function and user interest before presenting an efficient framework to predict the user's location with convincing fidelity. Thorough evaluations and comparisons on an authentic data set show that our proposed model significantly outperforms the state-of-the-arts approaches. Moreover, the high efficiency of our model also guarantees its applicability in real-world scenarios.","cites":"9","conferencePercentile":"79.45454545"},{"venue":"AAAI","id":"5d7b38e37b08136ed0518ea2d83be2baab7b74e2","venue_1":"AAAI","year":"1993","title":"Real-Time Self-Explanatory Simulation","authors":"Franz G. Amador, Adam Finkelstein, Daniel S. Weld","author_ids":"3074881, 1707541, 1780531","abstract":"We present Pika, an implemented self-explanatory simulator that is more than 5000 times faster than SimGen Mk2 [Forbus and Falkenhainer, 1992], the previous state of the art. Like SimGen, Pika automatically prepares and runs a numeric simulation of a physical device specied as a particular in-stantiation of a general domain theory, and it is capable of explaining its reasoning and the simulated behavior. Unlike SimGen, Pika's model-ing language allows arbitrary algebraic and differential equations with no prespecied causal direction ; Pika infers the appropriate causality and solves the equations as necessary to prepare for numeric integration.","cites":"21","conferencePercentile":"53.37837838"},{"venue":"AAAI","id":"16b1b7e8ba1172003093216b95d1bc0e557fd200","venue_1":"AAAI","year":"1993","title":"Innovative Design as Systematic Search","authors":"Dorothy Neville, Daniel S. Weld","author_ids":"2292922, 1780531","abstract":"We present a new algorithm, sie, for designing lumped parameter models from rst principles. sie uses a qualitative representation of parameter interactions to guide its search and speed the test for working designs. But sie's interaction set representation is considerably simpler than ibis's space of potential and existing interactions. Furthermore, sie is both complete and systematic | it explores the space of possible designs in an nonredundant manner.","cites":"4","conferencePercentile":"12.83783784"},{"venue":"AAAI","id":"a4e58566ad9bc746aaf6737286f324587408329a","venue_1":"AAAI","year":"1993","title":"A Framework for Model-Based Repair","authors":"Ying Sun, Daniel S. Weld","author_ids":"1707882, 1780531","abstract":"We describe irs, a program that combines partial-order planning with gde-style, model-based diagnosis to achieve a n i n tegrated approach to repair. Our system makes three contributions to the eld of diagnosis. First, we provide a unied treatment o f b o t h information-gathering and state-altering actions via the uwl representation language. Second, we describe a w a y to use part-replacement operations (in addition to probes) to gather diagnostic information. Finally, we dene a cost function for decision making that accounts for both the eventual need to repair broken parts and the dependence of costs on the device state.","cites":"12","conferencePercentile":"33.78378378"},{"venue":"AAAI","id":"2a2a1aade8fa04cdb705eda9bf8630567b12afa5","venue_1":"AAAI","year":"1994","title":"Temporal Planning with Continuous Change","authors":"J. Scott Penberthy, Daniel S. Weld","author_ids":"2280042, 1780531","abstract":"we present ZENO, a least commitment planner that handles actions occurring over extended intervals of time. Deadline goals, metric preconditions , metric effects, and continuous change are supported. Simultaneous actions are alIowed when their effects do not interfere. Unlike most planners that deal with complex languages, the ZENO planning algorithm is sound and complete. The running code is a complete implementation of the formal algorithm, capable of solving simple problems (i.e., those involving less than a dozen steps).","cites":"112","conferencePercentile":"95.15418502"},{"venue":"AAAI","id":"5ee9cba780815c063c90068d77632dda8522627e","venue_1":"AAAI","year":"1994","title":"Task-Decomposition via Plan Parsing","authors":"Anthony Barrett, Daniel S. Weld","author_ids":"3953542, 1780531","abstract":"Task-decomposition planners make use of schemata that dene tasks in terms of partially ordered sets of tasks and primitive actions. Most existing task-decomposition planners synthesize plans via a top-down approach, called task reduction, which uses schemata to replace tasks with networks of tasks and actions until only actions remain. In this paper we present a bottom-up plan parsing approach to task-decomposition. Instead of reducing tasks into actions, we use an incremental parsing algorithm to recognize which partial primitive plans match the schemata. In essence, our approach exploits the observation that schemata are a convenient means for reducing search. We compile the schemata into a declarative search control language (like that used in machine learning research), which rejects plan renements that cannot be parsed. We demonstrate that neither parsing nor reduction dominates the other on eciency grounds and provide preliminary empirical results comparing the two. We note that our parsing approach allows convenient comparison (and combination) of dierent search control technologies, generates minimal plans, and handles expressive languages (e.g., universal quantication and conditional eects) with ease.","cites":"29","conferencePercentile":"70.26431718"},{"venue":"AAAI","id":"1ec03afff525b056897700ebe37202212825add4","venue_1":"AAAI","year":"2004","title":"Solving Concurrent Markov Decision Processes","authors":"Mausam, Daniel S. Weld","author_ids":"2674444, 1780531","abstract":"Typically, Markov decision problems (MDPs) assume a single action is executed per decision epoch, but in the real world one may frequently execute certain actions in parallel. This paper explores concurrent MDPs, MDPs which allow multiple non-conflicting actions to be executed simultaneously, and presents two new algorithms. Our first approach exploits two provably sound pruning rules, and thus guarantees solution optimality. Our second technique is a fast, sampling-based algorithm, which produces close-to-optimal solutions extremely quickly. Experiments show that our approaches outperform the existing algorithms producing up to two orders of magnitude speedup.","cites":"21","conferencePercentile":"62.5748503"},{"venue":"AAAI","id":"390d21356ca6c7c9764a70b0688ed96424819bec","venue_1":"AAAI","year":"2013","title":"Negative Influence Minimizing by Blocking Nodes in Social Networks","authors":"Senzhang Wang, Xiaojian Zhao, Yan Chen, Zhoujun Li, Kai Zhang, Jiali Xia","author_ids":"3210262, 1710473, 1700696, 1707275, 4420840, 2089731","abstract":"Social networks are becoming vital platforms for the spread of positive information such as innovations and negative information propagation like malicious rumors. In this paper, we address the problem of minimizing the influence of negative information. When negative information such as a rumor emerges in the social network and part of users have already adopted it, our goal is to minimize the size of ultimately contaminated users by discovering and blocking k uninfected users. A greedy method for efficiently finding a good approximate solution to this problem is proposed. The comparison experimental results on the Enron email network dataset demonstrate our proposed method is more effective than centrality based methods, such as degree centrality, betweenness centrality and PageRank.","cites":"2","conferencePercentile":"37.09090909"},{"venue":"AAAI","id":"30fc251eefe47c6ab77b9b75cbfb4c01bcb23e99","venue_1":"AAAI","year":"2012","title":"Lessons Learned From a Rational Reconstruction of Minstrel","authors":"Brandon Robert Tearse, Peter A. Mawhorter, Michael Mateas, Noah Wardrip-Fruin","author_ids":"2663075, 3100313, 1780919, 2814077","abstract":"Scott Turner's 1993 Minstrel system was a high water mark in story generation, harnessing the concept of imaginative recall to generate creative stories. Using case based reasoning and an author level planning system, Minstrel models human creative processes. However, the algorithmic and representational commitments made in Minstrel were never subject to principled and quantitative analysis. By rationally reconstructing Minstrel, we are able to investigate Turner's computational model of creativity and learn new lessons about his architecture. We find that Minstrel's original performance was tied to a well groomed case library, but by modifying several components of the algorithm we can create a more general version which can construct stories using a sparser and less structured case library. Through a rational reconstruction of Minstrel, we both learn new architectural and algorithmic lessons about Minstrel's computational model of creativity as well as make his architecture available to the contemporary research community for further experimentation.","cites":"3","conferencePercentile":"30.79268293"},{"venue":"AAAI","id":"073cdeb933afa65d7b82b6656340fee49461cdbd","venue_1":"AAAI","year":"2015","title":"Multi-Agent Pathfinding as a Combinatorial Auction","authors":"Ofra Amir, Guni Sharon, Roni Stern","author_ids":"2212554, 2360602, 2106020","abstract":"This paper proposes a mapping between multi-agent pathfinding (MAPF) and combinatorial auctions (CAs). In MAPF, agents need to reach their goal destinations without colliding. Algorithms for solving MAPF aim at assigning agents non-conflicting paths that minimize agents' travel costs. In CA problems, agents bid over bundles of items they desire. Auction mechanisms aim at finding an allocation of bundles that maximizes social welfare. In the proposed mapping of MAPF to CAs, agents bid on paths to their goals and the auction allocates non-colliding paths to the agents. Using this formulation, auction mechanisms can be naturally used to solve a range of MAPF problem variants. In particular, auction mechanisms can be applied to non-cooperative settings with self-interested agents while providing optimality guarantees and robustness to manipulations by agents. The paper further shows how to efficiently implement an auction mechanism for MAPF, utilizing methods and representations from both the MAPF and CA literatures.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"ce5a3ed72e4e12b53899d0b3cbb859e1ce197678","venue_1":"AAAI","year":"2016","title":"On the Effectiveness of Linear Models for One-Class Collaborative Filtering","authors":"Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, Darius Braziunas","author_ids":"2095747, 2844480, 1732536, 2239754","abstract":"In many personalised recommendation problems, there are examples of items users prefer or like, but no examples of items they dislike. A state-of-the-art method for such implicit feedback, or one-class collaborative filtering (OC-CF), problems is SLIM, which makes recommendations based on a learned item-item similarity matrix. While SLIM has been shown to perform well on implicit feedback tasks, we argue that it is hindered by two limitations: first, it does not produce user-personalised predictions, which hampers recommendation performance; second, it involves solving a constrained optimisation problem, which impedes fast training. In this paper, we propose LRec, a variant of SLIM that overcomes these limitations without sacrificing any of SLIM's strengths. At its core, LRec employs linear logistic regression; despite this simplicity, LRec consistently and significantly outperforms all existing methods on a range of datasets. Our results thus illustrate that the OC-CF problem can be effectively tackled via linear classification models.","cites":"5","conferencePercentile":"86.31756757"},{"venue":"AAAI","id":"49e4261cfec45821b047f046dfc875359223cf2d","venue_1":"AAAI","year":"2008","title":"Examining Difficulties Software Developers Encounter in the Adoption of Statistical Machine Learning","authors":"Kayur Patel, James Fogarty, James A. Landay, Beverly L. Harrison","author_ids":"2760803, 1738171, 1708404, 1768833","abstract":"Statistical machine learning continues to show promise as a tool for addressing complex problems in a variety of domains. An increasing number of developers are therefore looking to use statistical machine learning algorithms within applications. We have conducted two initial studies examining the difficulties that developers encounter when creating a statistical machine learning component of a larger application. We first interviewed researchers with experience integrating statistical machine learning into applications. We then sought to directly observe and quantify some of the behavior described in our interviews using a laboratory study of developers attempting to build a simple application that uses statistical machine learning. This paper presents the difficulties we observed in our studies, discusses current challenges to developer adoption of statistical machine learning, and proposes potential approaches to better supporting developers creating statistical machine learning components of applications.","cites":"8","conferencePercentile":"49.52531646"},{"venue":"AAAI","id":"25ee19989640de8f9142eb2174bb1ddc6ad6067a","venue_1":"AAAI","year":"1994","title":"Toward the Essential Nature of Statistical Knowledge in Sense Resolution","authors":"Jill Fain Lehman","author_ids":"2142730","abstract":"The statistical basis for sense resolution decisions is arrived at by the application of a process to a corpus of instances. In general, once the process has been applied to the corpus, the system contains both some residual representation of the instances and some explicit augmentation of that representation with information that was implicit in the corpus. For example, part of the residual representation of He feels happy on Fridays might be the (word sense) pair (happy feel-as-emotion), and part of the augmentation might be the probability of happy co-occurring with the sense of feel as an emotion. We show that for the simple residual representation of (word sense) pairs, the existence of such a representation in and of itself captures much of the regularity inherent in the data. We also demonstrate that augmenting the residual representation with the actual number of times each pair occurs in the training corpus provides most of the remainder of the power of probabalistic approaches. Finally, we show how viewing this residual representation as a form of episodic memory can enable symbolic, knowledge-rich systems to take advantage of this source of regularity in performing sense resolution.'","cites":"11","conferencePercentile":"47.57709251"},{"venue":"AAAI","id":"014da84e90231a62a3a0f69a8558d349592207c9","venue_1":"AAAI","year":"2013","title":"Take or Wait? Learning Turn-Taking from Multiparty Data","authors":"Iolanda Leite, Hannaneh Hajishirzi, Sean Andrist, Jill Fain Lehman","author_ids":"1698537, 2548384, 2211183, 2142730","abstract":"We build turn-taking models for autonomous characters in language-based interactions with small groups of children. Two models explore the use of support vector machines given the same multimodal features, but different methods for collecting turn-taking labels.","cites":"2","conferencePercentile":"37.09090909"},{"venue":"AAAI","id":"1b09809b79a7b053391bdd414d4233132747f6ec","venue_1":"AAAI","year":"2011","title":"Effective End-User Interaction with Machine Learning","authors":"Saleema Amershi, James Fogarty, Ashish Kapoor, Desney S. Tan","author_ids":"1719124, 1738171, 7665582, 1719056","abstract":"End-user interactive machine learning is a promising tool for enhancing human productivity and capabilities with large unstructured data sets. Recent work has shown that we can create end-user interactive machine learning systems for specific applications. However, we still lack a generalized understanding of how to design effective end-user interaction with interactive machine learning systems. This work presents three explorations in designing for effective end-user interaction with machine learning in CueFlik, a system developed to support Web image search. These explorations demonstrate that interactions designed to balance the needs of end-users and machine learning algorithms can significantly improve the effectiveness of end-user interactive machine learning.","cites":"17","conferencePercentile":"81.27147766"},{"venue":"AAAI","id":"ff661ceab11a5461421fce637c2f78de059c4edf","venue_1":"AAAI","year":"2011","title":"Integrating Rules and Description Logics by Circumscription","authors":"Qian Yang, Jia-Huai You, Zhiyong Feng","author_ids":"1762791, 8352837, 1683334","abstract":"We present a new approach to characterizing the semantics for the integration of rules and first-order logic in general, and description logics in particular, based on a circumscrip-tion characterization of answer set programming, introduced earlier by Lin and Zhou. We show that both Rosati's semantics based on NM-models and Lukasiewicz's answer set semantics can be characterized by circumscription, and the difference between the two can be seen as a matter of circum-scription policies. This approach leads to a number of new insights. First, we rebut a criticism on Lukasiewicz's semantics for its inability to reason for negative consequences. Second, our approach leads to a spectrum of possible semantics based on different circumscription policies, and shows a clear picture of how they are related. Finally, we show that the idea of this paper can be applied to first-order general stable models.","cites":"1","conferencePercentile":"16.15120275"},{"venue":"AAAI","id":"43425cc021b4615c863f1c5f63656a9dd221169d","venue_1":"AAAI","year":"2014","title":"Advice Provision for Energy Saving in Automobile Climate Control Systems","authors":"Amos Azaria, Sarit Kraus, Claudia V. Goldman, Omer Tsimhoni","author_ids":"1746466, 1691597, 1728547, 1723297","abstract":"Reducing energy consumption of climate control systems is important in order to reduce human environmental footprint. The need to save energy becomes even greater when considering an electric car, since heavy use of the climate control system may exhaust the battery. In this paper we consider a method for an automated agent to provide advice to drivers which will motivate them to reduce the energy consumption of their climate control unit. Our approach takes into account both the energy consumption of the climate control system and the expected comfort level of the driver. We therefore build two models, one for assessing the energy consumption of the climate control system as a function of the system's settings, and the other, models human comfort level as a function of the climate control sys-tem's settings. Using these models, the agent provides advice to the driver considering how to set the climate control system. The agent advises settings which try to preserve a high level of comfort while consuming as little energy as possible. We empirically show that drivers equipped with our agent which provides them with advice significantly save energy as compared to drivers not equipped with our agent.","cites":"10","conferencePercentile":"87.27272727"},{"venue":"AAAI","id":"8384c3276c376175bfa4645806ba549de65547d9","venue_1":"AAAI","year":"2016","title":"Personalized Alert Agent for Optimal User Performance","authors":"Avraham Shvartzon, Amos Azaria, Sarit Kraus, Claudia V. Goldman, Joachim Meyer, Omer Tsimhoni","author_ids":"2135414, 1746466, 1691597, 1728547, 1740608, 1723297","abstract":"Preventive maintenance is essential for the smooth operation of any equipment. Still, people occasionally do not maintain their equipment adequately. Maintenance alert systems attempt to remind people to perform maintenance. However, most of these systems do not provide alerts at the optimal timing, and nor do they take into account the time required for maintenance or compute the optimal timing for a specific user. We model the problem of maintenance performance, assuming maintenance is time consuming. We solve the optimal policy for the user, i.e., the optimal timing for a user to perform maintenance. This optimal strategy depends on the value of user's time, and thus it may vary from user to user and may change over time. Based on the solved optimal strategy we present a personalized maintenance agent, which, depending on the value of user's time, provides alerts to the user when she should perform maintenance. In an experiment using a spaceship computer game, we show that receiving alerts from the personalized alert agent significantly improves user performance.","cites":"1","conferencePercentile":"40.70945946"},{"venue":"AAAI","id":"3d61ed4e32292bdac1985a2c089378307429f3b7","venue_1":"AAAI","year":"2010","title":"The Genetic Algorithm as a General Diffusion Model for Social Networks","authors":"Mayank Lahiri, Manuel Cebrián","author_ids":"2965558, 1709539","abstract":"Diffusion processes taking place in social networks are used to model a number of phenomena, such as the spread of human or computer viruses, and the adoption of products in 'viral marketing' campaigns. It is generally difficult to obtain accurate information about how such spreads actually occur, so a variety of stochastic diffusion models are used to simulate spreading processes in networks instead. We show that a canonical genetic algorithm with a spatially distributed population , when paired with specific forms of Holland's synthetic hyperplane-defined objective functions, can simulate a large and rich class of diffusion models for social networks. These include standard diffusion models, such as the independent cascade and competing processes models. In addition , our genetic algorithm diffusion model (GADM) can also model complex phenomena such as information diffusion. We demonstrate an application of the GADM to modeling information flow in a large, dynamic social network derived from e-mail headers.","cites":"14","conferencePercentile":"63.48122867"},{"venue":"AAAI","id":"fd4a23990114bb86c149c35c0feff5c055cd9c11","venue_1":"AAAI","year":"2016","title":"Text Classification with Heterogeneous Information Network Kernels","authors":"Chenguang Wang, Yangqiu Song, Haoran Li, Ming Zhang, Jiawei Han","author_ids":"8205951, 1809614, 3274802, 1720939, 1722175","abstract":"Text classification is an important problem with many applications. Traditional approaches represent text as a bag-of-words and build classifiers based on this representation. Rather than words, entity phrases, the relations between the entities, as well as the types of the entities and relations carry much more information to represent the texts. This paper presents a novel text as network classification framework , which introduces 1) a structured and typed heterogeneous information networks (HINs) representation of texts, and 2) a meta-path based approach to link texts. We show that with the new representation and links of texts, the struc-tured and typed information of entities and relations can be incorporated into kernels. Particularly, we develop both simple linear kernel and indefinite kernel based on meta-paths in the HIN representation of texts, where we call them HIN-kernels. Using Freebase, a well-known world knowledge base, to construct HIN for texts, our experiments on two benchmark datasets show that the indefinite HIN-kernel based on weighted meta-paths outperforms the state-of-the-art methods and other HIN-kernels.","cites":"6","conferencePercentile":"90.2027027"},{"venue":"AAAI","id":"3aa4bcb9f1891fde90790090ba828e03c716675c","venue_1":"AAAI","year":"2008","title":"Sparse Projections over Graph","authors":"Deng Cai, Xiaofei He, Jiawei Han","author_ids":"1745280, 3945955, 1722175","abstract":"Recent study has shown that canonical algorithms such as Principal Component Analysis (PCA) and Linear Discrimi-nant Analysis (LDA) can be obtained from graph based di-mensionality reduction framework. However, these algorithms yield projective maps which are linear combination of all the original features. The results are difficult to be interpreted psychologically and physiologically. This paper presents a novel technique for learning a sparse projection over graphs. The data in the reduced subspace is represented as a linear combination of a subset of the most relevant features. Comparing to PCA and LDA, the results obtained by sparse projection are often easier to be interpreted. Our algorithm is based on a graph embedding model, which encodes the discriminating and geometrical structure in terms of the data affinity. Once the embedding results are obtained, we then apply regularized regression for learning a set of sparse basis functions. Specifically, by using a L1-norm regular-izer (e.g. lasso), the sparse projections can be efficiently computed. Experimental results on two document databases demonstrate the effectiveness of our method.","cites":"5","conferencePercentile":"37.65822785"},{"venue":"AAAI","id":"32eeba2ff1ef4259de7802c8ee8cecb6d6c581a3","venue_1":"AAAI","year":"2007","title":"Isometric Projection","authors":"Deng Cai, Xiaofei He, Jiawei Han","author_ids":"1745280, 3945955, 1722175","abstract":"Recently the problem of dimensionality reduction has received a lot of interests in many fields of information processing. We consider the case where data is sampled from a low dimensional manifold which is embedded in high dimensional Euclidean space. The most popular manifold learning algorithms include Locally Linear Embedding, ISOMAP, and Laplacian Eigenmap. However, these algorithms are nonlin-ear and only provide the embedding results of training samples. In this paper, we propose a novel linear dimensional-ity reduction algorithm, called Isometric Projection. Iso-metric Projection constructs a weighted data graph where the weights are discrete approximations of the geodesic distances on the data manifold. A linear subspace is then obtained by preserving the pairwise distances. In this way, Isometric Projection can be defined everywhere. Comparing to Principal Component Analysis (PCA) which is widely used in data processing , our algorithm is more capable of discovering the intrinsic geometrical structure. Specially, PCA is optimal only when the data space is linear, while our algorithm has no such assumption and therefore can handle more complex data space. Experimental results on two real life data sets illustrate the effectiveness of the proposed method.","cites":"25","conferencePercentile":"76.2611276"},{"venue":"AAAI","id":"71bbdd26105f0614f40b05b6ac164ba7a81a07d4","venue_1":"AAAI","year":"2006","title":"Using Anticipation to Create Believable Behaviour","authors":"Carlos Martinho, Ana Paiva","author_ids":"1682637, 1738084","abstract":"Although anticipation is an important part of creating believable behaviour, it has had but a secondary role in the field of lifelike characters. In this paper, we show how a simple an-ticipatory mechanism can be used to control the behaviour of a synthetic character implemented as a software agent, without disrupting the user's suspension of disbelief. We describe the emotivector, an anticipatory mechanism coupled with a sensor, that: (1) uses the history of the sensor to anticipate the next sensor state; (2) interprets the mismatch between the prediction and the sensed value, by computing its attention grabbing potential and associating a basic qualitative sensation with the signal; (3) sends its interpretation along with the signal. When a signal from the sensor reaches the processing module of the agent, it carries recommendations such as: \" you should seriously take this signal into consideration, as it is much better than we had expected \" or \" just forget about this one, it is as bad as we predicted \". We delineate several strategies to manage several emotivectors at once and show how one of these strategies (meta-anticipation) transparently introduces the concept of uncertainty. Finally, we describe an experiment in which an emotivector-controlled synthetic character interacts with the user in the context of a word-puzzle game and present the evaluation supporting the adequacy of our approach.","cites":"16","conferencePercentile":"63.54466859"},{"venue":"AAAI","id":"37ffc9412005d030e99fa8c6dc7c6192b022a9ee","venue_1":"AAAI","year":"2013","title":"An Agent Model for the Appraisal of Normative Events Based in In-Group and Out-Group Relations","authors":"Nuno Ferreira, Samuel Mascarenhas, Ana Paiva, Gennaro di Tosto, Frank Dignum, John McBreen, Nick Degens, Gert Jan Hofstede, Giulia Andrighetto, Rosaria Conte","author_ids":"4216570, 2479450, 1738084, 2231570, 1716665, 2221824, 3175881, 2584600, 3317753, 1781042","abstract":"Emotional synthetic characters are able to evaluate (appraise) events as positive or negative with their emotional states being triggered by several factors. Currently , the vast majority of models for appraisal in synthetic characters consider factors related to the goals and preferences of the characters. We argue that appraisals that only take into consideration these \" personal \" factors are incomplete as other more social factors , such as the normative and the social context, including in-group and out-group relations, should be considered as well. Without them, moral emotions such as shame cannot be appraised, limiting the believabil-ity of the characters in certain situations. We present a model for the appraisal of characters' actions that evaluates whether actions by in-group and out-group members which conform, or not, to social norms generate different emotions depending on the social relations between the characters. The model was then implemented in an architecture for virtual agents and evaluated with humans. Results suggest that the emotions generated by our model are perceived by the participants, taking into account the social context and that participants experienced very similar emotions, both in type and intensity, to the emotions appraised and generated by the characters .","cites":"4","conferencePercentile":"55.45454545"},{"venue":"AAAI","id":"65c5c9056b10cdd16743524fffa9508c7272d01d","venue_1":"AAAI","year":"2010","title":"What Is an Opinion About? Exploring Political Standpoints Using Opinion Scoring Model","authors":"Bi Chen, Leilei Zhu, Daniel Kifer, Dongwon Lee","author_ids":"5177468, 8674984, 1852261, 1784227","abstract":"In this paper, we propose a generative model to automatically discover the hidden associations between topics words and opinion words. By applying those discovered hidden associations, we construct the opinion scoring models to extract statements which best express opinionists' standpoints on certain topics. For experiments , we apply our model to the political area. First, we visualize the similarities and dissimilarities between Republican and Democratic senators with respect to various topics. Second, we compare the performance of the opinion scoring models with 14 kinds of methods to find the best ones. We find that sentences extracted by our opinion scoring models can effectively express opinionists' standpoints.","cites":"11","conferencePercentile":"54.94880546"},{"venue":"AAAI","id":"590159c5f3bdfaf785a31b9f0c814d2c8f6f05d0","venue_1":"AAAI","year":"2012","title":"Non-Intrusive Load Monitoring Using Prior Models of General Appliance Types","authors":"Oliver Parson, Siddhartha Ghosh, Mark Weal, Alex Rogers","author_ids":"1862622, 1771217, 4507255, 1793672","abstract":"Non-intrusive appliance load monitoring is the process of dis-aggregating a household's total electricity consumption into its contributing appliances. In this paper we propose an approach by which individual appliances can be iteratively separated from an aggregate load. Unlike existing approaches, our approach does not require training data to be collected by sub-metering individual appliances, nor does it assume complete knowledge of the appliances present in the household. Instead, we propose an approach in which prior models of general appliance types are tuned to specific appliance instances using only signatures extracted from the aggregate load. The tuned appliance models are then used to estimate each appliance's load, which is subsequently subtracted from the aggregate load. This process is applied iteratively until all appliances for which prior behaviour models are known have been disaggregated. We evaluate the accuracy of our approach using the REDD data set, and show the disaggregation performance when using our training approach is comparable to when sub-metered training data is used. We also present a deployment of our system as a live application and demonstrate the potential for personalised energy saving feedback.","cites":"68","conferencePercentile":"99.3902439"},{"venue":"AAAI","id":"070664ceec7498f487b30b9f8e9bcd5ed58200f7","venue_1":"AAAI","year":"2008","title":"The Swarm Application Framework","authors":"Don Miner, Marie desJardins, Peter Hamilton","author_ids":"2249405, 1762584, 3267198","abstract":"The Swarm Application Framework (SAF) is a tool that makes the development of swarm applications more intuitive. Traditionally, swarm applications are created by programming several low-level rules. This approach leads to several problems in designing and testing swarms, which serve as inspiration for the features of SAF. SAF encourages a new paradigm for designing swarm applications: engineers can interact with a swarm at the abstract (swarm) level instead of the individual (agent) level. In this paper, we discuss the design of the framework, how agents and rules in SAF operate, and a planned rule abstraction feature.","cites":"2","conferencePercentile":"23.41772152"},{"venue":"AAAI","id":"68026944b1228a7f29d9d75ee243f19fde50f342","venue_1":"AAAI","year":"2011","title":"Learning a Kernel for Multi-Task Clustering","authors":"Quanquan Gu, Zhenhui Li, Jiawei Han","author_ids":"8155584, 1717163, 1722175","abstract":"Multi-task learning has received increasing attention in the past decade. Many supervised multi-task learning methods have been proposed, while unsupervised multi-task learning is still a rarely studied problem. In this paper , we propose to learn a kernel for multi-task clustering. Our goal is to learn a Reproducing Kernel Hilbert Space, in which the geometric structure of the data in each task is preserved, while the data distributions of any two tasks are as close as possible. This is formulated as a unified kernel learning framework, under which we study two types of kernel learning: nonparametric kernel learning and spectral kernel design. Both types of kernel learning can be solved by linear programming. Experiments on several cross-domain text data sets demonstrate that kernel k-means on the learned kernel can achieve better clustering results than traditional single-task clustering methods. It also outperforms the newly proposed multi-task clustering method.","cites":"16","conferencePercentile":"80.41237113"},{"venue":"AAAI","id":"9912b4d4a298c768b5f3d33f70586cb0cd366ba8","venue_1":"AAAI","year":"2015","title":"When Suboptimal Rules","authors":"Avshalom Elmalech, David Sarne, Avi Rosenfeld, Eden Shalom Erez","author_ids":"1822933, 1707363, 1955991, 1898888","abstract":"This paper represents a paradigm shift in what advice agents should provide people. Contrary to what was previously thought, we empirically show that agents that dispense optimal advice will not necessary facilitate the best improvement in people's strategies. Instead, we claim that agents should at times suboptimally advise. We provide results demonstrating the effectiveness of a suboptimal advising approach in extensive experiments in two canonical mixed agent-human advice-giving domains. Our proposed guideline for subopti-mal advising is to rely on the level of intuitiveness of the optimal advice as a measure for how much the suboptimal advice presented to the user should drift from the optimal value.","cites":"6","conferencePercentile":"84.80314961"},{"venue":"AAAI","id":"fae70cfaf7e7f2ebeb517dee8e1e91d611289031","venue_1":"AAAI","year":"2008","title":"Protein Structure Prediction on the Face Centered Cubic Lattice by Local Search","authors":"Manuel Cebrián, Iván Dotú, Pascal Van Hentenryck, Peter Clote","author_ids":"1709539, 1795628, 8388443, 1721166","abstract":"Ab initio protein structure prediction is an important problem for which several algorithms have been developed. Algorithms differ by how they represent 3D protein conformations (on-lattice, off-lattice, coarse-grain or fine-grain model), by the energy model they consider, and whether they are heuris-tic or exact algorithms. This paper presents a local search algorithm to find the native state for the Hydrophobic-Polar (HP) model on the Face Centered Cubic (FCC) lattice; i.e. a self-avoiding walk on the FCC lattice with maximum number of H-H contacts. The algorithm relies on a randomized, structured initialization, a novel fitness function to guide the search, and efficient data structures to obtain self-avoiding walks. Experimental results on benchmark instances show the efficiency and excellent performance of our algorithm, and illustrate the biological pertinence of the FCC lattice.","cites":"15","conferencePercentile":"68.82911392"},{"venue":"AAAI","id":"0e479e8738b153b20fc2e49692d3d3a0297299c5","venue_1":"AAAI","year":"2016","title":"Incremental Stochastic Factorization for Online Reinforcement Learning","authors":"André da Motta Salles Barreto, Rafael L. Beirigo, Joelle Pineau, Doina Precup","author_ids":"1689289, 2907660, 1723772, 1724729","abstract":"A construct that has been receiving attention recently in reinforcement learning is stochastic factorization (SF), a particular case of non-negative factorization (NMF) in which the matrices involved are stochastic. The idea is to use SF to approximate the transition matrices of a Markov decision process (MDP). This is useful for two reasons. First, learning the factors of the SF instead of the transition matrices can reduce significantly the number of parameters to be estimated. Second , it has been shown that SF can be used to reduce the number of operations needed to compute an MDP's value function. Recently, an algorithm called expectation-maximization SF (EMSF) has been proposed to compute a SF directly from transitions sampled from an MDP. In this paper we take a closer look at EMSF. First, by exploiting the assumptions underlying the algorithm, we show that it is possible to reduce it to simple multiplicative update rules similar to the ones that helped popularize NMF. Second, we analyze the optimization process underlying EMSF and find that it minimizes a modified version of the Kullback-Leibler divergence that is particularly well-suited for learning a SF from data sampled from an arbitrary distribution. Third, we build on this improved understanding of EMSF to draw an interesting connection with NMF and probabilistic latent semantic analysis. We also exploit the simplified update rules to introduce a new version of EMSF that generalizes and significantly improves its precursor. This new algorithm provides a practical mechanism to control the trade-off between memory usage and computing time, essentially freeing the space complexity of EMSF from its dependency on the number of sample transitions. The algorithm can also compute its approximation incrementally, which makes it possible to use it concomitantly with the collection of data. This feature makes the new version of EMSF particularly suitable for online reinforcement learning. Empirical results support the utility of the proposed algorithm.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"2c85356cd182c16e0a2e5c4a97112efbc1132cdf","venue_1":"AAAI","year":"2004","title":"Metrics for Finite Markov Decision Processes","authors":"Norm Ferns, Prakash Panangaden, Doina Precup","author_ids":"1757489, 1784317, 1724729","abstract":"Markov decision processes (MDPs) offer a popular mathematical tool for planning and learning in the presence of uncertainty (Boutilier, Dean, & Hanks 1999). MDPs are a standard formalism for describing multi-stage decision making in probabilistic environments. The objective of the decision making is to maximize a cumulative measure of long-term performance, called the return. Dynamic programming algorithms, e.g., value iteration or policy iteration (Puterman 1994), allow us to compute the optimal expected return for any state, as well as the way of behaving (policy) that generates this return. However, in many practical applications the state space of an MDP is simply too large, possibly even continuous, for such standard algorithms to be applied. A typical means of overcoming such circumstances is to partition the state space in the hope of obtaining an \" essentially equivalent \" reduced system. One defines a new MDP over the partition blocks, and if it is small enough, it can be solved by classical methods. The hope is that optimal values and policies for the reduced MDP can be extended to optimal values and policies for the original MDP. The notion of equivalence for stochastic processes is problematic because it requires that the transition probabilities agree exactly. This is not a robust concept, especially considering that usually, the numbers used in probabilistic models come from experimentation or are approximate estimates ; what is needed is a quantitative notion of equivalence. In our work we provide such a notion via semimetrics, distance functions on the state space that assign distances quantifying \" how equivalent \" states are. These semimetrics could potentially be used as a new theoretical tool to analyze current state compression algorithms for MDPs, or in practice to guide state aggregation directly. The ultimate goal of this research is to efficiently compress and analyze continuous state space MDPs. Here we focus on finite MDPs, but note that most of our results should hold, with slight modifications , in the context of continuous state spaces. Recent MDP research on defining equivalence relations on MDPs (Givan, Dean, & Greig 2003) has built on the notion of strong probabilistic bisimulation from concurrency theory. Bisimulation was introduced by Larsen and Skou Roughly speaking, two states of a process are deemed equivalent if all the transitions of one state can be matched by transitions of the other state, and the results are themselves bisimilar. The extension of bisimulation to …","cites":"47","conferencePercentile":"86.22754491"},{"venue":"AAAI","id":"085ff88b5adfb598b2a6ba7e93c3593fe0925063","venue_1":"AAAI","year":"2006","title":"Representing Systems with Hidden State","authors":"Christopher Hundt, Prakash Panangaden, Joelle Pineau, Doina Precup","author_ids":"2818697, 1784317, 1723772, 1724729","abstract":"We discuss the problem of finding a good state representation in stochastic systems with observations. We develop a duality theory that generalizes existing work in predictive state representations as well as automata theory. We discuss how this theoretical framework can be used to build learning algorithms, approximate planning algorithms as well as to deal with continuous observations .","cites":"6","conferencePercentile":"40.20172911"},{"venue":"AAAI","id":"06820436117be0ff39186cad7236c4226cf2bcf4","venue_1":"AAAI","year":"2010","title":"Using Bisimulation for Policy Transfer in MDPs","authors":"Pablo Samuel Castro, Doina Precup","author_ids":"2282000, 1724729","abstract":"Knowledge transfer has been suggested as a useful approach for solving large Markov Decision Processes. The main idea is to compute a decision-making policy in one environment and use it in a different environment, provided the two are \" close enough \". In this paper, we use bisimulation-style met-rics (Ferns et al., 2004) to guide knowledge transfer. We propose algorithms that decide what actions to transfer from the policy computed on a small MDP task to a large task, given the bisimulation distance between states in the two tasks. We demonstrate the inherent \" pessimism \" of bisimulation met-rics and present variants of this metric aimed to overcome this pessimism, leading to improved action transfer. We also show that using this approach for transferring temporally extended actions (Sutton et al., 1999) is more successful than using it exclusively with primitive actions. We present theoretical guarantees on the quality of the transferred policy, as well as promising empirical results.","cites":"6","conferencePercentile":"36.86006826"},{"venue":"AAAI","id":"3aa9a101d4d3ae1c532d1794f01dc2b54de01802","venue_1":"AAAI","year":"2010","title":"Activity and Gait Recognition with Time-Delay Embeddings","authors":"Jordan Frank, Shie Mannor, Doina Precup","author_ids":"1978412, 1712535, 1724729","abstract":"Activity recognition based on data from mobile wearable devices is becoming an important application area for machine learning. We propose a novel approach based on a combination of feature extraction using time-delay embedding and supervised learning. The computational requirements are considerably lower than existing approaches, so the processing can be done in real time on a low-powered portable device such as a mobile phone. We evaluate the performance of our algorithm on a large, noisy data set comprising over 50 hours of data from six different subjects, including activities such as running and walking up or down stairs. We also demonstrate the ability of the system to accurately classify an individual from a set of 25 people, based only on the characteristics of their walking gait. The system requires very little parameter tuning, and can be trained with small amounts of data.","cites":"40","conferencePercentile":"91.80887372"},{"venue":"AAAI","id":"299a88f4de2603e6fe0bdc10ca57caf4fe188d85","venue_1":"AAAI","year":"2011","title":"Learning Compact Representations of Time-Varying Processes","authors":"Philip Bachman, Doina Precup","author_ids":"1723066, 1724729","abstract":"We seek informative representations of the processes underlying time series data. As a first step, we address problems in which these processes can be approximated by linear models that vary smoothly over time. To facilitate estimation of these linear models, we introduce a method of dimension reduction which significantly reduces error when models are estimated locally for each point in time. This improvement is gained by performing dimension reduction implicitly through the model parameters rather than directly in the observation space. Methodology Modeling and predicting the behavior of processes that vary over time is a field rife with potential applications. Our approach to modeling such processes is related to prior work such as projection pursuit regression (Friedman and Stuetzle 1981), sliced inverse regression (Li 1991), locally-weighted regression (Atkeson, Moore, and Schaal 1997), and varying-coefficient models (Hastie and Tibshirani 1993). Additionally , our approach can serve to extend more recent work, with the learning of varying-coefficient/varying-structure models (Kolar, Song, and Xing 2009) and the learning of time-varying graphical models (Song, Kolar, and Xing 2009) being perhaps the most immediate examples. Formally, our method seeks a set of b basis functions {β 1 , ..., β b } such that, at each time t, the observed output y t can be predicted from the observed input x t as follows: y t = b i=1 a i t (β i · x t), (1) where we assume y t is univariate, x t is n-dimensional, the basis weights a i t vary smoothly over time, and the · represents a dot product. To learn a suitable set of b basis functions for a sequence of m observations drawn from a particular process, we first perform a locally-weighted regression on the sequence so that at each time point y t ≈ ˆ β t · x t , where: ˆ β t = arg minˆβ m t =1 w σ (t , t)||y t − (ˆ β · x t)|| 2 , (2) where w σ (t , t) is a (Gaussian) kernel weighting function, with mean t and width σ, evaluated at t. If the observation generating process can be approximated by (1), and the basis weights a i t are changing sufficiently smoothly with respect to the kernel width σ, a reasonable set of basis functions should appear as the principal components of the set of pseudo-observations comprising the coefficient vectors …","cites":"0","conferencePercentile":"5.841924399"},{"venue":"AAAI","id":"052fed41fb7e56178fe681b2cd3e86020f8dc8b4","venue_1":"AAAI","year":"2012","title":"Compressed Least-Squares Regression on Sparse Spaces","authors":"Mahdi Milani Fard, Yuri Grinberg, Joelle Pineau, Doina Precup","author_ids":"2852410, 2534418, 1723772, 1724729","abstract":"Recent advances in the area of compressed sensing suggest that it is possible to reconstruct high-dimensional sparse signals from a small number of random projections. Domains in which the sparsity assumption is applicable also offer many interesting large-scale machine learning prediction tasks. It is therefore important to study the effect of random projections as a dimensional-ity reduction method under such sparsity assumptions. In this paper we develop the bias–variance analysis of a least-squares regression estimator in compressed spaces when random projections are applied on sparse input signals. Leveraging the sparsity assumption, we are able to work with arbitrary non i.i.d. sampling strategies and derive a worst-case bound on the entire space. Empirical results on synthetic and real-world datasets shows how the choice of the projection size affects the performance of regression on compressed spaces, and highlights a range of problems where the method is useful. Modern machine learning methods have to deal with overwhelmingly large datasets, e.g. for text, sound, image and video processing, as well as for time series prediction and analysis. Much of this data contains very high numbers of features or attributes, sometimes exceeding the number of labelled instances available for training. Even though learning from such data may seem hopeless, in reality, the data often contains structure which can facilitate the development of learning algorithms. In this paper, we focus on a very common type of structure, in which the instances are sparse, in the sense that a very small percentage of the features in each instance is non-zero. For example, a text may be encoded as a very large feature vector (millions of dimensions) with each feature being 1 if a corresponding dictionary word is present in the text, and zero otherwise. Hence, in each document, a very small number of features will be non-zero. Several algorithms have been designed to deal with this setting (which we discuss in detail at the end of the paper). Here, we focus on a new class of methods for learning in large, sparse feature sets: random projections (Daven-port, Wakin, and Baraniuk 2006; Baraniuk and Wakin 2009). Random projections have originated recently in the signal The idea was motivated by the need to sample and store very efficiently large datasets (such as images and video). The basic idea is that if the signal is generated as a linear combination of a small set of functions (chosen from a much …","cites":"12","conferencePercentile":"74.54268293"},{"venue":"AAAI","id":"5fb3c6c605bbc152126ef87bc7cf1cdfaf6b91a6","venue_1":"AAAI","year":"2015","title":"Representation Discovery for MDPs Using Bisimulation Metrics","authors":"Sherry Shanshan Ruan, Gheorghe Comanici, Prakash Panangaden, Doina Precup","author_ids":"2844010, 1819858, 1784317, 1724729","abstract":"We provide a novel, flexible, iterative refinement algorithm to automatically construct an approximate state-space representation for Markov Decision Processes (MDPs). Our approach leverages bisimulation metrics, which have been used in prior work to generate features to represent the state space of MDPs. We address a drawback of this approach, which is the expensive computation of the bisimulation metrics. We propose an algorithm to generate an iteratively improving sequence of state space partitions. Partial metric computations guide the representation search and provide much lower space and computational complexity, while maintaining strong convergence properties. We provide theoretical results guaranteeing convergence as well as experimental illustrations of the accuracy and savings (in time and memory usage) of the new algorithm, compared to traditional bisimulation metric computation.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"551a0949a520ae40e47d5979dbfb35aa94b4a6fc","venue_1":"AAAI","year":"2012","title":"Algorithmic and Human Teaching of Sequential Decision Tasks","authors":"Maya Cakmak, Manuel Lopes","author_ids":"1790096, 8317919","abstract":"A helpful teacher can significantly improve the learning rate of a learning agent. Teaching algorithms have been formally studied within the field of Algorithmic Teaching. These give important insights into how a teacher can select the most informative examples while teaching a new concept. However the field has so far focused purely on classification tasks. In this paper we introduce a novel method for optimally teaching sequential decision tasks. We present an algorithm that automatically selects the set of most informative demonstrations and evaluate it on several navigation tasks. Next, we explore the idea of using this algorithm to produce instructions for humans on how to choose examples when teaching sequential decision tasks. We present a user study that demonstrates the utility of such instructions.","cites":"20","conferencePercentile":"89.32926829"},{"venue":"AAAI","id":"140ef106e99b2cf354e7e2586e780e08af2a60b3","venue_1":"AAAI","year":"2013","title":"RockIt: Exploiting Parallelism and Symmetry for MAP Inference in Statistical Relational Models","authors":"Jan Nößner, Mathias Niepert, Heiner Stuckenschmidt","author_ids":"3138118, 2780262, 1698459","abstract":"ROCKIT is a maximum a-posteriori (MAP) query engine for statistical relational models. MAP inference in graphical models is an optimization problem which can be compiled to integer linear programs (ILPs). We describe several advances in translating MAP queries to ILP instances and present the novel meta-algorithm cutting plane aggregation (CPA). CPA exploits local context-specific symmetries and bundles up sets of linear constraints. The resulting counting constraints lead to more compact ILPs and make the symmetry of the ground model more explicit to state-of-the-art ILP solvers. Moreover, ROCKIT parallelizes most parts of the MAP inference pipeline taking advantage of ubiquitous shared-memory multi-core architectures. We report on extensive experiments with Markov logic network (MLN) benchmarks showing that ROCKIT outperforms the state-of-the-art systems ALCHEMY, MARKOV THEBEAST, and TUFFY both in terms of efficiency and quality of results.","cites":"41","conferencePercentile":"98.90909091"},{"venue":"AAAI","id":"3aa8d2a7493fe56a317f7ac2f2a9108e71a633e0","venue_1":"AAAI","year":"2010","title":"A Probabilistic-Logical Framework for Ontology Matching","authors":"Mathias Niepert, Christian Meilicke, Heiner Stuckenschmidt","author_ids":"2780262, 1795542, 1698459","abstract":"Ontology matching is the problem of determining correspondences between concepts, properties, and individuals of different heterogeneous ontologies. With this paper we present a novel probabilistic-logical framework for ontology matching based on Markov logic. We define the syntax and semantics and provide a for-malization of the ontology matching problem within the framework. The approach has several advantages over existing methods such as ease of experimentation, inco-herence mitigation during the alignment process, and the incorporation of a-priori confidence values. We show empirically that the approach is efficient and more accurate than existing matchers on an established ontol-ogy alignment benchmark dataset.","cites":"37","conferencePercentile":"90.61433447"},{"venue":"AAAI","id":"541146c75ea36a3a334edae3782e0ddd9fb05317","venue_1":"AAAI","year":"2007","title":"Partial Matchmaking using Approximate Subsumption","authors":"Heiner Stuckenschmidt","author_ids":"1698459","abstract":"Description Logics, and in particular the web ontology language OWL has been proposed as an appropriate basis for computing matches between structured objects for the sake of information integration and service discovery. A drawback of the direct use of subsumption as a matching criterion is the inability to compute partial matches and qualify the degree of mismatch. In this paper, we describe a method for overcoming these problems that is based on approximate logical reasoning. In particular, we approximate the subsumption relation by defining the notion of subsumption with respect to a certain subset of the concept and relation names. We present the formal semantics of this relation, describe a sound and complete algorithm for computing approximate subsumption and discuss its application to matching tasks.","cites":"20","conferencePercentile":"71.21661721"},{"venue":"AAAI","id":"d350745cd04e2f1a4d60dd045779de2d1775c5b5","venue_1":"AAAI","year":"2014","title":"The Importance of Cognition and Affect for Artificially Intelligent Decision Makers","authors":"Celso de Melo, Jonathan Gratch, Peter J. Carnevale","author_ids":"1977901, 1730824, 3126441","abstract":"Agency – the capacity to plan and act – and experience – the capacity to sense and feel – are two critical aspects that determine whether people will perceive non-human entities, such as autonomous agents, to have a mind. There is evidence that the absence of either can reduce cooperation. We present an experiment that tests the necessity of both for cooperation with agents. In this experiment we manipulated people's perceptions about the cognitive and affective abilities of agents, when engaging in the ultimatum game. The results indicated that people offered more money to agents that were perceived to make decisions according to their intentions (high agency), rather than randomly (low agency). Additionally, the results showed that people offered more money to agents that expressed emotion (high experience), when compared to agents that did not (low experience). We discuss the implications of this agency-experience theoretical framework for the design of artificially intelligent decision makers.","cites":"1","conferencePercentile":"25.90909091"},{"venue":"AAAI","id":"3bb1555124dafca5db939169c71d62c676aa908d","venue_1":"AAAI","year":"2007","title":"The More the Merrier: Multi-Party Negotiation with Virtual Humans","authors":"Patrick G. Kenny, Arno Hartholt, Jonathan Gratch, David R. Traum, Stacy Marsella, William R. Swartout","author_ids":"3181776, 1705118, 1730824, 1784659, 1788771, 1684040","abstract":"The goal of the Virtual Humans Project at the University of Southern California's Institute for Creative Technologies is to enrich virtual training environments with virtual humans – autonomous agents that support face-to-face interaction with trainees in a variety of roles – through bringing together many different areas of research including speech recognition, natural language understanding, dialogue management, cognitive modeling, emotion modeling, non-verbal behavior and speech and knowledge management. The demo at AAAI will focus on our work using virtual humans to train negotiation skills. Conference attendees will negotiate with a virtual human doctor and elder to try to move a clinic out of harm's way in single and multi-party negotiation scenarios using the latest iteration of our Virtual Humans framework. The user will use natural speech to talk to the embodied agents, who will respond in accordance with their internal task model and state. The characters will carry out a multi-party dialogue with verbal and non-verbal behavior. A video of a single-party version of the scenario was shown at AAAI-06. This new interactive demo introduces several new features, including multi-party negotiation, dynamically generated non-verbal behavior and a central ontology.","cites":"1","conferencePercentile":"13.94658754"},{"venue":"AAAI","id":"6e5c1bebdb61e7c8dec448e10f1fe2709e917c1a","venue_1":"AAAI","year":"2006","title":"Towards a Validated Model of \"Emotional Intelligence\"","authors":"Jonathan Gratch, Stacy Marsella, Wenji Mao","author_ids":"1730824, 1788771, 2419472","abstract":"This article summarizes recent progress in developing a validated computational account of the cognitive antecedents and consequences of emotion. We describe the potential of this work to impact a variety of AI problem domains.","cites":"13","conferencePercentile":"59.51008646"},{"venue":"AAAI","id":"11dc7c7b97eb9c3421e0c23c3bf410fb9baa5719","venue_1":"AAAI","year":"1994","title":"Improving Learning Performance Through Rational Resource Allocation","authors":"Jonathan Gratch, Steve A. Chien, Gerald DeJong","author_ids":"1730824, 1733548, 1802807","abstract":"This article shows how rational analysis can be used to minimize learning cost for a general class of statistical learning problems. We discuss the factors that influence learning cost and show that the problem of effr-cient learning can be cast as a resource optimization problem. Solutions found in this way can be significantly more efficient than the best solutions that do not account for these factors. We introduce a heuristic learning algorithm that approximately solves this optimization problem and document its performance improvements on synthetic and real-world problems. se1191]) of these factors to minimize learning cost. We discuss this in the context of parametric hypothesis selection problems, an abstract class of statistical learning problems where a system must select one of a finite set of hypothesized courses of action, where the quality of each hypothesis is described as a function of some unknown parameters (e.g. A learning system determines and refines estimates of these parameters by \" paying for \" training examples.","cites":"10","conferencePercentile":"46.25550661"},{"venue":"AAAI","id":"2e3e9046a2bd8cd8f871fb068ddd9650a4e7a580","venue_1":"AAAI","year":"1992","title":"COMPOSER: A Probabilistic Solution to the Utility Problem in Speed-Up Learning","authors":"Jonathan Gratch, Gerald DeJong","author_ids":"1730824, 1802807","abstract":"In machine learning there is considerable interest in techniques which improve planning ability. Initial investigations have identified a wide variety of techniques to address this issue. Progress has been hampered by the utility problem , a basic tradeoff between the benefit of learned knowledge and the cost to locate and apply relevant knowledge. In this paper we describe the COMPOSER system which embodies a probabilistic solution to the utility problem. We outline the statistical foundations of our approach and compare it against four other approaches which appear in the literature .","cites":"71","conferencePercentile":"81.25"},{"venue":"AAAI","id":"edac5e6e5b2acc83740238c43426d8a9dd9084bc","venue_1":"AAAI","year":"2013","title":"Towards Joint Inference for Complex Ontology Matching","authors":"Christian Meilicke, Jan Nößner, Heiner Stuckenschmidt","author_ids":"1795542, 3138118, 1698459","abstract":"In this paper, we show how to model the matching problem as a problem of joint inference. In opposite to existing approaches , we distinguish between the layer of labels and the layer of concepts and properties. Entities from both layers appear as first class citizens in our model. We present an example and explain the benefits of our approach. Moreover, we argue that our approach can be extended to generate correspondences involving complex concept descriptions.","cites":"3","conferencePercentile":"47.09090909"},{"venue":"AAAI","id":"82514167c90906e6dc60c105509996c1a62f9ba2","venue_1":"AAAI","year":"2010","title":"Fast Algorithms for Top-k Approximate String Matching","authors":"Zhenglu Yang, Jianjun Yu, Masaru Kitsuregawa","author_ids":"2881049, 2936762, 1716799","abstract":"Top-k approximate querying on string collections is an important data analysis tool for many applications, and it has been exhaustively studied. However, the scale of the problem has increased dramatically because of the prevalence of the Web. In this paper, we aim to explore the efficient top-k similar string matching problem. Several efficient strategies are introduced, such as length aware and adaptive q-gram selection. We present a general q-gram based framework and propose two efficient algorithms based on the strategies introduced. Our techniques are experimentally evaluated on three real data sets and show a superior performance.","cites":"14","conferencePercentile":"63.48122867"},{"venue":"AAAI","id":"662d2e372aa707dca23f267769654a344ce904d5","venue_1":"AAAI","year":"2013","title":"Automated Workflow Synthesis","authors":"Haoqi Zhang, Eric Horvitz, David C. Parkes","author_ids":"3162562, 1688884, 1702994","abstract":"By coordinating efforts from humans and machines, human computation systems can solve problems that machines cannot tackle alone. A general challenge is to design efficient human computation algorithms or work-flows with which to coordinate the work of the crowd. We introduce a method for automated workflow synthesis aimed at ideally harnessing human efforts by learning about the crowd's performance on tasks and synthesizing an optimal workflow for solving a problem. We present experimental results for human sorting tasks, which demonstrate both the benefit of understanding and optimizing the structure of workflows based on observations. Results also demonstrate the benefits of using value of information to guide experiments for identifying efficient workflows with fewer experiments.","cites":"4","conferencePercentile":"55.45454545"},{"venue":"AAAI","id":"21a05dd05de42514eaad7b9be9174d442e183f1e","venue_1":"AAAI","year":"2015","title":"SMT-Based Nonlinear PDDL+ Planning","authors":"Daniel Bryce, Sicun Gao, David J. Musliner, Robert P. Goldman","author_ids":"2264691, 2236979, 2871109, 2473054","abstract":"PDDL+ planning involves reasoning about mixed discrete-continuous change over time. Nearly all PDDL+ planners assume that continuous change is linear. We present a new technique that accommodates nonlinear change by encoding problems as nonlinear hybrid systems. Using this encoding , we apply a Satisfiability Modulo Theories (SMT) solver to find plans. We show that it is important to use a novel planning-specific heuristic for variable selection for SMT solving, which is inspired by recent advances in planning as SAT. We show the promising performance of the resulting solver on challenging nonlinear problems.","cites":"9","conferencePercentile":"91.96850394"},{"venue":"AAAI","id":"1742163f76dcaa65eb2bb65c33e04799b6861546","venue_1":"AAAI","year":"2010","title":"Panlingual Lexical Translation via Probabilistic Inference","authors":"Mausam, Stephen Soderland, Oren Etzioni","author_ids":"2674444, 2751022, 1741101","abstract":"The bare minimum lexical resource required to translate between a pair of languages is a translation dictionary. Unfortunately , dictionaries exist only between a tiny fraction of the 49 million possible language-pairs making machine translation virtually impossible between most of the languages. This paper summarizes the last four years of our research motivated by the vision of panlingual communication. Our research comprises three key steps. First, we compile over 630 freely available dictionaries over the Web and convert this data into a single representation – the translation graph. Second , we build several inference algorithms that infer translations between word pairs even when no dictionary lists them as translations. Finally, we run our inference procedure of-fline to construct PANDICTIONARY– a sense-distinguished, massively multilingual dictionary that has translations in more than 1000 languages. Our experiments assess the quality of this dictionary and find that we have 4 times as many translations at a high precision of 0.9 compared to the English Wiktionary, which is the lexical resource closest to PANDIC-TIONARY.","cites":"21","conferencePercentile":"77.64505119"},{"venue":"AAAI","id":"2519ed73f8084b993664e5a0c240e2dd37ba7349","venue_1":"AAAI","year":"2014","title":"Diagram Understanding in Geometry Questions","authors":"Min Joon Seo, Hannaneh Hajishirzi, Ali Farhadi, Oren Etzioni","author_ids":"1903588, 2548384, 2653250, 1741101","abstract":"Automatically solving geometry questions is a long-standing AI problem. A geometry question typically includes a textual description accompanied by a diagram. The first step in solving geometry questions is diagram understanding, which consists of identifying visual elements in the diagram, their locations, their geometric properties, and aligning them to corresponding textual descriptions. In this paper, we present a method for diagram understanding that identifies visual elements in a diagram while maximizing agreement between textual and visual data. We show that the method's objective function is submodular; thus we are able to introduce an efficient method for diagram understanding that is close to optimal. To empirically evaluate our method, we compile a new dataset of geometry questions (tex-tual descriptions and diagrams) and compare with base-lines that utilize standard vision techniques. Our experimental evaluation shows an F1 boost of more than 17% in identifying visual elements and 25% in aligning visual elements with their textual descriptions.","cites":"19","conferencePercentile":"96.70454545"},{"venue":"AAAI","id":"478b4a5123bd5fda98bb35e6317d7f3555fec97d","venue_1":"AAAI","year":"2016","title":"Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions","authors":"Peter Clark, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter D. Turney, Daniel Khashabi","author_ids":"6232140, 1741101, 2236429, 1763442, 3385516, 1689647, 1783281","abstract":"What capabilities are required for an AI system to pass standard 4th Grade Science Tests? Previous work has examined the use of Markov Logic Networks (MLNs) to represent the requisite background knowledge and interpret test questions, but did not improve upon an information retrieval (IR) baseline. In this paper, we describe an alternative approach that operates at three levels of representation and reasoning: information retrieval, corpus statistics, and simple inference over a semi-automatically constructed knowledge base, to achieve substantially improved results. We evaluate the methods on six years of unseen, unedited exam questions from the NY Regents Science Exam (using only non-diagram, multiple choice questions), and show that our overall system's score is 71.3%, an improvement of 23.8% (absolute) over the MLN-based method described in previous work. We conclude with a detailed analysis, illustrating the complementary strengths of each method in the ensemble. Our datasets are being released to enable further research.","cites":"8","conferencePercentile":"92.73648649"},{"venue":"AAAI","id":"fb62fae47f2ccef2e11eefb112765cdbbe4f0400","venue_1":"AAAI","year":"2015","title":"Tensor-Variate Restricted Boltzmann Machines","authors":"Tu Dinh Nguyen, Truyen Tran, Dinh Q. Phung, Svetha Venkatesh","author_ids":"3314511, 6254479, 1749657, 1679520","abstract":"Restricted Boltzmann Machines (RBMs) are an important class of latent variable models for representing vector data. An under-explored area is multimode data, where each data point is a matrix or a tensor. Standard RBMs applying to such data would require vectorizing matrices and tensors, thus resulting in unnecessarily high dimensionality and at the same time, destroying the inherent higher-order interaction structures. This paper introduces Tensor-variate Restricted Boltz-mann Machines (TvRBMs) which generalize RBMs to capture the multiplicative interaction between data modes and the latent variables. TvRBMs are highly compact in that the number of free parameters grows only linear with the number of modes. We demonstrate the capacity of TvRBMs on three real-world applications: handwritten digit classification, face recognition and EEG-based alcoholic diagnosis. The learnt features of the model are more discriminative than the rivals, resulting in better classification performance.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"30cfa5ac0fc6ee63820c658067a433076f51b20b","venue_1":"AAAI","year":"2012","title":"A Sequential Decision Approach to Ordinal Preferences in Recommender Systems","authors":"Truyen Tran, Dinh Q. Phung, Svetha Venkatesh","author_ids":"6254479, 1749657, 1679520","abstract":"We propose a novel sequential decision approach to modeling ordinal ratings in collaborative filtering problems. The rating process is assumed to start from the lowest level, evaluates against the latent utility at the corresponding level and moves up until a suitable ordinal level is found. Crucial to this generative process is the underlying utility random variables that govern the generation of ratings and their modelling choices. To this end, we make a novel use of the generalised extreme value distributions, which is found to be particularly suitable for our modeling tasks and at the same time, facilitate our inference and learning procedure. The proposed approach is flexible to incorporate features from both the user and the item. We evaluate the proposed framework on three well-known datasets: MovieLens, Dating Agency and Netflix. In all cases, it is demonstrated that the proposed work is competitive against state-of-the-art collaborative filtering methods.","cites":"5","conferencePercentile":"46.79878049"},{"venue":"AAAI","id":"3d2a533ee37967b7c701d5794a6403d498b994d6","venue_1":"AAAI","year":"2014","title":"Generalized Higher-Order Tensor Decomposition via Parallel ADMM","authors":"Fanhua Shang, Yuanyuan Liu, James Cheng","author_ids":"3062185, 1691845, 1717691","abstract":"Higher-order tensors are becoming prevalent in many scientific areas such as computer vision, social network analysis, data mining and neuroscience. Traditional ten-sor decomposition approaches face three major challenges: model selecting, gross corruptions and computational efficiency. To address these problems, we first propose a parallel trace norm regularized tensor decomposition method, and formulate it as a convex optimization problem. This method does not require the rank of each mode to be specified beforehand, and can automatically determine the number of factors in each mode through our optimization scheme. By considering the low-rank structure of the observed tensor, we analyze the equivalent relationship of the trace norm between a low-rank tensor and its core tensor. Then, we cast a non-convex tensor decomposition model into a weighted combination of multiple much smaller-scale matrix trace norm minimization. Finally, we develop two parallel alternating direction methods of multipli-ers (ADMM) to solve our problems. Experimental results verify that our regularized formulation is effective, and our methods are robust to noise or outliers.","cites":"5","conferencePercentile":"67.5"},{"venue":"AAAI","id":"417bfc803ce688c6fc150db10edb7ffe0c96ee69","venue_1":"AAAI","year":"2016","title":"Scalable Algorithms for Tractable Schatten Quasi-Norm Minimization","authors":"Fanhua Shang, Yuanyuan Liu, James Cheng","author_ids":"3062185, 1691845, 1717691","abstract":"The Schatten-p quasi-norm (0<p<1) is usually used to replace the standard nuclear norm in order to approximate the rank function more accurately. However, existing Schatten-p quasi-norm minimization algorithms involve singular value decomposition (SVD) or eigenvalue decomposition (EVD) in each iteration, and thus may become very slow and impractical for large-scale problems. In this paper, we first define two tractable Schatten quasi-norms, i.e., the Frobenius/nuclear hybrid and bi-nuclear quasi-norms, and then prove that they are in essence the Schatten-2/3 and 1/2 quasi-norms, respectively , which lead to the design of very efficient algorithms that only need to update two much smaller factor matrices. We also design two efficient proximal alternating linearized minimization algorithms for solving representative matrix completion problems. Finally, we provide the global convergence and performance guarantees for our algorithms, which have better convergence properties than existing algorithms. Experimental results on synthetic and real-world data show that our algorithms are more accurate than the state-of-the-art methods, and are orders of magnitude faster.","cites":"4","conferencePercentile":"79.72972973"},{"venue":"AAAI","id":"8f1a09e7e00a4d4d16558536e19b96907c7435f2","venue_1":"AAAI","year":"2015","title":"A Simulator of Human Emergency Mobility Following Disasters: Knowledge Transfer from Big Disaster Data","authors":"Xuan Song, Quanshi Zhang, Yoshihide Sekimoto, Ryosuke Shibasaki, Nicholas Jing Yuan, Xing Xie","author_ids":"3970122, 2337228, 2703973, 1721111, 2123146, 1687677","abstract":"The frequency and intensity of natural disasters has significantly increased over the past decades and this trend is predicted to continue. Facing these possible and unexpected disasters, understanding and simulating of human emergency mobility following disasters will become the critical issue for planning effective humanitarian relief, disaster management, and long-term societal reconstruction. However, due to the uniqueness of various disasters and the unavailability of reliable and large scale human mobility data, such kind of research is very difficult to be performed. Hence, in this paper, we collect big and heterogeneous data (e.g. 1.6 million users' GPS records in three years, 17520 times of Japan earthquake data in four years, news reporting data, transportation network data and etc.) to capture and analyze human emergency mobility following different disasters. By mining these big data, we aim to understand what basic laws govern human mobility following disasters, and develop a general model of human emergency mobility for generating and simulating large amount of human emergency movements. The experimental results and validations demonstrate the efficiency of our simulation model, and suggest that human mobility following disasters may be significantly more predictable and can be easier simulated than previously thought.","cites":"4","conferencePercentile":"73.46456693"},{"venue":"AAAI","id":"6eff8fd4fb27f3b23cb6ab8c0fb5bf3f0dc10db2","venue_1":"AAAI","year":"2008","title":"The Hidden Permutation Model and Location-Based Activity Recognition","authors":"Hung Hai Bui, Dinh Q. Phung, Svetha Venkatesh, Hai Phan","author_ids":"1707085, 1749657, 1679520, 2286832","abstract":"Permutation modeling is challenging because of the combi-natorial nature of the problem. However, such modeling is often required in many real-world applications, including activity recognition where subactivities are often permuted and partially ordered. This paper introduces a novel Hidden Permutation Model (HPM) that can learn the partial ordering constraints in permuted state sequences. The HPM is parame-terized as an exponential family distribution and is flexible so that it can encode constraints via different feature functions. A chain-flipping Metropolis-Hastings Markov chain Monte Carlo (MCMC) is employed for inference to overcome the O(n!) complexity. Gradient-based maximum likelihood parameter learning is presented for two cases when the permutation is known and when it is hidden. The HPM is evaluated using both simulated and real data from a location-based activity recognition domain. Experimental results indicate that the HPM performs far better than other baseline models, including the naive Bayes classifier, the HMM classifier, and Kirshner's multinomial permutation model. Our presented HPM is generic and can potentially be utilized in any problem where the modeling of permuted states from noisy data is needed.","cites":"9","conferencePercentile":"52.21518987"},{"venue":"AAAI","id":"a4e256b432015576501a080000ba68c82bb4bcf6","venue_1":"AAAI","year":"2016","title":"Little Is Much: Bridging Cross-Platform Behaviors through Overlapped Crowds","authors":"Meng Jiang, Peng Cui, Nicholas Jing Yuan, Xing Xie, Shiqiang Yang","author_ids":"3775803, 1685435, 2123146, 1687677, 1689674","abstract":"People often use multiple platforms to fulfill their different information needs. With the ultimate goal of serving people intelligently, a fundamental way is to get comprehensive understanding about user needs. How to organically integrate and bridge cross-platform information in a human-centric way is important. Existing transfer learning assumes either fully-overlapped or non-overlapped among the users. However, the real case is the users of different platforms are partially overlapped. The number of overlapped users is often small and the explicitly known overlapped users is even less due to the lacking of unified ID for a user across different platforms. In this paper, we propose a novel semi-supervised transfer learning method to address the problem of cross-platform behavior prediction , called XPTRANS. To alleviate the sparsity issue, it fully exploits the small number of overlapped crowds to optimally bridge a user's behaviors in different platforms. Extensive experiments across two real social networks show that XPTRANS significantly outperforms the state-of-the-art. We demonstrate that by fully exploiting 26% overlapped users, XPTRANS can predict the behaviors of non-overlapped users with the same accuracy as overlapped users, which means the small overlapped crowds can successfully bridge the information across different platforms.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"8198b8c3c9bf2464f80a87c3d08a95b4be75ba95","venue_1":"AAAI","year":"2010","title":"Ordered Completion for First-Order Logic Programs on Finite Structures","authors":"Vernon Asuncion, Fangzhen Lin, Yan Zhang, Yi Zhou","author_ids":"2504718, 1720499, 3397734, 4017197","abstract":"In this paper, we propose a translation from normal first-order logic programs under the answer set semantics to first-order theories on finite structures. Specifically, we introduce ordered completions which are modifications of Clark's completions with some extra predicates added to keep track of the derivation order, and show that on finite structures, classical models of the ordered-completion of a normal logic program correspond exactly to the answer sets (stable models) of the logic program.","cites":"16","conferencePercentile":"69.62457338"},{"venue":"AAAI","id":"106b757ef2022997ab9766df30f28873ab480dcb","venue_1":"AAAI","year":"2010","title":"First-Order Indefinability of Answer Set Programs on Finite Structures","authors":"Yin Chen, Yan Zhang, Yi Zhou","author_ids":"1743327, 3397734, 4017197","abstract":"An answer set program with variables is first-order defin-able on finite structures if the set of its finite answer sets can be captured by a first-order sentence, otherwise this program is first-order indefinable on finite structures. In this paper , we study the problem of first-order indefinability of answer set programs. We provide an Ehrenfeucht-Fra¨ıssé game-theoretic characterization for the first-order indefinability of answer set programs on finite structures. As an application of this approach, we show that the well-known finding Hamilto-nian cycles program is not first-order definable on finite structures. We then define two notions named the 0-1 property and unbounded cycles or paths under the answer set semantics, from which we develop two sufficient conditions that may be effectively used in proving a program's first-order indefin-ability on finite structures under certain circumstances.","cites":"1","conferencePercentile":"11.09215017"},{"venue":"AAAI","id":"3837836cb88a1fa532236c1b570f41319645382e","venue_1":"AAAI","year":"2011","title":"Bounded Forgetting","authors":"Yi Zhou, Yan Zhang","author_ids":"4017197, 3397734","abstract":"The result of forgetting some predicates in a first-order sentence may not exist in the sense that it might not be captured by any first-order sentences. This, indeed, severely restricts the usage of forgetting in applications. To address this issue, we propose a notion called k-forgetting, also called bounded forgetting in general, for any fixed number k. We present several equivalent characterizations of bounded forgetting and show that the result of bounded forgetting, on one hand, can always be captured by a single first-order sentence, and on the other hand, preserves the information that we are concerned with.","cites":"6","conferencePercentile":"49.14089347"},{"venue":"AAAI","id":"212285c0e6541fccef9db3d1b04efd9c3a5a7997","venue_1":"AAAI","year":"2011","title":"Progression Semantics for Disjunctive Logic Programs","authors":"Yi Zhou, Yan Zhang","author_ids":"4017197, 3397734","abstract":"In this paper, we extend the progression semantics for first-order disjunctive logic programs and show that it coincides with the stable model semantics. Based on it, we further show how disjunctive answer set programming is related to Satisfi-ability Modulo Theories.","cites":"6","conferencePercentile":"49.14089347"},{"venue":"AAAI","id":"b645929eed92a2ed741da22e580a170f0a76a692","venue_1":"AAAI","year":"2012","title":"Ordered Completion for Logic Programs with Aggregates","authors":"Vernon Asuncion, Yan Zhang, Yi Zhou","author_ids":"2504718, 3397734, 4017197","abstract":"In this paper, we show that first-order logic programs with monotone aggregates under the stable model semantics can be captured in classical first-order logic. More precisely, we extend the notion of ordered completion for logic programs with a large variety of aggregates so that every stable model of a program with aggregates corresponds to a classical model of its enhanced ordered completion, and vice versa.","cites":"3","conferencePercentile":"30.79268293"},{"venue":"AAAI","id":"f840f3e373f03521d58a8bf5bab9fe27c39d155b","venue_1":"AAAI","year":"2004","title":"Learning Hierarchical Hidden Markov Models with General State Hierarchy","authors":"Hung Hai Bui, Dinh Q. Phung, Svetha Venkatesh","author_ids":"1707085, 1749657, 1679520","abstract":"The hierarchical hidden Markov model (HHMM) is an extension of the hidden Markov model to include a hierarchy of the hidden states. This form of hierarchical modeling has been found useful in applications such as handwritten character recognition, behavior recognition, video indexing, and text retrieval. Nevertheless, the state hierarchy in the original HHMM is restricted to a tree structure. This prohibits two different states from having the same child, and thus does not allow for sharing of common substructures in the model. In this paper, we present a general HHMM in which the state hierarchy can be a lattice allowing arbitrary sharing of sub-structures. Furthermore, we provide a method for numerical scaling to avoid underflow, an important issue in dealing with long observation sequences. We demonstrate the working of our method in a simulated environment where a hierarchical behavioral model is automatically learned and later used for recognition.","cites":"1","conferencePercentile":"12.5748503"},{"venue":"AAAI","id":"0b7bb02fccc4f6a5c6f8fa0130b5df4b42959af0","venue_1":"AAAI","year":"2014","title":"Modeling Subjective Experience-Based Learning under Uncertainty and Frames","authors":"Hyungil Ahn, Rosalind W. Picard","author_ids":"2259303, 1719389","abstract":"In this paper we computationally examine how subjective experience may help or harm the decision maker's learning under uncertain outcomes, frames and their interactions. To model subjective experience, we propose the \" experienced-utility function \" based on a prospect theory (PT)-based parameterized subjective value function. Our analysis and simulations of two-armed bandit tasks present that the task domain (underlying outcome distributions) and framing (reference point selection) influence experienced utilities and in turn, the \" subjective discriminability \" of choices under uncertainty. Experiments demonstrate that subjective discriminability improves on objective discriminability by the use of the experienced-utility function with appropriate framing for a given task domain, and that bigger subjective dis-criminability leads to more optimal decisions in learning under uncertainty.","cites":"2","conferencePercentile":"38.63636364"},{"venue":"AAAI","id":"7b92ee9d47a0faaba0d8db7e8d8be1e9def2a76d","venue_1":"AAAI","year":"2006","title":"Incremental Least Squares Policy Iteration for POMDPs","authors":"Hui Li, Xuejun Liao, Lawrence Carin","author_ids":"1750828, 2585822, 1746676","abstract":"We present a new algorithm, called incremental least squares policy iteration (ILSPI), for solving the infinite-horizon stationary policy for partially observable Markov decision processes (POMDPs). The ILSPI algorithm computes a basis representation of the infinite-horizon value function by minimizing the square of Bellman residual and performs policy improvement in reachable belief states. A number of optimal basis functions are determined by the algorithm to minimize the Bellman residual incrementally, via efficient computations. We show that, by using optimally determined basis functions, the policy can be improved successively on a set of most probable belief points sampled from the reachable belief set. The results on four benchmark problems demonstrate that the ILSPI is competitive in performance to state-of-the-art value iteration algorithms and yet is computationally more efficient.","cites":"1","conferencePercentile":"14.4092219"},{"venue":"AAAI","id":"bbd210f3edf414dbb135959729ef74eeb0f4b802","venue_1":"AAAI","year":"2016","title":"MOOCs Meet Measurement Theory: A Topic-Modelling Approach","authors":"Jiazhen He, Benjamin I. P. Rubinstein, James Bailey, Rui Zhang, Sandra Milligan, Jeffrey Chan","author_ids":"2748363, 1868067, 6263638, 1680558, 3090088, 6273657","abstract":"This paper adapts topic models to the psychometric testing of MOOC students based on their online forum post-ings. Measurement theory from education and psychology provides statistical models for quantifying a per-son's attainment of intangible attributes such as attitudes , abilities or intelligence. Such models infer latent skill levels by relating them to individuals' observed responses on a series of items such as quiz questions. The set of items can be used to measure a latent skill if individuals' responses on them conform to a Guttman scale. Such well-scaled items differentiate between individuals and inferred levels span the entire range from most basic to the advanced. In practice, education researchers manually devise items (quiz questions) while optimising well-scaled conformance. Due to the costly nature and expert requirements of this process, psycho-metric testing has found limited use in everyday teaching. We aim to develop usable measurement models for highly-instrumented MOOC delivery platforms, by using participation in automatically-extracted online forum topics as items. The challenge is to formalise the Guttman scale educational constraint and incorporate it into topic models. To favour topics that automatically conform to a Guttman scale, we introduce a novel reg-ularisation into non-negative matrix factorisation-based topic modelling. We demonstrate the suitability of our approach with both quantitative experiments on three Coursera MOOCs, and with a qualitative survey of topic interpretability on two MOOCs by domain expert interviews .","cites":"2","conferencePercentile":"61.31756757"},{"venue":"AAAI","id":"3a7cb4a60a0dfe16c35ef4ca4b74c156e59fcbba","venue_1":"AAAI","year":"2007","title":"Point-Based Policy Iteration","authors":"Shihao Ji, Ronald Parr, Hui Li, Xuejun Liao, Lawrence Carin","author_ids":"1869497, 1806178, 1750828, 2585822, 1746676","abstract":"We describe a point-based policy iteration (PBPI) algorithm for infinite-horizon POMDPs. PBPI replaces the exact policy improvement step of Hansen's policy iteration with point-based value iteration (PBVI). Despite being an approximate algorithm, PBPI is monotonic: At each iteration before convergence, PBPI produces a policy for which the values increase for at least one of a finite set of initial belief states, and decrease for none of these states. In contrast, PBVI cannot guarantee monotonic improvement of the value function or the policy. In practice PBPI generally needs a lower density of point coverage in the simplex and tends to produce superior policies with less computation. Experiments on several benchmark problems (up to 12,545 states) demonstrate the scalability and robustness of the PBPI algorithm.","cites":"19","conferencePercentile":"69.73293769"},{"venue":"AAAI","id":"ba98b5866e47d216f6a48b3932319fad18d27dcc","venue_1":"AAAI","year":"2011","title":"A Scalable Tree-Based Approach for Joint Object and Pose Recognition","authors":"Kevin Lai, Liefeng Bo, Xiaofeng Ren, Dieter Fox","author_ids":"1725820, 1766509, 7924812, 1776234","abstract":"Recognizing possibly thousands of objects is a crucial capability for an autonomous agent to understand and interact with everyday environments. Practical object recognition comes in multiple forms: Is this a coffee mug? (category recognition). Is this Alice's coffee mug? (instance recognition). Is the mug with the handle facing left or right? (pose recognition). We present a scal-able framework, Object-Pose Tree, which efficiently organizes data into a semantically structured tree. The tree structure enables both scalable training and testing , allowing us to solve recognition over thousands of object poses in near real-time. Moreover, by simultaneously optimizing all three tasks, our approach out-performs standard nearest neighbor and 1-vs-all classifications , with large improvements on pose recognition. We evaluate the proposed technique on a dataset of 300 household objects collected using a Kinect-style 3D camera. Experiments demonstrate that our system achieves robust and efficient object category, instance, and pose recognition on challenging everyday objects.","cites":"47","conferencePercentile":"98.62542955"},{"venue":"AAAI","id":"6393450ec74245cf591d70c376ae64f39bb9d87d","venue_1":"AAAI","year":"2010","title":"Collaborative Expert Portfolio Management","authors":"David H. Stern, Horst Samulowitz, Ralf Herbrich, Thore Graepel, Luca Pulina, Armando Tacchella","author_ids":"2776523, 1756353, 3234984, 1686971, 1716255, 1834340","abstract":"We consider the task of assigning experts from a portfolio of specialists in order to solve a set of tasks. We apply a Bayesian model which combines collaborative filtering with a feature-based description of tasks and experts to yield a general framework for managing a portfolio of experts. The model learns an embedding of tasks and problems into a latent space in which affinity is measured by the inner product. The model can be trained incrementally and can track non-stationary data, tracking potentially changing expert and task characteristics. The approach allows us to use a principled decision theoretic framework for expert selection, allowing the user to choose a utility function that best suits their objectives. The model component for taking into account the performance feedback data is pluggable, allowing flexibility. We apply the model to manage a portfolio of algorithms to solve hard combinatorial problems. This is a well studied area and we demonstrate a large improvement on the state of the art in one domain (constraint solving) and in a second domain (com-binatorial auctions) created a portfolio that performed significantly better than any single algorithm.","cites":"16","conferencePercentile":"69.62457338"},{"venue":"AAAI","id":"4744d8590ffa552d2fbbb31adaede64bfc981d97","venue_1":"AAAI","year":"2010","title":"Community-Guided Learning: Exploiting Mobile Sensor Users to Model Human Behavior","authors":"Daniel Peebles, Hong Lu, Nicholas D. Lane, Tanzeem Choudhury, Andrew T. Campbell","author_ids":"2259142, 3655082, 2772904, 1729948, 1690035","abstract":"Modeling human behavior requires vast quantities of accurately labeled training data, but for ubiquitous people-aware applications such data is rarely attainable. Even researchers make mistakes when labeling data, and consistent, reliable labels from low-commitment users are rare. In particular, users may give identical labels to activities with characteristically different signatures (e.g., labeling eating at home or at a restaurant as \" dinner \") or may give different labels to the same context (e.g., \" work \" vs. \" office \"). In this scenario, labels are unreliable but nonetheless contain valuable information for classification. To facilitate learning in such uncon-strained labeling scenarios, we propose Community-Guided Learning (CGL), a framework that allows existing classifiers to learn robustly from unreliably-labeled user-submitted data. CGL exploits the underlying structure in the data and the un-constrained labels to intelligently group crowd-sourced data. We demonstrate how to use similarity measures to determine when and how to split and merge contributions from different labeled categories and present experimental results that demonstrate the effectiveness of our framework.","cites":"25","conferencePercentile":"81.74061433"},{"venue":"AAAI","id":"b074a937a6f3f8c1d9aab9d695fa4ab3c213875b","venue_1":"AAAI","year":"2004","title":"PRECISE on ATIS: Semantic Tractability and Experimental Results","authors":"Ana-Maria Popescu, Alex Armanasu, Oren Etzioni, David Ko, Alexander Yates","author_ids":"1752145, 2177004, 1741101, 7372233, 3050028","abstract":"The need for Natural Language Interfaces to databases (NLIs) has become increasingly acute as more and more people access information through their web browsers, PDAs, and cell phones. Yet NLIs are only usable if they map natural language questions to SQL queries correctly — people are unwilling to trade reliable and predictable user interfaces for intelligent but unreliable ones. We describe a reliable NLI, PRECISE, that incorporates a modern statistical paser and a semantic module. PRECISE provably handles a large class of natural language questions correctly. On the benchmark ATIS data set, PRECISE achieves 93.8% accuracy.","cites":"0","conferencePercentile":"5.089820359"},{"venue":"AAAI","id":"935aeb0dd9327625c7aaa516bc822f75c962d58a","venue_1":"AAAI","year":"2014","title":"Mapping Users across Networks by Manifold Alignment on Hypergraph","authors":"Shulong Tan, Ziyu Guan, Deng Cai, Xuzhen Qin, Jiajun Bu, Chun Chen","author_ids":"2054844, 1749272, 1745280, 7710564, 8475311, 5371645","abstract":"Nowadays many people are members of multiple on-line social networks simultaneously, such as Facebook, Twitter and some other instant messaging circles. But these networks are usually isolated from each other. Mapping common users across these social networks will benefit many applications. Methods based on user-name comparison perform well on parts of users, however they can not work in the following situations: (a) users choose different usernames in different networks; (b) a unique username corresponds to different individuals. In this paper, we propose to utilize social structures to improve the mapping performance. Specifically , a novel subspace learning algorithm, Manifold Alignment on Hypergraph (MAH), is proposed. Different from traditional semi-supervised manifold alignment methods, we use hypergraph to model high-order relations here. For a target user in one network, the proposed algorithm ranks all users in the other network by their possibilities of being the corresponding user. Moreover, methods based on username comparison can be incorporated into our algorithm easily to further boost the mapping accuracy. Experimental results have demonstrated the effectiveness of our proposed algorithm in mapping users across networks.","cites":"11","conferencePercentile":"89.54545455"},{"venue":"AAAI","id":"2079a5a9ac8cbf53c8f2885a6ffc449ea558348e","venue_1":"AAAI","year":"2012","title":"A Bregman Divergence Optimization Framework for Ranking on Data Manifold and Its New Extensions","authors":"Bin Xu, Jiajun Bu, Chun Chen, Deng Cai","author_ids":"3448335, 8475311, 5371645, 1745280","abstract":"Recently, graph-based ranking algorithms have received considerable interests in machine learning, computer vision and information retrieval communities. Ranking on data manifold (or manifold ranking, MR) is one of the representative approaches. One of the limitations of manifold ranking is its high computational complexity (O(n 3), where n is the number of samples in database). In this paper, we cast the manifold ranking into a Breg-man divergence optimization framework under which we transform the original MR to an equivalent optimal kernel matrix learning problem. With this new formulation , two effective and efficient extensions are proposed to enhance the ranking performance. Extensive experimental results on two real world image databases show the effectiveness of the proposed approach.","cites":"2","conferencePercentile":"22.40853659"},{"venue":"AAAI","id":"9ef21d4da6df1e7282047190c20c4616254c1abe","venue_1":"AAAI","year":"2012","title":"Efficient Online Learning for Large-Scale Sparse Kernel Logistic Regression","authors":"Lijun Zhang, Rong Jin, Chun Chen, Jiajun Bu, Xiaofei He","author_ids":"1707675, 1718400, 5371645, 8475311, 3945955","abstract":"In this paper, we study the problem of large-scale Kernel Logistic Regression (KLR). A straightforward approach is to apply stochastic approximation to KLR. We refer to this approach as non-conservative online learning algorithm because it updates the kernel classifier after every received training example, leading to a dense classifier. To improve the sparsity of the KLR classifier, we propose two conservative online learning algorithms that update the classifier in a stochastic manner and generate sparse solutions. With appropriately designed updating strategies, our analysis shows that the two conservative algorithms enjoy similar theoretical guarantee as that of the non-conservative algorithm. Empirical studies on several benchmark data sets demonstrate that compared to batch-mode algorithms for KLR, the proposed conservative online learning algorithms are able to produce sparse KLR classifiers, and achieve similar classification accuracy but with significantly shorter training time. Furthermore , both the sparsity and classification accuracy of our methods are comparable to those of the online kernel SVM.","cites":"4","conferencePercentile":"39.17682927"},{"venue":"AAAI","id":"2e2715827a6841f783c4e814dc6fceb0b387e566","venue_1":"AAAI","year":"2007","title":"On the Benefits of Exploiting Underlying Goals in Argument-based Negotiation","authors":"Iyad Rahwan, Philippe Pasquier, Liz Sonenberg, Frank Dignum","author_ids":"1705156, 1717343, 1719425, 1716665","abstract":"Interest-based negotiation (IBN) is a form of negotiation in which agents exchange information about their underlying goals, with a view to improving the likelihood and quality of a deal. While this intuition has been stated informally in much previous literature, there is no formal analysis of the types of deals that can be reached through IBN and how they differ from those reachable using (classical) alternating offer bargaining. This paper bridges this gap by providing a formal framework for analysing the outcomes of IBN dialogues, and begins by analysing a specific IBN protocol.","cites":"21","conferencePercentile":"72.55192878"},{"venue":"AAAI","id":"71057fda754dcf4e04017f6da84ef9fb01e80972","venue_1":"AAAI","year":"2011","title":"Social Recommendation Using Low-Rank Semidefinite Program","authors":"Jianke Zhu, Hao Ma, Chun Chen, Jiajun Bu","author_ids":"1704030, 7186567, 5371645, 8475311","abstract":"The most critical challenge for the recommendation system is to achieve the high prediction quality on the large scale sparse data contributed by the users. In this paper, we present a novel approach to the social recommendation problem, which takes the advantage of the graph Laplacian regularization to capture the underlying social relationship among the users. Differently from the previous approaches, that are based on the conventional gradient descent optimization, we formulate the presented graph Laplacian regularized social recommendation problem into a low-rank semidefinite program, which is able to be efficiently solved by the quasi-Newton algorithm. We have conducted the empirical evaluation on a large scale dataset of high sparsity, the promising experimental results show that our method is very effective and efficient for the social recommendation task.","cites":"7","conferencePercentile":"55.67010309"},{"venue":"AAAI","id":"4105d9e5aea9c17d6b3305c59a08b4d1476fd1e5","venue_1":"AAAI","year":"2010","title":"G-Optimal Design with Laplacian Regularization","authors":"Chun Chen, Zhengguang Chen, Jiajun Bu, Can Wang, Lijun Zhang, Cheng Zhang","author_ids":"5371645, 8157596, 8475311, 1804563, 1707675, 3585347","abstract":"In many real world applications, labeled data are usually expensive to get, while there may be a large amount of unlabeled data. To reduce the labeling cost, active learning attempts to discover the most informative data points for labeling. Recently, Optimal Experimental Design (OED) techniques have attracted an increasing amount of attention. OED is concerned with the design of experiments that minimizes variances of a parameter-ized model. Typical design criteria include D-, A-, and E-optimality. However, all these criteria are based on an ordinary linear regression model which aims to minimize the empirical error whereas the geometrical structure of the data space is not well respected. In this paper , we propose a novel optimal experimental design approach for active learning, called Laplacian G-Optimal Design (LapGOD), which considers both discriminating and geometrical structures. By using Laplacian Regularized Least Squares which incorporates mani-fold regularization into linear regression, our proposed algorithm selects those data points that minimizes the maximum variance of the predicted values on the data manifold. We also extend our algorithm to nonlinear case by using kernel trick. The experimental results on various image databases have shown that our proposed LapGOD active learning algorithm can significantly enhance the classification accuracy if the selected data points are used as training data.","cites":"4","conferencePercentile":"27.1331058"},{"venue":"AAAI","id":"4eb753322f13443d0e463e6c7123088734b3583a","venue_1":"AAAI","year":"2016","title":"Co-occurrence Feature Learning for Skeleton based Action Recognition using Regularized Deep LSTM Networks","authors":"Wentao Zhu, Cuiling Lan, Junliang Xing, Wenjun Zeng, Yanghao Li, Li Shen, Xiaohui Xie","author_ids":"1778018, 2443131, 1757173, 1702938, 3128506, 1712125, 2834988","abstract":"Skeleton based action recognition distinguishes human actions using the trajectories of skeleton joints, which provide a very good representation for describing actions. Considering that recurrent neural networks (RNNs) with Long Short-Term Memory (LSTM) can learn feature representations and model long-term temporal dependencies automatically, we propose an end-to-end fully connected deep LSTM network for skeleton based action recognition. Inspired by the observation that the co-occurrences of the joints intrinsically characterize human actions, we take the skeleton as the input at each time slot and introduce a novel regularization scheme to learn the co-occurrence features of skeleton joints. To train the deep LSTM network effectively, we propose a new dropout algorithm which simultaneously operates on the gates, cells, and output responses of the LSTM neurons. Experimental results on three human action recognition datasets consistently demonstrate the effectiveness of the proposed model.","cites":"15","conferencePercentile":"97.97297297"},{"venue":"AAAI","id":"d7c58e4f16504500329315e06eeba700c4b7abca","venue_1":"AAAI","year":"2012","title":"Document Summarization Based on Data Reconstruction","authors":"Zhanying He, Chun Chen, Jiajun Bu, Can Wang, Lijun Zhang, Deng Cai, Xiaofei He","author_ids":"2355956, 5371645, 8475311, 1804563, 1707675, 1745280, 3945955","abstract":"Document summarization is of great value to many real world applications, such as snippets generation for search results and news headlines generation. Traditionally , document summarization is implemented by extracting sentences that cover the main topics of a document with a minimum redundancy. In this paper, we take a different perspective from data reconstruction and propose a novel framework named Document Summa-rization based on Data Reconstruction (DSDR). Specifically , our approach generates a summary which consist of those sentences that can best reconstruct the original document. To model the relationship among sentences, we introduce two objective functions: (1) linear reconstruction , which approximates the document by linear combinations of the selected sentences; (2) nonnega-tive linear reconstruction, which allows only additive, not subtractive, linear combinations. In this framework, the reconstruction error becomes a natural criterion for measuring the quality of the summary. For each objective function, we develop an efficient algorithm to solve the corresponding optimization problem. Extensive experiments on summarization benchmark data sets DUC 2006 and DUC 2007 demonstrate the effectiveness of our proposed approach.","cites":"21","conferencePercentile":"90.24390244"},{"venue":"AAAI","id":"dc7273966eb71ab2b676a09ab0142f47106d5d98","venue_1":"AAAI","year":"2015","title":"Identifying At-Risk Students in Massive Open Online Courses","authors":"Jiazhen He, James Bailey, Benjamin I. P. Rubinstein, Rui Zhang","author_ids":"2748363, 6263638, 1868067, 1680558","abstract":"Massive Open Online Courses (MOOCs) have received widespread attention for their potential to scale higher education, with multiple platforms such as Coursera, edX and Udacity recently appearing. Despite their successes , a major problem faced by MOOCs is low completion rates. In this paper, we explore the accurate early identification of students who are at risk of not completing courses. We build predictive models weekly, over multiple offerings of a course. Furthermore, we envision student interventions that present meaningful probabilities of failure, enacted only for marginal students. To be effective, predicted probabilities must be both well-calibrated and smoothed across weeks. Based on logistic regression, we propose two transfer learning algorithms to trade-off smoothness and accuracy by adding a regularization term to minimize the difference of failure probabilities between consecutive weeks. Experimental results on two offerings of a Coursera MOOC establish the effectiveness of our algorithms.","cites":"6","conferencePercentile":"84.80314961"},{"venue":"AAAI","id":"400cf0a4a689f65681a4c618471387ea61598283","venue_1":"AAAI","year":"2004","title":"Methods for Domain-Independent Information Extraction from the Web: An Experimental Comparison","authors":"Oren Etzioni, Michael J. Cafarella, Doug Downey, Ana-Maria Popescu, Tal Shaked, Stephen Soderland, Daniel S. Weld, Alexander Yates","author_ids":"1741101, 1725561, 2418071, 1752145, 3296031, 2751022, 1780531, 3050028","abstract":"Our KNOWITALL system aims to automate the tedious process of extracting large collections of facts (e.g., names of scientists or politicians) from the Web in an autonomous, domain-independent, and scalable manner. In its first major run, KNOWITALL extracted over 50,000 facts with high precision, but suggested a challenge: How can we improve KNOWITALL's recall and extraction rate without sacrificing precision? This paper presents three distinct ways to address this challenge and evaluates their performance. Rule Learning learns domain-specific extraction rules. Subclass Extraction automatically identifies sub-classes in order to boost recall. List Extraction locates lists of class instances , learns a \" wrapper \" for each list, and extracts elements of each list. Since each method bootstraps from KNOWITALL's domain-independent methods, no hand-labeled training examples are required. Experiments show the relative coverage of each method and demonstrate their synergy. In concert, our methods gave KNOWITALL a 4-fold to 19-fold increase in recall , while maintaining high precision, and discovered 10,300 cities missing from the Tipster Gazetteer.","cites":"92","conferencePercentile":"95.50898204"},{"venue":"AAAI","id":"26ee641cd56eeb1ab0acd26a898ac2a441f4caa1","venue_1":"AAAI","year":"2013","title":"The Effects of Performance-Contingent Financial Incentives in Online Labor Markets","authors":"Ming Yin, Yiling Chen, Yu-An Sun","author_ids":"4242996, 1775608, 1713993","abstract":"Online labor markets such as Amazon Mechanical Turk (MTurk) have emerged as platforms that facilitate the allocation of productive effort across global economies. Many of these markets compensate workers with monetary payments. We study the effects of performance-contingent financial rewards on work quality and worker effort in MTurk via two experiments. We find that the magnitude of performance-contingent financial rewards alone affects neither quality nor effort. However, when workers working on two tasks of the same type in a sequence, the change in the magnitude of the reward over the two tasks affects both. In particular, both work quality and worker effort increase (alternatively decrease) as the reward increases (alternatively decreases) for the second task. This suggests the existence of the anchoring effect on workers' perception of incentives in MTurk and that this effect can be leveraged in workflow design to increase the effectiveness of financial incentives.","cites":"10","conferencePercentile":"82"},{"venue":"AAAI","id":"9d46bcb6ee77633460c555f70cc67972c89aee2d","venue_1":"AAAI","year":"2007","title":"Multi-Label Learning by Instance Differentiation","authors":"Min-Ling Zhang, Zhi-Hua Zhou","author_ids":"3044867, 1692625","abstract":"Multi-label learning deals with ambiguous examples each may belong to several concept classes simultaneously. In this learning framework, the inherent ambiguity of each example is explicitly expressed in the output space by being associated with multiple class labels. While on the other hand, its ambiguity is only implicitly encoded in the input space by being represented by only a single instance. Based on this recognition , we hypothesize that if the inherent ambiguity can be explicitly expressed in the input space appropriately , the problem of multi-label learning can be solved more effectively. We justify this hypothesis by proposing a novel multi-label learning approach named INS-DIF. The core of INSDIF is instance differentiation that transforms an example into a bag of instances each of which reflects the example's relationship with one of the possible classes. In this way, INSDIF directly addresses the inherent ambiguity of each example in the input space. A two-level classification strategy is employed to learn from the transformed examples. Applications to automatic web page categorization, natural scene classification and gene functional analysis show that our approach outperforms several well-established multi-label learning algorithms.","cites":"30","conferencePercentile":"81.30563798"},{"venue":"AAAI","id":"1cd01a7c94bdb4c556a7772f06a4943652de0f40","venue_1":"AAAI","year":"2006","title":"Improve Web Search Using Image Snippets","authors":"Xiao-Bing Xue, Zhi-Hua Zhou, Zhongfei Zhang","author_ids":"1773152, 1692625, 1720488","abstract":"The Web has become the largest information repository over the world. Therefore, effectively and efficiently searching the Web becomes a key challenge. Previous research on Web search mainly attempts to exploit the text in the Web pages and the link information between the pages. This paper shows that the Web search performance can be enhanced if image information is considered. In detail, a new Web search framework is proposed, where image snippets are extracted for the Web pages, which are then provided along with text snippets to the user such that it is much easier and more accurate for the user to identify the Web pages he or she expects and to re-formulate the initial query. Experimental evaluations demonstrate the promise of the proposed framework.","cites":"7","conferencePercentile":"43.08357349"},{"venue":"AAAI","id":"1a810820bb73aa097e62bff01506251ead0c7642","venue_1":"AAAI","year":"2006","title":"A New Approach to Estimating the Expected First Hitting Time of Evolutionary Algorithms","authors":"Yang Yu, Zhi-Hua Zhou","author_ids":"3839568, 1692625","abstract":"Evolutionary algorithms (EA) have been shown to be very effective in solving practical problems, yet many important theoretical issues of them are not clear. The expected first hitting time is one of the most important theoretical issues of evolutionary algorithms, since it implies the average computational time complexity. In this paper, we establish a bridge between the expected first hitting time and another important theoretical issue , i.e., convergence rate. Through this bridge, we propose a new general approach to estimating the expected first hitting time. Using this approach, we analyze EAs with different configurations, including three mutation operators, with/without population, a recombination operator and a time variant mutation operator, on a hard problem. The results show that the proposed approach is helpful for analyzing a broad range of evolutionary algorithms. Moreover, we give an explanation of what makes a problem hard to EAs, and based on the recognition, we prove the hardness of a general problem.","cites":"29","conferencePercentile":"77.23342939"},{"venue":"AAAI","id":"c9b9af8381ba3bbed2e51adc222abb7a416121d1","venue_1":"AAAI","year":"2005","title":"Boosting Sex Identification Performance","authors":"Shumeet Baluja, Henry A. Rowley","author_ids":"1767244, 1716559","abstract":"This paper presents a method based on AdaBoost to identify the sex of a person from a low resolution grayscale picture of their face. The method described here is implemented in a system that will process well over 10 9 images. The goal of this work is to create an efficient system that is both simple to implement and maintain; the methods described here are extremely fast and have straightforward implementations. We achieve 80% accuracy in sex identification with less than 10 pixel comparisons and 90% accuracy with less than 50 pixel comparisons. The best classifiers published to date use Support Vector Machines; we match their accuracies with as few as 500 comparison operations on a 20×20 pixel image. The AdaBoost based classifiers presented here achieve over 93% accuracy; these match or surpass the accuracies of the SVM-based classifiers, and yield performance that is 50 times faster.","cites":"119","conferencePercentile":"98.95104895"},{"venue":"AAAI","id":"66ef0364f2e865c35ce5003e129ba6fc57a2afa4","venue_1":"AAAI","year":"2014","title":"Semantic Segmentation Using Multiple Graphs with Block-Diagonal Constraints","authors":"Ke Zhang, Wei Zhang, Sheng Zeng, Xiangyang Xue","author_ids":"1697503, 1739541, 1735445, 5507458","abstract":"In this paper we propose a novel method for image semantic segmentation using multiple graphs. The multi-view affinity graph is constructed by leveraging the consistency between semantic space and multiple visual spaces. With block-diagonal constraints, we enforce the affinity matrix to be sparse such that the pairwise potential for dissimilar superpixels is close to zero. By a divide-and-conquer strategy, the optimization for learning affinity matrix is decomposed into several subproblems that can be solved in parallel. Using the neighborhood relationship between superpixels and the consistency between affinity matrix and label-confidence matrix, we infer the semantic label for each superpixel of unlabeled images by minimizing an objective whose closed form solution can be easily obtained. Experimental results on two real-world image datasets demonstrate the effectiveness of our method.","cites":"1","conferencePercentile":"25.90909091"},{"venue":"AAAI","id":"4ac4fe32daf7f86234e8af403bf3dac835114fcb","venue_1":"AAAI","year":"2010","title":"Non-I.I.D. Multi-Instance Dimensionality Reduction by Learning a Maximum Bag Margin Subspace","authors":"Wei Ping, Ye Xu, Kexin Ren, Chi-Hung Chi, Shen Furao","author_ids":"2352591, 6617071, 2181364, 2839762, 1728090","abstract":"Multi-instance learning, as other machine learning tasks, also suffers from the curse of dimensionality. Although dimensionality reduction methods have been investigated for many years, multi-instance dimension-ality reduction methods remain untouched. On the other hand, most algorithms in multi-instance framework treat instances in each bag as independently and identically distributed (i.i.d.) samples, which fail to utilize the structure information conveyed by instances in a bag. In this paper, we propose a multi-instance di-mensionality reduction method, which treats instances in each bag as non-i.i.d. samples. To capture the structure information conveyed by instances in a bag, we regard every bag as a whole entity. To utilize the bag label information, we maximize the bag margin between positive and negative bags. By maximizing the defined bag margin objective function, we learn a subspace to obtain salient representation of original data. Experiments demonstrate the effectiveness of the method.","cites":"8","conferencePercentile":"43.85665529"},{"venue":"AAAI","id":"3bb73498d2cd05b3a523f84b6c64b33003f4fb64","venue_1":"AAAI","year":"2015","title":"Automatic Generation of Alternative Starting Positions for Simple Traditional Board Games","authors":"Umair Z. Ahmed, Krishnendu Chatterjee, Sumit Gulwani","author_ids":"2136867, 1746331, 2108314","abstract":"Simple board games, like Tic-Tac-Toe and CONNECT-4, play an important role not only in the development of mathematical and logical skills, but also in the emotional and social development. In this paper, we address the problem of generating targeted starting positions for such games. This can facilitate new approaches for bringing novice players to mastery , and also leads to discovery of interesting game variants. We present an approach that generates starting states of varying hardness levels for player 1 in a two-player board game, given rules of the board game, the desired number of steps required for player 1 to win, and the expertise levels of the two players. Our approach leverages symbolic methods and iterative simulation to efficiently search the extremely large state space. We present experimental results that include discovery of states of varying hardness levels for several simple grid-based board games. The presence of such states for standard game variants like 4 × 4 Tic-Tac-Toe opens up new games to be played that have never been played as the default start state is heavily biased.","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"015dd61f136735606d0f09ba87f55cb553b3e2c5","venue_1":"AAAI","year":"2014","title":"Synthesis of Geometry Proof Problems","authors":"Chris Alvin, Sumit Gulwani, Rupak Majumdar, Supratik Mukhopadhyay","author_ids":"2136178, 2108314, 1737382, 1807340","abstract":"This paper presents a semi-automated methodology for generating geometric proof problems of the kind found in a high-school curriculum. We formalize the notion of a geometry proof problem and describe an algorithm for generating such problems over a user-provided figure. Our experimental results indicate that our problem generation algorithm can effectively generate proof problems in elementary geometry. On a corpus of 110 figures taken from popular geometry textbooks , our system generated an average of about 443 problems per figure in an average time of 4.7 seconds per figure.","cites":"9","conferencePercentile":"84.43181818"},{"venue":"AAAI","id":"510e4105778ff08a3e850c7ca6f020a9509cff48","venue_1":"AAAI","year":"2014","title":"Programming by Example Using Least General Generalizations","authors":"Mohammad Raza, Sumit Gulwani, Natasa Milic-Frayling","author_ids":"1747061, 2108314, 1780840","abstract":"Recent advances in Programming by Example (PBE) have supported new applications to text editing, but existing approaches are limited to simple text strings. In this paper we address transformations in richly formatted documents, using an approach based on the idea of least general generalizations from inductive inference , which avoids the scalability issues faced by state-of-the-art PBE methods. We describe a novel domain specific language (DSL) that expresses transformations over XML structures describing richly formatted content , and a synthesis algorithm that generates a minimal program with respect to a natural subsumption ordering in our DSL. We present experimental results on tasks collected from online help forums, showing an average of 4.17 examples required for task completion.","cites":"4","conferencePercentile":"59.54545455"},{"venue":"AAAI","id":"41e8b1f4ad25917f55c6f0f0d8c9c120e73cc971","venue_1":"AAAI","year":"2012","title":"Automatically Generating Algebra Problems","authors":"Rohit Singh, Sumit Gulwani, Sriram K. Rajamani","author_ids":"1686691, 2108314, 1685546","abstract":"We propose computer-assisted techniques for helping with pedagogy in Algebra. In particular, given a proof problem p (of the form Left-hand-side-term = Right-hand-side-term), we show how to automatically generate problems that are similar to p. We believe that such a tool can be used by teachers in making examinations where they need to test students on problems similar to what they taught in class, and by students in generating practice problems tailored to their specific needs. Our first insight is that we can generalize p syntactically to a query Q that implicitly represents a set of problems [[Q]] (which includes p). Our second insight is that we can explore the space of problems [[Q]] automatically, use classical results from polynomial identity testing to generate only those problems in [[Q]] that are correct, and then use pruning techniques to generate only unique and interesting problems. Our third insight is that with a small amount of manual tuning on the query Q, the user can interactively guide the computer to generate problems of interest to her. We present the technical details of the above mentioned steps, and also describe a tool where these steps have been implemented. We also present an empirical evaluation on a wide variety of problems from various sub-fields of algebra including polynomials, trigonometry, calculus, determinants etc. Our tool is able to generate a rich corpus of similar problems from each given problem; while some of these similar problems were already present in the textbook, several were new!","cites":"33","conferencePercentile":"95.57926829"},{"venue":"AAAI","id":"1d8adfeda50a124b3b7b11dd2a7a81fee19a4033","venue_1":"AAAI","year":"2014","title":"Scalable Complex Contract Negotiation with Structured Search and Agenda Management","authors":"Xiaoqin Shelley Zhang, Mark Klein, Ivan Marsá-Maestre","author_ids":"8719932, 3920905, 1684818","abstract":"A large number of interdependent issues in complex contract negotiation poses a significant challenge for current approaches, which becomes even more apparent when negotiation problems scale up. To address this challenge, we present a structured anytime search process with an agenda management mechanism using a hierarchical negotiation model, where agents search at various levels during the negotiation with the guidance of a mediator. This structured negotiation process increases computational efficiency, making negotiations scalable for large number of interdependent issues. To validate the contributions of our approach, 1) we developed our proposed negotiation model using a hierarchical problem structure and a constraint-based preference model for real-world applications; 2) we defined a scenario matrix to capture various characteristics of negotiation scenarios and developed a scenario generator that produces test cases according to this matrix; and 3) we performed an extensive set of experiments to study the performance of this structured negotiation protocol and the influence of different scenario parameters, and investigated the Pareto efficiency and social welfare op-timality of the negotiation outcomes. The experimental result supports the hypothesis that this hierarchical negotiation approach greatly improves scalability with the complexity of the negotiation scenarios.","cites":"0","conferencePercentile":"9.431818182"},{"venue":"AAAI","id":"11a7a77e9eda4a5419211d9643bba173c71bd6b5","venue_1":"AAAI","year":"2008","title":"Hybrid Markov Logic Networks","authors":"Jue Wang, Pedro M. Domingos","author_ids":"1718812, 1740213","abstract":"Markov logic networks (MLNs) combine first-order logic and Markov networks, allowing us to handle the complexity and uncertainty of real-world problems in a single consistent framework. However, in MLNs all variables and features are discrete, while most real-world applications also contain continuous ones. In this paper we introduce hybrid MLNs, in which continuous properties (e.g., the distance between two objects) and functions over them can appear as features. Hybrid MLNs have all distributions in the exponential family as special cases (e.g., multivariate Gaussians), and allow much more compact modeling of non-i.i.d. data than propositional representations like hybrid Bayesian networks. We also introduce inference algorithms for hybrid MLNs, by extending the MaxWalkSAT and MC-SAT algorithms to continuous domains. Experiments in a mobile robot mapping domain—involving joint classification, clustering and regression—illustrate the power of hybrid MLNs as a model-ing language, and the accuracy and efficiency of the inference algorithms.","cites":"62","conferencePercentile":"95.25316456"},{"venue":"AAAI","id":"45e97c3c0bf23d6cc727075604e7b1bf96f6bef9","venue_1":"AAAI","year":"2005","title":"Modeling Human Behavior for Virtual Training Systems","authors":"Yohei Murakami, Yuki Sugimoto, Toru Ishida","author_ids":"8703425, 2692870, 1709883","abstract":"Constructing highly realistic agents is essential if agents are to be employed in virtual training systems. In training for collaboration based on face-to-face interaction, the generation of emotional expressions is one key. In training for guidance based on one-to-many interaction such as direction giving for evacuations, emotional expressions must be supplemented by diverse agent behaviors to make the training realistic. To reproduce diverse behavior, we characterize agents by using a various combinations of operation rules instantiated by the user operating the agent. To accomplish this goal, we introduce a user modeling method based on participa-tory simulations. These simulations enable us to acquire information observed by each user in the simulation and the operating history. Using these data and the domain knowledge including known operation rules, we can generate an explanation for each behavior. Moreover , the application of hypothetical reasoning, which offers consistent selection of hypotheses, to the generation of explanations allows us to use otherwise incompatible operation rules as domain knowledge. In order to validate the proposed modeling method, we apply it to the acquisition of an evacuee's model in a fire-drill experiment. We successfully acquire a subject's model corresponding to the results of an interview with the subject.","cites":"28","conferencePercentile":"77.62237762"},{"venue":"AAAI","id":"678bee270823a07ac867ee5d4494e633c83eb116","venue_1":"AAAI","year":"2016","title":"To Swap or Not to Swap? Exploiting Dependency Word Pairs for Reordering in Statistical Machine Translation","authors":"Christian Hadiwinoto, Yang Liu, Hwee Tou Ng","author_ids":"3271719, 1750084, 1707384","abstract":"Reordering poses a major challenge in machine translation (MT) between two languages with significant differences in word order. In this paper, we present a novel reordering approach utilizing sparse features based on dependency word pairs. Each instance of these features captures whether two words, which are related by a dependency link in the source sentence dependency parse tree, follow the same order or are swapped in the translation output. Experiments on Chinese-to-English translation show a statistically significant improvement of 1.21 BLEU point using our approach, compared to a state-of-the-art statistical MT system that incorporates prior reordering approaches.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"d9b0eec4560b4410aa7998bff6a13a1ba88b272a","venue_1":"AAAI","year":"2016","title":"Implicit Discourse Relation Classification via Multi-Task Neural Networks","authors":"Yang Liu, Sujian Li, Xiaodong Zhang, Zhifang Sui","author_ids":"1750084, 1695451, 1795001, 1728854","abstract":"Without discourse connectives, classifying implicit discourse relations is a challenging task and a bottleneck for building a practical discourse parser. Previous research usually makes use of one kind of discourse framework such as PDTB or RST to improve the classification performance on discourse relations. Actually, under different discourse annotation frameworks, there exist multiple corpora which have internal connections. To exploit the combination of different discourse corpora , we design related discourse classification tasks specific to a corpus, and propose a novel Convolutional Neural Network embedded multi-task learning system to synthesize these tasks by learning both unique and shared representations for each task. The experimental results on the PDTB implicit discourse relation classification task demonstrate that our model achieves significant gains over baseline systems.","cites":"5","conferencePercentile":"86.31756757"},{"venue":"AAAI","id":"4fe47e871a7e868cd53e529e9df2a53789fa32fa","venue_1":"AAAI","year":"2014","title":"A Strategy-Aware Technique for Learning Behaviors from Discrete Human Feedback","authors":"Robert Tyler Loftin, James MacGlashan, Bei Peng, Matthew E. Taylor, Michael L. Littman, Jeff Huang, David L. Roberts","author_ids":"2060093, 2700008, 7258152, 2988095, 1735162, 3404131, 5797583","abstract":"This paper introduces two novel algorithms for learning behaviors from human-provided rewards. The primary novelty of these algorithms is that instead of treating the feedback as a numeric reward signal, they interpret feedback as a form of discrete communication that depends on both the behavior the trainer is trying to teach and the teaching strategy used by the trainer. For example , some human trainers use a lack of feedback to indicate whether actions are correct or incorrect, and interpreting this lack of feedback accurately can significantly improve learning speed. Results from user studies show that humans use a variety of training strategies in practice and both algorithms can learn a contextual bandit task faster than algorithms that treat the feedback as numeric. Simulated trainers are also employed to evaluate the algorithms in both contextual bandit and sequential decision-making tasks with similar results.","cites":"13","conferencePercentile":"92.5"},{"venue":"AAAI","id":"497269e5b56c775c6a5b326cf463445db9c16802","venue_1":"AAAI","year":"2015","title":"Causal Inference via Sparse Additive Models with Application to Online Advertising","authors":"Wei Sun, Pengyuan Wang, Dawei Yin, Jian Yang, Yi Chang","author_ids":"1712625, 1771116, 2115608, 1704854, 1787097","abstract":"Advertising effectiveness measurement is a fundamental problem in online advertising. Various causal inference methods have been employed to measure the causal effects of ad treatments. However, existing methods mainly focus on linear logistic regression for uni-variate and binary treatments and are not well suited for complex ad treatments of multi-dimensions, where each dimension could be discrete or continuous. In this paper we propose a novel two-stage causal inference framework for assessing the impact of complex ad treatments. In the first stage, we estimate the propensity parameter via a sparse additive model; in the second stage, a propensity-adjusted regression model is applied for measuring the treatment effect. Our approach is shown to provide an unbiased estimation of the ad effectiveness under regularity conditions. To demonstrate the efficacy of our approach, we apply it to a real online advertising campaign to evaluate the impact of three ad treatments: ad frequency, ad channel, and ad size. We show that the ad frequency usually has a treatment effect cap when ads are showing on mobile device. In addition , the strategies for choosing best ad size are completely different for mobile ads and online ads.","cites":"4","conferencePercentile":"73.46456693"},{"venue":"AAAI","id":"07dca271ebff4a9126ad1f8e4e96465a4cb746ab","venue_1":"AAAI","year":"1994","title":"Database Learning for Software Agents","authors":"Mike Perkowitz, Oren Etzioni","author_ids":"3017541, 1741101","abstract":"With the amount of information available rapidly outstripping the ability of individuals to use it, we wish to explore how a software agent can learn a description of an information resource (such as a database on the internet) in order turn it into a well-understood tool at the agent's disposal. An agent who could do this would have access to all the information it could find without having to cache the internet. As the agent makes queries to an information resource , it will generalize from those queries and generate hypotheses about the structure and content of the database. We therefore formulate this problem as a learning problem in which the input is (1) the agent's model-its representation of the world; and (2) a series of queries to and responses from a database. The output is a mapping from fields in the information resource to predicates in the model. Our approach to this learning problem relies on overlap between the agent's model and the information in the database. The agent will use its own knowledge to form hypotheses about the structure of the records. We have developed the correspondence heuristic, which states that a correspondence of tokens between the agent's world model and the information resource indicates a correspondence between types. The agent matches the values of the fields in the database against facts in its model. The relationships that hold among these facts in the model are assumed to correspond to relationships in the database. Suppose that the agent makes a query to staffdir, the UW personnel directory, and gets back \" Oren Etzioni 206 \". The agent would have facts in its model like (lastname person37 Etzioni) and (office person37 206). From this query and this knowledge, the agent could conclude that the second field of the output is lastname and the third field is office. Our work has many similarities to structure-mapping work (Falkenhainer, Forbus, & Gentner 1986). Both approaches rely on discovering correspondences between separate domains. Structure-mapping, however, seeks correspondence between underlying structure, while the correspondence heuristic relates tokens in order to make inferences about the structure. The correspondence heuristic is an inductive bias which can be formalized as a determination: V(G Y)Pw A T(Y) A (W = w4>-S(Y) = WY)1 T is a type predicate such as \" on the UW faculty \". S is a syntactic predicate like \" the first field in the …","cites":"2","conferencePercentile":"22.46696035"},{"venue":"AAAI","id":"8ad8d2d8a1365a4217b7593a9e5baac65b271aac","venue_1":"AAAI","year":"1994","title":"Learning About Software Errors Via Systematic Experimentation","authors":"Terrance Goan, Oren Etzioni","author_ids":"2471487, 1741101","abstract":"Classical planners assume that their internal model is both correct and complete. The dynamic nature of real-world domains (e.g., multiuser software environments) makes these assumptions untenable. Several new planners (e.g.,XII [2]) have been designed to work with incomplete information, and strides have been made in planning with potentially incorrect information. But, efficient operation in the presence of incorrect information is highly dependent on a planner's ability to detect errors. Failing to recognize errors can result in unexpected and potentially destructive effects, as well as further corruption of the world model. This abstract describes ED (the Error Detective) which automatically generates error detection functions for a software robot (softbot). In addition to error detection , the functions generated by ED accurately diugnose the cause of the errors. The automatic generation of these functions is important due to the large number of conditions that can affect the success of command execution. In addition, the ability to diagnose the cause of an error can greatly reduce the number of preconditions which need to be checked,/resatisficd prior to a successful execution of the operator. In tackling this problem we utilize three key insights: (1) If an operator is completely specified, every error is due to some subset of the preconditions being unsatis-fied. (2) Software error messages generally signal only one error. For example, in UNIX, if you execute the di f f command on two files x and y, where both files are not readable, the error message would be \"di f f : x : Permission denied.\" Itprovidesnoinformation about the status of file y. More formally: error-msg(-pl and-p2) = (error-msg(-pl) or error-msg(-p2)), where-pl and-p2 represent unsatisfied preconditions. (3) Since software errors do not interact, errors can bc fixed incrementally (the decomposable fault assumption). This means we need not assume just a single fault has occurred, rather we assume that if error-msg(-pl and-p2) = error-msg(-p2) and we re-execute the operator (after achieving p2), we will now get error-msg(-pl) which can be handled in turn. ED \" learns \" the error diagnosis functions via a decision tree. The attributes which compose the training instances are: error message length (number of tokens) and a binary (present or not present) attribute for every token seen in the collected error messages. And the classes are sets of preconditions which may be at fault. We compared the accuracy of the decision tree with two other methods: (1) our current …","cites":"0","conferencePercentile":"6.387665198"},{"venue":"AAAI","id":"8c0507e4fd16cb33f29dee72ebf1770a6441ebf4","venue_1":"AAAI","year":"2010","title":"Optimal Strategies for Reviewing Search Results","authors":"Jeff Huang, Anna Kazeykina","author_ids":"1787345, 2634414","abstract":"Web search engines respond to a query by returning more results than can be reasonably reviewed. These results typically include the title, link, and snippet of content from the target link. Each result has the potential to be useful or useless and thus reviewing it has a cost and potential benefit. This paper studies the behavior of a rational agent in this setting, whose objective is to maximize the probability of finding a satisfying result while minimizing cost. We propose two similar agents with different capabilities: one that only compares result snippets relatively and one that predicts from the result snippet whether the result will be satisfying. We prove that the optimal strategy for both agents is a stopping rule: the agent reviews a fixed number of results until the marginal cost is greater than the marginal expected benefit, maximizing the overall expected utility. Finally, we discuss the relationship between rational agents and search users and how our findings help us understand reviewing behaviors.","cites":"5","conferencePercentile":"32.08191126"},{"venue":"AAAI","id":"4526a83672b221b75123d75ce86bf01e097e7fe2","venue_1":"AAAI","year":"1994","title":"Learning Decision Lists Using Homogeneous Rules","authors":"Richard Segal, Oren Etzioni","author_ids":"3275715, 1741101","abstract":"A decision list is an ordered list of conjunctive rules (Rivest 1987). Inductive algorithms such as AQ and CN2 learn decision lists incrementally, one rule at a time. Such algorithms face the rule overlap problem | the classication accuracy of the decision list depends on the overlap between the learned rules. Thus, even though the rules are learned in isolation, they can only be evaluated in concert. Existing algorithms solve this problem by adopting a greedy, iterative structure. Once a rule is learned, the training examples that match the rule are removed from the training set. We propose a novel solution to the problem: composing decision lists from homogeneous rules, rules whose classication accuracy does not change with their position in the decision list. We prove that the problem of nding a maximally accurate decision list can be reduced to the problem of nding maximally accurate homogeneous rules. We report on the performance of our algorithm on data sets from the UCI repository and on the MONK's problems.","cites":"51","conferencePercentile":"85.24229075"},{"venue":"AAAI","id":"3e2823580614383945b9d767bb28cc89d2b5d970","venue_1":"AAAI","year":"2013","title":"Detecting Patterns of Crime with Series Finder","authors":"Tong Wang, Cynthia Rudin, Daniel Wagner, Rich Sevieri","author_ids":"1695404, 1756737, 1772579, 2405213","abstract":"Many crimes can happen every day in a major city, and figuring out which ones are committed by the same individual or group is an important and difficult data mining challenge. To do this, we propose a pattern detection algorithm called Series Finder, that grows a pattern of discovered crimes from within a database, starting from a \" seed \" of a few crimes. Series Finder incorporates both the common characteristics of all patterns and the unique aspects of each specific pattern. We compared Series Finder with classic clustering and classification models applied to crime analysis. It has promising results on a decade's worth of crime pattern data from the Cambridge Police Department.","cites":"7","conferencePercentile":"73.27272727"},{"venue":"AAAI","id":"a4245eb568912dfbf5f7d50977359b4f47e0dd9f","venue_1":"AAAI","year":"2015","title":"Automated Analysis of Commitment Protocols Using Probabilistic Model Checking","authors":"Akin Günay, Songzheng Song, Yang Liu, Jie Zhang","author_ids":"1711988, 1791025, 1750084, 1698586","abstract":"Commitment protocols provide an effective formalism for the regulation of agent interaction. Although existing work mainly focus on the design-time development of static commitment protocols, recent studies propose methods to create them dynamically at run-time with respect to the goals of the agents. These methods require agents to verify new commitment protocols taking their goals, and beliefs about the other agents' behavior into account. Accordingly, in this paper, we first propose a probabilistic model to formally capture commitment protocols according to agents' beliefs. Secondly, we identify a set of important properties for the verification of a new commitment protocol from an agent's perspective and formalize these properties in our model. Thirdly, we develop probabilistic model checking algorithms with advanced reduction for efficient verification of these properties. Finally, we implement these algorithms as a tool and evaluate the proposed properties over different commitment protocols.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"0bb9a4e36248eb21f671cc7e429f940d3b4010c5","venue_1":"AAAI","year":"1994","title":"Omnipotence Without Omniscience: Efficient Sensor Management for Planning","authors":"Keith Golden, Oren Etzioni, Daniel S. Weld","author_ids":"3186159, 1741101, 1780531","abstract":"Classical planners have traditionally made the closed world assumption-facts absent from the planner's world model are false. Incomplete-information planners make the open world assumption the truth value of a fact absent from the planner's model is unknown, and must be sensed. The open world assumption leads to two difficulties: (1) H ow can the planner determine the scope of a universally quantified goal? (2) When is a sensory action redundant, yielding information already known to the planner? This paper describes the fully-implemented XII planner, which solves both problems by representing and reasoning about Zocal closed world information (LCW). We report on experiments utilizing our UNIX softbot (software robot) which demonstrate that LCW can substantially improve the soft-bot's performance by eliminating redundant information gathering.","cites":"32","conferencePercentile":"73.34801762"},{"venue":"AAAI","id":"5aef8a6992fbd56b3309f6b56337d124951bb71d","venue_1":"AAAI","year":"2015","title":"A Novel Neural Topic Model and Its Supervised Extension","authors":"Ziqiang Cao, Sujian Li, Yang Liu, Wenjie Li, Heng Ji","author_ids":"2314396, 1695451, 1750084, 1749930, 1739737","abstract":"Topic modeling techniques have the benefits of model-ing words and documents uniformly under a probabilis-tic framework. However, they also suffer from the limitations of sensitivity to initialization and unigram topic distribution, which can be remedied by deep learning techniques. To explore the combination of topic mod-eling and deep learning techniques, we first explain the standard topic model from the perspective of a neural network. Based on this, we propose a novel neural topic model (NTM) where the representation of words and documents are efficiently and naturally combined into a uniform framework. Extending from NTM, we can easily add a label layer and propose the supervised neu-ral topic model (sNTM) to tackle supervised tasks. Experiments show that our models are competitive in both topic discovery and classification/regression tasks.","cites":"14","conferencePercentile":"95.59055118"},{"venue":"AAAI","id":"994afdf0db0cb0456f4f76468380822c2f532726","venue_1":"AAAI","year":"2015","title":"Learning Entity and Relation Embeddings for Knowledge Graph Completion","authors":"Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, Xuan Zhu","author_ids":"2427350, 1990595, 1753344, 1750084, 2588313","abstract":"Knowledge graph completion aims to perform link prediction between entities. In this paper, we consider the approach of knowledge graph embeddings. Recently, models such as TransE and TransH build entity and relation embeddings by regarding a relation as translation from head entity to tail entity. We note that these models simply put both entities and relations within the same semantic space. In fact, an entity may have multiple aspects and various relations may focus on different aspects of entities, which makes a common space insufficient for modeling. In this paper, we propose TransR to build entity and relation embeddings in separate entity space and relation spaces. Afterwards, we learn embeddings by first projecting entities from entity space to corresponding relation space and then building translations between projected entities. In experiments , we evaluate our models on three tasks including link prediction, triple classification and rela-tional fact extraction. Experimental results show significant and consistent improvements compared to state-of-the-art baselines including TransE and TransH. The source code of this paper can be obtained from https: //github.com/mrlyk423/relation extraction.","cites":"67","conferencePercentile":"100"},{"venue":"AAAI","id":"6363cfe79b33d66deeeba0e68e89f15b3e1e657f","venue_1":"AAAI","year":"2015","title":"Topical Word Embeddings","authors":"Yang Liu, Zhiyuan Liu, Tat-Seng Chua, Maosong Sun","author_ids":"1750084, 1990595, 1684968, 1753344","abstract":"Most word embedding models typically represent each word using a single vector, which makes these models indiscriminative for ubiquitous homonymy and poly-semy. In order to enhance discriminativeness, we employ latent topic models to assign topics for each word in the text corpus, and learn topical word embeddings (TWE) based on both words and their topics. In this way, contextual word embeddings can be flexibly obtained to measure contextual word similarity. We can also build document representations, which are more expressive than some widely-used document models such as latent topic models. In the experiments, we evaluate the TWE models on two tasks, contextual word similarity and text classification. The experimental results show that our models outperform typical word embedding models including the multi-prototype version on contextual word similarity, and also exceed latent topic models and other representative document models on text classification. The source code of this paper can be obtained from https://github.com/ largelymfs/topical_word_embeddings.","cites":"7","conferencePercentile":"88.11023622"},{"venue":"AAAI","id":"5f27266b3abee6ccd670367e2de944e19472a72a","venue_1":"AAAI","year":"1994","title":"A Prototype Reading Coach that Listens","authors":"Jack Mostow, Steven F. Roth, Alexander G. Hauptmann, Matthew Kane","author_ids":"1695106, 1697331, 7661726, 1727420","abstract":" We report progress on a new approach to combatting illiteracy-getting computers to listen to children read aloud. We describe a fully automated prototype coach for oral reading. It displays a story on the screen, listens as a child reads it, and decides whether and how to intervene. We report on pilot experiments with low-reading second graders to test whether these interventions are technically feasible to automate and pedagogically effective to perform. By adapting a continuous speech recognizer, we detected 49% of the misread words, with a false alarm rate under 4%. By incorporating the interventions in a simulated coach, we enabled the children to read and comprehend material at a reading level 0.6 years higher than what they could read on their own. We show how the prototype uses the recognizer to trigger these interventions automatically.","cites":"94","conferencePercentile":"91.62995595"},{"venue":"AAAI","id":"56dd08bda4aa863222a7ab152c597a142b07d4ae","venue_1":"AAAI","year":"1994","title":"A Reading Coach that Listens: (Edited) Video Transcript","authors":"Jack Mostow, Alexander G. Hauptmann, Steven F. Roth, Matthew Kane, Adam Swift, Lin Lawrence Chase, Bob Weide","author_ids":"1695106, 7661726, 1697331, 1727420, 2497927, 4849653, 2340973","abstract":"Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.","cites":"2","conferencePercentile":"22.46696035"},{"venue":"AAAI","id":"3df825e086b00dd4132c34ecbf638f9a6dc4320d","venue_1":"AAAI","year":"2010","title":"Integrating Transfer Learning in Synthetic Student","authors":"Nan Li, William W. Cohen, Kenneth R. Koedinger","author_ids":"1736069, 1702241, 1718810","abstract":"Building an intelligent agent, which simulates human-level learning appropriate for learning math, science, or a second language, could potentially benefit both education in understanding human learning, and artificial intelligence in creating human-level intelligence. Recently, we have proposed an efficient approach to acquiring procedural knowledge using transfer learning. However, it operated as a separate module. In this paper, we describe how to integrate this module into a machine-learning agent, SimStudent, that learns procedural knowledge from examples and through problem solving. We illustrate this method in the domain of algebra, after which we consider directions for future research in this area.","cites":"0","conferencePercentile":"3.754266212"},{"venue":"AAAI","id":"cf8e68ab6c4f6c10a9780b692b86d5309f67970c","venue_1":"AAAI","year":"2016","title":"Finding One's Best Crowd: Online Learning By Exploiting Source Similarity","authors":"Yang Liu, Mingyan Liu","author_ids":"1750084, 1724680","abstract":"We consider an online learning problem (classification or prediction) involving disparate sources of sequentially arriving data, whereby a user over time learns the best set of data sources to use in constructing the classifier by exploiting their similarity. We first show that, when (1) the similarity information among data sources is known, and (2) data from different sources can be acquired without cost, then a judicious selection of data from different sources can effectively enlarge the training sample size compared to using a single data source, thereby improving the rate and performance of learning; this is achieved by bounding the classification error of the resulting classifier. We then relax assumption (1) and characterize the loss in learning performance when the similarity information must also be acquired through repeated sampling. We further relax both (1) and (2) and present a cost-efficient algorithm that identifies a best crowd from a potentially large set of data sources in terms of both classifier performance and data acquisition cost. This problem has various applications, including online prediction systems with time series data of various forms, such as financial markets, advertisement and network measurement.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"62c0ac04b5b4e9e67efb0027c983eb0f211671d0","venue_1":"AAAI","year":"2015","title":"Contrastive Unsupervised Word Alignment with Non-Local Features","authors":"Yang Liu, Maosong Sun","author_ids":"1750084, 1753344","abstract":"Word alignment is an important natural language processing task that indicates the correspondence between natural languages. Recently, unsupervised learning of log-linear models for word alignment has received considerable attention as it combines the merits of gener-ative and discriminative approaches. However, a major challenge still remains: it is intractable to calculate the expectations of non-local features that are critical for capturing the divergence between natural languages. We propose a contrastive approach that aims to differentiate observed training examples from noises. It not only introduces prior knowledge to guide unsupervised learning but also cancels out partition functions. Based on the observation that the probability mass of log-linear models for word alignment is usually highly concentrated, we propose to use top-n alignments to approximate the expectations with respect to posterior distributions. This allows for efficient and accurate calculation of expectations of non-local features. Experiments show that our approach achieves significant improvements over state-of-the-art unsupervised word alignment methods.","cites":"7","conferencePercentile":"88.11023622"},{"venue":"AAAI","id":"630e1fda761d3c10f1f4ab4e56087c8078b4cfb2","venue_1":"AAAI","year":"2014","title":"Reconsidering Mutual Information Based Feature Selection: A Statistical Significance View","authors":"Nguyen Xuan Vinh, Jeffrey Chan, James Bailey","author_ids":"1724678, 6273657, 6263638","abstract":"Mutual information (MI) based approaches are a popular feature selection paradigm. Although the stated goal of MI-based feature selection is to identify a subset of features that share the highest mutual information with the class variable, most current MI-based techniques are greedy methods that make use of low dimensional MI quantities. The reason for using low dimensional approximation has been mostly attributed to the difficulty associated with estimating the high dimensional MI from limited samples. In this paper, we argue a different viewpoint that, given a very large amount of data, the high dimensional MI objective is still problematic to be employed as a meaningful optimization criterion, due to its overfitting nature: the MI almost always increases as more features are added, thus leading to a trivial solution which includes all features. We propose a novel approach to the MI-based feature selection problem , in which the overfitting phenomenon is controlled rigourously by means of a statistical test. We develop local and global optimization algorithms for this new feature selection model, and demonstrate its effectiveness in the applications of explaining variables and objects.","cites":"2","conferencePercentile":"38.63636364"},{"venue":"AAAI","id":"17a0cd086d4af010c49074f32ad139da12f15ad9","venue_1":"AAAI","year":"2015","title":"A Hybrid Approach of Classifier and Clustering for Solving the Missing Node Problem","authors":"Sigalit Sina, Avi Rosenfeld, Sarit Kraus, Navot Akiva","author_ids":"2993550, 1955991, 1691597, 3332806","abstract":"An important area of social network research is identifying missing information which is not explicitly represented in the network or is not visible to all. In this paper, we propose a novel Hybrid Approach of Classifier and Clustering, which we refer to as HACC, to solve the missing node identification problem in social networks. HACC utilizes a classifier as a preprocessing step in order to integrate all known information into one similarity measure and then uses a clustering algorithm to identify missing nodes. Specifically, we used the information on the network structure, attributes about known users (nodes) and pictorial information to evaluate HACC and found that it performs significantly better than other missing node algorithms. We also argue that HACC is a general approach and domain independent and can be easily applied to other domains. We support this claim by evaluating HACC on a second authorship identification domain as well.","cites":"2","conferencePercentile":"51.65354331"},{"venue":"AAAI","id":"23d67e22b15779fb92afced00383ed4656bd7c13","venue_1":"AAAI","year":"2015","title":"Providing Arguments in Discussions Based on the Prediction of Human Argumentative Behavior","authors":"Ariel Rosenfeld, Sarit Kraus","author_ids":"2101552, 1691597","abstract":"Argumentative discussion is a highly demanding task. In order to help people in such situations, this paper provides an innovative methodology for developing an agent that can support people in argumentative discussions by proposing possible arguments to them. By analyzing more than 130 human discussions and 140 questionnaires , answered by people, we show that the well-established Argumentation Theory is not a good predic-tor of people's choice of arguments. Then, we present a model that has 76% accuracy when predicting peoples top three argument choices given a partial deliberation. We present the Predictive and Relevance based Heuris-tic agent (PRH), which uses this model with a heuris-tic that estimates the relevance of possible arguments to the last argument given in order to propose possible arguments. Through extensive human studies with over 200 human subjects, we show that peoples satisfaction from the PRH agent is significantly higher than from other agents that propose arguments based on Argumen-tation Theory, predict arguments without the heuristics or only the heuristics. People also use the PRH agent's proposed arguments significantly more often than those proposed by the other agents.","cites":"16","conferencePercentile":"96.61417323"},{"venue":"AAAI","id":"3fa884dcec5b7e0547cc080f00a87718734269af","venue_1":"AAAI","year":"2005","title":"Team Member Reallocation via Tree Pruning","authors":"Noa Agmon, Gal A. Kaminka, Sarit Kraus","author_ids":"2442305, 1725049, 1691597","abstract":"This paper considers the task reallocation problem, where £ agents are to be extracted from a coordinated group of ¤ agents in order to perform a new task. The interaction between the team members and the cost associated with this interaction are represented by a weighted graph. Consider a group of ¤ robots organized in a formation, the graph is the monitoring graph which represents the sensorial capabilities of the robots, i.e., which robot can sense the other and at what cost. Following this example, the team member reallocation problem this paper deals with is the extraction of £ robots from the group in order to acquire a new target, while minimizing the cost of the interaction of the remaining group. In general, the method proposed here shifts the utility from the team member itself to the interaction between the members, and calculates the reallocation according to this interaction utility. We found that this can be done optimally by a deter-ministic polynomial time algorithm under several constraints, the first constraint is that £ ¦ ¥ ¨ § © ¤. We describe several other domains in which this method is applicable.","cites":"2","conferencePercentile":"16.25874126"},{"venue":"AAAI","id":"51037e762fa4081f5f1523f614db129133c3fb36","venue_1":"AAAI","year":"2005","title":"Supporting Collaborative Activity","authors":"Meirav Hadad, Gilad Armon-Kest, Gal A. Kaminka, Sarit Kraus","author_ids":"2996406, 1998140, 1725049, 1691597","abstract":"This paper presents a model—SharedActivity—for collabo-rative agents acting in a group. The model suggests mental states for agents with different levels of cooperation and permits the formation of groups in which members increase individual benefits. Unlike previous models, the model covers group member behavior where group members do not have a joint goal, but act collaboratively. The model defines key components of a collaborative activity and provides a platform for supporting such activity. We studied the behavior of the model in a simulation environment. Results show how the benefit attained by cooperation is influenced by the complexity of the environment, the number of group members, and the social dependencies between the members. The results demonstrate that the model covers social behavior both in settings previously addressed, as well as in novel settings.","cites":"8","conferencePercentile":"36.18881119"},{"venue":"AAAI","id":"5d6d6055bf89b6df4001b689abd4c8aa7aa4f003","venue_1":"AAAI","year":"2012","title":"Counting-MLNs: Learning Relational Structure for Decision Making","authors":"Aniruddh Nath, Matthew Richardson","author_ids":"3046228, 2347225","abstract":"Many first-order probabilistic models can be represented much more compactly using aggregation operations such as counting. While traditional statistical relational representations share factors across sets of interchangeable random variables, representations that explicitly model aggregations also exploit interchange-ability of random variables within factors. This is especially useful in decision making settings, where an agent might need to reason about counts of the different types of objects it interacts with. Previous work on counting formulas in statistical relational representations has mostly focused on the problem of exact inference on an existing model. The problem of learning such models is largely unexplored. In this paper , we introduce Counting Markov Logic Networks (C-MLNs), an extension of Markov logic networks that can compactly represent complex counting formulas. We present a structure learning algorithm for C-MLNs; we apply this algorithm to the novel problem of generalizing natural language instructions, and to relational reinforcement learning in the Crossblock domain, in which standard MLN learning algorithms fail to find any useful structure. The C-MLN policies learned from natural language instructions are compact and intuitive, and, despite requiring no instructions on test games, win 20% more Crossblock games than a state-of-the-art algorithm for following natural language instructions.","cites":"2","conferencePercentile":"22.40853659"},{"venue":"AAAI","id":"044d02766ecff60244ab7ac0ed4719b4752a57bf","venue_1":"AAAI","year":"2005","title":"Cooperative Exploration in the Electronic Marketplace","authors":"David Sarne, Sarit Kraus","author_ids":"1707363, 1691597","abstract":"In this paper we study search strategies of agents that represent buyer agents' coalitions in electronic marketplaces. The representative agents operate in environments where numerous potential complex opportunities can be found. Each opportunity is associated with several different terms and conditions thus differing from other opportunities by its value for the coalition. Given a search cost, the goal of the representative agent is to find the best set of opportunities which fulfills the coalition's demands with the maximum overall utility, to be divided among the coalition members. Given the option of side-payments, this strategy will always be preferred by all coalition members (thus no conflict of interests), regardless of the coalition's payoff division protocol. We analyze the incentive to form such coalitions and extract the optimal search strategy for their representative agents, with a distinction between operating in B2C and C2C markets. Based on our findings we suggest efficient algorithms to be used by the representative agents for calculating their strategy and the appropriate derived expected utilities. A computational-based example is given, illustrating the achieved performance as a function of the het-erogeneity level of the coalition's members.","cites":"15","conferencePercentile":"59.26573427"},{"venue":"AAAI","id":"815365c6c5bafb1cf510782062fa814daa175859","venue_1":"AAAI","year":"1994","title":"A Qualitative Physics Compiler","authors":"Adam Farquhar","author_ids":"3017458","abstract":"Predicting the behavior of physical systems is essential to both common sense and engineering tasks. It is made especially challenging by the lack of complete precise knowledge of the phenomena in the domain and the system being modelled. We present an implemented approach to automatically building and simulating qualitative models of physical systems. Imprecise knowledge of phenomena is expressed by qualitative representations of monotonic functions and variable values. Incomplete knowledge about the system is either inferred or alternative complete descriptions that will affect behavior are explored. The architecture and algorithms used support both effective implementation and formal analysis. The expressiveness of the modelling language and strength of the resulting predictions are demonstrated by substantial applications to complex systems.","cites":"25","conferencePercentile":"66.07929515"},{"venue":"AAAI","id":"0935b4f7606bf8f9f25019cdc62a25ef7e50f0c8","venue_1":"AAAI","year":"2005","title":"Solving the Auction-Based Task Allocation Problem in an Open Environment","authors":"David Sarne, Sarit Kraus","author_ids":"1707363, 1691597","abstract":"In this paper we analyze the process of allocating tasks to self-interested agents in uncertain changing open environments. The allocator in our model is responsible for the performance of dynamically arriving tasks using a second price reverse auction as the allocation protocol. Since the agents are self-interested (i.e. each agent attempts to maximize its own revenue), previous models concerning cooperative agents aiming for a joint goal are not applicable. Thus the main challenge is to identify a set of equilibrium strategies-a stable solution where no agent can benefit from changing its strategy given the other agents' strategies-for any specific environmental settings. We formulate the model and discuss the difficulty in extracting the agents' equilibrium strategies directly from the model's equations. Consequently we propose an efficient algorithm to accurately approximate the agents' equilibrium strategies. A comparative illustration through simulation of the system performance in a closed and open environments is given, emphasizing the advantage of the allocator operating in the latter environment, reaching results close to those obtained by a central en-forceable allocation.","cites":"9","conferencePercentile":"39.86013986"},{"venue":"AAAI","id":"320ec8a9b9256405a7c3ee7b6b1a6aafb489cdf5","venue_1":"AAAI","year":"2010","title":"Multilinear Maximum Distance Embedding Via L1-Norm Optimization","authors":"Yang Liu, Yan Liu, Keith C. C. Chan","author_ids":"1739842, 1681842, 1757062","abstract":"Dimensionality reduction plays an important role in many machine learning and pattern recognition tasks. In this paper, we present a novel dimensionality reduction algorithm called multilinear maximum distance embedding (M 2 DE), which includes three key components. To preserve the local geometry and discriminant information in the embedded space, M 2 DE utilizes a new objective function, which aims to maximize the distances between some particular pairs of data points, such as the distances between nearby points and the distances between data points from different classes. To make the mapping of new data points straightforward, and more importantly, to keep the natural tensor structure of high-order data, M 2 DE integrates multilinear techniques to learn the transformation matrices sequentially. To provide reasonable and stable embedding results, M 2 DE employs the L 1-norm, which is more robust to outliers, to measure the dissimilarity between data points. Experiments on various datasets demonstrate that M 2 DE achieves good embedding results of high-order data for classification tasks.","cites":"4","conferencePercentile":"27.1331058"},{"venue":"AAAI","id":"79e91b6f403a40a5fc0a7c4f4e4f1d6a56658686","venue_1":"AAAI","year":"2011","title":"Ordinal Regression via Manifold Learning","authors":"Yang Liu, Yan Liu, Keith C. C. Chan","author_ids":"1739842, 1681842, 1757062","abstract":"Ordinal regression is an important research topic in machine learning. It aims to automatically determine the implied rating of a data item on a fixed, discrete rating scale. In this paper, we present a novel ordinal regression approach via manifold learning, which is capable of uncovering the embedded nonlinear structure of the data set according to the observations in the high-dimensional feature space. By optimizing the order information of the observations and preserving the intrinsic geometry of the data set simultaneously, the proposed algorithm provides the faithful ordinal regression to the new coming data points. To offer more general solution to the data with natural tensor structure, we further introduce the multilinear extension of the proposed algorithm, which can support the ordinal regression of high order data like images. Experiments on various data sets validate the effectiveness of the proposed algorithm as well as its extension.","cites":"2","conferencePercentile":"24.05498282"},{"venue":"AAAI","id":"a9c2b8c5e9452760b1e7ce317df6bbc5af7c6c20","venue_1":"AAAI","year":"2005","title":"Impact of Linguistic Analysis on the Semantic Graph Coverage and Learning of Document Extracts","authors":"Jure Leskovec, Natasa Milic-Frayling, Marko Grobelnik","author_ids":"1702139, 1780840, 1775954","abstract":"Automatic document summarization is a problem of creating a document surrogate that adequately represents the full document content. We aim at a summarization system that can replicate the quality of summaries created by humans. In this paper we investigate the machine learning method for extracting full sentences from documents based on the document semantic graph structure. In particular, we explore how the Support Vector Machines (SVM) learning method is affected by the quality of linguistic analyses and the corresponding semantic graph representations. We apply two types of linguistic analysis: (1) a simple part-of-speech tagging of noun phrases and verbs and (2) full logical form analysis which identifies Subject-Predicate-Object triples, and then build the semantic graphs. We train the SVM classifier to identify summary nodes and use these nodes to extract sentences. Experiments with the DUC 2002 and CAST datasets show that the SVM based extraction of sentences does not differ significantly for the simple and the sophisticated syntactic analysis. In both cases the graph attributes used in learning are essential for the classifier performance and the quality of extracted summaries.","cites":"21","conferencePercentile":"69.23076923"},{"venue":"AAAI","id":"0ac1ce628f725291d476eada36d5b7284fb492ce","venue_1":"AAAI","year":"2008","title":"A Theory of Expressiveness in Mechanisms","authors":"Michael Benisch, Norman M. Sadeh, Tuomas Sandholm","author_ids":"2742523, 2464164, 1732422","abstract":"A key trend in the world—especially in electronic commerce—is a demand for higher levels of expressiveness in the mechanisms that mediate interactions, such as the allocation of resources, matching of peers, and elicitation of opinions from large and diverse communities. Intuitively, one would think that this increase in expressiveness would lead to more efficient mechanisms (e.g., due to better matching of supply and demand). However, until now we have lacked a general way of characterizing the expressiveness of these mechanisms, analyzing how it impacts the actions taken by rational agents—and ultimately the outcome of the mechanism. In this technical report we introduce a general model of expressiveness for mechanisms. Our model is based on a new measure which we refer to as the maximum impact dimension. The measure captures the number of different ways that an agent can impact the outcome of a mechanism. We proceed to uncover a fundamental connection between this measure and the concept of shattering from computational learning theory. We also provide a way to determine an upper bound on the expected efficiency of any mechanism under its most efficient Nash equilibrium which, remarkably, depends only on the mech-anism's expressiveness. We show that for any setting and any prior over agent preferences, the bound on efficiency of a mechanism designed optimally under a constraint on expressiveness increases strictly as more expressiveness is allowed (until the bound reaches full efficiency). In addition, we prove that a small increase in expressiveness can potentially lead to an arbitrarily large increase in the efficiency bound, depending on the prior. We conclude with a study of a restricted class of mechanisms which we call channel based. The restriction is that these mechanisms take expressions of value through channels from agents to outcomes, and select the outcome with the largest sum. (Channel-based mechanisms subsume most combinatorial and multi-attribute auctions, any Vickrey-Clarke-Groves mechanism, etc.) In this class, a natural measure of expressiveness is the number of channels allowed (this generalizes the k-wise dependence measure of expressiveness traditionally used in the combinatorial auction literature). As a sanity check of our general domain-independent measure of expressiveness, we show that it appropriately relates to the number of channels when applied to channel-based mechanisms. This allows us to transfer all of our results regarding efficiency to this domain.","cites":"15","conferencePercentile":"68.82911392"},{"venue":"AAAI","id":"20c9557931fcb056790cf10b8333cde9847372ec","venue_1":"AAAI","year":"2015","title":"A Faster Core Constraint Generation Algorithm for Combinatorial Auctions","authors":"Benedikt Bünz, Sven Seuken, Benjamin Lubin","author_ids":"2364429, 1884044, 2335065","abstract":"Computing prices in core-selecting combinatorial auctions is a computationally hard problem. Auctions with many bids can only be solved using a recently proposed core constraint generation (CCG) algorithm, which may still take days on hard instances. In this paper, we present a new algorithm that significantly outperforms the current state of the art. Towards this end, we first provide an alternative definition of the set of core constraints , where each constraint is weakly stronger, and prove that together these constraints define the identical polytope to the previous definition. Using these new theoretical insights we develop two new algorith-mic techniques which generate additional constraints in each iteration of the CCG algorithm by 1) exploiting separability in allocative conflicts between participants in the auction, and 2) by leveraging non-optimal solutions. We show experimentally that our new algorithm leads to significant speed-ups on a variety of large com-binatorial auction problems. Our work provides new insights into the structure of core constraints and advances the state of the art in fast algorithms for computing core prices in large combinatorial auctions.","cites":"2","conferencePercentile":"51.65354331"},{"venue":"AAAI","id":"096375c7076fd4563fc3f440b02bc6e0bba9def7","venue_1":"AAAI","year":"2011","title":"Detecting Multilingual and Multi-Regional Query Intent in Web Search","authors":"Yi Chang, Ruiqiang Zhang, Srihari Reddy, Yan Liu","author_ids":"1787097, 1763629, 2246185, 1681842","abstract":"With rapid growth of commercial search engines, detecting multilingual and multi-regional intent underlying search queries becomes a critical challenge to serve international users with diverse language and region requirements. We introduce a query intent probabilistic model, whose input is the number of clicks on documents from different regions and in different language, while the output of this model is a smoothed probabilistic distribution of multilingual and multi-regional query intent. Based on an editorial test to evaluate the accuracy of the intent classifier, our probabilis-tic model could improve the accuracy of multilingual intent detection for 15%, and improve multi-regional intent detection for 18%. To improve web search quality, we propose a set of new ranking features to combine multilingual and multi-regional query intent with document language/region attributes, and apply different approaches in integrating intent information to directly affect ranking. The experiments show that the novel features could provide 2.31% NDCG@1 improvement and 1.81% NDCG@5 improvement.","cites":"1","conferencePercentile":"16.15120275"},{"venue":"AAAI","id":"fa32534452326ea9f2add206a64d0be764439f6b","venue_1":"AAAI","year":"2011","title":"Transfer Latent Semantic Learning: Microblog Mining with Less Supervision","authors":"Dan Zhang, Yan Liu, Richard D. Lawrence, Vijil Chenthamarakshan","author_ids":"3385810, 1681842, 1943602, 1776280","abstract":"The increasing volume of information generated on micro-blogging sites such as Twitter raises several challenges to traditional text mining techniques. First, most texts from those sites are abbreviated due to the constraints of limited characters in one post; second, the input usually comes in streams of large-volumes. Therefore, it is of significant importance to develop effective and efficient representations of abbreviated texts for better filtering and mining. In this paper, we introduce a novel transfer learning approach, namely transfer latent semantic learning, that utilizes a large number of related tagged documents with rich information from other sources (source domain) to help build a robust latent semantic space for the abbreviated texts (target domain). This is achieved by simultaneously minimizing the document reconstruction error and the classification error of the labeled examples from the source domain by building a classifier with hinge loss in the latent semantic space. We demonstrate the effectiveness of our method by applying them to the task of classifying and tagging abbreviated texts. Experimental results on both synthetic datasets and real application datasets, including Reuters-21578 and Twitter data, suggest substantial improvements using our approach over existing ones.","cites":"4","conferencePercentile":"35.2233677"},{"venue":"AAAI","id":"ef9e17ef4dc2b42c5ec2cacf9a504f844ced484b","venue_1":"AAAI","year":"2012","title":"Query-Oriented Multi-Document Summarization via Unsupervised Deep Learning","authors":"Yan Liu, Sheng-hua Zhong, Wenjie Li","author_ids":"1681842, 1700861, 1749930","abstract":"Extractive style query oriented multi document summariza tion generates the summary by extracting a proper set of sentences from multiple documents based on the pre given query. This paper proposes a novel multi document summa rization framework via deep learning model. This uniform framework consists of three parts: concepts extraction, summary generation, and reconstruction validation, which work together to achieve the largest coverage of the docu ments content. A new query oriented extraction technique is proposed to concentrate distributed information to hidden units layer by layer. Then, the whole deep architecture is fi ne tuned by minimizing the information loss of reconstruc tion validation. According to the concentrated information, dynamic programming is used to seek most informative set of sentences as the summary. Experiments on three bench mark datasets demonstrate the effectiveness of the proposed framework and algorithms.","cites":"7","conferencePercentile":"55.18292683"},{"venue":"AAAI","id":"2ac72a7d5900f8fd3f4b8af0226fbee74ab5797c","venue_1":"AAAI","year":"2015","title":"Detecting Change Points in the Large-Scale Structure of Evolving Networks","authors":"Leto Peel, Aaron Clauset","author_ids":"2570515, 1978989","abstract":"Interactions among people or objects are often dynamic in nature and can be represented as a sequence of networks , each providing a snapshot of the interactions over a brief period of time. An important task in analyzing such evolving networks is change-point detection , in which we both identify the times at which the large-scale pattern of interactions changes fundamentally and quantify how large and what kind of change occurred. Here, we formalize for the first time the network change-point detection problem within an on-line probabilistic learning framework and introduce a method that can reliably solve it. This method combines a generalized hierarchical random graph model with a Bayesian hypothesis test to quantitatively determine if, when, and precisely how a change point has occurred. We analyze the detectability of our method using synthetic data with known change points of different types and magnitudes, and show that this method is more accurate than several previously used alternatives. Applied to two high-resolution evolving social networks, this method identifies a sequence of change points that align with known external \" shocks \" to these networks. Networks are frequently used as a general framework to quantify and analyze the interactions between objects or people. Network models can be used to better understand the large-scale structure of interactions by identifying clusters of highly interacting communities or functional groups of structurally equivalent nodes. However, these interactions are often dynamic in nature, and traditional approaches can overlook the non-stationary structure of real networks. In these dynamic and temporally evolving systems we are not only interested in understanding the large-scale structure but also identifying if, when and how it changes in time. For instance, in social networks, change points may be the result of normal periodic behavior, as in the weekly transition from weekdays to weekends. In other cases, change points may result from the collective anticipation of or response to external events or system \" shocks \". Detecting such changes in social networks could provide a better understanding of patterns of social life and an early detection of social stress caused by, e.g, natural or man-made disasters. Here we define the network change-point detection problem and introduce an online probabilistic learning algorithm for solving it. Identifying a change point requires inferring a structural \" norm \" for interactions across a sequence of graphs and accurately detecting if, when and how this norm has shifted at some …","cites":"18","conferencePercentile":"97.55905512"},{"venue":"AAAI","id":"2874d484bb61f04ce44214e1c9aa9417e68ac6e7","venue_1":"AAAI","year":"2010","title":"Assisting Users with Clustering Tasks by Combining Metric Learning and Classification","authors":"Sumit Basu, Danyel Fisher, Steven M. Drucker, Hao Lu","author_ids":"1801676, 3031307, 2311676, 1707741","abstract":"Interactive clustering refers to situations in which a human labeler is willing to assist a learning algorithm in automatically clustering items. We present a related but somewhat different task, assisted clustering, in which a user creates explicit groups of items from a large set and wants suggestions on what items to add to each group. While the traditional approach to interactive clustering has been to use metric learning to induce a distance metric, our situation seems equally amenable to classification. Using clusterings of documents from human subjects, we found that one or the other method proved to be superior for a given cluster, but not uniformly so. We thus developed a hybrid mechanism for combining the metric learner and the classifier. We present results from a large number of trials based on human clusterings, in which we show that our combination scheme matches and often exceeds the performance of a method which exclusively uses either type of learner.","cites":"11","conferencePercentile":"54.94880546"},{"venue":"AAAI","id":"69ca72a0183220bc3a9d3a76892a36a6c23ee13e","venue_1":"AAAI","year":"2008","title":"Loop Formulas for Logic Programs with Arbitrary Constraint Atoms","authors":"Jia-Huai You, Guohua Liu","author_ids":"8352837, 1700953","abstract":"We formulate loop formulas for logic programs with arbitrary constraint atoms, for the semantics based on conditional satisfaction. This provides a method for answer set computation by computing models of completion. One particular attractive candidate for the latter task is pseudo-boolean constraint solvers. To strengthen this connection, we show examples of compact encoding of aggregates and global constraints by pseudo-boolean constraints.","cites":"10","conferencePercentile":"54.90506329"},{"venue":"AAAI","id":"38e84f6dae8971c750edac1e0f8d2adbc566064d","venue_1":"AAAI","year":"2012","title":"Interactive Narrative: A Novel Application of Artificial Intelligence for Computer Games","authors":"Mark O. Riedl, Vadim Bulitko","author_ids":"2757194, 1884952","abstract":"Game Artificial Intelligence (Game AI) is a sub-discipline of Artificial Intelligence (AI) and Machine Learning (ML) that explores the ways in which AI and ML can augment player experiences in computer games. Storytelling is an integral part of many modern computer games; within games stories create context, motivate the player, and move the action forward. Interactive Narrative is the use of AI to create and manage stories within games, creating the perception that the player is a character in a dynamically unfolding and responsive story. This paper introduces Game AI and focuses on the open research problems of Interactive Narrative. 1 Artificial Intelligence in Computer Games (Game AI) refers to algorithmic techniques to augment the player's experience in computer and video games. The goal of Game AI as a discipline is to produce the illusion of intelligence in the behavior of Non-Player Characters (NPCs—the opponents, companions, and other entities in the virtual game world) in the virtual world of the computer game. Almost all modern computer games utilize some form of artificial intelligence , making games the largest class of commercial product through with public regularly comes into contact with artificial intelligence. The most common forms of Game AI in modern computers are those that select animations for NPCs and allow the NPCs to navigate through the virtual environment without failure (i.e., pathfinding). It is not always the case that a commercial computer game product requires sophisticated or cutting-edge artificial intelligence techniques. Modern computer games typically devote a majority of processor time to graphics. Even when processor time is available, modern computer games do not necessarily require sophisticated algorithms ; the illusion of intelligence can often be accomplished quickly with clever design specifications, finite state machines, and rules. Game AI as practiced in industry thus 1 This paper was invited as a \" What's Hot \" paper to the AAAI'12 Sub-Area Spotlights track. encompasses a larger class of algorithms, data representations , hacks, and workarounds used to convey this illusion of intelligence. Laird and van Lent (2001) put forth an argument for AI in computer games as an academic pursuit. They specifically argued that those pursuing complete, \" human-level \" AI systems should use computer games as testbeds for research endeavors. This opened computer games up to a wide range of academic research goals under the Game AI umbrella: • \" Human-Level \" AI. The development of artificial intelligence algorithms …","cites":"3","conferencePercentile":"30.79268293"},{"venue":"AAAI","id":"27b06452d84f06f0d4559f263bbcef08c4d3e55b","venue_1":"AAAI","year":"2013","title":"Story Generation with Crowdsourced Plot Graphs","authors":"Boyang Li, Stephen Lee-Urban, George Johnston, Mark O. Riedl","author_ids":"2089181, 1731992, 6859164, 2757194","abstract":"Story generation is the problem of automatically selecting a sequence of events that meet a set of criteria and can be told as a story. Story generation is knowledge-intensive; traditional story generators rely on a priori defined domain models about fictional worlds, including characters, places, and actions that can be performed. Manually authoring the domain models is costly and thus not scalable. We present a novel class of story generation system that can generate stories in an unknown domain. Our system (a) automatically learns a domain model by crowdsourcing a corpus of narrative examples and (b) generates stories by sampling from the space defined by the domain model. A large-scale evaluation shows that stories generated by our system for a previously unknown topic are comparable in quality to simple stories authored by untrained humans.","cites":"29","conferencePercentile":"98.18181818"},{"venue":"AAAI","id":"0cc95944a0fcbeb402b02bc86b522bef79873f16","venue_1":"AAAI","year":"2014","title":"Automatic Game Design via Mechanic Generation","authors":"Alexander Zook, Mark O. Riedl","author_ids":"3194972, 2757194","abstract":"Game designs often center on the game mechanics— rules governing the logical evolution of the game. We seek to develop an intelligent system that generates computer games. As first steps towards this goal we present a composable and cross-domain representation for game mechanics that draws from AI planning action representations. We use a constraint solver to generate mechanics subject to design requirements on the form of those mechanics—what they do in the game. A planner takes a set of generated mechanics and tests whether those mechanics meet playabil-ity requirements—controlling how mechanics function in a game to affect player behavior. We demonstrate our system by modeling and generating mechanics in a role-playing game, platformer game, and combined role-playing-platformer game.","cites":"11","conferencePercentile":"89.54545455"},{"venue":"AAAI","id":"6489618779962be7ee6978e71569e76c098d8eaf","venue_1":"AAAI","year":"2008","title":"Supporting Manual Mapping Revision using Logical Reasoning","authors":"Christian Meilicke, Heiner Stuckenschmidt, Andrei Tamilin","author_ids":"1795542, 1698459, 3001648","abstract":"Finding correct semantic correspondences between ontolo-gies is one of the most challenging problems in the area of semantic web technologies. Experiences with benchmarking matching systems revealed that even the manual revision of automatically generated mappings is a very difficult problem because it has to take the semantics of the ontologies as well as interactions between correspondences into account. In this paper, we propose methods for supporting human experts in the task of revising automatically created mappings. In particular , we present non-standard reasoning methods for detecting and propagating implications of expert decisions on the correctness of a mapping. We show that the use of these reasoning methods significantly reduces the effort of mapping revision in terms of the number of decisions that have to be made by the expert.","cites":"16","conferencePercentile":"71.20253165"},{"venue":"AAAI","id":"c2190346046d024cf71798cffe31498e8c07a843","venue_1":"AAAI","year":"2015","title":"Scheherazade: Crowd-Powered Interactive Narrative Generation","authors":"Boyang Li, Mark O. Riedl","author_ids":"2089181, 2757194","abstract":"Interactive narrative is a form of storytelling in which users affect a dramatic storyline through actions by assuming the role of characters in a virtual world. This extended abstract outlines the SCHEHERAZADE-IF system , which uses crowdsourcing and artificial intelligence to automatically construct text-based interactive narrative experiences.","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"4345a211f0477d7674e88cd4f058f807bc9b6f63","venue_1":"AAAI","year":"2007","title":"Repairing Ontology Mappings","authors":"Christian Meilicke, Heiner Stuckenschmidt, Andrei Tamilin","author_ids":"1795542, 1698459, 3001648","abstract":"Automatically discovering semantic relations between on-tologies is an important task with respect to overcoming semantic heterogeneity on the semantic web. Existing ontology matching systems, however, often produce erroneous map-pings. In this paper, we address the problem of errors in mappings by proposing a completely automatic debugging method for ontology mappings. The method uses logical reasoning to discover and repair logical inconsistencies caused by erroneous mappings. We describe the debugging method and report experiments on mappings submitted to the ontol-ogy alignment evaluation challenge that show that the proposed method actually improves mappings created by different matching systems without any human intervention.","cites":"76","conferencePercentile":"96.29080119"},{"venue":"AAAI","id":"0bcb8d2f32887c53be5c8fc2a9d6d36a1b8c6801","venue_1":"AAAI","year":"2006","title":"Modeling Human Decision Making in Cliff-Edge Environments","authors":"Ron Katz, Sarit Kraus","author_ids":"1775783, 1691597","abstract":"In this paper we propose a model for human learning and decision making in environments of repeated Cliff-Edge (CE) interactions. In CE environments, which include common daily interactions, such as sealed-bid auctions and the Ultimatum Game (UG), the probability of success decreases monotonically as the expected reward increases. Thus, CE environments are characterized by an underlying conflict between the strive to maximize profits and the fear of causing the entire deal to fall through. We focus on the behavior of people who repeatedly compete in one-shot CE interactions, with a different opponent in each interaction. Our model, which is based upon the Deviated Virtual Reinforcement Learning (DVRL) algorithm, integrates the Learning Direction Theory with the Reinforcement Learning algorithm. We also examined several other models, using an innovative methodology in which the decision dynamics of the models were compared with the empirical decision patterns of individuals during their interactions. An analysis of human behavior in auctions and in the UG reveals that our model fits the decision patterns of far more subjects than any other model.","cites":"5","conferencePercentile":"35.5907781"},{"venue":"AAAI","id":"1e484ea72354e357e8353a06eb9aafae06fe65a3","venue_1":"AAAI","year":"2012","title":"Never-Ending Learning","authors":"Tom M. Mitchell, William W. Cohen, Estevam R. Hruschka, Partha Pratim Talukdar, Justin Betteridge, Andrew Carlson, Bhavana Dalvi Mishra, Matthew Gardner, Bryan Kisiel, Jayant Krishnamurthy, Ni Lao, Kathryn Mazaitis, Thahir Mohamed, Ndapandula Nakashole, Emmanouil Antonios Platanios, Alan Ritter, Mehdi Samadi, Burr Settles, Richard C. Wang, Derry Tanti Wijaya, Abhinav Gupta, Xinlei Chen, Abulhair Saparov, Malcolm Greaves, Joel Welling","author_ids":"1779250, 1702241, 1842532, 2406435, 2601895, 2650199, 3183347, 1914777, 1761033, 2884955, 1914797, 2406799, 3276135, 3115592, 1930580, 4655992, 2033688, 1717452, 3018648, 2129412, 1776251, 3225716, 2407368, 2744464, 4639871","abstract":"Whereas people learn many different types of knowledge from diverse experiences over many years, most current machine learning systems acquire just a single function or data model from just a single data set. We propose a never-ending learning paradigm for machine learning, to better reflect the more ambitious and encompassing type of learning performed by humans. As a case study, we describe the Never-Ending Language Learner (NELL), which achieves some of the desired properties of a never-ending learner, and we discuss lessons learned. NELL has been learning to read the web 24 hours/day since January 2010, and so far has acquired a knowledge base with over 80 million confidence-weighted beliefs (e.g., servedWith(tea, biscuits)). NELL has also learned millions of features and parameters that enable it to read these beliefs from the web. Additionally, it has learned to reason over these beliefs to infer new beliefs, and is able to extend its ontology by synthesizing new relational predicates. NELL can be tracked online at http://rtw.ml.cmu.edu, and followed on Twitter at @CMUNELL.","cites":"61","conferencePercentile":"99.08536585"},{"venue":"AAAI","id":"0c557a5be89a80848b31da93fdd2075d5af7168d","venue_1":"AAAI","year":"2006","title":"Deciding Semantic Matching of Stateless Services","authors":"Duncan Hull, Evgeny Zolin, Andrey Bovykin, Ian Horrocks, Ulrike Sattler, Robert Stevens","author_ids":"2482542, 2730882, 2212463, 1692169, 1695737, 1702360","abstract":"We present a novel approach to describe and reason about stateless information processing Semantic Web Services. It can be seen as an extension of standard descriptions which makes explicit the relationship between inputs and outputs and takes into account OWL ontologies to fix the meaning of the terms used in a service description. This allows us to define a notion of matching between services that yields high precision and recall for service location. We explain why matching of these kinds of services is decidable, and provide examples of biomedical web services to illustrate the utility of our approach.","cites":"29","conferencePercentile":"77.23342939"},{"venue":"AAAI","id":"0f49036578a9e17b495eac5bacae8741bdcb5ab9","venue_1":"AAAI","year":"2013","title":"Video Saliency Detection via Dynamic Consistent Spatio-Temporal Attention Modelling","authors":"Sheng-hua Zhong, Yan Liu, Feifei Ren, Jinghuan Zhang, Tongwei Ren","author_ids":"1700861, 1681842, 6129219, 1738694, 1744930","abstract":"Human vision system actively seeks salient regions and movements in video sequences to reduce the search effort. Modeling computational visual saliency map provides important information for semantic understanding in many real world applications. In this paper, we propose a novel video saliency detection model for detecting the attended regions that correspond to both interesting objects and dominant motions in video sequences. In spatial saliency map, we inherit the classical bottom-up spatial saliency map. In temporal saliency map, a novel optical flow model is proposed based on the dynamic consistency of motion. The spatial and the temporal saliency maps are constructed and further fused together to create a novel attention model. The proposed attention model is evaluated on three video datasets. Empirical validations demonstrate the salient regions detected by our dynamic consistent saliency map highlight the interesting objects effectively and efficiency. More importantly , the automatically video attended regions detected by proposed attention model are consistent with the ground truth saliency maps of eye movement data.","cites":"6","conferencePercentile":"68.90909091"},{"venue":"AAAI","id":"3a25edbd7926db90bc4bb937cf44be2079e50af3","venue_1":"AAAI","year":"2010","title":"Bayesian Policy Search for Multi-Agent Role Discovery","authors":"Aaron Wilson, Alan Fern, Prasad Tadepalli","author_ids":"1950287, 1791751, 1729906","abstract":"Bayesian inference is an appealing approach for leveraging prior knowledge in reinforcement learning (RL). In this paper we describe an algorithm for discovering different classes of roles for agents via Bayesian inference. In particular, we develop a Bayesian policy search approach for Multi-Agent RL (MARL), which is model-free and allows for priors on policy parameters. We present a novel optimization algorithm based on hybrid MCMC, which leverages both the prior and gradient information estimated from trajectories. Our experiments in a complex real-time strategy game demonstrate the effective discovery of roles from supervised trajectories, the use of discovered roles for successful transfer to similar tasks, and the discovery of roles through reinforcement learning.","cites":"1","conferencePercentile":"11.09215017"},{"venue":"AAAI","id":"4892b33fb2b35d7a4e2cd00b09df689311079b46","venue_1":"AAAI","year":"2015","title":"Maestoso: An Intelligent Educational Sketching Tool for Learning Music Theory","authors":"Paul Taele, Laura Barreto, Tracy Anne Hammond","author_ids":"1729199, 2771409, 2662321","abstract":"Learning music theory not only has practical benefits for musicians to write, perform, understand, and express music better, but also for both non-musicians to improve critical thinking, math analytical skills, and music appreciation. However, current external tools applicable for learning music theory through writing when human instruction is unavailable are either limited in feedback, lacking a written modality, or assuming already strong familiarity of music theory concepts. In this paper, we describe Maestoso, an educational tool for novice learners to learn music theory through sketching practice of quizzed music structures. Maestoso first automatically recognizes students' sketched input of quizzed concepts , then relies on existing sketch and gesture recognition techniques to automatically recognize the input , and finally generates instructor-emulated feedback. From our evaluations, we demonstrate that Maestoso performs reasonably well on recognizing music structure elements and that novice students can comfortably grasp introductory music theory in a single session.","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"41c12b4793a52b7b759684f6dfb1dfca8f64e690","venue_1":"AAAI","year":"2008","title":"Using a Geometric-Based Sketch Recognition Approach to Sketch Chinese Radicals","authors":"Paul Taele, Tracy Anne Hammond","author_ids":"1729199, 2662321","abstract":"Unlike English, where unfamiliar words can be queried for its meaning by typing out its letters, the analogous operation in Chinese is far from trivial due to the nature of its written language. One approach for querying Chinese characters involve referencing their dictionary component called radicals. This is advantageous since users would not need to know their pronunciation nor their stroke-order, a requirement in other querying approaches. Currently though, sketching a character's radical for querying is an unsupported capability in existing systems. Using the geometric-based LADDER sketching language combined with the Sezgin low-level recognizer, we were able to construct an application which can first recognize handwritten sketches of Chinese radical, and then output candidate Chinese characters which contain that radical. Thus, we were able to demonstrate that a geometric-based sketch recognition approach can be used to easily build applications for recognizing symbols related to Chinese characters while having reasonable recognition rates. Unlike current image-based recognition systems, our system also maintains stroke order information of characters. Since stroke order is important in written Chinese, our system can be easily expanded for use in Chinese language education by providing visual feedback to students on correct stroke order.","cites":"4","conferencePercentile":"32.75316456"},{"venue":"AAAI","id":"1ea7125b789ef938bffe10c7588e6b071c4ff73c","venue_1":"AAAI","year":"2015","title":"Graph Analysis for Detecting Fraud, Waste, and Abuse in Healthcare Data","authors":"Juan Liu, Eric Bier, Aaron Wilson, Tomonori Honda, Kumar Sricharan, Leilani Gilpin, John Alexis Guerra Gómez, Daniel Davies","author_ids":"1719430, 2829019, 1950287, 2727268, 2804956, 3133401, 2314315, 4815514","abstract":"Detection of fraud, waste, and abuse (FWA) is an important yet difficult problem. In this paper, we describe a system to detect suspicious activities in large healthcare claims datasets. Each healthcare dataset is viewed as a heterogeneous network of patients, doctors, pharmacies, and other entities. These networks can be large, with millions of patients, hundreds of thousands of doctors, and tens of thousands of pharmacies, for example. Graph analysis techniques are developed to find suspicious individuals, suspicious relationships between individuals, unusual changes over time, unusual geospatial dispersion, and anomalous networks within the overall graph structure. The system has been deployed on multiple sites and data sets, both government and commercial, to facilitate the work of FWA investigation analysts.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"2d03baec8ac1568e6813aa43d625d552524f977e","venue_1":"AAAI","year":"2010","title":"Toward an Architecture for Never-Ending Language Learning","authors":"Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam R. Hruschka, Tom M. Mitchell","author_ids":"2650199, 2601895, 1761033, 1717452, 1842532, 1779250","abstract":"We consider here the problem of building a never-ending language learner; that is, an intelligent computer agent that runs forever and that each day must (1) extract, or read, information from the web to populate a growing structured knowledge base, and (2) learn to perform this task better than on the previous day. In particular, we propose an approach and a set of design principles for such an agent, describe a partial implementation of such a system that has already learned to extract a knowledge base containing over 242,000 beliefs with an estimated precision of 74% after running for 67 days, and discuss lessons learned from this preliminary attempt to build a never-ending learning agent.","cites":"564","conferencePercentile":"100"},{"venue":"AAAI","id":"e5bed1cfa48711241548e5914535290da0fddc83","venue_1":"AAAI","year":"2016","title":"Affective Personalization of a Social Robot Tutor for Children's Second Language Skills","authors":"Goren Gordon, Samuel Spaulding, Jacqueline Kory Westlund, Jin Joo Lee, Luke Plummer, Marayna Martinez, Madhurima Das, Cynthia Breazeal","author_ids":"2443849, 3340456, 3197681, 2689649, 2324074, 3368719, 7354881, 1711777","abstract":"Though substantial research has been dedicated towards using technology to improve education, no current methods are as effective as one-on-one tutoring. A critical, though relatively understudied, aspect of effective tutoring is modulating the student's affective state throughout the tutoring session in order to maximize long-term learning gains. We developed an integrated experimental paradigm in which children play a second-language learning game on a tablet, in collaboration with a fully autonomous social robotic learning companion. As part of the system, we measured children's valence and engagement via an automatic facial expression analysis system. These signals were combined into a reward signal that fed into the robot's affective reinforcement learning algorithm. Over several sessions, the robot played the game and personalized its motivational strategies (using verbal and non-verbal actions) to each student. We evaluated this system with 34 children in preschool classrooms for a duration of two months. We saw that (1) children learned new words from the repeated tutoring sessions, (2) the affective policy person-alized to students over the duration of the study, and (3) students who interacted with a robot that person-alized its affective feedback strategy showed a significant increase in valence, as compared to students who interacted with a non-personalizing robot. This integrated system of tablet-based educational content, af-fective sensing, affective policy learning, and an autonomous social robot holds great promise for a more comprehensive approach to personalized tutoring.","cites":"3","conferencePercentile":"72.63513514"},{"venue":"AAAI","id":"62fe5a8aef6de2db4658f5056d95f44f589f3233","venue_1":"AAAI","year":"2015","title":"Bayesian Active Learning-Based Robot Tutor for Children's Word-Reading Skills","authors":"Goren Gordon, Cynthia Breazeal","author_ids":"2443849, 1711777","abstract":"Effective tutoring requires personalization of the interaction to each student. Continuous and efficient assessment of the student's skills are a prerequisite for such personalization. We developed a Bayesian active-learning algorithm that continuously and efficiently assesses a child's word-reading skills and implemented it in a social robot. We then developed an integrated experimental paradigm in which a child plays a novel story-creation tablet game with the robot. The robot is portrayed as a younger peer who wishes to learn to read, framing the assessment of the child's word-reading skills as well as empowering the child. We show that our algorithm results in an accurate representation of the child's word-reading skills for a large age range, 4-8 year old children, and large initial reading skill range. We also show that employing child-specific assessment-based tutoring results in an age-and initial reading skill-independent learning, compared to random tutoring. Finally, our integrated system enables us to show that implementing the same learning algorithm on the robot's reading skills results in knowledge that is comparable to what the child thinks the robot has learned. The child's perception of the robot's knowledge is age-dependent and may facilitate an indirect assessment of the development of theory-of-mind.","cites":"5","conferencePercentile":"80.31496063"},{"venue":"AAAI","id":"6d3462c10e105c9dab71547d65eea740505156cf","venue_1":"AAAI","year":"2008","title":"Anticipatory Perceptual Simulation for Human-Robot Joint Practice: Theory and Application Study","authors":"Guy Hoffman, Cynthia Breazeal","author_ids":"2736490, 1711777","abstract":"With the aim of fluency and efficiency in human-robot teams, we have developed a cognitive architecture based on the neuro-psychological principles of anticipation and perceptual simulation through top-down biasing. An instantiation of this architecture was implemented on a non-anthropomorphic robotic lamp, performing in a human-robot collaborative task. In a human-subject study, in which the robot works on a joint task with untrained subjects, we find our approach to be significantly more efficient and fluent than in a comparable system without anticipatory perceptual simulation. We also show the robot and the human to be increasingly contributing at a similar rate. Through self-report, we find significant differences between the two conditions in the sense of team fluency, the team's improvement over time, and the robot's contribution to the efficiency and fluency. We also find difference in verbal attitudes towards the robot: most notably, subjects working with the anticipatory robot attribute more positive and more human qualities to the robot, but display increased self-blame and self-deprecation.","cites":"15","conferencePercentile":"68.82911392"},{"venue":"AAAI","id":"700bfd92c1d219744f1ea68962efe3a0a040ff28","venue_1":"AAAI","year":"2011","title":"Comparing Agents' Success against People in Security Domains","authors":"Raz Lin, Sarit Kraus, Noa Agmon, Samuel Barrett, Peter Stone","author_ids":"3042933, 1691597, 2442305, 2622696, 1728389","abstract":"The interaction of people with autonomous agents has become increasingly prevalent. Some of these settings include security domains, where people can be characterized as uncooperative , hostile, manipulative, and tending to take advantage of the situation for their own needs. This makes it challenging to design proficient agents to interact with people in such environments. Evaluating the success of the agents automatically before evaluating them with people or deploying them could alleviate this challenge and result in better designed agents. In this paper we show how Peer Designed Agents (PDAs) – computer agents developed by human subjects – can be used as a method for evaluating autonomous agents in security domains. Such evaluation can reduce the effort and costs involved in evaluating autonomous agents interacting with people to validate their efficacy. Our experiments included more than 70 human subjects and 40 PDAs developed by students. The study provides empirical support that PDAs can be used to compare the proficiency of autonomous agents when matched with people in security domains .","cites":"6","conferencePercentile":"49.14089347"},{"venue":"AAAI","id":"2e4c64a3a6ab8d0daa1e6d533c23b0611331e640","venue_1":"AAAI","year":"2012","title":"Automated Strategies for Determining Rewards for Human Work","authors":"Amos Azaria, Yonatan Aumann, Sarit Kraus","author_ids":"1746466, 2090792, 1691597","abstract":"We consider the problem of designing automated strategies for interactions with human subjects, where the humans must be rewarded for performing certain tasks of interest. We focus on settings where there is a single task that must be performed many times by different humans (e.g. answering a questionnaire), and the humans require a fee for performing the task. In such settings, our objective is to minimize the average cost for effectuating the completion of the task. We present two automated strategies for designing efficient agents for the problem, based on two different models of human behavior. The first, the Reservation Price Based Agent (RPBA), is based on the concept of a reservation price, and the second, the No Bargaining Agent (NBA), uses principles from behavioral science. The performance of the agents has been tested in extensive experiments with real human subjects , where NBA outperforms both RPBA and strategies developed by human experts.","cites":"12","conferencePercentile":"74.54268293"},{"venue":"AAAI","id":"6f8cd096abec01a9c46b7f294cc066ef4d6c091a","venue_1":"AAAI","year":"2012","title":"Agent-Human Coordination with Communication Costs Under Uncertainty","authors":"Asaf Frieder, Raz Lin, Sarit Kraus","author_ids":"2246621, 3042933, 1691597","abstract":"Coordination in mixed agent-human environments is an important, yet not a simple, problem. Little attention has been given to the issues raised in teams that consist of both computerized agents and people. In such situations different considerations are in order, as people tend to make mistakes and they are affected by cognitive, social and cultural factors. In this paper we present a novel agent designed to proficiently coordinate with a human counterpart. The agent uses a neural network model that is based on a pre-existing knowledge base which allows it to achieve an efficient modeling of a human's decisions and predict their behavior. A novel communication mechanism which takes into account the expected effect of communication on the other member will allow communication costs to be minimized. In extensive simulations involving more than 200 people we investigated our approach and showed that our agent achieves better coordination when involved, compared to settings in which only humans or another state-of-the-art agent are involved.","cites":"4","conferencePercentile":"39.17682927"},{"venue":"AAAI","id":"11c55aa088117e6d0e172b60c37eb2a65553bbea","venue_1":"AAAI","year":"2011","title":"User-Controllable Learning of Location Privacy Policies With Gaussian Mixture Models","authors":"Justin Cranshaw, Jonathan Mugan, Norman M. Sadeh","author_ids":"2660203, 2874422, 2464164","abstract":"With smart-phones becoming increasingly commonplace, there has been a subsequent surge in applications that continuously track the location of users. However, serious privacy concerns arise as people start to widely adopt these applications. Users will need to maintain policies to determine under which circumstances to share their location. Specifying these policies however, is a cumbersome task, suggesting that machine learning might be helpful. In this paper, we present a user-controllable method for learning location sharing policies. We use a classifier based on multivariate Gaussian mixtures that is suitably modified so as to restrict the evolution of the underlying policy to favor incremental and therefore human-understandable changes as new data arrives. We evaluate the model on real location-sharing policies collected from a live location-sharing social network, and we show that our method can learn policies in a user-controllable setting that are just as accurate as policies that do not evolve incrementally. Additionally, we highlight the strength of the generative modeling approach we take, by showing how our model easily extends to the semi-supervised setting.","cites":"16","conferencePercentile":"80.41237113"},{"venue":"AAAI","id":"6443e33dec1ea316a3c6fc067e4f21666f5003d7","venue_1":"AAAI","year":"2013","title":"Social Rankings in Human-Computer Committees","authors":"Moshe Bitan, Ya'akov Gal, Sarit Kraus, Elad Dokow, Amos Azaria","author_ids":"2694775, 1721094, 1691597, 1769207, 1746466","abstract":"Despite committees and elections being widespread in the real-world, the design of agents for operating in human-computer committees has received far less attention than the theoretical analysis of voting strategies. We address this gap by providing an agent design that outperforms other voters in groups comprising both people and computer agents. In our setting participants vote by simultaneously submitting a ranking over a set of candidates and the election system uses a social welfare rule to select a ranking that minimizes disagreements with participants' votes. We ran an extensive study in which hundreds of people participated in repeated voting rounds with other people as well as computer agents that differed in how they employ strategic reasoning in their voting behavior. Our results show that over time, people learn to deviate from truthful voting strategies, and use heuristics to guide their play, such as repeating their vote from the previous round. We show that a computer agent using a best response voting strategy was able to outperform people in the game. Our study has implication for agent designers, highlighting the types of strategies that enable agents to succeed in committees comprising both human and computer participants. This is the first work to study the role of computer agents in voting settings involving both human and agent participants .","cites":"2","conferencePercentile":"37.09090909"},{"venue":"AAAI","id":"55e2d2ba7e5087eb1eb7535269554ea837444ba9","venue_1":"AAAI","year":"2013","title":"An Agent Design for Repeated Negotiation and Information Revelation with People","authors":"Noam Peled, Ya'akov Gal, Sarit Kraus","author_ids":"2995670, 1721094, 1691597","abstract":"Many negotiations in the real world are characterized by incomplete information, and participants' success depends on their ability to reveal information in a way that facilitates agreement without compromising the individual gains of agents. This paper presents a novel agent design for repeated negotiation in incomplete information settings that learns to reveal information strategically during the negotiation process. The agent used classical machine learning techniques to predict how people make and respond to offers during the negotiation, how they reveal information and their response to potential revelation actions by the agent. The agent was evaluated empirically in an extensive empirical study spanning hundreds of human subjects. Results show that the agent was able to outperform people. In particular, it learned (1) to make offers that were beneficial to people while not compromising its own benefit; (2) to incrementally reveal information to people in a way that increased its expected performance. The approach generalizes to new settings without the need to acquire additional data. This work demonstrates the efficacy of combining machine learning with opponent modeling techniques towards the design of computer agents for negotiating with people in settings of incomplete information.","cites":"3","conferencePercentile":"47.09090909"},{"venue":"AAAI","id":"1a1497c685b315c7274a78618df4c5c74b9ac140","venue_1":"AAAI","year":"2011","title":"Strategic Information Disclosure to People with Multiple Alternatives","authors":"Amos Azaria, Zinovi Rabinovich, Sarit Kraus, Claudia V. Goldman","author_ids":"1746466, 1756878, 1691597, 1728547","abstract":"In this article, we study automated agents that are designed to encourage humans to take some actions over others by strategically disclosing key pieces of information. To this end, we utilize the framework of persuasion games&#8212;a branch of game theory that deals with asymmetric interactions where one player (Sender) possesses more information about the world, but it is only the other player (Receiver) who can take an action. In particular, we use an extended persuasion model, where the Sender&#8217;s information is imperfect and the Receiver has more than two alternative actions available. We design a computational algorithm that, from the Sender&#8217;s standpoint, calculates the optimal information disclosure rule. The algorithm is parameterized by the Receiver&#8217;s decision model (i.e., what choice he will make based on the information disclosed by the Sender) and can be retuned accordingly.\n We then provide an extensive experimental study of the algorithm&#8217;s performance in interactions with human Receivers. First, we consider a fully rational (in the Bayesian sense) Receiver decision model and experimentally show the efficacy of the resulting Sender&#8217;s solution in a routing domain. Despite the discrepancy in the Sender&#8217;s and the Receiver&#8217;s utilities from each of the Receiver&#8217;s choices, our Sender agent successfully persuaded human Receivers to select an option more beneficial for the agent. Dropping the Receiver&#8217;s rationality assumption, we introduce a machine learning procedure that generates a more realistic human Receiver model. We then show its significant benefit to the Sender solution by repeating our routing experiment. To complete our study, we introduce a second (supply--demand) experimental domain and, by contrasting it with the routing domain, obtain general guidelines for a Sender on how to construct a Receiver model.","cites":"25","conferencePercentile":"91.58075601"},{"venue":"AAAI","id":"778deea6699f3a50359ee0c16dd2b93d8a337998","venue_1":"AAAI","year":"2013","title":"Movie Recommender System for Profit Maximization (Short LBP)","authors":"Amos Azaria, Avinatan Hassidim, Sarit Kraus, Adi Eshkol, Ofer Weintraub, Irit Netanely","author_ids":"1746466, 1809983, 1691597, 2075787, 2432356, 3211878","abstract":"In this paper we provide an algorithm for utility maximization of a movie supplier service, in two different settings, one with prices and the other without. This algorithm is provided along with an extensive experiment demonstrating its performance. We also uncover a phenomenon where movie consumers prefer watching and even paying for movies that they have already seen in the past than movies that are new to them.","cites":"0","conferencePercentile":"9.090909091"},{"venue":"AAAI","id":"3c19761bf611b2f21d04202766ef7b84f1dd6e8b","venue_1":"AAAI","year":"2013","title":"Teamwork with Limited Knowledge of Teammates","authors":"Samuel Barrett, Peter Stone, Sarit Kraus, Avi Rosenfeld","author_ids":"2622696, 1728389, 1691597, 1955991","abstract":"While great strides have been made in multiagent teamwork, existing approaches typically assume extensive information exists about teammates and how to coordinate actions. This paper addresses how robust teamwork can still be created even if limited or no information exists about a specific group of teammates, as in the ad hoc teamwork scenario. The main contribution of this paper is the first empirical evaluation of an agent cooperating with teammates not created by the authors, where the agent is not provided expert knowledge of its teammates. For this purpose, we develop a general-purpose teammate modeling method and test the resulting ad hoc team agent's ability to collaborate with more than 40 unknown teams of agents to accomplish a benchmark task. These agents were designed by people other than the authors without these designers planning for the ad hoc teamwork setting. A secondary contribution of the paper is a new transfer learning algorithm, TwoStageTransfer, that can improve results when the ad hoc team agent does have some limited observations of its current teammates.","cites":"26","conferencePercentile":"97.27272727"},{"venue":"AAAI","id":"43c6000b76c4c350df2854ec8b6aeace9fc78159","venue_1":"AAAI","year":"2013","title":"Advice Provision in Multiple Prospect Selection Problems","authors":"Amos Azaria, Sarit Kraus","author_ids":"1746466, 1691597","abstract":"When humans face a broad spectrum of topics, where each topic consists of several options, they usually make a decision on each topic separately. Usually, a person will perform better by making a global decision, however, taking all consequences into account is extremely difficult. We present a novel computational method for advice-generation in an environment where people need to decide among multiple selection problems. This method is based on the prospect theory and uses machine learning techniques. We graphically present this advice to the users and compare it with an advice which encourages the users to always select the option with a higher expected outcome. We show that our method outperforms the expected outcome approach in terms of user happiness and satisfaction.","cites":"1","conferencePercentile":"25.09090909"},{"venue":"AAAI","id":"7c60ef6c9a7c57f89592f081e76f97ab72ed3ff8","venue_1":"AAAI","year":"2014","title":"Leveraging Fee-Based, Imperfect Advisors in Human-Agent Games of Trust","authors":"Cody Buntain, Amos Azaria, Sarit Kraus","author_ids":"2767299, 1746466, 1691597","abstract":"This paper explores whether the addition of costly, imperfect , and exploitable advisors to Berg's investment game enhances or detracts from investor performance in both one-shot and multi-round interactions. We then leverage our findings to develop an automated investor agent that performs as well as or better than humans in these games. To gather this data, we extended Berg's game and conducted a series of experiments using Ama-zon's Mechanical Turk to determine how humans behave in these potentially adversarial conditions. Our results indicate that, in games of short duration, advisors do not stimulate positive behavior and are not useful in providing actionable advice. In long-term interactions , however, advisors do stimulate positive behavior with significantly increased investments and returns. By modeling human behavior across several hundred participants , we were then able to develop agent strategies that maximized return on investment and performed as well as or significantly better than humans. In one-shot games, we identified an ideal investment value that, on average, resulted in positive returns as long as advi-sor exploitation was not allowed. For the multi-round games, our agents relied on the corrective presence of advisors to stimulate positive returns on maximum investment .","cites":"2","conferencePercentile":"38.63636364"},{"venue":"AAAI","id":"6fdc5a0a938547d0562974dd551d6de0ce7f0907","venue_1":"AAAI","year":"2014","title":"Generating Content for Scenario-Based Serious-Games Using CrowdSourcing","authors":"Sigalit Sina, Avi Rosenfeld, Sarit Kraus","author_ids":"2993550, 1955991, 1691597","abstract":"Scenario-based serious-games have become an important tool for teaching new skills and capabilities. An important factor in the development of such systems is reducing the time and cost overheads in manually creating content for these scenarios. To address this challenge, we present Scenario-Gen, an automatic method for generating content about everyday activities through combining computer science techniques with the crowd. ScenarioGen uses the crowd in three different ways: to capture a database of scenarios of everyday activities, to generate a database of likely replacements for specific events within that scenario, and to evaluate the resulting scenarios. We evaluated ScenarioGen in 6 different content domains and found that it was consistently rated as coherent and consistent as the originally captured content. We also compared ScenarioGen's content to that created by traditional planning techniques. We found that both methods were equally effective in generating coherent and consistent scenarios, yet ScenarioGen's content was found to be more varied and easier to create.","cites":"4","conferencePercentile":"59.54545455"},{"venue":"AAAI","id":"e510d678f11dc88f9a251129bb0aae9c049dab7e","venue_1":"AAAI","year":"2014","title":"Advice Provision for Choice Selection Processes with Ranked Options","authors":"Amos Azaria, Ya'akov Gal, Claudia V. Goldman, Sarit Kraus","author_ids":"1746466, 1721094, 1728547, 1691597","abstract":"Choice selection processes are a family of bilateral games of incomplete information in which a computer agent generates advice for a human user while considering the effect of the advice on the user's behavior in future interactions. The human and the agent may share certain goals, but are essentially self-interested. This paper extends selection processes to settings in which the actions available to the human are ordered and thus the user may be influenced by the advice even though he doesn't necessarily follow it exactly. In this work we also consider the case in which the user obtains some observation on the sate of the world. We propose several approaches to model human decision making in such settings. We incorporate these models into two optimization techniques for the agent advice provision strategy. In the first one the agent used a social utility approach which considered the benefits and costs for both agent and person when making suggestions. In the second approach we simplified the human model in order to allow modeling and solving the agent strategy as an MDP. In an empirical evaluation involving human users on AMT, we showed that the social utility approach significantly outperformed the MDP approach.","cites":"0","conferencePercentile":"9.431818182"},{"venue":"AAAI","id":"794c3f71a60ecc7155e7226d62c7b816aad729e6","venue_1":"AAAI","year":"2015","title":"Intelligent Agents for Rehabilitation and Care of Disabled and Chronic Patients","authors":"Sarit Kraus","author_ids":"1691597","abstract":"The number of people with disabilities is continuously increasing. Providing patients who have disabilities with the rehabilitation and care necessary to allow them good quality of life creates overwhelming demands for health and rehabilitation services. We suggest that advancements in intelligent agent technology provide new opportunities for improving the provided services. We will discuss the challenges of building an agent for the health care domain and present four capabilities that are required for an agent in the health care domain: planning, monitoring, intervention and encouragement. We will discuss the importance of personaliz-ing all of them and the need to facilitate cooperation between the automated agent and the human care givers. We will review recent technology that can be used toward the development of agents that can have these capabilities and their promise in automating services such as physiotherapy, speech therapy and cognitive training.","cites":"2","conferencePercentile":"51.65354331"},{"venue":"AAAI","id":"864936b321b4557a72c5c570af00448ad313362a","venue_1":"AAAI","year":"2013","title":"Analyzing the Effectiveness of Adversary Modeling in Security Games","authors":"Thanh Hong Nguyen, Rong Yang, Amos Azaria, Sarit Kraus, Milind Tambe","author_ids":"2209310, 1797063, 1746466, 1691597, 1701620","abstract":"Recent deployments of Stackelberg security games (SSG) have led to two competing approaches to handle boundedly rational human adversaries: (1) integrating models of human (adversary) decision-making into the game-theoretic algorithms , and (2) applying robust optimization techniques that avoid adversary modeling. A recent algorithm (MATCH) based on the second approach was shown to outperform the leading modeling-based algorithm even in the presence of significant amount of data. Is there then any value in using human behavior models in solving SSGs? Through extensive experiments with 547 human subjects playing 11102 games in total, we emphatically answer the question in the affirmative, while providing the following key contributions: (i) we show that our algorithm, SU-BRQR, based on a novel integration of human behavior model with the subjective utility function, significantly outperforms both MATCH and its improvements; (ii) we are the first to present experimental results with security intelligence experts, and find that even though the experts are more rational than the Amazon Turk workers, SU-BRQR still outperforms an approach assuming perfect rationality (and to a more limited extent MATCH); (iii) we show the advantage of SU-BRQR in a new, large game setting and demonstrate that sufficient data enables it to improve its performance over MATCH.","cites":"63","conferencePercentile":"100"},{"venue":"AAAI","id":"0e937b39d9863b388bc89ac5a757d11808112646","venue_1":"AAAI","year":"2007","title":"Semi-Supervised Learning with Very Few Labeled Training Examples","authors":"Zhi-Hua Zhou, De-Chuan Zhan, Qiang Yang","author_ids":"1692625, 1721819, 1733090","abstract":"In semi-supervised learning, a number of labeled examples are usually required for training an initial weakly useful predictor which is in turn used for exploiting the unlabeled examples. However, in many real-world applications there may exist very few labeled training examples, which makes the weakly useful pre-dictor difficult to generate, and therefore these semi-supervised learning methods cannot be applied. This paper proposes a method working under a two-view setting. By taking advantages of the correlations between the views using canonical component analysis, the proposed method can perform semi-supervised learning with only one labeled training example. Experiments and an application to content-based image retrieval validate the effectiveness of the proposed method.","cites":"35","conferencePercentile":"85.90504451"},{"venue":"AAAI","id":"1d9ee2aaa319ec6e2e637f5933ccb224264ce353","venue_1":"AAAI","year":"2010","title":"Intentions in Equilibrium","authors":"John Grant, Sarit Kraus, Michael Wooldridge","author_ids":"6505693, 1691597, 4769905","abstract":"Intentions have been widely studied in AI, both in the context of decision-making within individual agents and in multi-agent systems. Work on intentions in multi-agent systems has focused on joint intention models, which characterise the mental state of agents with a shared goal engaged in teamwork. In the absence of shared goals, however, intentions play another crucial role in multi-agent activity: they provide a basis around which agents can mutually coordinate activities. Models based on shared goals do not attempt to account for or explain this role of intentions. In this paper, we present a formal model of multi-agent systems in which belief-desire-intention agents choose their intentions taking into account the intentions of others. To understand rational mental states in such a setting, we formally define and investigate notions of multi-agent intention equilibrium, which are related to equilibrium concepts in game theory.","cites":"5","conferencePercentile":"32.08191126"},{"venue":"AAAI","id":"132b5d9f17ea00d4df2b0b14ad85b0165e07807b","venue_1":"AAAI","year":"2010","title":"Facilitating the Evaluation of Automated Negotiators using Peer Designed Agents","authors":"Raz Lin, Sarit Kraus, Yinon Oshrat, Ya'akov Gal","author_ids":"3042933, 1691597, 2811288, 1721094","abstract":"Computer agents are increasingly deployed in settings in which they make decisions with people, such as electronic commerce, collaborative interfaces, and cognitive assistants. However, the scientific evaluation of computational strategies for human-computer decision-making is a costly process, involving time, effort and personnel. This paper investigates the use of Peer Designed Agents (PDA)—computer agents developed by human subjects—as a tool for facilitating the evaluation process of automatic negotiators that were developed by researchers. It compares the performance between automatic negotiators that interacted with PDAs to automatic negotiators that interacted with actual people in different domains. The experiments included more than 300 human subjects and 50 PDAs developed by students. Results showed that the automatic negotiators outperformed PDAs in the same situations in which they outperformed people, and that on average, they exhibited the same measure of generosity towards their negotiation partners. These patterns occurred for all types of domains, and for all types of automated negotiators, despite the fact that there were individual differences between the behavior of PDAs and people. The study thus provides an empirical proof that PDAs can alleviate the evaluation process of automatic negotiators, and facilitate their design.","cites":"15","conferencePercentile":"66.72354949"},{"venue":"AAAI","id":"5d48961c2100f89b8458f8d9a2b7aa54ce16445f","venue_1":"AAAI","year":"2008","title":"Spatial Scaffolding for Sociable Robot Learning","authors":"Cynthia Breazeal, Matt Berlin","author_ids":"1711777, 2210819","abstract":"Spatial scaffolding is a naturally occurring human teaching behavior, in which teachers use their bodies to spatially structure the learning environment to direct the attention of the learner. Robotic systems can take advantage of simple, highly reliable spatial scaffolding cues to learn from human teachers. We present an integrated robotic architecture that combines social attention and machine learning components to learn tasks effectively from natural spatial scaffolding interactions with human teachers. We evaluate the performance of this architecture in comparison to human learning data drawn from a novel study of the use of embodied cues in human task learning and teaching behavior. This evaluation provides quantitative evidence for the utility of spatial scaffolding to learning systems. In addition, this evaluation supported the construction of a novel, interactive demonstration of a hu-manoid robot taking advantage of spatial scaffolding cues to learn from natural human teaching behavior.","cites":"0","conferencePercentile":"7.120253165"},{"venue":"AAAI","id":"232dfd09846f86536dfc6d106e3547dab50f89ff","venue_1":"AAAI","year":"2015","title":"Refer-to-as Relations as Semantic Knowledge","authors":"Song Feng, Sujith Ravi, Ravi Kumar, Polina Kuznetsova, Wei Liu, Alexander C. Berg, Tamara L. Berg, Yejin Choi","author_ids":"1747989, 2703695, 3455556, 2812245, 3406338, 1743555, 1685538, 1699545","abstract":"We study Refer-to-as relations as a new type of semantic knowledge. Compared to the much studied Is-a relation, which concerns factual taxonomic knowledge, Refer-to-as relations aim to address pragmatic semantic knowledge. For example , a \" penguin \" is a \" bird \" from a taxonomic point of view, but people rarely refer to a \" penguin \" as a \" bird \" in vernacular use. This observation closely relates to the entry-level categorization studied in Psychology. We posit that Refer-to-as relations can be learned from data, and that both textual and visual information would be helpful in inferring the relations. By integrating existing lexical structure knowledge with language statistics and visual similarities, we formulate a collective inference approach to map all object names in an encyclopedia to commonly used names for each object. Our contributions include a new labeled data set, the collective inference and optimization approach, and the computed mappings and similarities.","cites":"7","conferencePercentile":"88.11023622"},{"venue":"AAAI","id":"5a01b25b182fa7387878e65c7c0c62a605334e0d","venue_1":"AAAI","year":"2010","title":"Recognizing Multi-Agent Activities from GPS Data","authors":"Adam Sadilek, Henry A. Kautz","author_ids":"1743087, 1690271","abstract":"Recent research has shown that surprisingly rich models of human behavior can be learned from GPS (positional) data. However, most research to date has concentrated on mod-eling single individuals or aggregate statistical properties of groups of people. Given noisy real-world GPS data, we—in contrast—consider the problem of modeling and recognizing activities that involve multiple related individuals playing a variety of roles. Our test domain is the game of capture the flag—an outdoor game that involves many distinct cooperative and competitive joint activities. We model the domain using Markov logic, a statistical relational language, and learn a theory that jointly denoises the data and infers occurrences of high-level activities, such as capturing a player. Our model combines constraints imposed by the geometry of the game area, the motion model of the players, and by the rules and dynamics of the game in a probabilistically and logically sound fashion. We show that while it may be impossible to directly detect a multi-agent activity due to sensor noise or malfunction , the occurrence of the activity can still be inferred by considering both its impact on the future behaviors of the people involved as well as the events that could have preceded it. We compare our unified approach with three alternatives (both probabilistic and nonprobabilistic) where either the denoising of the GPS data and the detection of the high-level activities are strictly separated, or the states of the players are not considered , or both. We show that the unified approach with the time window spanning the entire game, although more com-putationally costly, is significantly more accurate.","cites":"40","conferencePercentile":"91.80887372"},{"venue":"AAAI","id":"da7f6534c3480064369e650133a1256627a3f4dd","venue_1":"AAAI","year":"2013","title":"Teaching Classification Boundaries to Humans","authors":"Sumit Basu, Janara Christensen","author_ids":"1801676, 1841345","abstract":"Given a classification task, what is the best way to teach the resulting boundary to a human? While machine learning techniques can provide excellent methods for finding the boundary, including the selection of examples in an online setting, they tell us little about how we would teach a human the same task. We propose to investigate the problem of example selection and presentation in the context of teaching humans, and explore a variety of mechanisms in the interests of finding what may work best. In particular, we begin with the baseline of random presentation and then examine combinations of several mechanisms: the indication of an exam-ple's relative difficulty, the use of the shaping heuristic from the cognitive science literature (moving from easier examples to harder ones), and a novel kernel-based \" coverage model \" of the subject's mastery of the task. From our experiments on 54 human subjects learning and performing a pair of synthetic classification tasks via our teaching system, we found that we can achieve the greatest gains with a combination of shaping and the coverage model.","cites":"12","conferencePercentile":"87.09090909"},{"venue":"AAAI","id":"11dba0acd058cd50fe501d9c1814833a3b09d7b9","venue_1":"AAAI","year":"2006","title":"Local Negotiation in Cellular Networks: From Theory to Practice","authors":"Raz Lin, Daphna Dor-Shifer, Sarit Kraus, David Sarne","author_ids":"3042933, 1930737, 1691597, 1707363","abstract":"This paper describes a novel negotiation protocol for cellular networks, which intelligently improves the performance of the network. Our proposed reactive mechanism enables the dynamic adaptation of the base stations to continuous changes in service demands, thereby improving the overall network performance. This mechanism is important when a frequent global optimization is infeasible or substantially costly. The proposed local negotiation mechanism is incorporated into a simulated network based on cutting-edge industry technologies. Experimental results suggest a rapid adjustment to changes in bandwidth demand and overall improvement in the number of served users over time. Although we tested our algorithm based on the service level, which is measured as the number of covered handsets, our algorithm supports negotiation for any set of parameters, aiming to optimize network's performance according to any measure of performance specified by the service provider.","cites":"8","conferencePercentile":"46.39769452"},{"venue":"AAAI","id":"5dd96a01d66ba5cd48a1b05e854ceb66bb18c58d","venue_1":"AAAI","year":"2007","title":"A Robotic Weight Loss Coach","authors":"Cory D. Kidd, Cynthia Breazeal","author_ids":"1733529, 1711777","abstract":"We present a rationale for studying long-term human-robot interaction and explain why new applications are necessary for this type of experimentation. The design and implementation of a robot that has been implemented is briefly described with the outline of a study that is under way. Vision Human-robot interaction (HRI) is now understood well enough to allow us to build useful long-term HRI systems that can function outside of the laboratory. However, little is known about how humans will respond to robots being present in their homes, offices, or other environments for extended periods of time. Most experiments thus far have been short-term, in-laboratory studies, for example, our work with several different robots (Kidd & Breazeal 2005) and (Breazeal et al. 2005); the work by several researchers at CMU (Kiesler & Goetz 2002) or (Gockley, Forlizzi, & Simmons 2007); and studies by Dautenhahn, et al. (Koay et al. 2006) or (Walters et al. 2007) that have informed the HRI community about narrowly focused aspects of interaction. There are exceptions to the short-term lab work in which researchers have tried to study interaction over longer periods of time. Among the several examples, we have done work in local nursing homes (Turkle et al. in press) with the Paro robot (Saito et al. 2003). Kahn and colleagues have studied Aibos in a variety of situations (e.g. (Khan et al. 2006)). The PaPeRo robot from NEC has been tested in homes. The challenge with these studies is that there are not compelling applications to keep a person interested in using a robot for long periods of time – weeks, months, or even years. The most interesting robots for long-term use are currently entertainment robots such as Sony's discontinued Aibo or WowWee's RoboSapien. In order to carry out long-term HRI studies, there must be robot systems capable of managing sustained engagement. A simple entertainment robot or a single-purpose robot such as iRobot's Roomba will not suffice for studying how people interact with a robot over time and whether results from short-term studies will be valid over longer durations. In order to carry out these long-term studies, our first step is to Figure 1: Weight loss coach prototype construct a sociable robot system that a person will have a compelling reason to interact with over time. Application We are building a robotic weight loss coach that is being put into homes for an extended HRI study. …","cites":"26","conferencePercentile":"77.44807122"},{"venue":"AAAI","id":"2b79f0311bfc67ffad79f4db08c2b0dfabaaf79b","venue_1":"AAAI","year":"2010","title":"Ad Hoc Autonomous Agent Teams: Collaboration without Pre-Coordination","authors":"Peter Stone, Gal A. Kaminka, Sarit Kraus, Jeffrey S. Rosenschein","author_ids":"1728389, 1725049, 1691597, 1735970","abstract":"As autonomous agents proliferate in the real world, both in software and robotic settings, they will increasingly need to band together for cooperative activities with previously unfamiliar teammates. In such ad hoc team settings, team strategies cannot be developed a priori. Rather, an agent must be prepared to cooperate with many types of teammates: it must collaborate without pre-coordination. This paper challenges the AI community to develop theory and to implement prototypes of ad hoc team agents. It defines the concept of ad hoc team agents, specifies an evaluation paradigm, and provides examples of possible theoretical and empirical approaches to challenge. The goal is to encourage progress towards this ambitious , newly realistic, and increasingly important research goal.","cites":"90","conferencePercentile":"98.97610921"},{"venue":"AAAI","id":"092746b7c3ef49c896580ce4e948fb318516cb0f","venue_1":"AAAI","year":"2006","title":"Perspective Taking: An Organizing Principle for Learning in Human-Robot Interaction","authors":"Matt Berlin, Jesse Gray, Andrea Lockerd Thomaz, Cynthia Breazeal","author_ids":"2210819, 2726591, 1682788, 1711777","abstract":"The ability to interpret demonstrations from the perspective of the teacher plays a critical role in human learning. Robotic systems that aim to learn effectively from human teachers must similarly be able to engage in perspective taking. We present an integrated architecture wherein the robot's cognitive function-ality is organized around the ability to understand the environment from the perspective of a social partner as well as its own. The performance of this architecture on a set of learning tasks is evaluated against human data derived from a novel study examining the importance of perspective taking in human learning. Perspective taking, both in humans and in our architecture, fo-cuses the agent's attention on the subset of the problem space that is important to the teacher. This constrained attention allows the agent to overcome ambiguity and incompleteness that can often be present in human demonstrations and thus learn what the teacher intends to teach.","cites":"34","conferencePercentile":"81.70028818"},{"venue":"AAAI","id":"6d5fce398290bb9bff99483da921adbcb8625df9","venue_1":"AAAI","year":"2007","title":"Gender-Sensitive Automated Negotiators","authors":"Ron Katz, Sarit Kraus","author_ids":"1775783, 1691597","abstract":"This paper introduces an innovative approach for automated negotiating using the gender of human opponents. Our approach segments the information acquired from previous opponents , stores it in two databases, and models the typical behavior of males and of females. The two models are used in order to match an optimal strategy to each of the two sub-populations. In addition to the basic separation, we propose a learning algorithm which supplies an online indicator for the gender separability-level of the population, which tunes the level of separation the algorithm activates. The algorithm we present can be generally applied in different environments with no need for configuration of parameters. Experiments in 4 different one-shot domains, comparing the performance of the gender based separation approach with a basic approach which is not gender sensitive, revealed higher payoffs of the former in almost all the domains. Moreover, using the proposed learning algorithm further improved the results.","cites":"7","conferencePercentile":"42.58160237"},{"venue":"AAAI","id":"1499afb3fa7e57e3756bbe9e70263b5c4d6af0e4","venue_1":"AAAI","year":"2008","title":"Efficient Algorithms to Solve Bayesian Stackelberg Games for Security Applications","authors":"Praveen Paruchuri, Jonathan P. Pearce, Janusz Marecki, Milind Tambe, Fernando Ordóñez, Sarit Kraus","author_ids":"1794606, 2375932, 1995313, 1701620, 2445927, 1691597","abstract":"In a class of games known as Stackelberg games, one agent (the leader) must commit to a strategy that can be observed by the other agent (the adversary/follower) before the adversary chooses its own strategy. We consider Bayesian Stackelberg games, in which the leader is uncertain about the type of the adversary it may face. Such games are important in security domains, where, for example, a security agent (leader) must commit to a strategy of patrolling certain areas, and an adversary (follower) can observe this strategy over time before choosing where to attack. We present here two different MIP-formulations, ASAP (providing approximate policies with controlled randomization) and DOBSS (providing optimal policies) for Bayesian Stackelberg games. DOBSS is currently the fastest optimal procedure for Bayesian Stackel-berg games and is in use by police at the Los Angeles International Airport(LAX) to schedule their activities.","cites":"14","conferencePercentile":"66.61392405"},{"venue":"AAAI","id":"630613b8490f9cdcdd65d17bdd3ea969caa43d9e","venue_1":"AAAI","year":"2008","title":"ARMOR Security for Los Angeles International Airport","authors":"James Pita, Manish Jain, Fernando Ordóñez, Christopher Portway, Milind Tambe, Craig Western, Praveen Paruchuri, Sarit Kraus","author_ids":"2621125, 1807305, 2445927, 1883714, 1701620, 2435811, 1794606, 1691597","abstract":"Security at major locations of economic or political importance is a key concern around the world, particularly given the threat of terrorism. Limited security resources prevent full security coverage at all times, which allows adversaries to observe and exploit patterns in selective patrolling or monitoring , e.g. they can plan an attack avoiding existing patrols. Hence, randomized patrolling or monitoring is important, but randomization must provide distinct weights to different actions based on their complex costs and benefits. To this end, this demonstration showcases a promising transition of the latest in multi-agent algorithms into a deployed application. In particular, it exhibits a software assistant agent called ARMOR (Assistant for Randomized Monitoring over Routes) that casts this patrolling/monitoring problem as a Bayesian Stackelberg game, allowing the agent to appropriately weigh the different actions in randomization, as well as uncertainty over adversary types. ARMOR combines two key features: (i) It uses the fastest known solver for Bayesian Stackelberg games called DOBSS, where the dominant mixed strategies enable randomization; (ii) Its mixed-initiative based interface allows users to occasionally adjust or override the automated schedule based on their local constraints. ARMOR has been successfully deployed since August 2007 at the Los Angeles International Airport (LAX) to randomize checkpoints on the roadways entering the airport and canine patrol routes within the airport terminals.","cites":"13","conferencePercentile":"64.71518987"},{"venue":"AAAI","id":"03dfd94387d335941aa98b7369e9ac51c25c614a","venue_1":"AAAI","year":"2012","title":"Far Out: Predicting Long-Term Human Mobility","authors":"Adam Sadilek, John Krumm","author_ids":"1743087, 1690256","abstract":"Much work has been done on predicting where is one going to be in the immediate future, typically within the next hour. By contrast, we address the open problem of predicting human mobility far into the future, a scale of months and years. We propose an efficient nonparametric method that extracts significant and robust patterns in location data, learns their associations with contextual features (such as day of week), and subsequently leverages this information to predict the most likely location at any given time in the future. The entire process is formulated in a principled way as an eigendecompo-sition problem. Evaluation on a massive dataset with more than 32,000 days worth of GPS data across 703 diverse subjects shows that our model predicts the correct location with high accuracy, even years into the future. This result opens a number of interesting avenues for future research and applications .","cites":"33","conferencePercentile":"95.57926829"},{"venue":"AAAI","id":"35526c6844a75b9888fbea859635771c0b095e03","venue_1":"AAAI","year":"2011","title":"Optimal Rewards versus Leaf-Evaluation Heuristics in Planning Agents","authors":"Jonathan Sorg, Satinder P. Singh, Richard L. Lewis","author_ids":"3158065, 1699868, 2406437","abstract":"Planning agents often lack the computational resources needed to build full planning trees for their environments. Agent designers commonly overcome this finite-horizon approximation by applying an evaluation function at the leaf-states of the planning tree. Recent work has proposed an alternative approach for overcoming computational constraints on agent design: modify the reward function. In this work, we compare this reward design approach to the common leaf-evaluation heuristic approach for improving planning agents. We show that in many agents, the reward design approach strictly subsumes the leaf-evaluation approach, i.e., there exists a reward function for every leaf-evaluation heuristic that leads to equivalent behavior, but the converse is not true. We demonstrate that this generality leads to improved performance when an agent makes approximations in addition to the finite-horizon approximation. As part of our contribution, we extend PGRD, an online reward design algorithm, to develop reward design algorithms for Sparse Sampling and UCT, two algorithms capable of planning in large state spaces.","cites":"11","conferencePercentile":"70.4467354"},{"venue":"AAAI","id":"7f700a4b27ed6222f83c4ccf50599371a78d2186","venue_1":"AAAI","year":"2008","title":"Physical Search Problems Applying Economic Search Models","authors":"Yonatan Aumann, Noam Hazon, Sarit Kraus, David Sarne","author_ids":"2090792, 3075116, 1691597, 1707363","abstract":"This paper considers the problem of an agent searching for a resource or a tangible good in a physical environment, where at each stage of its search it observes one source where this good can be found. The cost of acquiring the resource or good at a given source is uncertain (a-priori), and the agent can observe its true value only when physically arriving at the source. Sample applications involving this type of search include agents in exploration and patrol missions (e.g., an agent seeking to find the best location to deploy sensing equipment along its path). The uniqueness of these settings is that the expense of observing the source on each step of the process derives from the last source the agent explored. We analyze three variants of the problem, differing in their objective: minimizing the total expected cost, maximizing the success probability given an initial budget, and minimizing the budget necessary to obtain a given success probability. For each variant, we first introduce and analyze the problem with a single agent, either providing a polynomial solution to the problem or proving it is NP-Complete. We also introduce an innovative fully polynomial time approximation scheme algorithm for the minimum budget variant. Finally, the results for the single agent case are generalized to multi-agent settings .","cites":"10","conferencePercentile":"54.90506329"},{"venue":"AAAI","id":"0fcd047a1a6e391c8a6c140967355ec2a0ad8c9e","venue_1":"AAAI","year":"2006","title":"Reinforcement Learning with Human Teachers: Evidence of Feedback and Guidance with Implications for Learning Performance","authors":"Andrea Lockerd Thomaz, Cynthia Breazeal","author_ids":"1682788, 1711777","abstract":"As robots become a mass consumer product, they will need to learn new skills by interacting with typical human users. Past approaches have adapted reinforcement learning (RL) to accept a human reward signal; however , we question the implicit assumption that people shall only want to give the learner feedback on its past actions. We present findings from a human user study showing that people use the reward signal not only to provide feedback about past actions, but also to provide future directed rewards to guide subsequent actions. Given this, we made specific modifications to the simulated RL robot to incorporate guidance. We then analyze and evaluate its learning performance in a second user study, and we report significant improvements on several measures. This work demonstrates the importance of understanding the human-teacher/robot-learner system as a whole in order to design algorithms that support how people want to teach while simultaneously improving the robot's learning performance.","cites":"95","conferencePercentile":"96.9740634"},{"venue":"AAAI","id":"1ea10803d90b7d0d71137f7de498511950685cb8","venue_1":"AAAI","year":"2010","title":"Using Closed Captions as Supervision for Video Activity Recognition","authors":"Sonal Gupta, Raymond J. Mooney","author_ids":"2701297, 1797655","abstract":"Recognizing activities in real-world videos is a difficult problem exacerbated by background clutter, changes in camera angle & zoom, and rapid camera movements. Large corpora of labeled videos can be used to train automated activity recognition systems, but this requires expensive human labor and time. This paper explores how closed captions that naturally accompany many videos can act as weak supervision that allows automatically collecting 'labeled' data for activity recognition. We show that such an approach can improve activity retrieval in soccer videos. Our system requires no manual labeling of video clips and needs minimal human supervision. We also present a novel caption classifier that uses additional linguistic information to determine whether a specific comment refers to an ongoing activity. We demonstrate that combining linguistic analysis and automatically trained activity recognizers can significantly improve the precision of video retrieval.","cites":"10","conferencePercentile":"52.21843003"},{"venue":"AAAI","id":"7793e3f51f3c373bd75f9768e927ff6632fe8d69","venue_1":"AAAI","year":"2008","title":"Multi-Label Dimensionality Reduction via Dependence Maximization","authors":"Yin Zhang, Zhi-Hua Zhou","author_ids":"1685889, 1692625","abstract":"Multilabel learning deals with data associated with multiple labels simultaneously. Like other data mining and machine learning tasks, multilabel learning also suffers from the <i>curse of dimensionality</i>. Dimensionality reduction has been studied for many years, however, multilabel dimensionality reduction remains almost untouched. In this article, we propose a multilabel dimensionality reduction method, MDDM, with two kinds of projection strategies, attempting to project the original data into a lower-dimensional feature space maximizing the dependence between the original feature description and the associated class labels. Based on the Hilbert-Schmidt Independence Criterion, we derive a eigen-decomposition problem which enables the dimensionality reduction process to be efficient. Experiments validate the performance of MDDM.","cites":"65","conferencePercentile":"95.88607595"},{"venue":"AAAI","id":"93788f1c5ff0ae86b6be861a719f303aa4460cd4","venue_1":"AAAI","year":"2010","title":"Cost-Sensitive Semi-Supervised Support Vector Machine","authors":"Yu-Feng Li, James T. Kwok, Zhi-Hua Zhou","author_ids":"2634254, 1776349, 1692625","abstract":"In this paper, we study cost-sensitive semi-supervised learning where many of the training examples are un-labeled and different misclassification errors are associated with unequal costs. This scenario occurs in many real-world applications. For example, in some disease diagnosis, the cost of erroneously diagnosing a patient as healthy is much higher than that of diagnosing a healthy person as a patient. Also, the acquisition of labeled data requires medical diagnosis which is expensive , while the collection of unlabeled data such as basic health information is much cheaper. We propose the CS4VM (Cost-Sensitive Semi-Supervised Support Vector Machine) to address this problem. We show that the CS4VM, when given the label means of the unlabeled data, closely approximates the supervised cost-sensitive SVM that has access to the ground-truth labels of all the unlabeled data. This observation leads to an efficient algorithm which first estimates the label means and then trains the CS4VM with the plug-in label means by an efficient SVM solver. Experiments on a broad range of data sets show that the proposed method is capable of reducing the total cost and is computationally efficient.","cites":"9","conferencePercentile":"48.63481229"},{"venue":"AAAI","id":"34461284b8011525fde1ade3d17dafda0be8aa79","venue_1":"AAAI","year":"2011","title":"Dynamic Resource Allocation in Conservation Planning","authors":"Daniel Golovin, Andreas Krause, Beth Gardner, Sarah J. Converse, Steve Morey","author_ids":"2707208, 3421686, 2751846, 2295347, 2723352","abstract":"Consider the problem of protecting endangered species by selecting patches of land to be used for conservation purposes. Typically, the availability of patches changes over time, and recommendations must be made dynamically. This is a challenging prototypical example of a sequential optimization problem under uncertainty in computational sustainability. Existing techniques do not scale to problems of realistic size. In this paper, we develop an efficient algorithm for adaptively making recommendations for dynamic conservation planning, and prove that it obtains near-optimal performance. We further evaluate our approach on a detailed reserve design case study of conservation planning for three rare species in the Pacific Northwest of the United States.","cites":"18","conferencePercentile":"82.98969072"},{"venue":"AAAI","id":"63c7f13da6e5a6045b572a25df5b54d3b97adbdd","venue_1":"AAAI","year":"2015","title":"Incentivizing Users for Balancing Bike Sharing Systems","authors":"Adish Singla, Marco Santoni, Gábor Bartók, Pratik Mukerji, Moritz Meenen, Andreas Krause","author_ids":"1703727, 2493425, 2210750, 3184815, 1957917, 3421686","abstract":"Bike sharing systems have been recently adopted by a growing number of cities as a new means of transportation offering citizens a flexible, fast and green alternative for mobility. Users can pick up or drop off the bicycles at a station of their choice without prior notice or time planning. This increased flexibility comes with the challenge of unpredictable and fluctuating demand as well as irregular flow patterns of the bikes. As a result, these systems can incur imbalance problems such as the unavailability of bikes or parking docks at stations. In this light, operators deploy fleets of vehicles which redistribute the bikes in order to guarantee a desirable service level. Can we engage the users themselves to solve the imbalance problem in bike sharing systems? In this paper, we address this question and present a crowdsourcing mechanism that incentivizes the users in the bike repositioning process by providing them with alternate choices to pick or return bikes in exchange for monetary incentives. We design the complete architecture of the incentives system which employs optimal pricing policies using the approach of regret minimization in online learning. We investigate the incentive compatibility of our mechanism and extensively evaluate it through simulations based on data collected via a survey study. Finally, we deployed the proposed system through a smartphone app among users of a large scale bike sharing system operated by a public transport company, and we provide results from this experimental deployment. To our knowledge, this is the first dynamic incentives system for bikes redistribution ever deployed in a real-world bike sharing system.","cites":"9","conferencePercentile":"91.96850394"},{"venue":"AAAI","id":"0462fdc605d408533c270e45e0d6daffa5bb1981","venue_1":"AAAI","year":"2015","title":"Submodular Surrogates for Value of Information","authors":"Yuxin Chen, Shervin Javdani, Amin Karbasi, J. Andrew Bagnell, Siddhartha S. Srinivasa, Andreas Krause","author_ids":"1790059, 2833491, 1697131, 1756566, 1752197, 3421686","abstract":"How should we gather information to make effective decisions? A classical answer to this fundamental problem is given by the decision-theoretic value of information. Unfortunately, optimizing this objective is intractable, and myopic (greedy) approximations are known to perform poorly. In this paper, we introduce DIRECT, an efficient yet near-optimal algorithm for nonmyopically optimizing value of information. Crucially, DIRECT uses a novel surrogate objective that is: (1) aligned with the value of information problem (2) efficient to evaluate and (3) adaptive submod-ular. This latter property enables us to utilize an efficient greedy optimization while providing strong approximation guarantees. We demonstrate the utility of our approach on four diverse case-studies: touch-based robotic localization, comparison-based preference learning, wildlife conservation management, and preference elicitation in behavioral economics. In the first application, we demonstrate DIRECT in closed-loop on an actual robotic platform.","cites":"4","conferencePercentile":"73.46456693"},{"venue":"AAAI","id":"30e547dfab832ea0428b137d9e4824a22d8efd0b","venue_1":"AAAI","year":"2015","title":"Lazier Than Lazy Greedy","authors":"Baharan Mirzasoleiman, Ashwinkumar Badanidiyuru, Amin Karbasi, Jan Vondrák, Andreas Krause","author_ids":"2389094, 1797240, 1697131, 1733259, 3421686","abstract":"Is it possible to maximize a monotone submodular function faster than the widely used lazy greedy algorithm (also known as accelerated greedy), both in theory and practice? In this paper, we develop the first linear-time algorithm for maximizing a general monotone submodular function subject to a cardinality constraint. We show that our randomized algorithm , STOCHASTIC-GREEDY, can achieve a (1 − 1/e − ε) approximation guarantee, in expectation, to the optimum solution in time linear in the size of the data and independent of the cardinality constraint. We empirically demonstrate the effectiveness of our algorithm on submodular functions arising in data summarization, including training large-scale kernel methods, exemplar-based clustering, and sensor placement. We observe that STOCHASTIC-GREEDY practically achieves the same utility value as lazy greedy but runs much faster. More surprisingly, we observe that in many practical scenarios STOCHASTIC-GREEDY does not evaluate the whole fraction of data points even once and still achieves indistinguishable results compared to lazy greedy.","cites":"22","conferencePercentile":"98.58267717"},{"venue":"AAAI","id":"4ca8c2bf193bed3868a96638dabc2300f15d5e15","venue_1":"AAAI","year":"2016","title":"Noisy Submodular Maximization via Adaptive Sampling with Applications to Crowdsourced Image Collection Summarization","authors":"Adish Singla, Sebastian Tschiatschek, Andreas Krause","author_ids":"1703727, 3302876, 3421686","abstract":"We address the problem of maximizing an unknown submodular function that can only be accessed via noisy evaluations. Our work is motivated by the task of summarizing content, e.g., image collections, by leveraging users' feedback in form of clicks or ratings. For sum-marization tasks with the goal of maximizing coverage and diversity, submodular set functions are a natural choice. When the underlying submodular function is unknown, users' feedback can provide noisy evaluations of the function that we seek to maximize. We provide a generic algorithm – EXPGREEDY – for maximizing an unknown submodular function under cardinality constraints. This algorithm makes use of a novel exploration module – TOPX – that proposes good elements based on adaptively sampling noisy function evaluations. TOPX is able to accommodate different kinds of observation models such as value queries and pairwise comparisons. We provide PAC-style guarantees on the quality and sampling cost of the solution obtained by EXPGREEDY. We demonstrate the effectiveness of our approach in an interactive, crowdsourced image collection summarization application.","cites":"2","conferencePercentile":"61.31756757"},{"venue":"AAAI","id":"ddb4d9dab2198494de565657fc0a4efc6e4e5f25","venue_1":"AAAI","year":"2016","title":"Approximate K-Means++ in Sublinear Time","authors":"Olivier Bachem, Mario Lucic, S. Hamed Hassani, Andreas Krause","author_ids":"1936951, 2291549, 3391216, 3421686","abstract":"The quality of K-Means clustering is extremely sensitive to proper initialization. The classic remedy is to apply k-means++ to obtain an initial set of centers that is provably competitive with the optimal solution. Unfortunately, k-means++ requires k full passes over the data which limits its applicability to massive datasets. We address this problem by proposing a simple and efficient seeding algorithm for K-Means clustering. The main idea is to replace the exact D 2-sampling step in k-means++ with a substantially faster approximation based on Markov Chain Monte Carlo sampling. We prove that, under natural assumptions on the data, the proposed algorithm retains the full theoretical guarantees of k-means++ while its computational complexity is only sublinear in the number of data points. For such datasets, one can thus obtain a prov-ably good clustering in sublinear time. Extensive experiments confirm that the proposed method is competitive with k-means++ on a variety of real-world, large-scale datasets while offering a reduction in runtime of several orders of magnitude.","cites":"4","conferencePercentile":"79.72972973"},{"venue":"AAAI","id":"caa4bc73fdd77d4fe1ab3b363fc7862fb9a3b4be","venue_1":"AAAI","year":"2014","title":"A Smart Range Helping Cognitively-Impaired Persons Cooking","authors":"Bruno Bouchard, Kevin Bouchard, Abdenour Bouzouane","author_ids":"3442900, 1691371, 3112124","abstract":"People suffering from a loss of autonomy caused by a cognitive deficit generally have to perform important daily tasks (such as cooking) using devices and appliances designed for healthy people, which do not take into consideration their cognitive impairment. Using these devices is risky and may lead to a tragedy (e.g. fire). A potential solution to this issue is to provide automated systems, which perform tasks on behalf of the patient. However, clinical studies have shown that encouraging users to maintain their autonomy greatly help to preserve health, dignity, and motivation. Therefore, we present in this paper a new smart range prototype allowing monitoring and guiding a cognitively-impaired user in the activity of preparing a meal. This new original prototype is capable of giving adapted prompting to the user in the completion of several recipes by exploiting load cells, heat sensors and electromagnetic contacts embedded in the range. We currently own a provisional patent on this new invention, and we completed a first experimental phase.","cites":"1","conferencePercentile":"25.90909091"},{"venue":"AAAI","id":"09dc4b5b911b68d7cec68483e6a4ec1181aa5245","venue_1":"AAAI","year":"2006","title":"Inferring User's Preferences using Ontologies","authors":"Vincent Schickel, Boi Faltings","author_ids":"2241143, 1735128","abstract":"We consider recommender systems that filter information and only show the most preferred items. Good recommendations can be provided only when an accurate model of the user's preferences is available. We propose a novel technique for filling in missing elements of a user's preference model using the knowledge captured in an ontology. Furthermore, we show through experiments on the MovieLens data set that our model achieves a high prediction accuracy and personaliza-tion level when little about the user's preferences is known.","cites":"23","conferencePercentile":"72.76657061"},{"venue":"AAAI","id":"1ba4c6ff784f93b5eafb4a58515ea58246b77cb8","venue_1":"AAAI","year":"2008","title":"RADAR: A Personal Assistant that Learns to Reduce Email Overload","authors":"Michael Freed, Jaime G. Carbonell, Geoffrey J. Gordon, Jordan Hayes, Brad A. Myers, Daniel P. Siewiorek, Stephen F. Smith, Aaron Steinfeld, Anthony Tomasic","author_ids":"1678912, 1707929, 1736834, 2341458, 1707801, 1742634, 1679597, 1792714, 1693125","abstract":"Email client software is widely used for personal task management, a purpose for which it was not designed and is poorly suited. Past attempts to remedy the problem have focused on adding task management features to the client UI. RADAR uses an alternative approach modeled on a trusted human assistant who reads mail, identifies task-relevant message content, and helps manage and execute tasks. This paper describes the integration of diverse AI technologies and presents results from human evaluation studies comparing RADAR user performance to unaided COTS tool users and users partnered with a human assistant. As machine learning plays a central role in many system components, we also compare versions of RADAR with and without learning. Our tests show a clear advantage for learning-enabled RADAR over all other test conditions. Once widely hailed as the \" killer app \" for networked computing, email now gets more attention as a source of inefficiency, error, and stress. Complaints about excessive time spent processing, storing, finding, and collating messages are commonplace among office workers at every level and across organization type (Balter 1998). Business self-help books (e.g., Song et al. 2007) coach readers on regaining control of their lives from the \" tyranny of email. \" Studies of email overload show that the problem can negatively impact work performance (Dabbish and Kraut 2006) and that it imposes substantial costs on organizations and national economies (Spira and Goldes 2007). Early exploration of the problem focused on the ever-increasing volume of email that users send and receive. More recent investigations emphasize the centrality of email in workplace tasks of all kinds, the resulting adoption of email for personal task management (Mackay 1988; Whittaker and Sidner 1996), and the many inadequacies of email client software for this purpose (Belotti et al. 2003). Various projects have explored ways to reduce email overload by improving client software. Most focus on streamlining some aspect of message handling, e.g., by automatically filing messages into user-defined folders (e.g., Mock 2001), helping users quickly scan and decide what to do with unhandled messages (Cadiz et al. 2001), and identifying dependencies between messages in a conversational thread (Rohall et al. 2001). Belotti et al. (2003, 2005) have gone further and reconceptualized the email client in keeping with their view that \" dealing with email and dealing with tasks and projects are indistinguishable. \" Their system, Taskmaster, combines email client and to-do list functionality …","cites":"25","conferencePercentile":"83.38607595"},{"venue":"AAAI","id":"95ebe45f1ffbf1c34db3738d8fd30c2fbe486c08","venue_1":"AAAI","year":"2010","title":"Learning Spatial-Temporal Varying Graphs with Applications to Climate Data Analysis","authors":"Xi Chen, Yan Liu, Han Liu, Jaime G. Carbonell","author_ids":"1714741, 2254120, 1692120, 1707929","abstract":"An important challenge in understanding climate change is to uncover the dependency relationships between various climate observations and forcing factors. Graphical lasso, a recently proposed 1 penalty based structure learning algorithm, has been proven successful for learning underlying dependency structures for the data drawn from a multivariate Gaussian distribution. However, climatological data often turn out to be non-Gaussian, e.g. cloud cover, precipitation, etc. In this paper, we examine nonparametric learning methods to address this challenge. In particular, we develop a methodology to learn dynamic graph structures from spatial-temporal data so that the graph structures at adjacent time or locations are similar. Experimental results demonstrate that our method not only recovers the underlying graph well but also captures the smooth variation properties on both synthetic data and climate data.","cites":"8","conferencePercentile":"43.85665529"},{"venue":"AAAI","id":"4977eeb02d4e869dc9482353307dd166ea7d7044","venue_1":"AAAI","year":"2015","title":"Unsupervised Phrasal Near-Synonym Generation from Text Corpora","authors":"Dishan Gupta, Jaime G. Carbonell, Anatole Gershman, Steve Klein, David Miller","author_ids":"1918191, 1707929, 4119450, 2733317, 4355369","abstract":"Unsupervised discovery of synonymous phrases is useful in a variety of tasks ranging from text mining and search engines to semantic analysis and machine translation. This paper presents an unsupervised corpus-based conditional model: Near-Synonym System (NeSS) for finding phrasal synonyms and near synonyms that requires only a large monolingual corpus. The method is based on maximizing information-theoretic combinations of shared contexts and is parallelizable for large-scale processing. An evaluation framework with crowd-sourced judgments is proposed and results are compared with alternate methods, demonstrating considerably superior results to the literature and to thesaurus look up for multi-word phrases. Moreover, the results show that the statistical scoring functions and overall scala-bility of the system are more important than language specific NLP tools. The method is language-independent and practically useable due to accuracy and real-time performance via parallel decomposition.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"6bf2309a54a2ea27857de4c702e7e88b3da00753","venue_1":"AAAI","year":"1993","title":"Learning Interface Agents","authors":"Pattie Maes, Robyn Kozierok","author_ids":"1701876, 2683445","abstract":"Interface agents are computer programs that employ Artificial Intelligence techniques in order to provide assistance to a user dealing with a particular computer application. The paper discusses an interface agent which has been modelled closely after the metaphor of a personal assistant. The agent learns how to assist the user by (i) observing the user's actions and imitating them, (ii) receiving user feedback when it takes wrong actions and (iii) being trained by the user on the basis of hypothetical examples. The paper discusses how this learning agent was implemented using memory-based learning and reinforcement learning techniques. It presents actual results from two prototype agents built using these techniques: one for a meeting scheduling application and one for electronic mail. It argues that the machine learning approach to building interface agents is a feasible one which has several advantages over other approaches: it provides a customized and adaptive solution which is less costly and ensures better user acceptability. The paper also argues what the advantages are of the particular learning techniques used.","cites":"198","conferencePercentile":"94.59459459"},{"venue":"AAAI","id":"d967defc172ecd98830882277a0fb4844a373ed6","venue_1":"AAAI","year":"1994","title":"Collaborative Interface Agents","authors":"Yezdi Lashkari, Max Metral, Pattie Maes","author_ids":"2811001, 2611414, 1701876","abstract":"Interface agents are semi-intelligent systems which assist users with daily computer-based tasks. Recently, various researchers have proposed a learning approach towards building such agents and some working prototypes have been demonstrated. Such agents learn by`watching over the shoulder' of the user and detecting patterns and regularities in the user's behavior. Despite the successes booked, a major problem with the learning approach is that the agent has to learn from scratch and thus takes some time becoming useful. Secondly, the agent's competence is necessarily limited to actions it has seen the user perform. Collaboration between agents assisting diierent users can alleviate both of these problems. We present a framework for multi-agent collaboration and discuss results of a working prototype, based on learning agents for electronic mail.","cites":"243","conferencePercentile":"96.91629956"},{"venue":"AAAI","id":"fb25566db4ff4d676dc4aec99a0122966e3e90b0","venue_1":"AAAI","year":"2016","title":"The Constrained Laplacian Rank Algorithm for Graph-Based Clustering","authors":"Feiping Nie, Xiaoqian Wang, Michael I. Jordan, Heng Huang","author_ids":"1688370, 4329724, 1694621, 1748032","abstract":"Graph-based clustering methods perform clustering on a fixed input data graph. If this initial construction is of low quality then the resulting clustering may also be of low quality. Moreover, existing graph-based clustering methods require post-processing on the data graph to extract the clustering indicators. We address both of these drawbacks by allowing the data graph itself to be adjusted as part of the clustering procedure. In particular , our Constrained Laplacian Rank (CLR) method learns a graph with exactly k connected components (where k is the number of clusters). We develop two versions of this method, based upon the L1-norm and the L2-norm, which yield two new graph-based clustering objectives. We derive optimization algorithms to solve these objectives. Experimental results on synthetic datasets and real-world benchmark datasets exhibit the effectiveness of this new graph-based clustering method.","cites":"5","conferencePercentile":"86.31756757"},{"venue":"AAAI","id":"31a77506021cf868b549b92decaac127d3b88780","venue_1":"AAAI","year":"2015","title":"A Closed Form Solution to Multi-View Low-Rank Regression","authors":"Shuai Zheng, Xiao Cai, Chris H. Q. Ding, Feiping Nie, Heng Huang","author_ids":"2204012, 2016565, 1737469, 1688370, 1748032","abstract":"Real life data often includes information from different channels. For example, in computer vision, we can describe an image using different image features, such as pixel intensity, color, HOG, GIST feature, SIFT features , etc.. These different aspects of the same objects are often called multi-view (or multi-modal) data. Low-rank regression model has been proved to be an effective learning mechanism by exploring the low-rank structure of real life data. But previous low-rank regression model only works on single view data. In this paper, we propose a multi-view low-rank regression model by imposing low-rank constraints on multi-view regression model. Most importantly, we provide a closed-form solution to the multi-view low-rank regression model. Extensive experiments on 4 multi-view datasets show that the multi-view low-rank regression model outperforms single-view regression model and reveals that multi-view low-rank structure is very helpful.","cites":"2","conferencePercentile":"51.65354331"},{"venue":"AAAI","id":"31531ff4f106d1e196e619b859d0dc510e01c5a8","venue_1":"AAAI","year":"2015","title":"A Convex Formulation for Spectral Shrunk Clustering","authors":"Xiaojun Chang, Feiping Nie, Zhigang Ma, Yi Yang, Xiaofang Zhou","author_ids":"1729163, 1688370, 1727419, 1698559, 1720932","abstract":"Spectral clustering is a fundamental technique in the field of data mining and information processing. Most existing spectral clustering algorithms integrate dimen-sionality reduction into the clustering process assisted by manifold learning in the original space. However, the manifold in reduced-dimensional subspace is likely to exhibit altered properties in contrast with the original space. Thus, applying manifold information obtained from the original space to the clustering process in a low-dimensional subspace is prone to inferior performance. Aiming to address this issue, we propose a novel convex algorithm that mines the manifold structure in the low-dimensional subspace. In addition, our unified learning process makes the manifold learning particularly tailored for the clustering. Compared with other related methods, the proposed algorithm results in more structured clustering result. To validate the efficacy of the proposed algorithm, we perform extensive experiments on several benchmark datasets in comparison with some state-of-the-art clustering approaches. The experimental results demonstrate that the proposed algorithm has quite promising clustering performance.","cites":"6","conferencePercentile":"84.80314961"},{"venue":"AAAI","id":"9383f08c697b8aa43782e16c9a57e089911584d8","venue_1":"AAAI","year":"2015","title":"Large-Scale Multi-View Spectral Clustering via Bipartite Graph","authors":"Yeqing Li, Feiping Nie, Heng Huang, Junzhou Huang","author_ids":"2864470, 1688370, 1748032, 1768190","abstract":"In this paper, we address the problem of large-scale multi-view spectral clustering. In many real-world applications , data can be represented in various heterogeneous features or views. Different views often provide different aspects of information that are complementary to each other. Several previous methods of clustering have demonstrated that better accuracy can be achieved using integrated information of all the views than just using each view individually. One important class of such methods is multi-view spectral clustering, which is based on graph Laplacian. However, existing methods are not applicable to large-scale problem for their high computational complexity. To this end, we propose a novel large-scale multi-view spectral clustering approach based on the bipartite graph. Our method uses local manifold fusion to integrate heterogeneous features. To improve efficiency, we approximate the similarity graphs using bipartite graphs. Furthermore, we show that our method can be easily extended to handle the out-of-sample problem. Extensive experimental results on five benchmark datasets demonstrate the effectiveness and efficiency of the proposed method, where our method runs up to nearly 3000 times faster than the state-of-the-art methods.","cites":"4","conferencePercentile":"73.46456693"},{"venue":"AAAI","id":"9e5ec486118b23111f487e7a08f270f45ef520bb","venue_1":"AAAI","year":"2016","title":"Path Following with Adaptive Path Estimation for Graph Matching","authors":"Tao Wang, Haibin Ling","author_ids":"1685072, 1805398","abstract":"Graph matching plays an important role in many fields in computer vision. It is a well-known general NP-hard problem and has been investigated for decades. Among the large amount of algorithms for graph matching, the algorithms utilizing the path following strategy exhibited state-of-art performances. However, the main drawback of this category of algorithms lies in their high computational burden. In this paper, we propose a novel path following strategy for graph matching aiming to improve its computation efficiency. We first propose a path estimation method to reduce the computational cost at each iteration, and subsequently a method of adaptive step length to accelerate the convergence. The proposed approach is able to be integrated into all the algorithms that utilize the path following strategy. To validate our approach, we compare our approach with several recently proposed graph matching algorithms on three benchmark image datasets. Experimental results show that, our approach improves significantly the computation efficiency of the original algorithms, and offers similar or better matching results.","cites":"2","conferencePercentile":"61.31756757"},{"venue":"AAAI","id":"794ddb1f3b7598985d4d289b5b0664be736a50c4","venue_1":"AAAI","year":"2014","title":"Exploiting Competition Relationship for Robust Visual Recognition","authors":"Liang Du, Haibin Ling","author_ids":"1974855, 1805398","abstract":"Joint learning of similar tasks has been a popular trend in visual recognition and proven to be beneficial. Between-task similarity often provides useful cues, such as feature sharing, for learning visual clas-sifiers. By contrast, the competition relationship between visual recognition tasks (e.g., content independent writer identification and handwriting recognition) remains largely under-explored. A key challenge in visual recognition is to select the most discriminating features and remove irrelevant features related to intra-class variations. With the help of auxiliary competing tasks, we can identify such features within a joint learning model exploiting the competition relationship. Motivated by this intuition, we propose a novel way to exploit competition relationship for solving visual recognition problems. Specifically, given a target task and its competing tasks, we jointly model them by a generalized additive regression model with a competition constraint. This constraint effectively discourages choosing of irrelevant features (weak learners) that support the auxiliary competing tasks. We name the proposed algorithm CompBoost. In our study, CompBoost is applied to two visual recognition applications: (1) content-independent writer identification from handwriting scripts by exploiting competing tasks of handwriting recognition, and (2) actor-independent facial expression recognition by exploiting competing tasks of face recognition. In both experiments our approach demonstrates promising performance gains by exploiting the between-task competition.","cites":"2","conferencePercentile":"38.63636364"},{"venue":"AAAI","id":"1f849fa7f8455366049e57f95792eafe408d2ca6","venue_1":"AAAI","year":"2012","title":"A Testbed for Learning by Demonstration from Natural Language and RGB-Depth Video","authors":"Young Chol Song, Henry A. Kautz","author_ids":"3193978, 1690271","abstract":"We are developing a testbed for learning by demonstration combining spoken language and sensor data in a natural real-world environment. Microsoft Kinect RGB-Depth cameras allow us to infer high-level visual features , such as the relative position of objects in space, with greater precision and less training than required by traditional systems. Speech is recognized and parsed using a \" deep \" parsing system, so that language features are available at the word, syntactic, and semantic levels. We collected an initial data set of 10 episodes of 7 individuals demonstrating how to \" make tea \" , and created a \" gold standard \" hand annotation of the actions performed in each. Finally, we are constructing \" baseline \" HMM-based activity recognition models using the visual and language features, in order to be ready to evaluate the performance of our future work on deeper and more structured models. Most research in AI has explored problems of natural language understanding, visual perception, and learning and reasoning with commonsense knowledge in isolation. Recently , however, a number of researchers have argued that such a \" divide and conquer \" approach has reached a point of diminishing returns, and that significant progress in any of the areas requires a more integrated approach. In work coming out of the natural language community, this new direction 1 has been called grounded language learning (Brana-van, Zettlemoyer, and Barzilay 2010; Kollar et al. 2010; Chen and Mooney 2011), while in the machine vision community people speak of high-level or knowledge-based scene understanding (Kembhavi, Yeh, and Davis 2010). It is quite challenging, however, to begin this kind of research on integrated intelligence for two significant reasons: first, the work would appear to require expertise in (at least) natural language processing, vision, and knowledge representation and reasoning; and second, it is difficult to quantitatively measure progress, because there are few if any data sets and previous approaches against which one can compare. Our project addresses both of these concerns, and also forms a foundation for our own future work on integrated intelligent agents that can be taught to recognize and assist Figure 1: A screenshot from the activity recognition dataset, showing the RGB and depth streams. Agent, hand and object locations are marked. with complex real-world tasks. We are developing a testbed for learning by demonstration from natural language and sensor data, with the initial domain of kitchen activities. …","cites":"0","conferencePercentile":"4.725609756"},{"venue":"AAAI","id":"214cca90c9edfb7a72fb17050f5d8f654a69828c","venue_1":"AAAI","year":"2010","title":"Local and Global Regressive Mapping for Manifold Learning with Out-of-Sample Extrapolation","authors":"Yi Yang, Feiping Nie, Shiming Xiang, Yueting Zhuang, Wenhua Wang","author_ids":"1698559, 1688370, 1683738, 1755711, 4940203","abstract":"Over the past few years, a large family of manifold learning algorithms have been proposed, and applied to various applications. While designing new manifold learning algorithms has attracted much research attention , fewer research efforts have been focused on out-of-sample extrapolation of learned manifold. In this paper, we propose a novel algorithm of manifold learning. The proposed algorithm, namely Local and Global Regres-sive Mapping (LGRM), employs local regression models to grasp the manifold structure. We additionally impose a global regression term as regularization to learn a model for out-of-sample data extrapolation. Based on the algorithm, we propose a new manifold learning framework. Our framework can be applied to any manifold learning algorithms to simultaneously learn the low dimensional embedding of the training data and a model which provides explicit mapping of the out-of-sample data to the learned manifold. Experiments demonstrate that the proposed framework uncover the manifold structure precisely and can be freely applied to unseen data.","cites":"16","conferencePercentile":"69.62457338"},{"venue":"AAAI","id":"3b35f56c177146b59c6c6e47769e1b726e22fe18","venue_1":"AAAI","year":"2011","title":"Nonnegative Spectral Clustering with Discriminative Regularization","authors":"Yi Yang, Heng Tao Shen, Feiping Nie, Rongrong Ji, Xiaofang Zhou","author_ids":"1698559, 1724393, 1688370, 1725599, 1720932","abstract":"Clustering is a fundamental research topic in the field of data mining. Optimizing the objective functions of clustering algorithms, e.g. normalized cut and k-means, is an NP-hard optimization problem. Existing algorithms usually relax the elements of cluster indicator matrix from discrete values to continuous ones. Eigenvalue decomposition is then performed to obtain a relaxed continuous solution, which must be discretized. The main problem is that the signs of the relaxed continuous solution are mixed. Such results may deviate severely from the true solution, making it a nontrivial task to get the cluster labels. To address the problem, we impose an explicit nonnegative constraint for a more accurate solution during the relaxation. Besides, we additionally introduce a discriminative regularization into the objective to avoid overfitting. A new iterative approach is proposed to optimize the objective. We show that the algorithm is a general one which naturally leads to other extensions. Experiments demonstrate the effectiveness of our algorithm.","cites":"15","conferencePercentile":"78.35051546"},{"venue":"AAAI","id":"5c0effae9cac47113665c93d69c2e4da3aa82659","venue_1":"AAAI","year":"2011","title":"Learning Instance Specific Distance for Multi-Instance Classification","authors":"Hua Wang, Feiping Nie, Heng Huang","author_ids":"6098612, 1688370, 1748032","abstract":"Multi-Instance Learning (MIL) deals with problems where each training example is a bag, and each bag contains a set of instances. Multi-instance representation is useful in many real world applications, because it is able to capture more structural information than traditional flat single-instance representation. However, it also brings new challenges. Specifically, the distance between data objects in MIL is a set-to-set distance, which is harder to estimate than vector distances used in single-instance data. Moreover, because in MIL labels are assigned to bags instead of instances, although a bag belongs to a class, some, or even most, of its instances may not be truly related to the class. In order to address these difficulties, in this paper we propose a novel Instance Specific Distance (ISD) method for MIL, which computes the Class-to-Bag (C2B) distance by further considering the relevances of training instances with respect to their labeled classes. Taking into account the outliers caused by the weak label association in MIL, we learn ISD by solving an 0 +-norm minimization problem. An efficient algorithm to solve the optimization problem is presented, together with the rigorous proof of its convergence. The promising results on five benchmark multi-instance data sets and two real world multi-instance applications validate the effectiveness of the proposed method.","cites":"10","conferencePercentile":"67.18213058"},{"venue":"AAAI","id":"000077cbf43228058827467d7407523e7ebc809a","venue_1":"AAAI","year":"2015","title":"Predicting Emotion Perception Across Domains: A Study of Singing and Speaking","authors":"Biqiao Zhang, Emily Mower Provost, Robert Swedberg, Georg Essl","author_ids":"3099494, 3094624, 2788738, 1772683","abstract":"Emotion affects our understanding of the opinions and sentiments of others. Research has demonstrated that humans are able to recognize emotions in various domains , including speech and music, and that there are potential shared features that shape the emotion in both domains. In this paper, we investigate acoustic and visual features that are relevant to emotion perception in the domains of singing and speaking. We train regression models using two paradigms: (1) within-domain, in which models are trained and tested on the same domain and (2) cross-domain, in which models are trained on one domain and tested on the other domain. This strategy allows us to analyze the similarities and differences underlying the relationship between audiovisual feature expression and emotion perception and how this relationship is affected by domain of expression. We use kernel density estimation to model emotion as a probability distribution over the perception associated with multiple evaluators on the valence-activation space. This allows us to model the variation inherent in the reported perception. Results suggest that activation can be modeled more accurately across domains, compared to valence. Furthermore, visual features capture cross-domain emotion more accurately than acoustic features. The results provide additional evidence for a shared mechanism underlying spoken and sung emotion perception.","cites":"4","conferencePercentile":"73.46456693"},{"venue":"AAAI","id":"658339c73021674da17354eaaffc3cd326332117","venue_1":"AAAI","year":"2012","title":"Low-Rank Matrix Recovery via Efficient Schatten p-Norm Minimization","authors":"Feiping Nie, Heng Huang, Chris H. Q. Ding","author_ids":"1688370, 1748032, 1737469","abstract":"As an emerging machine learning and information retrieval technique, the matrix completion has been successfully applied to solve many scientific applications, such as collaborative prediction in information retrieval, video completion in computer vision, etc. The matrix completion is to recover a low-rank matrix with a fraction of its entries arbitrarily corrupted. Instead of solving the popularly used trace norm or nuclear norm based objective, we directly minimize the original formulations of trace norm and rank norm. We propose a novel Schatten p-Norm optimization framework that unifies different norm formulations. An efficient algorithm is derived to solve the new objective and followed by the rigorous theoretical proof on the convergence. The previous main solution strategy for this problem requires computing singular value decompositions-a task that requires increasingly cost as matrix sizes and rank increase. Our algorithm has closed form solution in each iteration, hence it converges fast. As a consequence, our algorithm has the capacity of solving large-scale matrix completion problems. Empirical studies on the recommendation system data sets demonstrate the promising performance of our new optimization framework and efficient algorithm.","cites":"32","conferencePercentile":"95.12195122"},{"venue":"AAAI","id":"12b4955b37a1447367a2f4be90ac2f355d91fc78","venue_1":"AAAI","year":"2005","title":"Selection and Ranking of Propositional Formulas for Large-Scale Service Directories","authors":"Ion Constantinescu, Walter Binder, Boi Faltings","author_ids":"1685108, 4303222, 1735128","abstract":"In this paper we consider scenarios, such as web service composition, where a planner needs to discover its operators by querying a potentially very large and dynamically changing directory. Our contribution is a directory system that represents service advertisements and requests as propo-sitional formulas and provides a flexible query language allowing complex selection and ranking expressions. The internal structure of the directory enables efficient selection and ranking in the presence of a large number of services thanks to its organization as a balanced tree with an extra \" intersection predicate \". In order to optimally exploit the index structure of the directory, a transformation scheme is applied to the original query. Experimental results on randomly generated service composition problems illustrate the benefits of our approach.","cites":"2","conferencePercentile":"16.25874126"},{"venue":"AAAI","id":"556599ee8c9a6eaa6bc9e142f525b80385971007","venue_1":"AAAI","year":"2014","title":"Globally and Locally Consistent Unsupervised Projection","authors":"Hua Wang, Feiping Nie, Heng Huang","author_ids":"6098612, 1688370, 1748032","abstract":"In this paper, we propose an unsupervised projection method for feature extraction to preserve both global and local consistencies of the input data in the projected space. Traditional unsupervised feature extraction methods, such as principal component analysis (PCA) and locality preserving projections (LPP), can only explore either the global or local geometric structures of the input data, but not the both at the same time. In our new method, we introduce a new measurement using the neighborhood data variances to assess the data locality, by which we propose to learn an optimal projection by rewarding both the global and local structures of the input data. The formulated optimization problem is challenging to solve, because it ends up a trace ratio minimization problem. In this paper, as an important theoretical contribution, we propose a simple yet efficient optimization algorithm to solve the trace ratio problem with theoretically proved convergence. Extensive experiments have been performed on six benchmark data sets, where the promising results validate the proposed method. Dimensionality reduction is an important technique in statistical learning and pattern recognition, which has been widely applied to solve a variety of machine learning and computer vision problems, such as face recognition (Turk and Pentland 1991), image annotation (Wang, Huang, and Ding 2010b), to name a few. Dimensionality reduction algorithms usually seek to represent the input data in their lower-dimensional \" intrinsic \" subspace/sub-manifold, in which irrelevant features are pruned and inherent data structures are more lucid. In the early ages, under the assumption that the input data objects are homogeneous but not relational, dimension-ality reduction algorithms were often devised to be linear. For example, Principal Component Analysis (PCA) (Jolliffe 2002) attempts to maximize the covariance among the input data points, and Linear Discriminant Analysis (LDA) (Fukunaga 1990) aims at maximizing the class separabil-ity. In recent years, manifold learning motivates many non-* To whom all correspondence should be addressed. linear dimensionality reduction algorithms using pairwise similarities between data objects, either computed from data attributes or directly obtained from experimental observations , which are nonlinear. These algorithms generally assume that the observed data are sampled from an underlying sub-manifold which are embedded in a high-dimensional observation space. Due to this reasonable assumption, manifold learning based nonlinear projection methods have demonstrated its usefulness in a number of real-world applications. However, a critical problem in most existing manifold learning techniques often hinders their applications in many real …","cites":"1","conferencePercentile":"25.90909091"},{"venue":"AAAI","id":"00b5f0b72ba47d1c186456a28e3f115d03973aea","venue_1":"AAAI","year":"2014","title":"A Convex Formulation for Semi-Supervised Multi-Label Feature Selection","authors":"Xiaojun Chang, Feiping Nie, Yi Yang, Heng Huang","author_ids":"1729163, 1688370, 1698559, 1748032","abstract":"Explosive growth of multimedia data has brought challenge of how to efficiently browse, retrieve and organize these data. Under this circumstance, different approaches have been proposed to facilitate multimedia analysis. Several semi-supervised feature selection algorithms have been proposed to exploit both labeled and unlabeled data. However, they are implemented based on graphs, such that they cannot handle large-scale datasets. How to conduct semi-supervised feature selection on large-scale datasets has become a challenging research problem. Moreover, existing multi-label feature selection algorithms rely on eigen-decomposition with heavy computational burden, which further prevent current feature selection algorithms from being applied for big data. In this paper, we propose a novel convex semi-supervised multi-label feature selection algorithm, which can be applied to large-scale datasets. We evaluate performance of the proposed algorithm over five benchmark datasets and compare the results with state-of-the-art supervised and semi-supervised feature selection algorithms as well as baseline using all features. The experimental results demonstrate that our proposed algorithm consistently achieve superiors performances.","cites":"18","conferencePercentile":"96.13636364"},{"venue":"AAAI","id":"02be6be9cc026283be1a237890870ce7b514e3da","venue_1":"AAAI","year":"2014","title":"Feature Selection at the Discrete Limit","authors":"Miao Zhang, Chris H. Q. Ding, Ya Zhang, Feiping Nie","author_ids":"1800158, 1737469, 6295076, 1688370","abstract":"Feature selection plays an important role in many machine learning and data mining applications. In this paper , we propose to use L 2,p norm for feature selection with emphasis on small p. As p → 0, feature selection becomes discrete feature selection problem. We provide two algorithms, proximal gradient algorithm and rank-one update algorithm, which is more efficient at large regularization λ. We provide closed form solutions of the proximal operator at p = 0, 1/2. Experiments on real life datasets show that features selected at small p consistently outperform features selected at p = 1, the standard L 2,1 approach and other popular feature selection methods.","cites":"4","conferencePercentile":"59.54545455"},{"venue":"AAAI","id":"c3a03933fa1372ace794e5193fcae62171b8795a","venue_1":"AAAI","year":"2014","title":"Low-Rank Tensor Completion with Spatio-Temporal Consistency","authors":"Hua Wang, Feiping Nie, Heng Huang","author_ids":"6098612, 1688370, 1748032","abstract":"Video completion is a computer vision technique to recover the missing values in video sequences by filling the unknown regions with the known information. In recent research, tensor completion, a generalization of matrix completion for higher order data, emerges as a new solution to estimate the missing information in video with the assumption that the video frames are homogenous and correlated. However, each video clip often stores the heterogeneous episodes and the correlations among all video frames are not high. Thus, the regular tenor completion methods are not suitable to recover the video missing values in practical applications. To solve this problem, we propose a novel spatially-temporally consistent tensor completion method for recovering the video missing data. Instead of minimizing the average of the trace norms of all matrices unfolded along each mode of a tensor data, we introduce a new smoothness regularization along video time direction to utilize the temporal information between consecutive video frames. Meanwhile, we also minimize the trace norm of each individual video frame to employ the spatial correlations among pixels. Different to previous ten-sor completion approaches, our new method can keep the spatio-temporal consistency in video and do not assume the global correlation in video frames. Thus, the proposed method can be applied to the general and practical video completion applications. Our method shows promising results in all evaluations on both 3D biomed-ical image sequence and video benchmark data sets. Video completion is the process of filling in missing pix-els or replacing undesirable pixels in a video. The missing values in a video can be caused by many situations, e.g., the natural noise in video capture equipment, the occlusion from the obstacles in environment, segmenting or removing interested objects from videos. Video completion is of great importance to many applications such as video repairing and editing, movie post-production (e.g., remove unwanted objects), etc. Missing information recovery in images is called inpaint-* To whom all correspondence should be addressed. ing, which is usually accomplished by inferring or guessing the missing information from the surrounding regions, i.e. the spatial information. Video completion can be considered as an extension of 2D image inpainting to 3D. Video completion uses the information from the past and the future frames to fill the pixels in the missing region, i.e. the spatio-temporal information, which has been getting increasing attention in recent years. In computer vision, an important application area of artificial intelligence, …","cites":"6","conferencePercentile":"72.84090909"},{"venue":"AAAI","id":"e467b46236732a0941ea3e7b405ce81dde26977e","venue_1":"AAAI","year":"2015","title":"Learning Robust Locality Preserving Projection via p-Order Minimization","authors":"Hua Wang, Feiping Nie, Heng Huang","author_ids":"6098612, 1688370, 1748032","abstract":"Locality preserving projection (LPP) is an effective di-mensionality reduction method based on manifold learning, which is defined over the graph weighted squared 2-norm distances in the projected subspace. Since squared 2-norm distance is prone to outliers, it is desirable to develop a robust LPP method. In this paper, motivated by existing studies that improve the robustness of statistical learning models via 1-norm or not-squared 2-norm formulations, we propose a robust LPP (rLPP) formulation to minimize the p-th order of the 2-norm distances, which can better tolerate large outlying data samples because it suppress the introduced biased more than the 1-norm or not squared 2-norm minimizations. However, solving the formulated objective is very challenging because it not only non-smooth but also non-convex. As an important theoretical contribution of this work, we systematically derive an efficient iterative algorithm to solve the general p-th order 2-norm minimization problem, which, to the best of our knowledge, is solved for the first time in literature. Extensive empirical evaluations on the proposed rLPP method have been performed, in which our new method outperforms the related state-of-the-art methods in a variety of experimental settings and demonstrate its effectiveness in seeking better subspaces on both noiseless and noisy data.","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"8682a678f5127d5df49435539c9e1b74b184bf87","venue_1":"AAAI","year":"2005","title":"Superstabilizing, Fault-Containing Distributed Combinatorial Optimization","authors":"Adrian Petcu, Boi Faltings","author_ids":"2416107, 1735128","abstract":"Self stabilization in distributed systems is the ability of a system to respond to transient failures by eventually reaching a legal state, and maintaining it afterwards. This makes such systems particularly interesting because they can tolerate faults, and are able to cope with dynamic environments. We propose the first self stabilizing mechanism for multia-gent combinatorial optimization, which works on general networks and stabilizes in a state corresponding to the optimal solution of the optimization problem. Our algorithm is based on dynamic programming, and requires a linear number of messages to find the optimal solution in the absence of faults. We show how our algorithm can be made super-stabilizing, in the sense that while transiting from one stable state to the next, our system preserves the assignments from the previous optimal state, until the new optimal solution is found. We offer equal bounds for the stabilization and the superstabiliza-tion time. Furthermore, we describe a general scheme for fault containment and fast response time upon low impact failures. Multiple , isolated failures are handled effectively. To show the merits of our approach we report on experiments with practically sized distributed meeting scheduling problems in a multiagent system.","cites":"3","conferencePercentile":"20.45454545"},{"venue":"AAAI","id":"00d640ee3ac3e063a2896cbb6c77c0cb5c9fce72","venue_1":"AAAI","year":"2015","title":"A New Granger Causal Model for Influence Evolution in Dynamic Social Networks: The Case of DBLP","authors":"Belkacem Chikhaoui, Mauricio Chiazzaro, Shengrui Wang","author_ids":"2026478, 1746490, 2875957","abstract":"This paper addresses a new problem concerning the evolution of influence relationships between communities in dynamic social networks. A weighted temporal multigraph is employed to represent the dynamics of the social networks and analyze the influence relationships between communities over time. To ensure the interpretability of the knowledge discovered, evolution of the influence relationships is assessed by introducing the Granger causality. Through extensive experiments, we empirically demonstrate the suitability of our model for studying the evolution of influence between communities. Moreover, we empirically show how our model is able to accurately predict the influence of communities over time using random forest regression.","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"12b8ee5429158e8b0dadd470f6bc413fdafbf0ea","venue_1":"AAAI","year":"2007","title":"Nonmyopic Informative Path Planning in Spatio-Temporal Models","authors":"Alexandra Meliou, Andreas Krause, Carlos Guestrin, Joseph M. Hellerstein","author_ids":"2283085, 3421686, 1730156, 1695576","abstract":"In many sensing applications we must continuously gather information to provide a good estimate of the state of the environment at every point in time. A robot may tour an environment , gathering information every hour. In a wireless sensor network, these tours correspond to packets being transmitted. In these settings, we are often faced with resource restrictions, like energy constraints. The users issue queries with certain expectations on the answer quality. Thus, we must optimize the tours to ensure the satisfaction of the user constraints, while at the same time minimize the cost of the query plan. For a single timestep, this optimization problem is NP-hard, but recent approximation algorithms with theoretical guarantees provide good solutions. In this paper, we present a new efficient algorithm, exploiting dynamic programming and submodularity of the information collected, that efficiently plans data collection tours for an entire (finite) horizon. Our algorithm can use any single step procedure as a black box, and, based on its properties, provides strong theoretical guarantees for the solution. We also provide an extensive empirical analysis demonstrating the benefits of nonmy-opic planning in two real world sensing applications.","cites":"36","conferencePercentile":"86.49851632"},{"venue":"AAAI","id":"45a4e5e80b09f0b36f860d49091db6ffa06b2409","venue_1":"AAAI","year":"2007","title":"Representative Explanations for Over-Constrained Problems","authors":"Barry O'Sullivan, Alexandre Papadopoulos, Boi Faltings, Pearl Pu","author_ids":"1738314, 2049870, 1735128, 1781996","abstract":"In many interactive decision making scenarios there is often no solution that satisfies all of the user's preferences. The decision process can be helped by providing explanations. Re-laxations show sets of consistent preferences and, thus, indicate which preferences can be enforced, while exclusion sets show which preferences can be relaxed to obtain a solution. We propose a new approach to explanation based on the notion of a representative set of explanations. The size of the set of explanations we compute is exponentially more compact than that found using common approaches from the literature based on finding all minimal conflicts.","cites":"22","conferencePercentile":"73.7388724"},{"venue":"AAAI","id":"915166e5c787fdcfba819fadda51ba32e937ba00","venue_1":"AAAI","year":"2010","title":"Myopic Policies for Budgeted Optimization with Constrained Experiments","authors":"Javad Azimi, Xiaoli Z. Fern, Alan Fern, Elizabeth Burrows, Frank Chaplen, Yanzhen Fan, Hong Liu, Jun Jaio, Rebecca Schaller","author_ids":"2582186, 1694273, 1791751, 4689681, 2034184, 3020513, 2407200, 2173561, 2637757","abstract":"Motivated by a real-world problem, we study a novel budgeted optimization problem where the goal is to optimize an unknown function f (x) given a budget. In our setting, it is not practical to request samples of f (x) at precise input values due to the formidable cost of precise experimental setup. Rather, we may request a constrained experiment, which is a subset r of the input space for which the experimenter returns x ∈ r and f (x). Importantly, as the constraints become looser, the experimental cost decreases, but the uncertainty about the location x of the next observation increases. Our goal is to manage this trade-off by selecting a sequence of constrained experiments to best optimize f within the budget. We introduce cost-sensitive policies for selecting constrained experiments using both model-free and model-based approaches, inspired by policies for unconstrained settings. Experiments on synthetic functions and functions derived from real-world experimental data indicate that our policies outperform random selection, that the model-based policies are superior to model-free ones, and give insights into which policies are preferable overall.","cites":"3","conferencePercentile":"22.52559727"},{"venue":"AAAI","id":"07a91afb52bc9e2ff95007d4ecb18a0192e71b74","venue_1":"AAAI","year":"2014","title":"Learning Scripts as Hidden Markov Models","authors":"John Walker Orr, Prasad Tadepalli, Janardhan Rao Doppa, Xiaoli Z. Fern, Thomas G. Dietterich","author_ids":"3287080, 1729906, 2089333, 1694273, 1699720","abstract":"Scripts have been proposed to model the stereotypical event sequences found in narratives. They can be applied to make a variety of inferences including filling gaps in the narratives and resolving ambiguous references. This paper proposes the first formal framework for scripts based on Hidden Markov Models (HMMs). Our framework supports robust inference and learning algorithms, which are lacking in previous clustering models. We develop an algorithm for structure and parameter learning based on Expectation Maximization and evaluate it on a number of natural datasets. The results show that our algorithm is superior to several informed baselines for predicting missing events in partial observation sequences.","cites":"11","conferencePercentile":"89.54545455"},{"venue":"AAAI","id":"139027b916def0c4ffc535e07cda72e483a983b6","venue_1":"AAAI","year":"2015","title":"Learning Greedy Policies for the Easy-First Framework","authors":"Jun Xie, Chao Ma, Janardhan Rao Doppa, Prashanth Mannem, Xiaoli Z. Fern, Thomas G. Dietterich, Prasad Tadepalli","author_ids":"1786096, 3449015, 2089333, 1700614, 1694273, 1699720, 1729906","abstract":"Easy-first, a search-based structured prediction approach , has been applied to many NLP tasks including dependency parsing and coreference resolution. This approach employs a learned greedy policy (action scoring function) to make easy decisions first, which constrains the remaining decisions and makes them easier. We formulate greedy policy learning in the Easy-first approach as a novel non-convex optimization problem and solve it via an efficient Majorization Minimization (MM) algorithm. Results on within-document corefer-ence and cross-document joint entity and event coref-erence tasks demonstrate that the proposed approach achieves statistically significant performance improvement over existing training regimes for Easy-first and is less susceptible to overfitting.","cites":"2","conferencePercentile":"51.65354331"},{"venue":"AAAI","id":"7687a0fe595f4e29cd98a53ed2d98d1adbb149fc","venue_1":"AAAI","year":"2013","title":"Discovering Hierarchical Structure for Sources and Entities","authors":"Aditya Pal, Nilesh N. Dalvi, Kedar Bellare","author_ids":"1908227, 1923209, 3195933","abstract":"In this paper, we consider the problem of jointly learning hierarchies over a set of sources and entities based on their containment relationship. We model the concept of hierarchy using a set of latent binary features and propose a generative model that assigns those latent features to sources and entities in order to maximize the probability of the observed containment. To avoid fixing the number of features beforehand, we consider a non-parametric approach based on the Indian Buffet Process. The hierarchies produced by our algorithm can be used for completing missing associations and discovering structural bindings in the data. Using simulated and real datasets we provide empirical evidence of the effectiveness of the proposed approach in comparison to the existing hierarchy agnostic approaches.","cites":"2","conferencePercentile":"37.09090909"},{"venue":"AAAI","id":"661ed3f4f6c9ae40eea8fc9ecb4af4eb9c9a67db","venue_1":"AAAI","year":"2015","title":"Incentives for Subjective Evaluations with Private Beliefs","authors":"Goran Radanovic, Boi Faltings","author_ids":"2667883, 1735128","abstract":"The modern web critically depends on aggregation of information from self-interested agents, for example opinion polls, product ratings, or crowdsourcing. We consider a setting where multiple objects (questions, products, tasks) are evaluated by a group of agents. We first construct a minimal peer prediction mechanism that elicits honest evaluations from a homogeneous population of agents with different private beliefs. Second, we show that it is impossible to strictly elicit honest evaluations from a heterogeneous group of agents with different private beliefs. Nevertheless, we provide a modified version of a divergence-based Bayesian Truth Serum that incentivizes agents to report consistently, making truthful reporting a weak equilibrium of the mechanism.","cites":"7","conferencePercentile":"88.11023622"},{"venue":"AAAI","id":"f8f2e0e929b1a1eb1ff75c80a6707df8fc07d0fe","venue_1":"AAAI","year":"2014","title":"A Region-Based Model for Estimating Urban Air Pollution","authors":"Arnaud Jutzeler, Jason Jingshi Li, Boi Faltings","author_ids":"2836859, 2010344, 1735128","abstract":"Air pollution has a direct impact to human health, and data-driven air quality models are useful for evaluating population exposure to air pollutants. In this paper, we propose a novel region-based Gaussian process model for estimating urban air pollution dispersion, and applied it to a large dataset of ultrafine particle (UFP) measurements collected from a network of sensors located on several trams in the city of Zurich. We show that compared to existing grid-based models, the region-based model produces better predictions across aggregates of all time scales. The new model is appropriate for many useful user applications such as exposure assessment and anomaly detection.","cites":"7","conferencePercentile":"77.5"},{"venue":"AAAI","id":"487ff2a76f7859723109c2670030241593de5200","venue_1":"AAAI","year":"2006","title":"Inconsistencies, Negations and Changes in Ontologies","authors":"Giorgos Flouris, Zhisheng Huang, Jeff Z. Pan, Dimitris Plexousakis, Holger Wache","author_ids":"1684066, 1693506, 1704953, 1705358, 1765833","abstract":"Ontology management and maintenance are considered cornerstone issues in current Semantic Web applications in which semantic integration and ontological reasoning play a fundamental role. The ability to deal with inconsistency and to accommodate change is of utmost importance in real-world applications of ontological reasoning and management, wherein the need for expressing negated assertions also arises naturally. For this purpose, precise, formal definitions of the the different types of inconsistency and negation in ontologies are required. Unfortunately, ontology languages based on Description Logics (DLs) do not provide enough expressive power to represent axiom negations. Furthermore, there is no single, well-accepted notion of inconsistency and negation in the Semantic Web community, due to the lack of a common and solid foundational framework. In this paper, we propose a general framework accounting for inconsistency, negation and change in ontologies. Different levels of negation and inconsistency in DL-based ontologies are distinguished. We demonstrate how this framework can provide a foundation for reasoning with and management of dynamic ontologies.","cites":"55","conferencePercentile":"91.93083573"},{"venue":"AAAI","id":"7041c45863c0d69ef22e5d1b4641496d87bf7119","venue_1":"AAAI","year":"2006","title":"Finding Maximally Satisfiable Terminologies for the Description Logic ALC","authors":"Thomas Andreas Meyer, Kevin Lee, Richard Booth, Jeff Z. Pan","author_ids":"1719208, 1737166, 4694781, 1704953","abstract":"For ontologies represented as Description Logic Tboxes, op-timised DL reasoners are able to detect logical errors, but there is comparatively limited support for resolving such problems. One possible remedy is to weaken the available information to the extent that the errors disappear, but to limit the weakening process as much as possible. The most obvious way to do so is to remove just enough Tbox sentences to eliminate the errors. In this paper we propose a tableau-like procedure for finding maximally concept-satisfiable terminologies represented in the description logic ALC. We discuss some optimisation techniques, and report on preliminary , but encouraging, experimental results.","cites":"56","conferencePercentile":"92.50720461"},{"venue":"AAAI","id":"17dd63bd42cab7c024680b278be8a3e433cb542f","venue_1":"AAAI","year":"2007","title":"Approximating OWL-DL Ontologies","authors":"Jeff Z. Pan, Edward Thomas","author_ids":"1704953, 1688697","abstract":"Efficient query answering over ontologies is one of the most useful and important services to support Semantic Web applications. Approximation has been identified as a potential way to reduce the complexity of query answering over OWL DL ontologies. Existing approaches are mainly based on syntactic approximation of ontological axioms and queries. In this paper, we propose to recast the idea of knowledge compilation into approximating OWL DL ontologies with DL-Lite ontologies, against which query answering has only polynomial data complexity. We identify a useful category of queries for which our approach guarantees also completeness. Furthermore, this paper reports on the implementation of our approach in the ONTOSEARCH2 system and preliminary , but encouraging, benchmark results which compare ONTOSEARCH2's response times on a number of queries with those of existing ontology reasoning systems.","cites":"52","conferencePercentile":"92.43323442"},{"venue":"AAAI","id":"366eadd0e0e76d2fa5fa6f5da31ebc7c94b715b8","venue_1":"AAAI","year":"2010","title":"Soundness Preserving Approximation for TBox Reasoning","authors":"Yuan Ren, Jeff Z. Pan, Yuting Zhao","author_ids":"3605114, 1704953, 1847268","abstract":"Large scale ontology applications require efficient and robust description logic (DL) reasoning services. Expressive DLs usually have very high worst case complexity while tractable DLs are restricted in terms of expressive power. This brings a new challenge: can users use expressive DLs to build their ontologies and still enjoy the efficient services as in tractable languages. In this paper, we present a soundness preserving approximate reasoning framework for TBox reasoning in OWL2-DL. The ontologies are encoded into EL ++ with additional data structures. A tractable algorithm is presented to classify such approximation by realizing more and more inference patterns. Preliminary evaluation shows that our approach can classify existing benchmarks in large scale efficiently with a high recall.","cites":"35","conferencePercentile":"89.07849829"},{"venue":"AAAI","id":"79a63ea71f25bbe9a02bc92f03780aedee76d59c","venue_1":"AAAI","year":"2011","title":"Towards Practical ABox Abduction in Large OWL DL Ontologies","authors":"Jianfeng Du, Guilin Qi, Yi-Dong Shen, Jeff Z. Pan","author_ids":"2849559, 1730054, 1744468, 1704953","abstract":"ABox abduction is an important aspect for abductive reasoning in Description Logics (DLs). It finds all minimal sets of ABox axioms that should be added to a background ontology to enforce entailment of a specified set of ABox axioms. As far as we know, by now there is only one ABox abduction method in expressive DLs computing abductive solutions with certain minimality. However, the method targets an ABox abduction problem that may have infinitely many abduc-tive solutions and may not output an abductive solution in finite time. Hence, in this paper we propose a new ABox abduction problem which has only finitely many abductive solutions and also propose a novel method to solve it. The method reduces the original problem to an abduction problem in logic programming and solves it with Prolog engines. Experimental results show that the method is able to compute abductive solutions in benchmark OWL DL ontologies with large ABoxes.","cites":"20","conferencePercentile":"87.11340206"},{"venue":"AAAI","id":"39c17cbe6fc483cc6150a0bdf8a0025d659ee09d","venue_1":"AAAI","year":"2014","title":"Incentives for Truthful Information Elicitation of Continuous Signals","authors":"Goran Radanovic, Boi Faltings","author_ids":"2667883, 1735128","abstract":"We consider settings where a collective intelligence is formed by aggregating information contributed from many independent agents, such as product reviews, community sensing, or opinion polls. We propose a novel mechanism that elicits both private signals and beliefs. The mechanism extends the previous versions of the Bayesian Truth Serum (the original BTS, the RBTS, and the multi-valued BTS), by allowing small populations and non-binary private signals, while not requiring additional assumptions on the belief updating process. For priors that are sufficiently smooth, such as Gaus-sians, the mechanism allows signals to be continuous.","cites":"16","conferencePercentile":"94.65909091"},{"venue":"AAAI","id":"05d031fb15aeff23a8f41343c2311907b2788645","venue_1":"AAAI","year":"2014","title":"Swissnoise: Online Polls with Game-Theoretic Incentives","authors":"Florent Garcin, Boi Faltings","author_ids":"2395924, 1735128","abstract":"There is much interest in crowdsourcing information that is distributed among many individuals, such as the likelihood of future events, election outcomes, the quality of products, or the consequence of a decision. To obtain accurate outcomes , various game-theoretic incentive schemes have been proposed. However, only prediction markets have been tried in practice. In this paper, we describe an experimental platform , swissnoise, that compares prediction markets with peer prediction schemes developed in recent AI research. It shows that peer prediction schemes can achieve similar performance while being applicable to a much broader range of questions.","cites":"3","conferencePercentile":"49.43181818"},{"venue":"AAAI","id":"b7d6c897ce988a4bd704299c34e3a2a87c915184","venue_1":"AAAI","year":"2014","title":"Acquiring Commonsense Knowledge for Sentiment Analysis through Human Computation","authors":"Marina Boia, Claudiu Cristian Musat, Boi Faltings","author_ids":"3063772, 2504407, 1735128","abstract":"Many Artificial Intelligence tasks need large amounts of commonsense knowledge. Because obtaining this knowledge through machine learning would require a huge amount of data, a better alternative is to elicit it from people through human computation. We consider the sentiment classification task, where knowledge about the contexts that impact word polarities is crucial, but hard to acquire from data. We describe a novel task design that allows us to crowdsource this knowledge through Amazon Mechanical Turk with high quality. We show that the commonsense knowledge acquired in this way dramatically improves the performance of established sentiment classification methods.","cites":"2","conferencePercentile":"38.63636364"},{"venue":"AAAI","id":"770f106ad13dd43283bd100d3d8bf536584264c5","venue_1":"AAAI","year":"2013","title":"A Robust Bayesian Truth Serum for Non-Binary Signals","authors":"Goran Radanovic, Boi Faltings","author_ids":"2667883, 1735128","abstract":"Several mechanisms have been proposed for incentivizing truthful reports of a private signals owned by rational agents, among them the peer prediction method and the Bayesian truth serum. The robust Bayesian truth serum (RBTS) for small populations and binary signals is particularly interesting since it does not require a common prior to be known to the mechanism. We further analyze the problem of the common prior not known to the mechanism and give several results regarding the restrictions that need to be placed in order to have an incentive-compatible mechanism. Moreover, we construct a Bayes-Nash incentive-compatible scheme called multi-valued RBTS that generalizes RBTS to operate on both small populations and non-binary signals.","cites":"26","conferencePercentile":"97.27272727"},{"venue":"AAAI","id":"5d74263314a5632559c0a02f18d4992b9ae7806f","venue_1":"AAAI","year":"2013","title":"A Novel Human Computation Game for Critique Aggregation","authors":"Claudiu Cristian Musat, Boi Faltings","author_ids":"2504407, 1735128","abstract":"We present a human computation game based on the popular board game-Dixit. We ask the players not only for annotations , but for a direct critique of the result of an automated system. We present the results of the initial run of the game, in which the answers of 15 players were used to profile the mistakes of an aspect-based opinion mining system. We show that the gameplay allowed us to identify the major faults of the extracted opinions. The players' actions thus helped improve the opinion extraction algorithm.","cites":"5","conferencePercentile":"62.54545455"},{"venue":"AAAI","id":"138eb51375ead4a0becaf731666f6844e369805f","venue_1":"AAAI","year":"1994","title":"Forming Beliefs about a Changing World","authors":"Fahiem Bacchus, Adam J. Grove, Joseph Y. Halpern, Daphne Koller","author_ids":"1736882, 2187850, 1691828, 1736370","abstract":"The situation calculus is a popular technique for reasoning about action and change. However, its restriction to a first-order syntax and pure deductive reasoning makes it unsuitable in many contexts. In particular, we often face uncertainty, due either to lack of knowledge or to some probabilistic aspects of the world. While attempts have been made to address aspects of this problem, most notably using nonmonotonic reasoning formalisms, the general problem of uncertainty in reasoning about action has not been fully dealt with in a logical framework. In this paper we present a theory of action that extends the situation calculus to deal with uncertainty. Our framework is based on applying the random-worlds approach of [BGHK94] to a situation calculus ontology, enriched to allow the expression of probabilistic action effects. Our approach is able to solve many of the problems imposed by incomplete and probabilistic knowledge within a unified framework. In particular, we obtain a default Markov property for chains of actions, a derivation of conditional independence from irrelevance , and a simple solution to the frame problem.","cites":"7","conferencePercentile":"36.56387665"},{"venue":"AAAI","id":"0786ee068a4d9dc4079e813a4fa0a067f5d3fccc","venue_1":"AAAI","year":"2008","title":"H-DPOP: Using Hard Constraints for Search Space Pruning in DCOP","authors":"Akshat Kumar, Adrian Petcu, Boi Faltings","author_ids":"2196236, 2416107, 1735128","abstract":"In distributed constraint optimization problems, dynamic programming methods have been recently proposed (e.g. DPOP). In dynamic programming many valuations are grouped together in fewer messages, which produce much less networking overhead than search. Nevertheless, these messages are exponential in size. The basic DPOP always communicates all possible assignments, even when some of them may be inconsistent due to hard constraints. Many real problems contain hard constraints that significantly reduce the space of feasible assignments. This paper introduces H-DPOP, a hybrid algorithm that is based on DPOP, which uses Constraint Decision Diagrams (CDD) to rule out infeasible assignments, and thus compactly represent UTIL messages. Experimental results show that H-DPOP requires several orders of magnitude less memory than DPOP, especially for dense and tightly-constrained problems.","cites":"8","conferencePercentile":"49.52531646"},{"venue":"AAAI","id":"1883ed384896a799cedf8b02633a09b8259fe985","venue_1":"AAAI","year":"2007","title":"Near-optimal Observation Selection using Submodular Functions","authors":"Andreas Krause, Carlos Guestrin","author_ids":"3421686, 1730156","abstract":"AI problems such as autonomous robotic exploration, automatic diagnosis and activity recognition have in common the need for choosing among a set of informative but possibly expensive observations. When monitoring spatial phenomena with sensor networks or mobile robots, for example, we need to decide which locations to observe in order to most effectively decrease the uncertainty, at minimum cost. These problems usually are NP-hard. Many observation selection objectives satisfy submodularity, an intuitive diminishing returns property – adding a sensor to a small deployment helps more than adding it to a large deployment. In this paper, we survey recent advances in systematically exploiting this submodu-larity property to efficiently achieve near-optimal observation selections, under complex constraints. We illustrate the effectiveness of our approaches on problems of monitoring environmental phenomena and water distribution networks.","cites":"125","conferencePercentile":"99.40652819"},{"venue":"AAAI","id":"c260cf8f8c6150927c2404b87fcc101f8dd091e0","venue_1":"AAAI","year":"2011","title":"Distributed Constraint Optimization Under Stochastic Uncertainty","authors":"Thomas Léauté, Boi Faltings","author_ids":"2001878, 1735128","abstract":"In many real-life optimization problems involving multiple agents, the rewards are not necessarily known exactly in advance , but rather depend on sources of exogenous uncertainty. For instance, delivery companies might have to coordinate to choose who should serve which foreseen customer, under uncertainty in the locations of the customers. The framework of Distributed Constraint Optimization under Stochastic Uncertainty was proposed to model such problems; in this paper , we generalize this formalism by introducing the concept of evaluation functions that model various optimization criteria. We take the example of three such evaluation functions , expectation, consensus, and robustness, and we adapt and generalize two previous algorithms accordingly. Our experimental results on a class of Vehicle Routing Problems show that incomplete algorithms are not only cheaper than complete ones (in terms of simulated time, Non-Concurrent Constraint Checks, and information exchange), but they are also often able to find the optimal solution. We also show that exchanging more information about the dependencies of their respective cost functions on the sources of uncertainty can help the agents discover higher-quality solutions.","cites":"14","conferencePercentile":"76.28865979"},{"venue":"AAAI","id":"394eddd9512bb6bc52091a1b32a6b1216c840b89","venue_1":"AAAI","year":"2012","title":"DUCT: An Upper Confidence Bound Approach to Distributed Constraint Optimization Problems","authors":"Brammert Ottens, Christos Dimitrakakis, Boi Faltings","author_ids":"2440615, 1720480, 1735128","abstract":"The Upper Confidence Bounds (UCB) algorithm is a well-known near-optimal strategy for the stochastic multi-armed bandit problem. Its extensions to trees, such as the Upper Confidence Tree (UCT) algorithm, have resulted in good solutions to the problem of Go. This paper introduces DUCT, a distributed algorithm inspired by UCT, for solving Distributed Constraint Optimization Problems (DCOP). Bounds on the solution quality are provided, and experiments show that, compared to existing DCOP approaches, DUCT is able to solve very large problems much more efficiently, or to find significantly higher quality solutions.","cites":"12","conferencePercentile":"74.54268293"},{"venue":"AAAI","id":"16c59f1c871686706c1ba7de6aa0a7da4ce8e41a","venue_1":"AAAI","year":"1992","title":"From Statistics to Beliefs","authors":"Fahiem Bacchus, Adam J. Grove, Daphne Koller, Joseph Y. Halpern","author_ids":"1736882, 2187850, 1736370, 1691828","abstract":"An intelligent agent uses known facts, including statistical knowledge, to assign degrees of belief to assertions it is uncertain about. We investigate three principled techniques for doing this. All three are applications of the principle of indiierence, because they assign equal degree of belief to all basic \\situations\" consistent with the knowledge base. They diier because there are competing intuitions about what the basic situations are. Various natural patterns of reasoning, such as the preference for the most speciic statistical data available, turn out to follow from some or all of the techniques. This is an improvement over earlier theories , such as work on direct inference and reference classes, which arbitrarily postulate these patterns without ooering any deeper explanations or guarantees of consistency. The three methods we investigate have surprising characterizations: there are connections to the principle of maximum entropy, a principle of maximal independence, and a \\center of mass\" principle. There are also unexpected connections between the three, that help us understand why the speciic language chosen (for the knowledge base) is much more critical in inductive reasoning of the sort we consider than it is in traditional deductive reasoning.","cites":"52","conferencePercentile":"73.21428571"},{"venue":"AAAI","id":"065377da48ed087704e36c804df0291ef044cf3a","venue_1":"AAAI","year":"1994","title":"Automatic Symbolic Traffic Scene Analysis Using Belief Networks","authors":"Timothy Huang, Daphne Koller, Jitendra Malik, Gary H. Ogasawara, B. Rao, Stuart J. Russell, Joseph Weber","author_ids":"8671869, 1736370, 1689212, 2842808, 2517198, 1690032, 6526051","abstract":"Automatic symbolic traffic scene analysis is essential to many areas of IVHS (Intelligent Vehicle Highway Systems). Traffic scene information can be used to optimize traffic flow during busy periods , identify stalled vehicles and accidents, and aid the decision-making of an autonomous vehicle controller. Improvements in technologies for machine vision-based surveillance and high-level symbolic reasoning have enabled us to develop a system for detailed, reliable traffic scene analysis. The machine vision component of our system employs a contour tracker and an affine motion model based on Kalman filters to extract vehicle trajec-tories over a sequence of traffic scene images. The symbolic reasoning component uses a dynamic belief network to make inferences about traffic events such as vehicle lane changes and stalls. In this paper , we discuss the key tasks of the vision and reasoning components as well as their integration into a working prototype.","cites":"62","conferencePercentile":"86.78414097"},{"venue":"AAAI","id":"354cb159b85d44de53c5e8e8b1393d084ac1b412","venue_1":"AAAI","year":"2006","title":"ODPOP: An Algorithm for Open/Distributed Constraint Optimization","authors":"Adrian Petcu, Boi Faltings","author_ids":"2416107, 1735128","abstract":"We propose ODPOP, a new distributed algorithm for open multiagent combinatorial optimization that feature unbounded domains (Faltings & Macho-Gonzalez 2005). The ODPOP algorithm explores the same search space as the dynamic programming algorithm DPOP (Petcu & Faltings 2005b) or ADOPT (Modi et al. 2005), but does so in an in-cremental, best-first fashion suitable for open problems. ODPOP has several advantages over DPOP. First, it uses messages whose size only grows linearly with the treewidth of the problem. Second, by letting agents explore values in a best-first order, it avoids incurring always the worst case complexity as DPOP, and on average it saves a significant amount of computation and information exchange. To show the merits of our approach, we report on experiments with practically sized distributed meeting scheduling problems in a multiagent system.","cites":"28","conferencePercentile":"76.5129683"},{"venue":"AAAI","id":"28c04fd653adf4cd7927d6ea2be1d06ff08a4b10","venue_1":"AAAI","year":"2012","title":"A Market-Based Coordination Mechanism for Resource Planning Under Uncertainty","authors":"Hadi Hosseini, Jesse Hoey, Robin Cohen","author_ids":"2322447, 1773895, 3486209","abstract":"Introduction Multiagent Resource Allocation (MARA) distributes a set of resources among a set of intelligent agents in order to respect the preferences of the agents and to maximize some measure of global utility, which may include minimizing total costs or maximizing total return. We are interested in MARA solutions that provide optimal or close-to-optimal allocation of resources in terms of maximizing a global welfare function with low communication and computation cost, with respect to the priority of agents, and temporal dependencies between resources. We propose an MDP approach for resource planning in multiagent environments. Our approach formulates internal preference modeling and success of each individual agent as a single MDP and then to optimize global utility, we apply a market-based solution to coordinate these decentralized MDPs.","cites":"0","conferencePercentile":"4.725609756"},{"venue":"AAAI","id":"1927f91deaf2fd7795bc4c08c2fedd92d2377ae7","venue_1":"AAAI","year":"2012","title":"Sensing the Air We Breathe - The OpenSense Zurich Dataset","authors":"Jason Jingshi Li, Boi Faltings, Olga Saukh, David Hasenfratz, Jan Beutel","author_ids":"2010344, 1735128, 2731697, 1882372, 1698582","abstract":"Monitoring and managing urban air pollution is a significant challenge for the sustainability of our environment. We quickly survey the air pollution modeling problem, introduce a new dataset of mobile air quality measurements in Zurich, and discuss the challenges of making sense of these data.","cites":"16","conferencePercentile":"83.23170732"},{"venue":"AAAI","id":"44c0ac2bb9dbe8e8748f3e0ff0a131b50626cebc","venue_1":"AAAI","year":"2012","title":"Symmetric Subgame Perfect Equilibria in Resource Allocation","authors":"Ludek Cigler, Boi Faltings","author_ids":"2723538, 1735128","abstract":"We analyze symmetric protocols to rationally coordinate on an asymmetric, efficient allocation in an infinitely repeated N-agent, C-resource allocation problems, where the resources are all homogeneous. Bhaskar proposed one way to achieve this in 2-agent, 1-resource games: Agents start by symmetrically randomizing their actions, and as soon as they each choose different actions, they start to follow a potentially asymmetric \" convention \" that prescribes their actions from then on. We extend the concept of convention to the general case of infinitely repeated resource allocation games with N agents and C resources. We show that for any convention, there exists a symmetric subgame-perfect equilibrium which implements it. We present two conventions: bourgeois, where agents stick to the first allocation; and market, where agents pay for the use of resources, and observe a global coordination signal which allows them to alternate between different allocations. We define price of anonymity of a convention as a ratio between the maximum social payoff of any (asymmetric) strategy profile and the expected social payoff of the subgame-perfect equilibrium which implements the convention. We show that while the price of anonymity of the bourgeois convention is infinite, the market convention decreases this price by reducing the conflict between the agents.","cites":"1","conferencePercentile":"13.87195122"},{"venue":"AAAI","id":"27b781d36ff519a2462ca37aaa2a9f052d201b23","venue_1":"AAAI","year":"2006","title":"Lessons on Applying Automated Recommender Systems to Information-Seeking Tasks","authors":"Joseph A. Konstan, Sean M. McNee, Cai-Nicolas Ziegler, Roberto Torres, Nishikant Kapoor, John Riedl","author_ids":"2478310, 3039934, 2116867, 3550550, 2995562, 8497382","abstract":"* Automated recommender systems predict user preferences by applying machine learning techniques to data on products, users, and past user preferences for products. Such systems have become increasingly popular in entertainment and e-commerce domains, but have thus far had little success in information-seeking domains such as identifying published research of interest. We report on several recent publications that show how recommenders can be extended to more effectively address information-seeking tasks by expanding the focus from accurate prediction of user preferences to identifying a useful set of items to recommend in response to the user's specific information need. Specific research demonstrates the value of diversity in recommendation lists, shows how users value lists of recommendations as something different from the sum of the individual recommendations within, and presents an analytic model for customizing a recommender to match user information-seeking needs.","cites":"16","conferencePercentile":"63.54466859"},{"venue":"AAAI","id":"e1e6f3e9ed994562253294b2037d18529d7d23cf","venue_1":"AAAI","year":"2015","title":"Consistent Knowledge Discovery from Evolving Ontologies","authors":"Freddy Lécué, Jeff Z. Pan","author_ids":"1863173, 1704953","abstract":"Deductive reasoning and inductive learning are the most common approaches for deriving knowledge. In real world applications when data is dynamic and incomplete, especially those exposed by sensors, reasoning is limited by dynamics of data while learning is biased by data incompleteness. Therefore discovering consistent knowledge from incomplete and dynamic data is a challenging open problem. In our approach the semantics of data is captured through ontologies to empower learning (mining) with (Description Logics) reasoning. Consistent knowledge discovery is achieved by applying generic, significative, representative association semantic rules. The experiments have shown scalable, accurate and consistent knowledge discovery with data from Dublin.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"80054c7a5640289ae098129e31adf75d65b2c3de","venue_1":"AAAI","year":"2014","title":"How Long Will It Take? Accurate Prediction of Ontology Reasoning Performance","authors":"Yong-Bin Kang, Jeff Z. Pan, Shonali Krishnaswamy, Wudhichart Sawangphol, Yuan-Fang Li","author_ids":"1823825, 1704953, 1781256, 3264787, 4495301","abstract":"For expressive ontology languages such as OWL 2 DL, classification is a computationally expensive task— 2NEXPTIME-complete in the worst case. Hence, it is highly desirable to be able to accurately estimate classification time, especially for large and complex ontolo-gies. Recently, machine learning techniques have been successfully applied to predicting the reasoning hardness category for a given (ontology, reasoner) pair. In this paper, we further develop predictive models to estimate actual classification time using regression techniques , with ontology metrics as features. Our large-scale experiments on 6 state-of-the-art OWL 2 DL rea-soners and more than 450 significantly diverse ontolo-gies demonstrate that the prediction models achieve high accuracy, good generalizability and statistical significance. Such prediction models have a wide range of applications. We demonstrate how they can be used to efficiently and accurately identify performance hotspots in a large and complex ontology, an otherwise very time-consuming and resource-intensive task.","cites":"3","conferencePercentile":"49.43181818"},{"venue":"AAAI","id":"20907c11c242fc1912d5ae09c81e4eedac960487","venue_1":"AAAI","year":"2012","title":"Querying Linked Ontological Data through Distributed Summarization","authors":"Achille Fokoue, Felipe Meneguzzi, Murat Sensoy, Jeff Z. Pan","author_ids":"2297836, 2920773, 1715430, 1704953","abstract":"As the semantic web expands, ontological data becomes distributed over a large network of data sources on the Web. Consequently, evaluating queries that aim to tap into this distributed semantic database necessitates the ability to consult multiple data sources efficiently. In this paper, we propose methods and heuristics to efficiently query distributed ontological data based on a series of properties of summarized data. In our approach , each source summarizes its data as another RDF graph, and relevant section of these summaries are merged and analyzed at query evaluation time. We show how the analysis of these summaries enables more efficient source selection, query pruning and transformation of expensive distributed joins into local joins.","cites":"4","conferencePercentile":"39.17682927"},{"venue":"AAAI","id":"fdaf02f65f60cd400ba22705ba3b0b7b2a4f5a0c","venue_1":"AAAI","year":"2015","title":"Bayesian Affect Control Theory of Self","authors":"Jesse Hoey, Tobias Schröder","author_ids":"1773895, 1763125","abstract":"Notions of identity and of the self have long been studied in social psychology and sociology as key guiding elements of social interaction and coordination. In the AI of the future, these notions will also play a role in producing natural, socially appropriate artificially intelligent agents that encompass subtle and complex human social and affective skills. We propose here a Bayesian generalization of the sociological affect control theory of self as a theoretical foundation for socio-affectively skilled artificial agents. This theory posits that each human maintains an internal model of his or her deep sense of \" self \" that captures their emotional, psychological , and socio-cultural sense of being in the world. The \" self \" is then externalised as an identity within any given interpersonal and institutional situation, and this situational identity is the person's local (in space and time) representation of the self. Situational identities govern the actions of humans according to affect control theory. Humans will seek situations that allow them to enact identities consistent with their sense of self. This consistency is cumulative over time: if some parts of a person's self are not actualized regularly, the person will have a growing feeling of inauthenticity that they will seek to resolve. In our present generalisation, the self is represented as a probability distribution, allowing it to be multi-modal (a person can maintain multiple different identities), uncertain (a person can be unsure about who they really are), and learnable (agents can learn the identities and selves of other agents). We show how the Bayesian affect control theory of self can underpin artificial agents that are socially intelligent.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"0b163a0c60a14131aafe738cd28abfa75867a187","venue_1":"AAAI","year":"2014","title":"Robust Distance Metric Learning in the Presence of Label Noise","authors":"Dong Wang, Xiaoyang Tan","author_ids":"1726751, 2248421","abstract":"Many distance learning algorithms have been developed in recent years. However, few of them consider the problem when the class labels of training data are noisy, and this may lead to serious performance deterioration. In this paper, we present a robust distance learning method in the presence of label noise, by extending a previous non-parametric discrimina-tive distance learning algorithm, i.e., Neighbourhood Components Analysis (NCA). Particularly, we analyze the effect of label noise on the derivative of likelihood with respect to the transformation matrix, and propose to model the conditional probability of the true label of each point so as to reduce that effect. The model is then optimized within the EM framework, with additional regularization used to avoid over-fitting. Our experiments on several UCI datasets and a real dataset with unknown noise patterns show that the proposed RNCA is more tolerant to class label noise compared to the original NCA method.","cites":"3","conferencePercentile":"49.43181818"},{"venue":"AAAI","id":"2b2805a082bc63793213108a5eb46e723e6bafad","venue_1":"AAAI","year":"2013","title":"Crowdsourcing for Deployable Intelligent Systems","authors":"Walter S. Lasecki","author_ids":"2598433","abstract":"My work aims to create a scaffold for deployable intelligent systems using crowdsourcing. Current approaches in artificial intelligence (AI) typically focus on solving a narrow subset of problems in a given space-for example: automatic speech recognition as part of a conversational assistant, machine vision as part of a question answering service for blind people, or planning as part of a home assistive robot. This approach is necessary to scope the solution, but often results in a large number of systems that are rarely deployed in real-world setting, but instead operate in toy domains, or in situations where other parts of the problem are assumed to be solved. The framework I have developed aims to use the crowd to help in two ways: (i) make it possible to use human intelligence to power parts of a system that automated approaches cannot or do not yet handle, and (ii) provide a means of enabling more effective deployable systems by people to provide reliable training data on-demand. This summary begins with a brief review of prior work, then outlines a number of different system that I have developed to demonstrate the capabilities of this framework , and concludes with future work to be completed as part of my thesis.","cites":"1","conferencePercentile":"25.09090909"},{"venue":"AAAI","id":"8bc814c9653ef7fe248986788dd2a53375317a3a","venue_1":"AAAI","year":"2008","title":"Trace Ratio Criterion for Feature Selection","authors":"Feiping Nie, Shiming Xiang, Yangqing Jia, Changshui Zhang, Shuicheng Yan","author_ids":"1688370, 1683738, 2717320, 1700883, 1698982","abstract":"Fisher score and Laplacian score are two popular feature selection algorithms, both of which belong to the general graph-based feature selection framework. In this framework, a feature subset is selected based on the corresponding score (subset-level score), which is calculated in a trace ratio form. Since the number of all possible feature subsets is very huge, it is often prohibitively expensive in computational cost to search in a brute force manner for the feature subset with the maximum subset-level score. Instead of calculating the scores of all the feature subsets, traditional methods calculate the score for each feature, and then select the leading features based on the rank of these feature-level scores. However, selecting the feature subset based on the feature-level score cannot guarantee the optimum of the subset-level score. In this paper, we directly optimize the subset-level score, and propose a novel algorithm to efficiently find the global optimal feature subset such that the subset-level score is maximized. Extensive experiments demonstrate the effectiveness of our proposed algorithm in comparison with the traditional methods for feature selection.","cites":"56","conferencePercentile":"94.46202532"},{"venue":"AAAI","id":"526b707ea85c98b0ab5a67a0c803165be19b824a","venue_1":"AAAI","year":"2011","title":"Goal Recognition with Markov Logic Networks for Player-Adaptive Games","authors":"Eunyoung Ha, Jonathan P. Rowe, Bradford W. Mott, James C. Lester","author_ids":"3048392, 1691423, 1735241, 1717955","abstract":"Goal recognition in digital games involves inferring players' goals from observed sequences of low-level player actions. Goal recognition models support player-adaptive digital games, which dynamically augment game events in response to player choices for a range of applications, including entertainment, training, and education. However, digital games pose significant challenges for goal recognition, such as exploratory actions and ill-defined goals. This paper presents a goal recognition framework based on Markov logic networks (MLNs). The model's parameters are directly learned from a corpus that was collected from player interactions with a non-linear educational game. An empirical evaluation demonstrates that the MLN goal recognition framework accurately predicts players' goals in a game environment with exploratory actions and ill-defined goals.","cites":"21","conferencePercentile":"88.65979381"},{"venue":"AAAI","id":"800b53592a62718ae30026858215755b558baab5","venue_1":"AAAI","year":"2006","title":"Probabilistic Goal Recognition in Interactive Narrative Environments","authors":"Bradford W. Mott, Sunyoung Lee, James C. Lester","author_ids":"1735241, 1684274, 1717955","abstract":"Recent years have witnessed a growing interest in interactive narrative-centered virtual environments for education, training, and entertainment. Narrative environments dynamically craft engaging story-based experiences for users, who are themselves active participants in unfolding stories. A key challenge posed by interactive narrative is recognizing users' goals so that narrative planners can dynamically orchestrate plot elements and character actions to create rich, customized stories. In this paper we present an inductive approach to predicting users' goals by learning probabilistic goal recognition models. This approach has been evaluated in a narrative environment for the domain of microbiology in which the user plays the role of a medical detective solving a science mystery. An empirical evaluation of goal recognition based on n-gram models and Bayesian networks suggests that the models offer significant predictive power.","cites":"32","conferencePercentile":"80.40345821"},{"venue":"AAAI","id":"a9164ba2edc98062076ed624acb26fccc63c3dce","venue_1":"AAAI","year":"2015","title":"Content-Based Collaborative Filtering for News Topic Recommendation","authors":"Zhongqi Lu, Zhicheng Dou, Jianxun Lian, Xing Xie, Qiang Yang","author_ids":"1693122, 7405268, 2813328, 1687677, 1733090","abstract":"News recommendation has become a big attraction with which major Web search portals retain their users. Two effective approaches are Content-based Filtering and Collabo-rative Filtering, each serving a specific recommendation scenario. The Content-based Filtering approaches inspect rich contexts of the recommended items, while the Collaborative Filtering approaches predict the interests of long-tail users by collaboratively learning from interests of related users. We have observed empirically that, for the problem of news topic displaying, both the rich context of news topics and the long-tail users exist. Therefore, in this paper, we propose a Content-based Collaborative Filtering approach (CCF) to bring both Content-based Filtering and Collaborative Filtering approaches together. We found that combining the two is not an easy task, but the benefits of CCF are impressive. On one hand, CCF makes recommendations based on the rich contexts of the news. On the other hand, CCF collaboratively analyzes the scarce feedbacks from the long-tail users. We tailored this CCF approach for the news topic displaying on the Bing front page and demonstrated great gains in attracting users. In the experiments and analyses part of this paper, we discuss the performance gains and insights in news topic recommendation in Bing.","cites":"7","conferencePercentile":"88.11023622"},{"venue":"AAAI","id":"1a01c38c06addad8cbfda0b1160de5bc4e6979f7","venue_1":"AAAI","year":"2013","title":"Localizing Web Videos from Heterogeneous Images","authors":"Xianming Liu, Yue Gao, Rongrong Ji, Shiyu Chang, Thomas S. Huang","author_ids":"8659574, 1744619, 1725599, 3307026, 1739208","abstract":"While geo-localization of web images has been widely studied, limited effort is devoted to that of web videos. Nevertheless, an accurate location inference approach specified on web videos is of fundamental importance, as it's occupying increasing proportions in web corpus. The key challenge comes from the lack of sufficient labels for model training. In this paper, we tackle this problem from a novel perspective, by \" transferring \" the large-scale web images with geographical tags to web videos, to make a carefully designed associations between visual content similarities. A group of experiments are conducted on a collected web image and video data set, where superior performance gains are reported over several alternatives.","cites":"1","conferencePercentile":"25.09090909"},{"venue":"AAAI","id":"94c8eb88e6716583439c60153d0f886aa33b6f48","venue_1":"AAAI","year":"2006","title":"Responsive Information Architect: Enabling Context-Sensitive Information Seeking","authors":"Michelle X. Zhou, Keith Houck, Shimei Pan, James Shaw, Vikram Aggarwal, Zhen Wen","author_ids":"1705742, 7645937, 2728986, 2320417, 3070134, 1735018","abstract":"Information seeking is an important but often difficult task especially when involving large and complex data sets. We hypothesize that a context-sensitive interaction paradigm can greatly assist users in their information seeking. Such a paradigm allows a system to both understand user data requests and present the requested information in context. Driven by this hypothesis, we have developed a suite of intelligent user interaction technologies and integrated them in a full-fledged, context-sensitive information system. In this paper, we review two sets of key technologies: context-sensitive multimodal input interpretation and automated multimedia output generation. We also share our evaluation results, which indicate that our approaches are capable of supporting context-sensitive information seeking for practical applications.","cites":"0","conferencePercentile":"5.763688761"},{"venue":"AAAI","id":"a122ed55b02c8753ccf4da86e64159604c2adce4","venue_1":"AAAI","year":"2016","title":"Knowledge Transfer with Interactive Learning of Semantic Relationships","authors":"Jonghyun Choi, Sung Ju Hwang, Leonid Sigal, Larry S. Davis","author_ids":"3826759, 2669230, 2956921, 1693428","abstract":"We propose a novel learning framework for object categoriza-tion with interactive semantic feedback. In this framework, a discriminative categorization model improves through human-guided iterative semantic feedbacks. Specifically, the model identifies the most helpful relational semantic queries to discriminatively refine the model. The user feedback on whether the relationship is semantically valid or not is incorporated back into the model, in the form of regularization, and the process iterates. We validate the proposed model in a few-shot multi-class classification scenario, where we measure classification performance on a set of 'target' classes, with few training instances, by leveraging and transferring knowledge from 'anchor' classes, that contain larger set of labeled instances.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"607fed9ee97708f07534816e8a9a70794dda7abf","venue_1":"AAAI","year":"1994","title":"Using Abstraction and Nondeterminism to Plan Reaction Loops","authors":"David J. Musliner","author_ids":"2871109","abstract":"By looping over a set of behaviors, reactive systems use repetition and feedback to deal with errors and environmental uncertainty. Their robust, fault-tolerant performance makes reactive systems desirable for executing plans. However, most planning systems cannot reason about the loops that characterize reactive systems. In this paper, we show how the structured application of abstraction and nondeterminism can map complex planning problems requiring loop plans into a simpler representation amenable to standard planning technologies. In the process, we illustrate key recipes for automatically building predictable reactive systems that are guaranteed to achieve their goals.","cites":"6","conferencePercentile":"33.92070485"},{"venue":"AAAI","id":"0deb2916518cd63dc591f9adeeebddeba87d994b","venue_1":"AAAI","year":"2005","title":"Modeling Form for On-line Following of Musical Performances","authors":"Bryan Pardo, William P. Birmingham","author_ids":"1744936, 2480427","abstract":"Automated musical accompaniment of human performers often requires an agent be able to follow a musical score with similar facility to that of a human performer. Systems described in the literature represent musical scores in a way that assumes no large-scale structural variation of the piece during performance. If the performer deviates from the expected path by skipping or repeating a section, the system may become lost. We describe a way to automatically generate a Markov model from a written score that models the score form, and an on-line algorithm to align a performance to a score. The resulting system can follow performances that take alternate paths through the score without losing its place. We compare the performance of our system to that of sequence-based score followers on a melodic corpus of 98 Jazz melodies. Results show that explicitly representing the branching structure of a score significantly improves score following when the branch a performer may take is unknown beforehand.","cites":"24","conferencePercentile":"73.6013986"},{"venue":"AAAI","id":"8bb34ce7f2fa2cdd69265f0c0fe1041190ac12b3","venue_1":"AAAI","year":"2016","title":"Labeling the Features Not the Samples: Efficient Video Classification with Minimal Supervision","authors":"Marius Leordeanu, Alexandra Radu, Shumeet Baluja, Rahul Sukthankar","author_ids":"1749627, 2973720, 1767244, 1694199","abstract":"Feature selection is essential for effective visual recognition. We propose an efficient joint classifier learning and feature selection method that discovers sparse, compact representations of input features from a vast sea of candidates, with an almost unsupervised formulation. Our method requires only the following knowledge , which we call the feature sign—whether or not a particular feature has on average stronger values over positive samples than over negatives. We show how this can be estimated using as few as a single labeled training sample per class. Then, using these feature signs, we extend an initial supervised learning problem into an (almost) unsupervised clustering formulation that can incorporate new data without requiring ground truth labels. Our method works both as a feature selection mechanism and as a fully competitive classifier. It has important properties, low computational cost and excellent accuracy, especially in difficult cases of very limited training data. We experiment on large-scale recognition in video and show superior speed and performance to established feature selection approaches such as AdaBoost, Lasso, greedy forward-backward selection , and powerful classifiers such as SVM.","cites":"1","conferencePercentile":"40.70945946"},{"venue":"AAAI","id":"b4fd53d5c71a4ce653e2f79e029b287584bab4d3","venue_1":"AAAI","year":"2016","title":"Stochastic Optimization for Kernel PCA","authors":"Lijun Zhang, Tianbao Yang, Jinfeng Yi, Rong Jin, Zhi-Hua Zhou","author_ids":"1707675, 1704606, 2882166, 1718400, 1692625","abstract":"Kernel Principal Component Analysis (PCA) is a popular extension of PCA which is able to find nonlinear patterns from data. However, the application of kernel PCA to large-scale problems remains a big challenge, due to its quadratic space complexity and cubic time complexity in the number of examples. To address this limitation, we utilize techniques from stochastic optimization to solve kernel PCA with linear space and time complexities per iteration. Specifically, we formulate it as a stochastic composite optimization problem, where a nuclear norm regularizer is introduced to promote low-rankness, and then develop a simple algorithm based on stochastic proximal gradient descent. During the optimization process, the proposed algorithm always maintains a low-rank factorization of iterates that can be conveniently held in memory. Compared to previous iterative approaches, a remarkable property of our algorithm is that it is equipped with an explicit rate of convergence. Theoretical analysis shows that the solution of our algorithm converges to the optimal one at an O(1/T) rate, where T is the number of iterations.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"d37c74fd3a41ce7000d877efb6989bad513a11dd","venue_1":"AAAI","year":"2016","title":"Learning Expected Hitting Time Distance","authors":"De-Chuan Zhan, Peng Hu, Zui Chu, Zhi-Hua Zhou","author_ids":"1721819, 2247815, 3378687, 1692625","abstract":"Most distance metric learning (DML) approaches focus on learning a Mahalanobis metric for measuring distances between examples. However, for particular feature representations , e.g., histogram features like BOW and SPM, Mahalanobis metric could not model the correlations between these features well. In this work, we define a non-Mahalanobis distance for histogram features, via Expected Hitting Time (EHT) of Markov Chain, which implicitly considers the high-order feature relationships between different histogram features. The EHT based distance is parameter-ized by transition probabilities of Markov Chain, we consequently propose a novel type of distance learning approach (LED, Learning Expected hitting time Distance) to learn appropriate transition probabilities for EHT based distance. We validate the effectiveness of LED on a series of real-world datasets. Moreover, experiments show that the learned transition probabilities are with good comprehensibility.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"c5087881ee41f1c92063a5595371df6049e04420","venue_1":"AAAI","year":"2016","title":"Column Sampling Based Discrete Supervised Hashing","authors":"Wang-Cheng Kang, Wu-Jun Li, Zhi-Hua Zhou","author_ids":"2741053, 7878359, 1692625","abstract":"By leveraging semantic (label) information, supervised hashing has demonstrated better accuracy than unsuper-vised hashing in many real applications. Because the hashing-code learning problem is essentially a discrete optimization problem which is hard to solve, most existing supervised hashing methods try to solve a relaxed continuous optimization problem by dropping the discrete constraints. However, these methods typically suffer from poor performance due to the errors caused by the relaxation. Some other methods try to directly solve the discrete optimization problem. However, they are typically time-consuming and unscalable. In this paper, we propose a novel method, called column sampling based discrete supervised hashing (COSDISH), to directly learn the discrete hashing code from semantic information. COSDISH is an iterative method, in each iteration of which several columns are sampled from the semantic similarity matrix and then the hashing code is decomposed into two parts which can be alternately optimized in a discrete way. Theoretical analysis shows that the learning (optimization) algorithm of COSDISH has a constant-approximation bound in each step of the alternating optimization procedure. Empirical results on datasets with semantic labels illustrate that COSDISH can outperform the state-of-the-art methods in real applications like image retrieval.","cites":"4","conferencePercentile":"79.72972973"},{"venue":"AAAI","id":"2b6fdf7dacaa9dbf5a0807050ef50696ab9f638b","venue_1":"AAAI","year":"2016","title":"Learning to Generate Posters of Scientific Papers","authors":"Yuting Qiang, Yanwei Fu, Yanwen Guo, Zhi-Hua Zhou, Leonid Sigal","author_ids":"3387134, 2356937, 1720424, 1692625, 2956921","abstract":"Researchers summarize and represent their paper content with scientific posters, which efficiently convey their ideas. Generating a good scientific poster, however , is challenging for novel researchers, since it needs to be readable, informative, and aesthetic. This paper for the first time studies the challenging problem of learning to generate posters from scientific papers. To this end, a data-driven framework is proposed by utilizing probabilistic graphical models. Specifically, given contents to display, the key elements of a good poster, including panel layout and attributes of each panel, are learned and inferred from data. Then composition of graphical elements within each panel is synthesized. To validate our framework, we contribute a Poster-Paper dataset with exhaustively labelled attributes of poster panels. Qualitative and quantitative results indicate the effectiveness of our framework.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"6eed923d43026b437e26b092a6e35bf52e4a9264","venue_1":"AAAI","year":"2016","title":"Towards Safe Semi-Supervised Learning for Multivariate Performance Measures","authors":"Yu-Feng Li, James T. Kwok, Zhi-Hua Zhou","author_ids":"2634254, 1776349, 1692625","abstract":"Semi-supervised learning (SSL) is an important research problem in machine learning. While it is usually expected that the use of unlabeled data can improve performance, in many cases SSL is outperformed by supervised learning using only labeled data. To this end, the construction of a performance-safe SSL method has become a key issue of SSL study. To alleviate this problem, we propose in this paper the UMVP (safe semi-sUpervised learning for Multi-Variate Performance measure) method, because of the need of various performance measures in practical tasks. The proposed method integrates multiple semi-supervised learners, and maximizes the worst-case performance gain to derive the final prediction. The overall problem is formulated as a maximin optimization. In oder to solve the resultant difficult maximin optimization, this paper shows that when the performance measure is the Top-k Precision, F β score or AUC, a minimax convex relaxation of the maximin optimization can be solved efficiently. Experimental results show that the proposed method can effectively improve the safeness of SSL under multiple multivariate performance measures.","cites":"2","conferencePercentile":"61.31756757"},{"venue":"AAAI","id":"73c603bc21205144105a01055a74f8082a14fc8d","venue_1":"AAAI","year":"2015","title":"Structured Sparsity with Group-Graph Regularization","authors":"Xin-Yu Dai, Jianbing Zhang, Shujian Huang, Jiajun Chen, Zhi-Hua Zhou","author_ids":"3035069, 2270690, 2046010, 1838162, 1692625","abstract":"In many learning tasks with structural properties, structural sparsity methods help induce sparse models, usually leading to better interpretability and higher generalization performance. One popular approach is to use group sparsity regularization that enforces sparsity on the clustered groups of features, while another popular approach is to adopt graph sparsity regularization that considers sparsity on the link structure of graph embedded features. Both the group and graph structural properties co-exist in many applications. However, group sparsity and graph sparsity have not been considered simultaneously yet. In this paper, we propose a g 2-regularization that takes group and graph sparsity into joint consideration, and present an effective approach for its optimization. Experiments on both synthetic and real data show that, enforcing group-graph sparsity lead to better performance than using group sparsity or graph sparsity only.","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"3ac6a5592872289f87821043491ab7d1100921e2","venue_1":"AAAI","year":"2015","title":"Online Bandit Learning for a Special Class of Non-Convex Losses","authors":"Lijun Zhang, Tianbao Yang, Rong Jin, Zhi-Hua Zhou","author_ids":"1707675, 1704606, 1718400, 1692625","abstract":"In online bandit learning, the learner aims to minimize a sequence of losses, while only observing the value of each loss at a single point. Although various algorithms and theories have been developed for online bandit learning, most of them are limited to convex losses. In this paper, we investigate the problem of online bandit learning with non-convex losses, and develop an efficient algorithm with formal theoretical guarantees. To be specific, we consider a class of losses which is a composition of a non-increasing scalar function and a linear function. This setting models a wide range of supervised learning applications such as online classification with a non-convex loss. Theoretical analysis shows that our algorithm achieves an O(poly(d)T 2/3) regret bound when the variation of the loss function is small. To the best of our knowledge, this is the first work in online bandit learning that does not rely on convexity.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"61c83d4f2810a90439354b7d252febfbf1954fed","venue_1":"AAAI","year":"2015","title":"Pareto Ensemble Pruning","authors":"Chao Qian, Yang Yu, Zhi-Hua Zhou","author_ids":"2280981, 3839568, 1692625","abstract":"Ensemble learning is among the state-of-the-art learning techniques, which trains and combines many base learners. Ensemble pruning removes some of the base learners of an ensemble, and has been shown to be able to further improve the generalization performance. However, the two goals of ensemble pruning, i.e., maximizing the generalization performance and minimizing the number of base learners, can conflict when being pushed to the limit. Most previous ensemble pruning approaches solve objectives that mix the two goals. In this paper, motivated by the recent theoretical advance of evolutionary optimization, we investigate solving the two goals explicitly in a bi-objective formulation and propose the PEP (Pareto Ensemble Pruning) approach. We disclose that PEP does not only achieve significantly better performance than the state-of-the-art approaches, and also gains theoretical support.","cites":"9","conferencePercentile":"91.96850394"},{"venue":"AAAI","id":"4642916ee5c2697356d02afdb3cd13b30b8051ba","venue_1":"AAAI","year":"2010","title":"Multi-Label Learning with Weak Label","authors":"Yu-Yin Sun, Yin Zhang, Zhi-Hua Zhou","author_ids":"2354749, 1685889, 1692625","abstract":"Multi-label learning deals with data associated with multiple labels simultaneously. Previous work on multi-label learning assumes that for each instance, the \" full \" label set associated with each training instance is given by users. In many applications , however, to get the full label set for each instance is difficult and only a \" partial \" set of labels is available. In such cases, the appearance of a label means that the instance is associated with this label, while the absence of a label does not imply that this label is not proper for the instance. We call this kind of problem \" weak label \" problem. In this paper, we propose the WELL (WEak Label Learning) method to solve the weak label problem. We consider that the classification boundary for each label should go across low density regions, and that each label generally has much smaller number of positive examples than negative examples. The objective is formulated as a convex optimization problem which can be solved efficiently. Moreover, we exploit the correlation between labels by assuming that there is a group of low-rank base similarities, and the appropriate similarities between instances for different labels can be derived from these base similarities. Experiments validate the performance of WELL.","cites":"31","conferencePercentile":"85.83617747"},{"venue":"AAAI","id":"6968371876a87f9a8b97c99e0ec1da9fab39f7ee","venue_1":"AAAI","year":"2010","title":"Multi-Instance Dimensionality Reduction","authors":"Yu-Yin Sun, Michael K. Ng, Zhi-Hua Zhou","author_ids":"2354749, 1678715, 1692625","abstract":"Multi-instance learning deals with problems that treat bags of instances as training examples. In single-instance learning problems, dimensionality reduction is an essential step for high-dimensional data analysis and has been studied for years. The curse of dimensionality also exists in multi-instance learning tasks, yet this difficult task has not been studied before. Direct application of existing single-instance dimensionality reduction objectives to multi-instance learning tasks may not work well since it ignores the characteristic of multi-instance learning that the labels of bags are known while the labels of instances are unknown. In this paper, we propose an effective model and develop an efficient algorithm to solve the multi-instance dimensionality reduction problem. We formulate the objective as an optimization problem by considering orthonormality and sparsity constraints in the projection matrix for dimensionality reduction, and then solve it by the gradient descent along the tangent space of the orthonormal matrices. We also propose an approximation for improving the efficiency. Experimental results validate the effectiveness of the proposed method.","cites":"4","conferencePercentile":"27.1331058"},{"venue":"AAAI","id":"3bd7638671c38eeb5fae2ba2ca7a66c8221f3d74","venue_1":"AAAI","year":"2011","title":"Improving Semi-Supervised Support Vector Machines Through Unlabeled Instances Selection","authors":"Yu-Feng Li, Zhi-Hua Zhou","author_ids":"2634254, 1692625","abstract":"Semi-supervised support vector machines (S3VMs) are a kind of popular approaches which try to improve learning performance by exploiting unlabeled data. Though S3VMs have been found helpful in many situations, they may degenerate performance and the resultant generalization ability may be even worse than using the labeled data only. In this paper, we try to reduce the chance of performance degenera-tion of S3VMs. Our basic idea is that, rather than exploiting all unlabeled data, the unlabeled instances should be selected such that only the ones which are very likely to be helpful are exploited, while some highly risky unlabeled instances are avoided. We propose the S3VM-us method by using hierarchical clustering to select the unlabeled instances. Experiments on a broad range of data sets over eighty-eight different settings show that the chance of performance degeneration of S3VM-us is much smaller than that of existing S3VMs.","cites":"7","conferencePercentile":"55.67010309"},{"venue":"AAAI","id":"c4a8f82452d5c577d8fb0fe2b0b0d0b07de61727","venue_1":"AAAI","year":"2011","title":"Localized K-Flats","authors":"Yong Wang, Yuan Jiang, Yi Wu, Zhi-Hua Zhou","author_ids":"7134629, 5465260, 2225331, 1692625","abstract":"K-flats is a model-based linear manifold clustering algorithm which has been successfully applied in many real-world scenarios. Though some previous works have shown that K-flats doesn't always provide good performance, little effort has been devoted to analyze its inherent deficiency. In this paper, we address this challenge by showing that the deteriorative performance of K-flats can be attributed to the usual reconstruction error measure and the infinitely extending representations of linear models. Then we propose Localized K-flats algorithm (LKF), which introduces localized representations of linear models and a new distortion measure, to remove confusion among different clusters. Experiments on both synthetic and real-world data sets demonstrate the efficiency of the proposed algorithm. Moreover , preliminary experiments show that LKF has the potential to group manifolds with nonlinear structure.","cites":"1","conferencePercentile":"16.15120275"},{"venue":"AAAI","id":"6bda3697c2e1342768d189fd96f35d0c3945ddc3","venue_1":"AAAI","year":"2012","title":"Multi-Label Learning by Exploiting Label Correlations Locally","authors":"Sheng-Jun Huang, Zhi-Hua Zhou","author_ids":"7649626, 1692625","abstract":"It is well known that exploiting label correlations is important for multi-label learning. Existing approaches typically exploit label correlations globally, by assuming that the label correlations are shared by all the instances. In real-world tasks, however, different instances may share different label correlations, and few correlations are globally applicable. In this paper, we propose the ML-LOC approach which allows label correlations to be exploited locally. To encode the local influence of label correlations, we derive a LOC code to enhance the feature representation of each instance. The global discrimination fitting and local correlation sensitivity are incorporated into a unified framework, and an alternating solution is developed for the optimization. Experimental results on a number of image, text and gene data sets validate the effectiveness of our approach.","cites":"27","conferencePercentile":"93.29268293"},{"venue":"AAAI","id":"2903fa577596989c1b5e032a87ca35f50dce5b0c","venue_1":"AAAI","year":"2012","title":"Towards Discovering What Patterns Trigger What Labels","authors":"Yu-Feng Li, Juhua Hu, Yuan Jiang, Zhi-Hua Zhou","author_ids":"2634254, 3120422, 5465260, 1692625","abstract":"In many real applications, especially those involving data objects with complicated semantics, it is generally desirable to discover the relation between patterns in the input space and labels corresponding to different semantics in the output space. This task becomes feasible with MIML (Multi-Instance Multi-Label learning), a recently developed learning framework , where each data object is represented by multiple instances and is allowed to be associated with multiple labels simultaneously. In this paper, we propose KISAR, an MIM-L algorithm that is able to discover what instances trigger what labels. By considering the fact that highly relevant labels usually share some patterns, we develop a convex optimization formulation and provide an alternating optimization solution. Experiments show that KISAR is able to discover reasonable relations between input patterns and output labels , and achieves performances that are highly competitive with many state-of-the-art MIML algorithms.","cites":"13","conferencePercentile":"77.28658537"},{"venue":"AAAI","id":"608058898434817be574407543ba9a51905b90e2","venue_1":"AAAI","year":"2012","title":"Rule Ensemble Learning Using Hierarchical Kernels in Structured Output Spaces","authors":"Naveen Nair, Amrita Saha, Ganesh Ramakrishnan, Shonali Krishnaswamy","author_ids":"2711899, 2909575, 1697088, 1781256","abstract":"The goal in Rule Ensemble Learning (REL) is simultaneous discovery of a small set of simple rules and their optimal weights that lead to good generalization. Rules are assumed to be conjunctions of basic propositions concerning the values taken by the input features. It has been shown that rule ensembles for classification can be learnt optimally and efficiently using hierarchical kernel learning approaches that explore the exponentially large space of conjunctions by exploiting its hierarchical structure. The regularizer employed penalizes large features and thereby selects a small set of short features. In this paper, we generalize the rule ensemble learning using hierarchical kernels (RELHKL) framework to multi class structured output spaces. We build on the StructSVM model for sequence prediction problems and employ a ρ-norm hierarchical regularizer for observation features and a conventional 2-norm reg-ularizer for state transition features. The exponentially large feature space is searched using an active set algorithm and the exponentially large set of constraints are handled using a cutting plane algorithm. The approach can be easily extended to other structured output problems. We perform experiments on activity recognition datasets which are prone to noise, sparseness and skew-ness. We demonstrate that our approach outperforms other approaches.","cites":"6","conferencePercentile":"51.82926829"},{"venue":"AAAI","id":"0fdc1c3fc5429037b49e12fd759a4520ac6b0a17","venue_1":"AAAI","year":"2013","title":"Multi-Label Learning with PRO Loss","authors":"Miao Xu, Yu-Feng Li, Zhi-Hua Zhou","author_ids":"2964618, 2634254, 1692625","abstract":"Multi-label learning methods assign multiple labels to one object. In practice, in addition to differentiating relevant labels from irrelevant ones, it is often desired to rank the relevant labels for an object, whereas the rankings of irrelevant labels are not important. Such a requirement, however, cannot be met because most existing methods were designed to optimize existing criteria, yet there is no criterion which encodes the aforementioned requirement. In this paper, we present a new criterion, PRO LOSS, concerning the prediction on all labels as well as the rankings of only relevant labels. We then propose ProSVM which optimizes PRO LOSS efficiently using alternating direction method of multipliers. We further improve its efficiency with an upper approximation that reduces the number of constraints from O(T 2) to O(T), where T is the number of labels. Experiments show that our proposals are not only superior on PRO LOSS, but also highly competitive on existing evaluation criteria.","cites":"6","conferencePercentile":"68.90909091"},{"venue":"AAAI","id":"b886fa080cc7ba0b90f808c2818ea1d009229a5b","venue_1":"AAAI","year":"2007","title":"Continuous State POMDPs for Object Manipulation Tasks","authors":"Emma Brunskill","author_ids":"2563117","abstract":"My research focus is on using continuous state partially observable Markov decision processes (POMDPs) to perform object manipulation tasks using a robotic arm. During object manipulation, object dynamics can be extremely complex, non-linear and challenging to specify. To avoid modeling the full complexity of possible dynamics , I instead use a model which switches between a discrete number of simple dynamics models. By learning these models and extending Porta's continuous state POMDP framework (Porta et al. 2006) to incorporate this switching dynamics model, we hope to handle tasks that involve absolute and relative dynamics within a single framework. This dynamics model may be applicable not only to object manipulation tasks, but also to a number of other problems, such as robot navigation. By using an explicit model of uncertainty, I hope to create solutions to object manipulation tasks that more robustly handle the noisy sensory information received by physical robots.","cites":"0","conferencePercentile":"5.489614243"},{"venue":"AAAI","id":"2dc382065cc0230d6446d66936a49addac337f36","venue_1":"AAAI","year":"2010","title":"PUMA: Planning Under Uncertainty with Macro-Actions","authors":"Ruijie He, Emma Brunskill, Nicholas Roy","author_ids":"1931250, 2563117, 1789920","abstract":"Planning in large, partially observable domains is challenging , especially when a long-horizon lookahead is necessary to obtain a good policy. Traditional POMDP planners that plan a different potential action for each future observation can be prohibitively expensive when planning many steps ahead. An efficient solution for planning far into the future in fully observable domains is to use temporally-extended sequences of actions, or \" macro-actions. \" In this paper, we present a POMDP algorithm for planning under uncertainty with macro-actions (PUMA) that automatically constructs and evaluates open-loop macro-actions within forward-search planning, where the planner branches on observations only at the end of each macro-action. Additionally, we show how to incrementally refine the plan over time, resulting in an anytime algorithm that provably converges to an ǫ-optimal policy. In experiments on several large POMDP problems which require a long horizon lookahead, PUMA outperforms existing state-of-the art solvers. Most partially observable Markov decision process (POMDP) planners select actions conditioned on the prior observation at each timestep: we refer to such planners as fully-conditional. When good performance relies on considering different possible observations far into the future, both online and offline fully-conditional planners typically struggle. An extreme alternative is unconditional (or \" open-loop \") planning where a sequence of actions is fixed and does not depend on the observations that will be received during execution. While open-loop planning can be extremely fast and perform surprisingly well in certain domains 1 , acting well in most real-world domains requires plans where at least some action choices are conditional on the obtained observations. This paper focuses on the significant subset of POMDP domains, including scientific exploration, target surveillance , and chronic care management, where it is possible to act well by planning using conditional sequences of open-loop, fixed-length action chains, or \" macro-actions. \" We call this approach semi-conditional planning, in that actions are chosen based on the received observations only at the end of each macro-action. 1 For a discussion of using open-loop planning for multi-robot tag for open-loop planning see Yu et al. (2005). We demonstrate that for certain domains, planning with macro-actions can offer performance close to fully-conditional planning at a dramatically reduced computational cost. In comparison to prior macro-action work, where a domain expert often hand-coded a good set of macro-actions for each problem, we present a technique for automatically constructing finite-length open-loop macro-actions. Our approach uses sub-goal states based …","cites":"32","conferencePercentile":"87.37201365"},{"venue":"AAAI","id":"1b3d8a73cc4cf7c99c04c9234b80fec6c135ce0a","venue_1":"AAAI","year":"2015","title":"Concurrent PAC RL","authors":"Zhaohan Guo, Emma Brunskill","author_ids":"2666751, 2563117","abstract":"In many real-world situations a decision maker may make decisions across many separate reinforcement learning tasks in parallel, yet there has been very little work on concurrent RL. Building on the efficient exploration RL literature, we introduce two new concurrent RL algorithms and bound their sample complexity. We show that under some mild conditions, both when the agent is known to be acting in many copies of the same MDP, and when they are not the same but are taken from a finite set, we can gain linear improvements in the sample complexity over not sharing information. This is quite exciting as a linear speedup is the most one might hope to gain. Our preliminary experiments confirm this result and show empirical benefits. The ability to share information across tasks to speed learning is a critical aspect of intelligence, and an important goal for autonomous agents. These tasks may themselves involve a sequence of stochastic decisions: consider an online store interacting with many potential customers, or a doctor treating many diabetes patients, or tutoring software teaching algebra to a classroom of students. Here each task (customer relationship management, patient treatment, student tutoring) can be modeled as a reinforcement learning (RL) problem, with one decision maker performing many tasks in parallel. In such cases there is an opportunity to improve outcomes for all tasks (customers, patients, students) by lever-aging shared information across the tasks. Interestingly, despite these compelling applications, there has been almost no work done on concurrent reinforcement learning. There has been a number of papers (e.g. (Evgeniou and Pontil 2004; Xue et al. 2007)) on supervised concurrent learning (referred to as multi-task learning). In this context, multiple supervised learning tasks, such as classification, are run in parallel, and information from each is used to speed learning. When the tasks themselves involve sequential decision making, like reinforcement learning, prior work has focused on sharing information serially across consecutive related tasks, such as in transfer learning (e.g. (Taylor and Stone 2009; Lazaric and Restelli 2011)) or online learning across a set of tasks (Brunskill and Li 2013). Note that multi-agent literature considers multiple agents acting in a single environment, whereas we consider the different problem of one agent / decision maker simultaneously acting in multiple environments. The critical distinction here is that the actions and rewards taken in one task do not directly impact the actions and rewards taken in any …","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"516b1eda00a955043fbcf037f128b117c9d9b10c","venue_1":"AAAI","year":"2014","title":"Learning with Augmented Class by Exploiting Unlabeled Data","authors":"Qing Da, Yang Yu, Zhi-Hua Zhou","author_ids":"2825549, 3839568, 1692625","abstract":"In many real-world applications of learning, the environment is open and changes gradually, which requires the learning system to have the ability of detecting and adapting to the changes. Class-incremental learning (C-IL) is an important and practical problem where data from unseen augmented classes are fed, but has not been studied well in the past. In C-IL, the system should beware of predicting instances from augmented classes as a seen class, and thus faces the challenge that no such instances were observed during training stage. In this paper, we tackle the challenge by using unlabeled data, which can be cheaply collected in many real-world applications. We propose the LACU framework as well as the LACU-SVM approach to learn the concept of seen classes while incorporating the structure presented in the unlabeled data, so that the misclassification risks among the seen classes as well as between the augmented and the seen classes are minimized simultaneously. Experiments on diverse datasets show the effectiveness of the proposed approach.","cites":"8","conferencePercentile":"81.25"},{"venue":"AAAI","id":"71af7fda055bd4fb23eefb8be78331d9c9f4da91","venue_1":"AAAI","year":"2014","title":"Multi-Instance Learning with Distribution Change","authors":"Wei-Jia Zhang, Zhi-Hua Zhou","author_ids":"8031207, 1692625","abstract":"Multi-instance learning deals with tasks where each example is a bag of instances, and the bag labels of training data are known whereas instance labels are unknown. Most previous studies on multi-instance learning assumed that the training and testing data are from the same distribution; however, this assumption is often violated in real tasks. In this paper, we present possibly the first study on multi-instance learning with distribution change. We propose the MICS approach by considering both bag-level and instance-level distribution change. Experiments show that MICS is almost always significantly better than many state-of-the-art multi-instance learning algorithms when distribution change occurs; and even when there is no distribution change, their performances are still comparable.","cites":"0","conferencePercentile":"9.431818182"},{"venue":"AAAI","id":"59bae5e5e8ef08d34a876dd876c4029371bb4d5e","venue_1":"AAAI","year":"2014","title":"Labeling Complicated Objects: Multi-View Multi-Instance Multi-Label Learning","authors":"Cam-Tu Nguyen, Xiaoliang Wang, Jing Liu, Zhi-Hua Zhou","author_ids":"2012152, 1753319, 5661757, 1692625","abstract":"Multi-Instance Multi-Label (MIML) is a learning framework where an example is associated with multiple labels and represented by a set of feature vectors (multiple instances). In the formalization of MIML learning, instances come from a single source (single view). To leverage multiple information sources (multi-view), we develop a multi-view MIML framework based on hierarchical Bayesian Network, and derive an effective learning algorithm based on variational inference. The model can naturally deal with examples in which some views could be absent (partial examples). On multi-view datasets, it is shown that our method is better than other multi-view and single-view approaches particularly in the presence of partial examples. On single-view benchmarks, extensive evaluation shows that our method is highly competitive or better than other MIML approaches on labeling examples and instances. Moreover, our method can effectively handle datasets with a large number of labels.","cites":"3","conferencePercentile":"49.43181818"},{"venue":"AAAI","id":"5dacc108011a7d0d683df4b4455239b7d6734356","venue_1":"AAAI","year":"2014","title":"Partial Multi-View Clustering","authors":"Shao-Yuan Li, Yuan Jiang, Zhi-Hua Zhou","author_ids":"1792205, 5465260, 1692625","abstract":"Real data are often with multiple modalities or coming from multiple channels, while multi-view clustering provides a natural formulation for generating clusters from such data. Previous studies assumed that each example appears in all views, or at least there is one view containing all examples. In real tasks, however, it is often the case that every view suffers from the missing of some data and therefore results in many partial examples , i.e., examples with some views missing. In this paper , we present possibly the first study on partial multi-view clustering. Our proposed approach, PVC, works by establishing a latent subspace where the instances corresponding to the same example in different views are close to each other, and similar instances (belonging to different examples) in the same view should be well grouped. Experiments on two-view data demonstrate the advantages of our proposed approach.","cites":"16","conferencePercentile":"94.65909091"},{"venue":"AAAI","id":"35ae470c78a31a8c9cdef1acbe075752b45034b7","venue_1":"AAAI","year":"2008","title":"Minimizing the Spread of Contamination by Blocking Links in a Network","authors":"Masahiro Kimura, Kazumi Saito, Hiroshi Motoda","author_ids":"3213729, 1727070, 1748072","abstract":"We address the problem of minimizing the propagation of undesirable things, such as computer viruses or malicious rumors , by blocking a limited number of links in a network, a dual problem to the influence maximization problem of finding the most influential nodes in a social network for information diffusion. This minimization problem is another approach to the problem of preventing the spread of contamination by removing nodes in a network. We propose a method for efficiently finding a good approximate solution to this problem based on a naturally greedy strategy. Using large real networks, we demonstrate experimentally that the proposed method significantly outperforms conventional link-removal methods. We also show that unlike the strategy of removing nodes, blocking links between nodes with high out-degrees is not necessarily effective.","cites":"29","conferencePercentile":"87.02531646"},{"venue":"AAAI","id":"1587857476ce759c461c34ec2055f4ff830579bc","venue_1":"AAAI","year":"2010","title":"Learning to Predict Opinion Share in Social Networks","authors":"Masahiro Kimura, Kazumi Saito, Kouzou Ohara, Hiroshi Motoda","author_ids":"3213729, 1727070, 1736451, 1748072","abstract":"We address the problem of predicting the expected opinion share over a social network at a target time from the opinion diffusion data under the value-weighted voter model with multiple opinions. The value update algorithm ensures that it converges to a correct solution and the share prediction results outperform a simple linear extrapolation approximation when the available data is limited. We further show in an extreme case of complete network that the opinion with the highest value eventually takes over, and the expected share prediction problem with uniform opinion value is not well-defined and any opinion can win.","cites":"11","conferencePercentile":"54.94880546"},{"venue":"AAAI","id":"30d9b8b7706874e5caeaad6054621604696ede4d","venue_1":"AAAI","year":"2005","title":"Ready or Not, Here I Come","authors":"Magdalena D. Bugajska, William Adams, Scott Thomas, J. Gregory Trafton, Alan C. Schultz","author_ids":"2799250, 8227315, 3184108, 1720577, 1803820","abstract":"I remember all the hype, concern, and downright panic surrounding Y2K. The predictions were rampant about the limitations with our computer systems. When computers were first invented, a specific year was depicted with the last two digits, hence the year 1992 was simply noted as 92. Everyone was thrown into turmoil about the year 2000 because in the computer world, the year 1900 and the year 2000 were considered the same date. Computers would not be able to recognize the difference between dates starting with 19 and dates starting with 20. Numerous agencies were mobilized in every area of industry to combat the problem. As a global entity, computers had become the intricate workings in every feasible area from banking to healthcare to national security. Should this system fail, worldwide panic would ensue.","cites":"1","conferencePercentile":"11.01398601"},{"venue":"AAAI","id":"1f7fa1a34f818d15489ac0501a77cab36f948e9a","venue_1":"AAAI","year":"2008","title":"Discourse Topic and Gestural Form","authors":"Jacob Eisenstein, Regina Barzilay, Randall Davis","author_ids":"1752524, 4452125, 1735802","abstract":"Coverbal gesture provides a channel for the visual expression of ideas. While some gestural emblems have culturally predefined forms (e.g., \" thumbs up \"), the relationship between gesture and meaning is, in general, not conventionalized. It is natural to ask whether such gestures can be interpreted in a speaker-independent way, or whether gestural form is determined by the speaker's idiosyncratic view of the discourse topic. We address this question using an audiovisual dataset across multiple speakers and topics. Our analysis employs a hierarchical Bayesian author-topic model, in which gestural patterns are stochastically generated by a mixture of speaker-specific and topic-specific priors. These gestural patterns are characterized using automatically-extracted visual features, based on spatio-temporal interest points. This framework detects significant cross-speaker patterns in gesture that are governed by the discourse topic, suggesting that even unstructured gesticu-lation can be interpreted across speakers. In addition, the success of this approach shows that the semantic characteristics of gesture can be detected via a low-level, interest point representation.","cites":"6","conferencePercentile":"41.4556962"},{"venue":"AAAI","id":"366ea98c3d55695e57dcc7814fa84a524b85ff1f","venue_1":"AAAI","year":"2007","title":"Enabling Domain-Awareness for a Generic Natural Language Interface","authors":"Yunyao Li, Ishan Chaudhuri, Huahai Yang, Satinder P. Singh, H. V. Jagadish","author_ids":"1718694, 2605334, 1777783, 1699868, 1735239","abstract":"In this paper, we present a learning-based approach for enabling domain-awareness for a generic natural language interface. Our approach automatically acquires domain knowledge from user interactions and incorporates the knowledge learned to improve the generic system. We have embedded our approach in a generic natural language interface and evaluated the extended system against two benchmark datasets. We found that the performance of the original generic system can be substantially improved through automatic domain knowledge extraction and incorporation. We also show that the generic system with domain-awareness enabled by our approach can achieve performance similar to that of previous learning-based domain-specific systems.","cites":"2","conferencePercentile":"19.43620178"},{"venue":"AAAI","id":"aa656997c9b7379f70b2c78b3ff2f2da7a4cd913","venue_1":"AAAI","year":"2004","title":"A Robotic Wayfinding System for the Visually Impaired","authors":"Vladimir A. Kulyukin, Chaitanya Gharpure, Pradnya Sute, Nathan DeGraw, John Nicholson","author_ids":"2638449, 2644874, 2931184, 1838943, 2369556","abstract":"We present an emerging indoor assisted navigation system for the visually impaired. The core of the system is a mobile robotic base with a sensor suite mounted on it. The sensor suite consists of an RFID reader and a laser range finder. Small passive RFID sensors are manually inserted in the environment. We describe how the system was deployed in two indoor environments and evaluated by visually impaired participants in a series of pilot experiments.","cites":"11","conferencePercentile":"50.5988024"},{"venue":"AAAI","id":"5ac428ff50230b0d17351b1c510c156100f1d4ed","venue_1":"AAAI","year":"2014","title":"Qualitative Reasoning with Modelica Models","authors":"Matthew Evans Klenk, Johan de Kleer, Daniel G. Bobrow, Bill Janssen","author_ids":"2176847, 3238472, 1753394, 1784961","abstract":"Qualitative reasoning can play an important role in early stage design. Currently, engineers explore the design space using simulation models built in languages such as Modelica. To make qualitative reasoning useful to them, designs specified in their languages must be translated into a qualitative modeling language for analysis. The contribution of this paper is a sound and effective mapping between Modelica and qualitative reasoning. To achieve a sound mapping, we extend envisioning, the process of generating all relevant qualitative behaviors , to support Modelica's declarative events. For an effective mapping, we identify three classes of additional constraints that should be inferred from the Modelica representation thereby exponentially reducing the number of unrealizable trajectories. We support this contribution with examples and a case study.","cites":"1","conferencePercentile":"25.90909091"},{"venue":"AAAI","id":"20f9d9384718c3b7d94676b8bb2162baef4e3347","venue_1":"AAAI","year":"2014","title":"Deploying CommunityCommands: A Software Command Recommender System Case Study","authors":"Wei Li, Justin Matejka, Tovi Grossman, George W. Fitzmaurice","author_ids":"2121690, 2578065, 3313809, 1703735","abstract":"In 2009 we presented the idea of using collaborative filtering within a complex software application to help users learn new and relevant commands (Matejka et al. 2009). This project continued to evolve and we explored the design space of a contextual software command recommender system and completed a four-week user study (Li et al. 2011). We then expanded the scope of our project by implementing CommunityCommands, a fully functional and deployable recommender system. CommunityCommands was made available as a publically available plug-in download for Autodesk \" s flagship software application AutoCAD. During a one-year period, the recommender system was used by more than 1100 AutoCAD users. In this paper, we present our system usage data and payoff. We also provide an in-depth discussion of the challenges and design issues associated with developing and deploying the front end AutoCAD plug-in and its back end system. This includes a detailed description of the issues surrounding cold start and privacy. We also discuss how our practical system architecture was designed to leverage Autodesk \" s existing Customer Involvement Program (CIP) data to deliver in-product contextual recommendations to end-users. Our work sets important groundwork for the future development of recommender systems within the domain of end-user software learning assistance.","cites":"1","conferencePercentile":"25.90909091"},{"venue":"AAAI","id":"a85370b906b2526a2189525c28d20abf66e250aa","venue_1":"AAAI","year":"2010","title":"Modeling Dynamic Multi-Topic Discussions in Online Forums","authors":"Hao Wu, Jiajun Bu, Chun Chen, Can Wang, Guang Qiu, Lijun Zhang, Jianfeng Shen","author_ids":"1739602, 8475311, 5371645, 1804563, 8249064, 1707675, 2356943","abstract":"In the form of topic discussions, users interact with each other to share knowledge and exchange information in online forums. Modeling the evolution of topic discussion reveals how information propagates on Internet and can thus help understand sociological phenomena and improve the performance of applications such as recommendation systems. In this paper , we argue that a user's participation in topic discussions is motivated by either her friends or her own preferences. Inspired by the theory of information flow, we propose dynamic topic discussion models by mining influential relationships between users and individual preferences. Reply relations of users are exploited to construct the fundamental influential social network. The property of discussed topics and time lapse factor are also considered in our modeling. Furthermore , we propose a novel measure called ParticipationRank to rank users according to how important they are in the social network and to what extent they prefer to participate in the discussion of a certain topic. The experiments show our model can simulate the evolution of topic discussions well and predict the tendency of user's participation accurately.","cites":"7","conferencePercentile":"40.27303754"},{"venue":"AAAI","id":"f9b09caf65114209b68426f8370eddd6faa84022","venue_1":"AAAI","year":"1994","title":"ALIVE: Artificial Life Interactive Video Environment","authors":"Pattie Maes, Trevor Darrell, Bruce Blumberg, Alex Pentland","author_ids":"1701876, 1753210, 3272601, 1682773","abstract":"References In this video we demonstrate a novel system which allows wireless full-body interaction between a 'human participant and a graphical world inhabited by autonomous agents. The system is called \" ALIVE \" , an acronym for Artificial Life Interactive Video Environment. The goal of ALIVE is to present a virtual environment in which a user can interact, in natural and believable ways, with autonomous semi-intelligent agents whose behavior is equally natural and believable. In ALIVE, a single CCD camera is used to obtain a color image of a person which is composited into a 3D graphical world. The composite world is projected onto a large video wall in a world-centered reference frame, which faces the user and acts as a type of \" magic mirror \". No goggles, gloves, or wires are needed for interaction with the world: agents and objects in the graphical world can be acted upon by the human participant through the use of domain-specific computer vision techniques that analyze the silhouette and gestures of the person. The agents inhabiting the world are modeled as self-contained autonomous systems with internal needs and motivations which are embodied in a dynamic world: they sense the world via sensors, and move in, and act on the world in real time in response to the user's gestures and actions. As a result of the presence of these semi-intelligent entities, the system does not just allow for the obvious direct-manipulation style of interaction, but also a more powerful, indirect style of interaction in which gestures can have more complex meanings, which may vary according to the situation in which the agents and user find themselves. The video presents a specific implementation of the ALIVE system which was demonstrated as part of SIGGRAPH-93's Tomorrow's Realities show. Approximately 500 attendees interacted with the ALIVE system over the course of 5 days. The video footage was taken during that time. More information on the ALIVE system in general may be found in [Maes93] and [Darrell94]. Information on the details of the behavior and agent model used in ALIVE may be found in [Blumberg94]. More information on details of the visual routines may be found in [Darrell94].","cites":"15","conferencePercentile":"54.40528634"},{"venue":"AAAI","id":"0d28f2b9c12d47506e567392c6d0e624c0617e12","venue_1":"AAAI","year":"2007","title":"A Multi-Dimensional Trust Model for Heterogeneous Contract Observations","authors":"Steven Reece, Stephen J. Roberts, Alex Rogers, Nicholas R. Jennings","author_ids":"1771392, 1768999, 1793672, 1786650","abstract":"In this paper we develop a novel probabilistic model of computational trust that allows agents to exchange and combine reputation reports over heterogeneous, correlated multi-dimensional contracts. We consider the specific case of an agent attempting to procure a bundle of services that are subject to correlated quality of service failures (e.g. due to use of shared resources or infrastructure), and where the direct experience of other agents within the system consists of contracts over different combinations of these services. To this end, we present a formalism based on the Kalman filter that represents trust as a vector estimate of the probability that each service will be successfully delivered, and a co-variance matrix that describes the uncertainty and correlations between these probabilities. We describe how the agents' direct experiences of contract outcomes can be represented and combined within this formalism, and we empirically demonstrate that our formalism provides significantly better trustworthiness estimates than the alternative of using separate single-dimensional trust models for each separate service (where information regarding the correlations between each estimate is lost).","cites":"12","conferencePercentile":"57.71513353"},{"venue":"AAAI","id":"0378e48ffe916055328b95ce606f89e1b18fedcd","venue_1":"AAAI","year":"2014","title":"Unsupervised Alignment of Natural Language Instructions with Video Segments","authors":"Iftekhar Naim, Young Chol Song, Qiguang Liu, Henry A. Kautz, Jiebo Luo, Daniel Gildea","author_ids":"2296971, 3193978, 2579796, 1690271, 1717319, 1793218","abstract":"We propose an unsupervised learning algorithm for automatically inferring the mappings between English nouns and corresponding video objects. Given a sequence of natural language instructions and an un-aligned video recording, we simultaneously align each instruction to its corresponding video segment, and also align nouns in each instruction to their corresponding objects in video. While existing grounded language acquisition algorithms rely on pre-aligned supervised data (each sentence paired with corresponding image frame or video segment), our algorithm aims to automatically infer the alignment from the temporal structure of the video and parallel text instructions. We propose two generative models that are closely related to the HMM and IBM 1 word alignment models used in statistical machine translation. We evaluate our algorithm on videos of biological experiments performed in wetlabs, and demonstrate its capability of aligning video segments to text instructions and matching video objects to nouns in the absence of any direct supervision.","cites":"11","conferencePercentile":"89.54545455"},{"venue":"AAAI","id":"b3e78e7c79d112ecaf53400f16e66aa8d4d04734","venue_1":"AAAI","year":"2013","title":"Crowd Formalization of Action Conditions","authors":"Walter S. Lasecki, Leon Weingard, Jeffrey P. Bigham, George Ferguson","author_ids":"2598433, 3063887, 1744846, 1752556","abstract":"Training intelligent systems is a time consuming and costly process that often limits their application to real-world problems. Prior work in crowdsourcing has attempted to compensate for this challenge by generating sets of labeled training data for machine learning algorithms. In this work, we seek to move beyond collecting just statistical data and explore how to gather structured, relational representations of a scenario using the crowd. We focus on activity recognition because of its broad applicability, high level of variation between individual instances, and difficulty of training systems a priori. We present ARchitect, a system that uses the crowd to ascertain pre and post conditions for actions observed in a video and find relations between actions. Our ultimate goal is to identify multiple valid execution paths from a single set of observations, which suggests one-off learning from the crowd is possible.","cites":"2","conferencePercentile":"37.09090909"},{"venue":"AAAI","id":"8f1da50036e0ba4fc3e3667134be0993af12dc91","venue_1":"AAAI","year":"2014","title":"Accurate Household Occupant Behavior Modeling Based on Data Mining Techniques","authors":"Márcia Baptista, Anjie Fang, Helmut Prendinger, Rui Prada, Yohei Yamaguchi","author_ids":"2116516, 1708424, 2356111, 1739111, 3865747","abstract":"An important requirement of household energy simulation models is their accuracy in estimating energy demand and its fluctuations. Occupant behavior has a major impact upon energy demand. However, Markov chains, the traditional approach to model occupant behavior , (1) has limitations in accurately capturing the coordinated behavior of occupants and (2) is prone to over-fitting. To address these issues, we propose a novel approach that relies on a combination of data mining techniques. The core idea of our model is to determine the behavior of occupants based on nearest neighbor comparison over a database of sample data. Importantly, the model takes into account features related to the coordination of occupants' activities. We use a customized distance function suited for mixed categorical and numerical data. Further, association rule learning allows us to capture the coordination between occupants. Using real data from four households in Japan we are able to show that our model outperforms the traditional Markov chain model with respect to occupant coordination and generalization of behavior patterns.","cites":"3","conferencePercentile":"49.43181818"},{"venue":"AAAI","id":"8950260eb10b7e3070bd5b68c084a72a8b7fb6dd","venue_1":"AAAI","year":"2010","title":"GTPA: A Generative Model For Online Mentor-Apprentice Networks","authors":"Muhammad Aurangzeb Ahmad, David A. Huffaker, Jing Wang, Jeffrey William Treem, Marshall Scott Poole, Jaideep Srivastava","author_ids":"2074962, 2018809, 1697912, 2054189, 2598028, 1744014","abstract":"There is a large body of work on the evolution of graphs in various domains, which shows that many real graphs evolve in a similar manner. In this paper we study a novel type of network formed by mentor-apprentice relationships in a massively multiplayer online role playing game. We observe that some of the static and dynamic laws which have been observed in many other real world networks are not observed in this network. Consequently well known graph generators like Preferential Attachment, Forest Fire, Butterfly, RTM, etc., cannot be applied to such mentoring networks. We propose a novel generative model to generate networks with the characteristics of mentoring networks.","cites":"7","conferencePercentile":"40.27303754"},{"venue":"AAAI","id":"9aee0befc6ef62d37bf7c08088aa548d954a7a04","venue_1":"AAAI","year":"2015","title":"Towards Cognitive Automation of Data Science","authors":"Alain Biem, Maria Butrico, Mark Feblowitz, Tim Klinger, Yuri Malitsky, Kenney Ng, Adam Perer, Chandra Reddy, Anton Riabov, Horst Samulowitz, Daby M. Sow, Gerald Tesauro, Deepak S. Turaga","author_ids":"3274372, 3162780, 2081710, 1948071, 1896196, 1771022, 2912842, 1784966, 1984577, 1756353, 3189707, 1699108, 1727257","abstract":"A Data Scientist typically performs a number of tedious and time-consuming steps to derive insight from a raw data set. The process usually starts with data ingestion, cleaning, and transformation (e.g. outlier removal, missing value imputa-tion), then proceeds to model building, and finally a presentation of predictions that align with the end-users objectives and preferences. It is a long, complex, and sometimes artful process requiring substantial time and effort, especially because of the combinatorial explosion in choices of algorithms (and platforms), their parameters, and their compositions. Tools that can help automate steps in this process have the potential to accelerate the time-to-delivery of useful results , expand the reach of data science to non-experts, and offer a more systematic exploration of the available options. This work presents a step towards this goal.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"360a12e2f5c56e53cc97007678ee97dd85ecef14","venue_1":"AAAI","year":"2015","title":"Ordering-Sensitive and Semantic-Aware Topic Modeling","authors":"Min Yang, Tianyi Cui, Wenting Tu","author_ids":"5184537, 2077934, 1680761","abstract":"Topic modeling of textual corpora is an important and challenging problem. In most previous work, the \" bag-of-words \" assumption is usually made which ignores the ordering of words. This assumption simplifies the computation, but it un-realistically loses the ordering information and the semantic of words in the context. In this paper, we present a Gaus-sian Mixture Neural Topic Model (GMNTM) which incorporates both the ordering of words and the semantic meaning of sentences into topic modeling. Specifically, we represent each topic as a cluster of multi-dimensional vectors and embed the corpus into a collection of vectors generated by the Gaussian mixture model. Each word is affected not only by its topic, but also by the embedding vector of its surrounding words and the context. The Gaussian mixture components and the topic of documents, sentences and words can be learnt jointly. Extensive experiments show that our model can learn better topics and more accurate word distributions for each topic. Quantitatively, comparing to state-of-the-art topic modeling approaches, GMNTM obtains significantly better performance in terms of perplexity, retrieval accuracy and classification accuracy.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"1c6825a7f639bd3b435ca01dae1b1a2d56b2d75f","venue_1":"AAAI","year":"2015","title":"Audit Games with Multiple Defender Resources","authors":"Jeremiah Blocki, Nicolas Christin, Anupam Datta, Ariel D. Procaccia, Arunesh Sinha","author_ids":"1721903, 2637728, 1699116, 1689184, 2370629","abstract":"Modern organizations (e.g., hospitals, social networks, government agencies) rely heavily on audit to detect and punish insiders who inappropriately access and disclose confidential information. Recent work on audit games models the strategic interaction between an auditor with a single audit resource and auditees as a Stackelberg game, augmenting associated well-studied security games with a configurable punishment parameter. We significantly generalize this audit game model to account for multiple audit resources where each resource is restricted to audit a subset of all potential violations, thus enabling application to practical auditing scenarios. We provide an FPTAS that computes an approximately optimal solution to the resulting non-convex optimization problem. The main technical novelty is in the design and correctness proof of an optimization transformation that enables the construction of this FPTAS. In addition, we experimentally demonstrate that this transformation significantly speeds up computation of solutions for a class of audit games and security games.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"44606757de114a94b579b8eb7167d716c6601973","venue_1":"AAAI","year":"2008","title":"Constraint Projections for Ensemble Learning","authors":"Daoqiang Zhang, Songcan Chen, Zhi-Hua Zhou, Qiang Yang","author_ids":"1772283, 1680768, 1692625, 1733090","abstract":"It is well-known that diversity among base classifiers is crucial for constructing a strong ensemble. Most existing ensemble methods obtain diverse individual learners through resampling the instances or features. In this paper, we propose an alternative way for ensemble construction by resampling pairwise constraints that specify whether a pair of instances belongs to the same class or not. Using pairwise constraints for ensemble construction is challenging because it remains unknown how to influence the base classifiers with the sampled pairwise constraints. We solve this problem with a two-step process. First, we transform the original instances into a new data representation using projections learnt from pairwise constraints. Then, we build the base clas-sifiers with the new data representation. We propose two methods for resampling pairwise constraints following the standard Bagging and Boosting algorithms, respectively. Extensive experiments validate the effectiveness of our method.","cites":"8","conferencePercentile":"49.52531646"},{"venue":"AAAI","id":"537e6b067b30da5d6791ebbb193b0e7828d63e5e","venue_1":"AAAI","year":"2016","title":"Modeling Human Ad Hoc Coordination","authors":"Peter Krafft, Chris L. Baker, Alex Pentland, Joshua B. Tenenbaum","author_ids":"2025970, 3058736, 1682773, 5119093","abstract":"Whether in groups of humans or groups of computer agents, collaboration is most effective between individuals who have the ability to coordinate on a joint strategy for collective action. However, in general a rational actor will only intend to coordinate if that actor believes the other group members have the same intention. This circular dependence makes rational coordination difficult in uncertain environments if communication between actors is unreliable and no prior agreements have been made. An important normative question with regard to coordination in these ad hoc settings is therefore how one can come to believe that other actors will coordinate , and with regard to systems involving humans, an important empirical question is how humans arrive at these expectations. We introduce an exact algorithm for computing the infinitely recursive hierarchy of graded beliefs required for rational coordination in uncertain environments, and we introduce a novel mechanism for multiagent coordination that uses it. Our algorithm is valid in any environment with a finite state space, and extensions to certain countably infinite state spaces are likely possible. We test our mechanism for multiagent coordination as a model for human decisions in a simple coordination game using existing experimental data. We then explore via simulations whether modeling humans in this way may improve human-agent collaboration. Forming shared plans that support mutually beneficial behavior within a group is central to collaborative social interaction and collective intelligence (Grosz and Kraus 1996). Indeed, many common organizational practices are designed to facilitate shared knowledge of the structure and goals of organizations, as well as mutual recognition of the roles that individuals in the organizations play. Once teams become physically separated and responsiveness or frequency of communication declines, the challenge of forming shared plans increases. Part of this difficulty is fundamentally computational. In theory, coming to a fully mutually recognized agreement on even a simple action plan among two choices can be literally impossible if communication is even mildly unreliable, even if an arbitrary amount of communication is This problem is well-studied within the AI literature (e.g., (Gmytrasiewicz and Durfee 1992)), though the core difficulties still manifest in contemporary research on \" ad hoc coordination \" —collaborative multiagent planning with previously unknown teammates (Stone et al. 2010). However, surprisingly little is known about the strategies that humans use to overcome the difficulties of coordination (Thomas et al. 2014). Understanding how and when people try to coordinate is …","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"f53c7ef11feb924f35c5339bfbf8b40a28881b0c","venue_1":"AAAI","year":"2012","title":"Online Sequence Alignment for Real-Time Audio Transcription by Non-Experts","authors":"Walter S. Lasecki, Christopher D. Miller, Donato Borrello, Jeffrey P. Bigham","author_ids":"2598433, 2598184, 3169100, 1744846","abstract":"Real-time transcription provides deaf and hard of hearing people visual access to spoken content, such as classroom instruction, and other live events. Currently, the only reliable source of real-time transcriptions are expensive, highly-trained experts who are able to keep up with speaking rates. Automatic speech recognition is cheaper but produces too many errors in realistic settings. We introduce a new approach in which partial captions from multiple non-experts are combined to produce a high-quality transcription in real-time. We demonstrate the potential of this approach with data collected from 20 non-expert captionists.","cites":"2","conferencePercentile":"22.40853659"},{"venue":"AAAI","id":"8cd3fc917cd9f213d0b091f37d561861da8d25d6","venue_1":"AAAI","year":"2005","title":"Using a Sketch Pad Interface for Interacting with a Robot Team","authors":"Marjorie Skubic, Derek Anderson, Samuel Blisard, Dennis Perzanowski, William Adams, J. Gregory Trafton, Alan C. Schultz","author_ids":"1809251, 2599274, 1928974, 3254427, 8227315, 1720577, 1803820","abstract":"Researchers at the University of Missouri-Columbia and at the Naval Research Laboratory have been working on human-robot interaction and communication. Our goals have been to make such interactions more intuitive and natural, as much as human-human communication is facilitated by shared modes of interaction. At AAAI 2005, we are exhibiting a sketch interface to control a team of mobile robots. Users can draw environment landmarks and label them, as well as indicate goal points and paths for robot navigation for a single robot or a group of robots, by drawing on the sketch pad of a tablet PC. Editing operations are also supported in the sketch interface, so that the user can move or delete environment landmarks and redraw goal points and robot trajectories. The sketch interface employs an approximate representation of the environment and landmarks with which the human user can interact. The interface extracts qualitative spatial information from the sketched landmarks on the map and the path drawn through the field of landmarks. This information is then relayed to the robots for subsequent action. From the robot's point of view in attempting to navigate, the task is based on its real-time sensing and the relative position of paths and landmarks, not the absolute positions of the sketched artifacts. The path or trajectory that the robot must take and information about objects in the environment are based qualitatively on the information which the human provides via the sketch pad and quantitatively by the onboard robot sensors obtained in real time.","cites":"6","conferencePercentile":"29.37062937"},{"venue":"AAAI","id":"37b798bfe195f8c1bf77697327ff526f6844c232","venue_1":"AAAI","year":"2007","title":"Spatial Representation and Reasoning for Human-Robot Collaboration","authors":"William G. Kennedy, Magdalena D. Bugajska, Matthew Marge, William Adams, Benjamin R. Fransen, Dennis Perzanowski, Alan C. Schultz, J. Gregory Trafton","author_ids":"2131112, 2799250, 2372948, 8227315, 2708380, 3254427, 1803820, 1720577","abstract":"How should a robot represent and reason about spatial information when it needs to collaborate effectively with a human? The form of spatial representation that is useful for robot navigation may not be useful in higher-level reasoning or working with humans as a team member. To explore this question, we have extended previous work on how children and robots learn to play hide and seek to a human-robot team covertly approaching a moving target. We used the cognitive modeling system, ACT-R, with an added spatial module to support the robot's spatial reasoning. The robot interacted with a team member through voice, gestures, and movement during the team's covert approach of a moving target. This paper describes the new robotic system and its integration of metric, symbolic, and cognitive layers of spatial representation and reasoning for its individual and team behavior.","cites":"24","conferencePercentile":"74.92581602"},{"venue":"AAAI","id":"0c9d73d93f0dc8f3cb2a35d32ee4de0a28d27960","venue_1":"AAAI","year":"2008","title":"Incorporating Mental Simulation for a More Effective Robotic Teammate","authors":"William G. Kennedy, Magdalena D. Bugajska, William Adams, Alan C. Schultz, J. Gregory Trafton","author_ids":"2131112, 2799250, 8227315, 1803820, 1720577","abstract":"How can we facilitate human-robot teamwork? The teamwork literature has identified the need to know the capabilities of teammates. How can we integrate the knowledge of another agent's capabilities for a justifiably intelligent teammate? This paper describes extensions to the cognitive architecture, ACT-R, and the use of artificial intelligence (AI) and cognitive science approaches to produce a more cognitively-plausible, autonomous robotic system that \" mentally \" simulates the decision-making of its teammate. The extensions to ACT-R added capabilities to interact with the real world through the robot's sensors and effectors and simulate the decision-making of its teammate. The AI applications provided visual sensor capabilities by methods clearly different than those used by humans. The integration of these approaches into intelligent team-based behavior is demonstrated on a mobile robot. Our \" TeamBot \" matches the descriptive work and theories on human teamwork. We illustrate our approach in a spatial, team-oriented task of a guard force responding appropriately to an alarm condition that requires the human and robot team to \" man \" two guard stations as soon as possible after the alarm.","cites":"6","conferencePercentile":"41.4556962"},{"venue":"AAAI","id":"e49ae7640c8e1a2642190bbdc115ab846b099213","venue_1":"AAAI","year":"2008","title":"Computational Influence for Training and Entertainment","authors":"David L. Roberts","author_ids":"5797583","abstract":"An interactive narrative is an education, training, or entertainment experience. There are two qualities that make an experience an interactive narrative. To understand those, let us clarify the meanings of interactive and narrative. Interactive: capable of acting on or influencing each other; and Narrative: presentation of events in a purposeful sequence. Thus, the qualities that define an interactive narrative are autonomy for players to act and intent of the system for the player to experience a narrative prescribed by an author. This conception of interactive narrative is broad and encompasses many types of entertainment and training experiences. One characteristic that sets it apart from other experiences and common games like Chess is that authorial intent often requires the player's experience to be dramatic or adhere to some aesthetic. There is a tension between the systematic control required to ensure the intent of the narrative and the player autonomy required for interactivity— the player-driven exploration that results in an interactive quality is a potential threat to the narrative. Therefore, AI researchers in the field of interactive narrative are interested in balancing the conflicting requirements of autonomy and authorial intent. It is in this area that both I and many interactive narrative researchers have focused their efforts (Roberts and Isbell 2008). While many of the existing research projects have met with success in their own right, they have also uncovered limitations in the state of the art. I plan to complete my dissertation by addressing some of these limitations. The tools of artificial intelligence and machine learning have often been applied in domains where the limits of human ability are stretched. For example, sophisticated AI algorithms retrieve information from the internet, filter spam from email inboxes, and aid doctors in diagnosing illnesses. In each of these cases, a technically-minded AI expert has created a technique to solve a class of problems and has put the power of that technology in the hands of a practitioner. Similarly, I plan to develop AI technologies for computer-based gaming and simulation that when given to game designers will ease their authorial burden and increase their expressive power. The fundamental question I plan to answer in my research is: How can we leverage the generalization characteristics of machine learning and ideas from social psychology to build an authoring tool that will enable domain experts to easily implement rich entertainment or training experiences through high level goal and …","cites":"0","conferencePercentile":"7.120253165"},{"venue":"AAAI","id":"8220b4c475e09567a19cc461dc12782c2aad4247","venue_1":"AAAI","year":"2008","title":"Exposing Parameters of a Trained Dynamic Model for Interactive Music Creation","authors":"Dan Morris, Ian Simon, Sumit Basu","author_ids":"1779342, 1710052, 1801676","abstract":"As machine learning (ML) systems emerge in end-user applications, learning algorithms and classifiers will need to be robust to an increasingly unpredictable operating environment. In many cases, the parameters governing a learning system cannot be optimized for every user scenario, nor can users typically manipulate parameters defined in the space and terminology of ML. Conventional approaches to user-oriented ML systems have typically hidden this complexity from users by automating parameter adjustment. We propose a new paradigm, in which model and algorithm parameters are exposed directly to end-users with intuitive labels, suitable for applications where parameters cannot be automatically optimized or where there is additional motivation – such as creative flexibility – to expose, rather than fix or automatically adapt, learning parameters. In our CHI 2008 paper, we introduced and evaluated MySong, a system that uses a Hidden Markov Model to generate chords to accompany a vocal melody. The present paper formally describes the learning underlying MySong and discusses the mechanisms by which MySong \" s learning parameters are exposed to users, as a case study in making ML systems user-configurable. We discuss the generalizability of this approach, and propose that intuitively exposing ML parameters is a key challenge for the ML and human-computer-interaction communities.","cites":"10","conferencePercentile":"54.90506329"},{"venue":"AAAI","id":"27331f48c87736ea12b9edec062e384d3bd58f88","venue_1":"AAAI","year":"2014","title":"Fraudulent Support Telephone Number Identification Based on Co-Occurrence Information on the Web","authors":"Xin Li, Yiqun Liu, Min Zhang, Shaoping Ma","author_ids":"1705796, 8653031, 1770849, 8093158","abstract":"\" Fraudulent support phones \" refers to the misleading telephone numbers placed on Web pages or other media that claim to provide services with which they are not associated. Most fraudulent support phone information is found on search engine result pages (SERPs), and such information substantially degrades the search engine user experience. In this paper, we propose an approach to identify fraudulent support telephone numbers on the Web based on the co-occurrence relations between telephone numbers that appear on SERPs. We start from a small set of seed official support phone numbers and seed fraudulent numbers. Then, we construct a co-occurrence graph according to the co-occurrence relationships of the telephone numbers that appear on Web pages. Additionally, we take the page layout information into consideration on the assumption that telephone numbers that appear in nearby page blocks should be regarded as more closely related. Finally, we develop a propagation algorithm to diffuse the trust scores of seed official support phone numbers and the distrust scores of the seed fraudulent numbers on the co-occurrence graph to detect additional fraudulent numbers. Experimental results based on over 1.5 million SERPs produced by a popular Chinese commercial search engine indicate that our approach outperforms TrustRank, Anti-TrustRank and Good-Bad Rank algorithms by achieving an AUC value of over 0.90.","cites":"2","conferencePercentile":"38.63636364"},{"venue":"AAAI","id":"3f9b7869c0b89c0356609265c3a43ca3bb0bd3f4","venue_1":"AAAI","year":"2007","title":"Turning Lectures into Comic Books Using Linguistically Salient Gestures","authors":"Jacob Eisenstein, Regina Barzilay, Randall Davis","author_ids":"1752524, 4452125, 1735802","abstract":"Creating video recordings of events such as lectures or meetings is increasingly inexpensive and easy. However, reviewing the content of such video may be time-consuming and difficult. Our goal is to produce a \" comic book \" summary, in which a transcript is augmented with keyframes that dis-ambiguate and clarify accompanying text. Unlike most previous keyframe extraction systems which rely primarily on visual cues, we present a linguistically-motivated approach that selects keyframes that contain salient gestures. Rather than learning gesture salience directly, it is estimated by measuring the contribution of gesture to understanding other discourse phenomena. More specifically, we bootstrap from multimodal coreference resolution to identify gestures that improve performance. We then select keyframes that capture these gestures. Our model predicts gesture salience as a hidden variable in a conditional framework, with observable features from both the visual and textual modalities. This approach significantly outperforms competitive baselines that do not use gesture information.","cites":"6","conferencePercentile":"38.4272997"},{"venue":"AAAI","id":"2ba92d274d99106e029cf7d38c9e840888c09d7b","venue_1":"AAAI","year":"2005","title":"Constraint-Based Entity Matching","authors":"Warren Shen, Xin Li, AnHai Doan","author_ids":"2019421, 1705796, 3030274","abstract":"Entity matching is the problem of deciding if two given mentions in the data, such as \" Helen Hunt \" and \" H. M. Hunt \" , refer to the same real-world entity. Numerous solutions have been developed, but they have not considered in depth the problem of exploiting integrity constraints that frequently exist in the domains. Examples of such constraints include \" a mention with age two cannot match a mention with salary 200K \" and \" if two paper citations match, then their authors are likely to match in the same order \". In this paper we describe a probabilistic solution to entity matching that exploits such constraints to improve matching accuracy. At the heart of the solution is a generative model that takes into account the constraints during the generation process, and provides well-defined interpretations of the constraints. We describe a novel combination of EM and relaxation labeling algorithms that efficiently learns the model, thereby matching mentions in an unsupervised way, without the need for annotated training data. Experiments on several real-world domains show that our solution can exploit constraints to significantly improve matching accuracy, by 3-12% F-1, and that the solution scales up to large data sets.","cites":"48","conferencePercentile":"90.03496503"},{"venue":"AAAI","id":"41343f7881754c360a0356578470b529497c7511","venue_1":"AAAI","year":"2010","title":"User-Specific Learning for Recognizing a Singer's Intended Pitch","authors":"Andrew Guillory, Sumit Basu, Dan Morris","author_ids":"1778413, 1801676, 1779342","abstract":"We consider the problem of automatic vocal melody transcription: translating an audio recording of a sung melody into a musical score. While previous work has focused on finding the closest notes to the singer's tracked pitch, we instead seek to recover the melody the singer intended to sing. Often, the melody a singer intended to sing differs from what they actually sang; our hypothesis is that this occurs in a singer-specific way. For example, a given singer may often be flat in certain parts of her range, or another may have difficulty with certain intervals. We thus pursue methods for singer-specific training which use learning to combine different methods for pitch prediction. In our experiments with human subjects, we show that via a short training procedure we can learn a singer-specific pitch predictor and significantly improve transcription of intended pitch over other methods. For an average user, our method gives a 20 to 30 percent reduction in pitch classification errors with respect to a baseline method which is comparable to commercial voice transcription tools. For some users, we achieve even more dramatic reductions. Our best results come from a combination of singer-specific-learning with non-singer-specific feature selection. We also discuss the implications of our work for training more general control signals. We make our experimental data available to allow others to replicate or extend our results.","cites":"0","conferencePercentile":"3.754266212"},{"venue":"AAAI","id":"47ed1c8bdf80a079ba0c42e1b80b8993213ae3dc","venue_1":"AAAI","year":"2014","title":"Predicting the Hardness of Learning Bayesian Networks","authors":"Brandon Malone, Kustaa Kangas, Matti Järvisalo, Mikko Koivisto, Petri Myllymäki","author_ids":"6428544, 3340277, 1790372, 2251289, 1699156","abstract":"There are various algorithms for finding a Bayesian network structure (BNS) that is optimal with respect to a given scoring function. No single algorithm dominates the others in speed, and, given a problem instance, it is a priori unclear which algorithm will perform best and how fast it will solve the problem. Estimating the runtimes directly is extremely difficult as they are complicated functions of the instance. The main contribution of this paper is characterization of the empirical hardness of an instance for a given algorithm based on a novel collection of non-trivial, yet efficiently computable features. Our empirical results, based on the largest evaluation of state-of-the-art BNS learning algorithms to date, demonstrate that we can predict the runtimes to a reasonable degree of accuracy , and effectively select algorithms that perform well on a particular instance. Moreover, we also show how the results can be utilized in building a portfolio algorithm that combines several individual algorithms in an almost optimal manner.","cites":"8","conferencePercentile":"81.25"},{"venue":"AAAI","id":"cca1f42869af7659490b9eed9937f1c9e3fbf675","venue_1":"AAAI","year":"2015","title":"Automatic Assessment of OCR Quality in Historical Documents","authors":"Anshul Gupta, Ricardo Gutierrez-Osuna, Matthew Christy, Boris Capitanu, Loretta Auvil, Liz Grumbach, Richard Furuta, Laura Mandell","author_ids":"2323660, 2907082, 2620689, 3290235, 1844405, 1955687, 1763643, 2947489","abstract":"Mass digitization of historical documents is a challenging problem for optical character recognition (OCR) tools. Issues include noisy backgrounds and faded text due to aging, border/marginal noise, bleed-through, skewing, warping, as well as irregular fonts and page layouts. As a result, OCR tools often produce a large number of spurious bounding boxes (BBs) in addition to those that correspond to words in the document. This paper presents an iterative classification algorithm to automatically label BBs (i.e., as text or noise) based on their spatial distribution and geometry. The approach uses a rule-base classifier to generate initial text/noise labels for each BB, followed by an iterative classifier that refines the initial labels by incorporating local information to each BB, its spatial location, shape and size. When evaluated on a dataset containing over 72,000 manually-labeled BBs from 159 historical documents, the algorithm can classify BBs with 0.95 precision and 0.96 recall. Further evaluation on a collection of 6,775 documents with ground-truth transcriptions shows that the algorithm can also be used to predict document quality (0.7 correlation) and improve OCR transcriptions in 85% of the cases.","cites":"4","conferencePercentile":"73.46456693"},{"venue":"AAAI","id":"067a40d9fe0942abfc8a31342a95f165a88ca5d6","venue_1":"AAAI","year":"2014","title":"Optimal Neighborhood Preserving Visualization by Maximum Satisfiability","authors":"Kerstin Bunte, Matti Järvisalo, Jeremias Berg, Petri Myllymäki, Jaakko Peltonen, Samuel Kaski","author_ids":"1721835, 1790372, 1866798, 1699156, 1685017, 8137459","abstract":"We present a novel approach to low-dimensional neighbor embedding for visualization, based on formulating an information retrieval based neighborhood preservation cost function as Maximum satisfiability on a discretized output display. The method has a rigorous interpretation as optimal vi-sualization based on the cost function. Unlike previous low-dimensional neighbor embedding methods, our formulation is guaranteed to yield globally optimal visualizations, and does so reasonably fast. Unlike previous manifold learning methods yielding global optima of their cost functions, our cost function and method are designed for low-dimensional visualization where evaluation and minimization of visualiza-tion errors are crucial. Our method performs well in experiments , yielding clean embeddings of datasets where a state-of-the-art comparison method yields poor arrangements. In a real-world case study for semi-supervised WLAN signal mapping in buildings we outperform state-of-the-art methods.","cites":"2","conferencePercentile":"38.63636364"},{"venue":"AAAI","id":"9507b40080b7a13f5ae946506f5bd44b82fcc7ae","venue_1":"AAAI","year":"2014","title":"Parametrized Families of Hard Planning Problems from Phase Transitions","authors":"Eleanor G. Rieffel, Davide Venturelli, Minh Do, Itay Hen, Jeremy Frank","author_ids":"1710276, 2626720, 4212526, 8621764, 1771131","abstract":"There are two complementary ways to evaluate planning algorithms: performance on benchmark problems derived from real applications and analysis of performance on parametrized families of problems with known properties. Prior to this work, few means of generating parametrized families of hard planning problems were known. We generate hard planning problems from the solvable/unsolvable phase transition region of well-studied NP-complete problems that map naturally to navigation and scheduling, aspects common to many planning domains. We observe significant differences between state-of-the-art planners on these problem families, enabling us to gain insight into the relative strengths and weaknesses of these planners. Our results confirm exponential scaling of hardness with problem size, even at very small problem sizes. These families provide complementary test sets exhibiting properties not found in existing benchmarks.","cites":"0","conferencePercentile":"9.431818182"},{"venue":"AAAI","id":"2330805936da78453f403ae30212fa3308257e70","venue_1":"AAAI","year":"2014","title":"Sketch Recognition with Natural Correction and Editing","authors":"Jie Wu, Changhu Wang, Liqing Zhang, Yong Rui","author_ids":"1717209, 1697065, 7137826, 1728806","abstract":"In this paper, we target at the problem of sketch recognition. We systematically study how to incorporate users' correction and editing into isolated and full sketch recognition. This is a natural and necessary interaction in real systems such as Vi-sio where very similar shapes exist. First, a novel algorithm is proposed to mine the prior shape knowledge for three editing modes. Second, to differentiate visually similar shapes, a novel symbol recognition algorithm is introduced by leverag-ing the learnt shape knowledge. Then, a novel editing detection algorithm is proposed to facilitate symbol recognition. Furthermore, both of the symbol recognizer and the editing detector are systematically incorporated into the full sketch recognition. Finally, based on the proposed algorithms, a real-time sketch recognition system is built to recognize hand-drawn flowcharts and diagrams with flexible interactions. Extensive experiments show the effectiveness of the proposed algorithms.","cites":"3","conferencePercentile":"49.43181818"},{"venue":"AAAI","id":"34de0dfd84bdac9780dd8d0f1ab450fb8162c196","venue_1":"AAAI","year":"2008","title":"Text Beautifier: An Affective-Text Tool to Tailor Written Text","authors":"Fahim Kawsar, Shaikh Mostafa Al Masum, Mitsuru Ishizuka","author_ids":"1792840, 2955278, 1687719","abstract":"We have spelling and grammar checking tools available on today's word processors. But what they are missing is a tool that can recommend several possibilities of a given written sentence to assist a user to write better sentences. Therefore , we aim to develop a linguistic tool to beautify text by applying our developed lexical resources regarding textual affect sensing. The developed tool will allow a user to beautify an input sentence in terms of tuning it on different scales like valence, affect, prospect, and praise. For example using such a tool one may get the recommendations like, \" Your lovely email makes me very glad \" , or \" I become glad to read your email \" , or \" I am very happy to obtain your nice email \" for the input sentence \" I am happy to receive your email \" after scaling up the input sentence on affective, or prospective, or valence scale respectively. Such tool will be especially helpful to the non-native English speakers to write better English.","cites":"1","conferencePercentile":"17.40506329"},{"venue":"AAAI","id":"cf51401f426028d4667c634c8c7920d4fadfd075","venue_1":"AAAI","year":"2007","title":"Adaptive Traitor Tracing with Bayesian Networks","authors":"Philip Zigoris, Hongxia Jin","author_ids":"2692519, 1705713","abstract":"The practical success of broadcast encryption hinges on the ability to (1) revoke the access of compromised keys and (2) determine which keys have been compromised. In this work we focus on the latter, the so-called traitor tracing problem. We present an adaptive tracing algorithm that selects forensic tests according to the information gain criteria. The results of the tests refine an explicit, Bayesian model of our beliefs that certain keys are compromised. In choosing tests based on this criteria, we significantly reduce the number of tests, as compared to the state-of-the-art techniques, required to identify compromised keys. As part of the work we developed an efficient , distributable inference algorithm that is suitable for our application and also give an efficient heuristic for choosing the optimal test.","cites":"0","conferencePercentile":"5.489614243"},{"venue":"AAAI","id":"652c43022c25f99d6696877b5b0031640085af4d","venue_1":"AAAI","year":"2011","title":"Identifying Missing Node Information in Social Networks","authors":"Ron Eyal, Sarit Kraus, Avi Rosenfeld","author_ids":"1901698, 1691597, 1955991","abstract":"In recent years, social networks have surged in popularity as one of the main applications of the Internet. This has generated great interest in researching these networks by various fields in the scientific community. One key aspect of social network research is identifying important missing information which is not explicitly represented in the network, or is not visible to all. To date, this line of research typically focused on what connections were missing between nodes, or what is termed the \"Missing Link Problem\". This paper introduces a new Missing Nodes Identification problem where missing members in the social network structure must be identified. Towards solving this problem, we present an approach based on clustering algorithms combined with measures from missing link research. We show that this approach has beneficial results in the missing nodes identification process and we measure its performance in several different scenarios .","cites":"6","conferencePercentile":"49.14089347"},{"venue":"AAAI","id":"15094cb279dd5da1ceeea0f176964cd828a6f2b0","venue_1":"AAAI","year":"2016","title":"Privacy-CNH: A Framework to Detect Photo Privacy with Convolutional Neural Network using Hierarchical Features","authors":"Lam Tran, Deguang Kong, Hongxia Jin, Ji Liu","author_ids":"3374343, 8720637, 1705713, 3256884","abstract":"Photo privacy is a very important problem in the digital age where photos are commonly shared on social networking sites and mobile devices. The main challenge in photo privacy detection is how to generate discriminant features to accurately detect privacy at risk photos. Existing photo privacy detection works, which rely on low-level vision features, are non-informative to the users regarding what privacy information is leaked from their photos. In this paper, we propose a new framework called Privacy-CNH that utilizes hierarchical features which include both object and convolutional features in a deep learning model to detect privacy at risk photos. The generation of object features enables our model to better inform the users about the reason why a photo has privacy risk. The combination of convolutional and object features provide a richer model to understand photo privacy from different aspects, thus improving photo privacy detection accuracy. Experimental results demonstrate that the proposed model outperforms the state-of-the-art work and the standard convolutional neural network (CNN) with convolutional features on photo privacy detection tasks.","cites":"4","conferencePercentile":"79.72972973"},{"venue":"AAAI","id":"7ec1b68b05dba4473127daab4d74f7214cf10424","venue_1":"AAAI","year":"2005","title":"Performing Bayesian Inference by Weighted Model Counting","authors":"Tian Sang, Paul Beame, Henry A. Kautz","author_ids":"2812761, 1791374, 1690271","abstract":"Over the past decade general satisfiability testing algorithms have proven to be surprisingly effective at solving a wide variety of constraint satisfaction problem, such as planning and scheduling (Kautz and Selman 2003). Solving such NP-complete tasks by \" compilation to SAT \" has turned out to be an approach that is of both practical and theoretical interest. Recently, (Sang et al. 2004) have shown that state of the art SAT algorithms can be efficiently extended to the harder task of counting the number of models (satisfying assignments) of a formula, by employing a technique called component caching. This paper begins to investigate the question of whether \" compilation to model-counting \" could be a practical technique for solving real-world #P-complete problems, in particular Bayesian inference. We describe an efficient translation from Bayesian networks to weighted model counting , extend the best model-counting algorithms to weighted model counting, develop an efficient method for computing all marginals in a single counting pass, and evaluate the approach on computationally challenging reasoning problems.","cites":"61","conferencePercentile":"92.48251748"},{"venue":"AAAI","id":"677583cfc715ec44e85a37e8c4055301e0f8f009","venue_1":"AAAI","year":"1994","title":"Noise Strategies for Improving Local Search","authors":"Bart Selman, Henry A. Kautz, Bram Cohen","author_ids":"1744679, 1690271, 2742787","abstract":"It has recently been shown that local search i s s u r-prisingly good at nding satisfying assignments for certain computationally hard classes of CNF formulas. The performance of basic local search m e t h o d s can be further enhanced by i n troducing mechanisms for escaping from local minima in the search space. We will compare three such m e c hanisms: simulated annealing, random noise, and a strategy called \\mixed random walk\". We show that mixed random walk is the superior strategy. W e also present results demonstrating the eeectiveness of local search w i t h w alk for solving circuit synthesis and circuit diagnosis problems. Finally, w e demonstrate that mixed random walk improves upon the best known methods for solving MAX-SAT problems.","cites":"534","conferencePercentile":"100"},{"venue":"AAAI","id":"330666bd912347b9c9a7ad77e0a3d3b58683533f","venue_1":"AAAI","year":"1994","title":"An Experiment in the Design of Software Agents","authors":"Henry A. Kautz, Bart Selman, Michael H. Coen, Steven P. Ketchpel, Chris Ramming","author_ids":"1690271, 1744679, 3155217, 2285915, 2697293","abstract":"We describe a bottom-up approach to the design of software agents. We built and tested an agent system that addresses the real-world problem of handling the activities involved in scheduling a visitor to our laboratory. The system employs both task-specific and user-centered agents, and communicates with users using both email and a graphical interface. This experiment has helped us to identify crucial requirements in the successful deployment of software agents, including issues of reliability, security, and ease of use. The architecture we developed to meet these requirements is flexible and extensible, and is guiding our current research on principles of agent design.","cites":"46","conferencePercentile":"83.25991189"},{"venue":"AAAI","id":"49d6c5d6e5243c163ba28f5c968f8e952ede6539","venue_1":"AAAI","year":"1993","title":"Reasoning With Characteristic Models","authors":"Henry A. Kautz, Michael Kearns, Bart Selman","author_ids":"1690271, 1799212, 1744679","abstract":"Formal AI systems traditionally represent knowledge using logical formulas. We will show, however, that for certain kinds of information, a model-based representation is more compact and enables faster reasoning than the corresponding formula-based representation. The central idea behind our work is to represent a large set of models by a subset of characteristic models. More specifically, we examine model-based representations of Horn theories, and show that there are large Horn theories that can be exactly represented by an exponentially smaller set of characteristic models. In addition, we will show that deduction based on a set of characteristic models takes only linear time, thus matching the performance using Horn theories. More surprisingly, abduction can be performed in polynomial time using a set of characteristic models, whereas abduction using Horn theories is NP-complete.","cites":"52","conferencePercentile":"74.32432432"},{"venue":"AAAI","id":"562dda9758bf081d69498735d62873061a002df4","venue_1":"AAAI","year":"1993","title":"An Empirical Study of Greedy Local Search for Satisfiability Testing","authors":"Bart Selman, Henry A. Kautz","author_ids":"1744679, 1690271","abstract":"GSAT is a randomized local search procedure for solving propositional satisfiability problems. GSAT can solve hard, randomly generated problems that are an order of magnitude larger than those that can be handled by more traditional approaches, such as the Davis-Putnam procedure. This paper presents the results of numerous experiments we have performed with GSAT, in order to improve our understanding of its capabilities and limitations. We first characterize the space traversed by GSAT. We will see that for nearly all problem classes we have encountered, the space consists of a steep descent followed by broad flat plateaus. We then compare GSAT with simulated annealing, and show how GSAT can be viewed as an efficient method for executing the low-temperature tail of an annealing schedule. Finally , we report on extensions to the basic GSAT procedure. We discuss two general, domain-independent extensions that dramatically improve GSAT's performance on structured problems: the use of clause weights, and a way to average in near-solutions when initializing the procedure before each try.","cites":"106","conferencePercentile":"86.48648649"},{"venue":"AAAI","id":"2f0281035fc8c19d1c7d5281481e9b2249a0858c","venue_1":"AAAI","year":"1991","title":"Integrating Metric and Qualitative Temporal Reasoning","authors":"Henry A. Kautz, Peter B. Ladkin","author_ids":"1690271, 1803342","abstract":"Research in Artiicial Intelligence on constraint-based representations for temporal reasoning has largely concentrated on two kinds of formalisms: systems of simple linear inequalities to encode metric relations between time points, and systems of binary constraints in Allen's temporal calculus to encode qualitative relations between time intervals. Each formalism has certain advantages. Linear inequalities can represent dates, durations , and other quantitive information; Allen's qualitative calculus can express relations between time intervals , such as disjointedness, that are useful for constraint based approaches to planning. In this paper we demonstrate how metric and Allen-style constraint networks can be integrated in a constraint based reasoning system. The highlights of the work include a simple but powerful logical language for expressing both quantitative and qualitative information ; translation algorithms between the metric and Allen sublanguages that entail minimal loss of information ; and a constraint-propagation procedure for problems expressed in a combination of metric and Allen constraints.","cites":"144","conferencePercentile":"93.18181818"},{"venue":"AAAI","id":"3169b06d2e7e0302b8d726041344fca26beb3669","venue_1":"AAAI","year":"1991","title":"Knowledge Compilation using Horn Approximations","authors":"Bart Selman, Henry A. Kautz","author_ids":"1744679, 1690271","abstract":"We present a new approach to developing fast and eecient knowledge representation systems. Previous approaches to the problem of tractable inference have used restricted languages or incomplete inference mechanisms | problems include lack of expressive power, lack of inferential power, and/or lack of a formal characterization of what can and cannot be inferred. To overcome these disadvantages, we introduce a knowledge compilation method. We allow the user to enter statements in a general, unrestricted representation language, which the system compiles into a restricted language that allows for eecient inference. Since an exact translation into a tractable form is often impossible, the system searches for the best approximation of the original information. We will describe how the approximation can be used to speed up inference without giving up correctness or completeness. We illustrate our method by studying the approximation of logical theories by Horn theories. Following the formal deenition of Horn approximation, we present \\anytime\" algorithms for generating such approximations. We subsequently discuss extensions to other useful classes of approximations.","cites":"117","conferencePercentile":"90.90909091"},{"venue":"AAAI","id":"fbb96dfced7457a6fafdf280d2bc605e6dfa2d24","venue_1":"AAAI","year":"2006","title":"A Fast Decision Tree Learning Algorithm","authors":"Jiang Su, Harry Zhang","author_ids":"3312453, 1806400","abstract":"There is growing interest in scaling up the widely-used decision-tree learning algorithms to very large data sets. Although numerous diverse techniques have been proposed , a fast tree-growing algorithm without substantial decrease in accuracy and substantial increase in space complexity is essential. In this paper, we present a novel, fast decision-tree learning algorithm that is based on a conditional independence assumption. The new algorithm has a time complexity of O(m · n), where m is the size of the training data and n is the number of attributes. This is a significant asymptotic improvement over the time complexity O(m · n 2) of the standard decision-tree learning algorithm C4.5, with an additional space increase of only O(n). Experiments show that our algorithm performs competitively with C4.5 in accuracy on a large number of UCI benchmark data sets, and performs even better and significantly faster than C4.5 on a large number of text classification data sets. The time complexity of our algorithm is as low as naive Bayes'. Indeed, it is as fast as naive Bayes but outperforms naive Bayes in accuracy according to our experiments. Our algorithm is a core tree-growing algorithm that can be combined with other scaling-up techniques to achieve further speedup.","cites":"23","conferencePercentile":"72.76657061"},{"venue":"AAAI","id":"69a38f3ca2a0a2a28c2994b5ed78b6e9b1ad1cff","venue_1":"AAAI","year":"2005","title":"Hidden Naive Bayes","authors":"Harry Zhang, Liangxiao Jiang, Jiang Su","author_ids":"1806400, 1746953, 3312453","abstract":"The conditional independence assumption of naive Bayes essentially ignores attribute dependencies and is often violated. On the other hand, although a Bayesian network can represent arbitrary attribute dependencies, learning an optimal Bayesian network from data is intractable. The main reason is that learning the optimal structure of a Bayesian network is extremely time consuming. Thus, a Bayesian model without structure learning is desirable. In this paper, we propose a novel model, called hidden naive Bayes (HNB). In an HNB, a hidden parent is created for each attribute which combines the influences from all other attributes. We present an approach to creating hidden parents using the average of weighted one-dependence estimators. HNB inherits the structural simplicity of naive Bayes and can be easily learned without structure learning. We propose an algorithm for learning HNB based on conditional mutual information. We experimentally test HNB in terms of classification accuracy, using the 36 UCI data sets recommended by Weka (Witten & Frank 2000), and compare it to naive","cites":"48","conferencePercentile":"90.03496503"},{"venue":"AAAI","id":"8cfe0cd78d143ea7e92d7ae78eb1e185496b7685","venue_1":"AAAI","year":"2005","title":"Representing Conditional Independence Using Decision Trees","authors":"Jiang Su, Harry Zhang","author_ids":"3312453, 1806400","abstract":"While the representation of decision trees is fully expressive theoretically, it has been observed that traditional decision trees has the replication problem. This problem makes decision trees to be large and learnable only when sufficient training data are available. In this paper, we present a new representation model, conditional independence trees (CITrees), to tackle the repli-cation problem from probability perspective. We propose a novel algorithm for learning CITrees. Our experiments show that CITrees outperform naive Bayes (Lan","cites":"8","conferencePercentile":"36.18881119"},{"venue":"AAAI","id":"9794c1179c22d35b5f1bce8f4f2ae38f537082b8","venue_1":"AAAI","year":"2015","title":"Continuity Editing for 3D Animation","authors":"Quentin Galvane, Rémi Ronfard, Christophe Lino, Marc Christie","author_ids":"1810286, 2898850, 2869929, 1701717","abstract":"We describe an optimization-based approach for automatically creating well-edited movies from a 3D animation. While previous work has mostly focused on the problem of placing cameras to produce nice-looking views of the action, the problem of cutting and pasting shots from all available cameras has never been addressed extensively. In this paper, we review the main causes of editing errors in literature and propose an editing model relying on a minimization of such errors. We make a plausible semi-Markov assumption, resulting in a dynamic programming solution which is computation-ally efficient. We also show that our method can generate movies with different editing rhythms and validate the results through a user study. Combined with state-of-the-art cinematography, our approach therefore promises to significantly extend the expressiveness and naturalness of virtual movie-making.","cites":"2","conferencePercentile":"51.65354331"},{"venue":"AAAI","id":"336f91acb18a8fbab4361c1d143fa2b6bf62d7b7","venue_1":"AAAI","year":"2012","title":"Content Recommendation for Attention Management in Unified Social Messaging","authors":"Hongxia Jin","author_ids":"1705713","abstract":"With the growing popularity of social networks and collaboration systems, people are increasingly working with or socially connected with each other. Unified messaging system provides a single interface for users to receive and process information from multiple sources. It is highly desirable to design attention management solution that can help users easily navigate and process dozens of unread messages from a unified message system. Moreover, with the proliferation of mobile devices people are now selectively consuming the most important messages on the go between different activities in their daily life. The information overload problem is especially acute for mobile users with small screen to display. In this paper, we present PAM, an intelligent end-to-end Person-alized Attention Management solution that employs analytical techniques that can learn user interests and organize and prioritize incoming messages based on user interests. For a list of unread messages, PAM generates a concise attention report that allows users to quickly scan the important new messages from his important social connections as well as messages about his most important tasks that the user is involved with. Our solution can also be applied in other applications such as news filtering and alerts on mobile devices. Our evaluation results demonstrate the effectiveness of PAM.","cites":"1","conferencePercentile":"13.87195122"},{"venue":"AAAI","id":"78dcce29e60c768dcb74474400330e54d0a44710","venue_1":"AAAI","year":"2005","title":"A New Strategy-Proof Greedy-Allocation Combinatorial Auction Protocol and Its Extension to Open Ascending Auction Protocol","authors":"Takayuki Ito, Makoto Yokoo, Atsushi Iwasaki, Shigeo Matsubara","author_ids":"1679044, 7157781, 1729674, 1837393","abstract":"This paper proposes a new combinatorial auction protocol called Average-Max-Minimal-Bundle (AM-MB) protocol. The characteristics of the AM-MB protocol are as follows: (i) it is strategyproof, i.e., truth-telling is a dominant strategy, (ii) the computational overhead is very low, since it allocates bundles greedily thereby avoiding an explicit com-binatorial optimization problem, and (iii) it can obtain higher social surplus and revenue than can the Max-Minimal-Bundle (M-MB) protocol, which also satisÞes (i) and (ii). Furthermore , this paper extends the AM-MB protocol to an open ascending-price protocol in which straightforward bidding is an ex-post Nash equilibrium.","cites":"1","conferencePercentile":"11.01398601"},{"venue":"AAAI","id":"632570a89ae9ce63591a3efe5b128fab1f762e38","venue_1":"AAAI","year":"2004","title":"A Qualitative-Quantitative Methods-Based e-Learning Support System in Economic Education","authors":"Tokuro Matsuo, Takayuki Ito, Toramatsu Shintani","author_ids":"2390206, 1679044, 1895121","abstract":"This paper describes a new qualitative-quantitative sim-ulator to help buyers learn how to make decisions when they purchase goods. In this paper, we propose an e-learning support system (LSDM) for assisting user decision making by applying artificial intelligence technology. When buyers purchase expensive items, they must carefully select these items from many alternatives. The learning support system provides useful information that assists consumers in purchasing goods. We employ qualitative simulations because the output simulation results are useful. Our system consists of a qualitative processing system and a quantitative calculation system. When users use the system, they first input information on the goods they want to purchase. The information input by users is used in the qualitative simulation. Next, they supply the details of their budgets, the rate of loans, and several other factors, on a form. The system then integrates the results of simulation and the user's input data and proposes plans to aid in their decision process. The system has several advantages: it can be used by simple input, the process of simulation is easy to understand, users can learn how to make decisions by trial and error, and the users can base their decision making on synthetic results.","cites":"2","conferencePercentile":"18.56287425"},{"venue":"AAAI","id":"119149d1e6919fba4522fc4cfd2e92f9cc214030","venue_1":"AAAI","year":"1994","title":"Automatic Depiction of Spatial Descriptions","authors":"Patrick Olivier, Toshiyuki Maeda, Jun'ichi Tsujii","author_ids":"1707234, 8074262, 8651704","abstract":"A novel combination of ideas from cognitive linguistics and spatial occupancy models in robotics has led to the WIP (Words Into Pictures) system. WIP automatically generates depictions of natural language descriptions of indoor scenes. A qualitative layer in the conceptual representation of objects underlies a mechanism by which alternative depictions arise for qualitatively distinct interpretations, as often occurs as a result of deictic/intrinsic reference frame ambiguity. At the same time, a quantitative layer, in conjunction with a potential field model of the semantics of projective prepositions, is used in the process of capturing the inherently fuzzy character of the meaning of natural language spatial predications.","cites":"22","conferencePercentile":"62.99559471"},{"venue":"AAAI","id":"b43991e13bd95050c85e8676664197e99a66c29b","venue_1":"AAAI","year":"2007","title":"Integrating Natural Language, Knowledge Representation and Reasoning, and Analogical Processing to Learn by Reading","authors":"Kenneth D. Forbus, Christopher Riesbeck, Lawrence Birnbaum, Kevin Livingston, Abhishek B. Sharma, Leo C. Ureel","author_ids":"1713121, 2542226, 1681932, 2447081, 1785252, 2503860","abstract":"Learning by reading requires integrating several strands of AI research. We describe a prototype system, Learning Reader, which combines natural language processing, a large-scale knowledge base, and analogical processing to learn by reading simplified language texts. We outline the architecture of Learning Reader and some of system-level results, then explain how these results arise from the components. Specifically, we describe the design, implementation, and performance characteristics of a natural language understanding model (DMAP) that is tightly coupled to a knowledge base three orders of magnitude larger than previous attempts. We show that knowing the kinds of questions being asked and what might be learned can help provide more relevant, efficient reasoning. Finally, we show that analogical processing provides a means of generating useful new questions and conjectures when the system ruminates off-line about what it has read.","cites":"28","conferencePercentile":"78.93175074"},{"venue":"AAAI","id":"aa07e5520bc89129a75f287b2d0ec3c70ab9425f","venue_1":"AAAI","year":"2014","title":"Crowdsourcing for Multiple-Choice Question Answering","authors":"Bahadir Ismail Aydin, Yavuz Selim Yilmaz, Yaliang Li, Qi Li, Jing Gao, Murat Demirbas","author_ids":"1868343, 2851712, 2694924, 1682467, 1698083, 1803371","abstract":"We leverage crowd wisdom for multiple-choice question answering, and employ lightweight machine learning techniques to improve the aggregation accuracy of crowdsourced answers to these questions. In order to develop more effective aggregation methods and evaluate them empirically, we developed and deployed a crowdsourced system for playing the \" Who wants to be a millionaire? \" quiz show. Analyzing our data (which consist of more than 200,000 answers), we find that by just going with the most selected answer in the aggrega-tion, we can answer over 90% of the questions correctly, but the success rate of this technique plunges to 60% for the later/harder questions in the quiz show. To improve the success rates of these later/harder questions, we investigate novel weighted aggregation schemes for aggregating the answers obtained from the crowd. By using weights optimized for reliability of participants (derived from the participants' confidence), we show that we can pull up the accuracy rate for the harder questions by 15%, and to overall 95% average accuracy. Our results provide a good case for the benefits of applying machine learning techniques for building more accurate crowdsourced question answering systems.","cites":"11","conferencePercentile":"89.54545455"},{"venue":"AAAI","id":"df8db63667a72137c83ef8a89204744fe933286d","venue_1":"AAAI","year":"2015","title":"Eigenvalues Ratio for Kernel Selection of Kernel Methods","authors":"Yong Liu, Shizhong Liao","author_ids":"7135550, 8376033","abstract":"The selection of kernel function which determines the mapping between the input space and the feature space is of crucial importance to kernel methods. Existing kernel selection approaches commonly use some measures of generalization error, which are usually difficult to estimate and have slow convergence rates. In this paper, we propose a novel measure, called eigenvalues ratio (ER), of the tight bound of generalization error for kernel selection. ER is the ratio between the sum of the main eigenvalues and that of the tail eigenvalues of the kernel matrix. Different from most of existing measures, ER is defined on the kernel matrix, so it can be estimated easily from the available training data, which makes it usable for kernel selection. We establish tight ER-based generalization error bounds of order O 1 n for several kernel-based methods under certain general conditions, while for most of existing measures, the convergence rate is at most O 1 √ n. Finally , to guarantee good generalization performance, we propose a novel kernel selection criterion by minimizing the derived tight generalization error bounds. Theoretical analysis and experimental results demonstrate that our kernel selection criterion is a good choice for kernel selection.","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"dbc4bf1e371cff4410018642b261ecf9cfda8c36","venue_1":"AAAI","year":"2006","title":"Ontology Based Semantic Modeling for Chinese Ancient Architectures","authors":"Yong Liu, Congfu Xu, Qiong Zhang, Yunhe Pan","author_ids":"7135550, 1682914, 7137272, 1778259","abstract":"Figure 1: Ancient architectures in southeast China; the top two photos are taken from Hefang Street in Hangzhou, and the other two are taken from Xitang town, Zhejiang Province. Abstract Modeling complex architectures is quite challenging. We introduce a novel intelligent system, which can generate semi-style or semi-structure Chinese ancient ar-chitectures automatically. By using an ontology based approach to analyze the styles of different architectures, geometry primitives (e.g. point, line, triangle, etc.) are converted into semantic architecture components (e.g. window, gate, roof, etc.) as knowledge. The following modeling process can be performed at different semantic levels, and it is appealing to users having domain knowledge. This intelligent architecture modeling system has been successfully applied in the digital heritage project for ancient architectures in southeast China.","cites":"0","conferencePercentile":"5.763688761"},{"venue":"AAAI","id":"9b1a1a1f9fba3bf3eff4d6b28ed38f7cfe7a3404","venue_1":"AAAI","year":"2012","title":"Approximating the Sum Operation for Marginal-MAP Inference","authors":"Qiang Cheng, Feng Chen, Jianwu Dong, Wenli Xu, Alexander T. Ihler","author_ids":"1732433, 1692998, 1729233, 1779759, 1740137","abstract":"We study the marginal-MAP problem on graphical models, and present a novel approximation method based on direct approximation of the sum operation. A primary difficulty of marginal-MAP problems lies in the non-commutativity of the sum and max operations, so that even in highly structured models, marginaliza-tion may produce a densely connected graph over the variables to be maximized, resulting in an intractable potential function with exponential size. We propose a chain decomposition approach for summing over the marginalized variables, in which we produce a struc-tured approximation to the MAP component of the problem consisting of only pairwise potentials. We show that this approach is equivalent to the maximiza-tion of a specific variational free energy, and it provides an upper bound of the optimal probability. Finally, experimental results demonstrate that our method performs favorably compared to previous methods.","cites":"1","conferencePercentile":"13.87195122"},{"venue":"AAAI","id":"0b29405972b49c6fb836373aa70822ffff494cec","venue_1":"AAAI","year":"2013","title":"A Generalized Student-t Based Approach to Mixed-Type Anomaly Detection","authors":"Yen-Cheng Lu, Feng Chen, Yang Chen, Chang-Tien Lu","author_ids":"2236202, 1692998, 5347575, 1752590","abstract":"Anomaly detection for mixed-type data is an important problem that has not been well addressed in the machine learning field. There are two challenging issues for mixed-type datasets, namely modeling mutual correlations between mixed-type attributes and capturing large variations due to anomalies. This paper presents BuffDetect, a robust error buffering approach for anomaly detection in mixed-type datasets. A new variant of the generalized linear model is proposed to model the dependency between mixed-type attributes. The model incorporates an error buffering component based on Student-t distribution to absorb the variations caused by anomalies. However, because of the non-Gaussian design, the problem becomes analytically intractable. We propose a novel Bayesian inference approach , which integrates Laplace approximation and several computational optimizations, and is able to efficiently approximate the posterior of high dimensional latent variables by iteratively updating the latent variables in groups. Extensive experimental evaluations based on 13 benchmark datasets demonstrate the effectiveness and efficiency of BuffDetect.","cites":"1","conferencePercentile":"25.09090909"},{"venue":"AAAI","id":"4f8b560f5c1761051f214d8b381333864152d421","venue_1":"AAAI","year":"2016","title":"Efficient Nonparametric Subgraph Detection Using Tree Shaped Priors","authors":"Nannan Wu, Feng Chen, Jianxin Li, Baojian Zhou, Naren Ramakrishnan","author_ids":"3232191, 1692998, 1716071, 2787368, 1755938","abstract":"Non-parametric graph scan (NPGS) statistics are used to detect anomalous connected subgraphs on graphs, and have a wide variety of applications, such as disease outbreak detection, road traffic congestion detection , and event detection in social media. In contrast to traditional parametric scan statistics (e.g., the Kulldorff statistic), NPGS statistics are free of distributional assumptions and can be applied to heterogeneous graph data. In this paper, we make a number of contributions to the computational study of NPGS statistics. First, we present a novel reformulation of the problem as a sequence of Budget Price-Collecting Steiner Tree (B-PCST) sub-problems. Second, we show that this refor-mulated problem is NP-hard for a large class of non-parametric statistic functions. Third, we further develop efficient exact and approximate algorithms for a special category of graphs in which the anomalous subgraphs can be reformulated in a fixed tree topology. Finally, using extensive experiments we demonstrate the performance of our proposed algorithms in two real-world application domains (water pollution detection in water sensor networks and spatial event detection in social media networks) and contrast against state-of-the-art connected subgraph detection methods.","cites":"1","conferencePercentile":"40.70945946"},{"venue":"AAAI","id":"42e57b767691d08318c92ddc8777aaab2bbb25e8","venue_1":"AAAI","year":"2016","title":"Assumed Density Filtering Methods for Learning Bayesian Neural Networks","authors":"Soumya Ghosh, Francesco Maria Delle Fave, Jonathan S. Yedidia","author_ids":"4944352, 1780619, 3198578","abstract":"Buoyed by the success of deep multilayer neural networks , there is renewed interest in scalable learning of Bayesian neural networks. Here, we study algorithms that utilize recent advances in Bayesian inference to efficiently learn distributions over network weights. In particular, we focus on recently proposed assumed density filtering based methods for learning Bayesian neu-ral networks – Expectation and Probabilistic backpropa-gation. Apart from scaling to large datasets, these techniques seamlessly deal with non-differentiable activation functions and provide parameter (learning rate, momentum) free learning. In this paper, we first rigorously compare the two algorithms and in the process develop several extensions, including a version of EBP for continuous regression problems and a PBP variant for binary classification. Next, we extend both algorithms to deal with multiclass classification and count regression problems. On a variety of diverse real world benchmarks , we find our extensions to be effective, achieving results competitive with the state-of-the-art.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"1a0de81a35c3c19d0c3fc6b0088deba18a4f422e","venue_1":"AAAI","year":"2015","title":"The Boundary Forest Algorithm for Online Supervised and Unsupervised Learning","authors":"Charles Mathy, Nate Derbinsky, José Bento, Jonathan Rosenthal, Jonathan S. Yedidia","author_ids":"2285959, 2646965, 8408343, 1919922, 3198578","abstract":"We describe a new instance-based learning algorithm called the Boundary Forest (BF) algorithm, that can be used for supervised and unsupervised learning. The algorithm builds a forest of trees whose nodes store previously seen examples. It can be shown data points one at a time and updates itself incrementally, hence it is naturally online. Few instance-based algorithms have this property while being simultaneously fast, which the BF is. This is crucial for applications where one needs to respond to input data in real time. The number of children of each node is not set beforehand but obtained from the training procedure, which makes the algorithm very flexible with regards to what data manifolds it can learn. We test its generalization performance and speed on a range of benchmark datasets and detail in which settings it outperforms the state of the art. Empirically we find that training time scales as O(DN log(N)) and testing as O(Dlog(N)), where D is the dimensionality and N the amount of data.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"70049eac376c3f467eb453533942f3e2061a0799","venue_1":"AAAI","year":"2015","title":"Proximal operators for multi-agent path planning","authors":"José Bento, Nate Derbinsky, Charles Mathy, Jonathan S. Yedidia","author_ids":"8408343, 2646965, 2285959, 3198578","abstract":"We address the problem of planning collision-free paths for multiple agents using optimization methods known as proximal algorithms. Recently this approach was explored in Bento et al. (2013), which demonstrated its ease of parallelization and decentralization, the speed with which the algorithms generate good quality solutions , and its ability to incorporate different proximal operators, each ensuring that paths satisfy a desired property. Unfortunately, the operators derived only apply to paths in 2D and require that any intermediate waypoints we might want agents to follow be preas-signed to specific agents, limiting their range of applicability. In this paper we resolve these limitations. We introduce new operators to deal with agents moving in arbitrary dimensions that are faster to compute than their 2D predecessors and we introduce landmarks, space-time positions that are automatically assigned to the set of agents under different optimality criteria. Finally, we report the performance of the new operators in several numerical experiments.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"42c4b93738102fa1a9dd12bb0bcae475d751a69e","venue_1":"AAAI","year":"2007","title":"Autonomous Development of a Grounded Object Ontology by a Learning Robot","authors":"Joseph Modayil, Benjamin Kuipers","author_ids":"3321484, 1688294","abstract":"We describe how a physical robot can learn about objects from its own autonomous experience in the continuous world. The robot identifies statistical regularities that allow it to represent a physical object with a cluster of sensations that violate a static world model, track that cluster over time, extract percepts from that cluster, form concepts from similar percepts, and learn reliable actions that can be applied to objects. We present a formalism for representing the ontology for objects and actions, a learning algorithm, and the results of an evaluation with a physical robot.","cites":"34","conferencePercentile":"85.16320475"},{"venue":"AAAI","id":"8475f0cba13ca793231f6814700568ba9d38f994","venue_1":"AAAI","year":"2016","title":"Topical Analysis of Interactions Between News and Social Media","authors":"Ting Hua, Yue Ning, Feng Chen, Chang-Tien Lu, Naren Ramakrishnan","author_ids":"1801004, 1957838, 1692998, 1752590, 1755938","abstract":"The analysis of interactions between social media and traditional news streams is becoming increasingly relevant for a variety of applications, including: understanding the underlying factors that drive the evolution of data sources, tracking the triggers behind events, and discovering emerging trends. Researchers have explored such interactions by examining volume changes or information diffusions, however, most of them ignore the semantical and topical relationships between news and social media data. Our work is the first attempt to study how news influences social media, or inversely, based on topical knowledge. We propose a hierarchical Bayesian model that jointly models the news and social media topics and their interactions. We show that our proposed model can capture distinct topics for individual datasets as well as discover the topic influences among multiple datasets. By applying our model to large sets of news and tweets, we demonstrate its significant improvement over baseline methods and explore its power in the discovery of interesting patterns for real world cases.","cites":"5","conferencePercentile":"86.31756757"},{"venue":"AAAI","id":"0123ae1b80f51d21fb232f35ef2f7f05279d4919","venue_1":"AAAI","year":"2005","title":"Large-Scale Localization from Wireless Signal Strength","authors":"Julie Letchner, Dieter Fox, Anthony LaMarca","author_ids":"1871864, 1776234, 7871341","abstract":"Knowledge of the physical locations of mobile devices such as laptops or PDA's is becoming increasingly important with the rise of location-based services such as specialized web search, navigation, and social network applications; furthermore , location information is a key foundation for high-level activity inferencing. In this paper we propose a novel technique for accurately estimating the locations of mobile devices and their wearers from wireless signal strengths. Our technique estimates time-varying device locations on a spatial connectivity graph whose outdoor edges correspond to streets and whose indoor edges represent hallways, staircases, elevators, etc. Use of a hierarchical Bayesian framework for learning a signal strength sensor model allows us not only to achieve higher accuracy than existing approaches, but to overcome many of their limitations. In particular, our technique is able to (1) seamlessly integrate new access points into the model, (2) make use of negative information (not detecting an access point), and (3) bootstrap a sensor model from sparse training data. Experiments demonstrate various properties of our system.","cites":"73","conferencePercentile":"95.27972028"},{"venue":"AAAI","id":"1faccf38fc41328b4d60269400b72412988633b6","venue_1":"AAAI","year":"1994","title":"An Artificial Discourse Language for Collaborative Negotiation","authors":"Candace L. Sidner","author_ids":"2668280","abstract":"Collaborations to accomplish common goals necessitate negotiation to share and reach agreement on the beliefs that agents hold as part of the collaboration. Negotiation in communication can be simulated by a series of exchanges in which agents propose, reject, counterpropose or seek supporting information for beliefs they wish to be held mutually. In an artificial language of negotiation, messages display the state of the agents' beliefs. Dialogues consisting of such messages clarify the means by which agents come to agree or fail to agree on mutual beliefs and individual intentions .","cites":"84","conferencePercentile":"91.18942731"},{"venue":"AAAI","id":"11431d45eca21b036cd6e5d0d62fa295e97b37ba","venue_1":"AAAI","year":"2012","title":"Discovering Spammers in Social Networks","authors":"Yin Zhu, Xiao Wang, Erheng Zhong, Nathan Nan Liu, He Li, Qiang Yang","author_ids":"6002814, 2632562, 1762818, 1768416, 1715041, 1733090","abstract":"As the popularity of the social media increases, as evidenced in Twitter, Facebook and China's Renren, spamming activities also picked up in numbers and variety. On social network sites, spammers often disguise themselves by creating fake accounts and hijacking normal users' accounts for personal gains. Different from the spammers in traditional systems such as SMS and email, spammers in social media behave like normal users and they continue to change their spamming strategies to fool anti-spamming systems. However, due to the privacy and resource concerns, many social media websites cannot fully monitor all the contents of users, making many of the previous approaches, such as topology-based and content-classification-based methods , infeasible to use. In this paper, we propose a Supervised Matrix Factorization method with Social Reg-ularization (SMFSR) for spammer detection in social networks that exploits both social activities as well as users' social relations in an innovative and highly scal-able manner. The proposed method detects spammers collectively based on users' social actions and social relations. We have empirically tested our method on data from Renren.com, which is one of the largest social networks in China, and demonstrated that our new method can improve the detection performance significantly.","cites":"18","conferencePercentile":"86.73780488"},{"venue":"AAAI","id":"001b57f4f9718b8230e564811f1c1f5f46c1b89e","venue_1":"AAAI","year":"2011","title":"Active Dual Collaborative Filtering with Both Item and Attribute Feedback","authors":"Luheng He, Nathan Nan Liu, Qiang Yang","author_ids":"3169141, 1768416, 1733090","abstract":"The new user problem (aka user cold start) is very common in online recommender systems. Active collabora-tive filtering (active CF) tries to solve this problem by intelligently soliciting user feedback in order to build an initial user profile with minimal costs. Existing methods only query the user for feedback on items, while users can have preferences over items as well as certain item attributes. In this paper, we extend active CF via user feedback on both items and attributes. For example , when making movie recommendations, the system can ask users for not only their favorite movies, but also attributes such as genres, actors, etc. We design a unified active CF framework for incorporating both item and attribute feedback based on the random walk model. We test the active CF algorithm on real-world movie recommendation data sets to demonstrate that appropriately querying for both item and feature feedback can significantly reduce the overall user effort measured in terms of number of queries. We show that we can achieve much better recommendation quality as compared to traditional active CF methods that support only item feedback.","cites":"6","conferencePercentile":"49.14089347"},{"venue":"AAAI","id":"479a7e182c7a6a2e2a802b4085adf91709867d33","venue_1":"AAAI","year":"2010","title":"Transfer Learning in Collaborative Filtering for Sparsity Reduction","authors":"Weike Pan, Evan Wei Xiang, Nathan Nan Liu, Qiang Yang","author_ids":"1746462, 1687976, 1768416, 1733090","abstract":"Data sparsity is a major problem for collaborative filtering (CF) techniques in recommender systems, especially for new users and items. We observe that, while our target data are sparse for CF systems, related and relatively dense auxiliary data may already exist in some other more mature application domains. In this paper, we address the data sparsity problem in a target domain by transferring knowledge about both users and items from auxiliary data sources. We observe that in different domains the user feedbacks are often heterogeneous such as ratings vs. clicks. Our solution is to integrate both user and item knowledge in auxiliary data sources through a principled matrix-based transfer learning framework that takes into account the data heterogeneity. In particular, we discover the principle coordinates of both users and items in the auxiliary data matrices, and transfer them to the target domain in order to reduce the effect of data sparsity. We describe our method, which is known as coordinate system transfer or CST, and demonstrate its effectiveness in alleviating the data sparsity problem in collaborative filtering. We show that our proposed method can significantly outperform several state-of-the-art solutions for this problem.","cites":"67","conferencePercentile":"97.6109215"},{"venue":"AAAI","id":"cfd3e95b8c957f541f6d312fa84675843791c908","venue_1":"AAAI","year":"2005","title":"Distributing Coalitional Value Calculations among Cooperative Agents","authors":"Talal Rahwan, Nicholas R. Jennings","author_ids":"1775071, 1786650","abstract":"The process of forming coalitions of software agents generally requires calculating a value for every possible coalition which indicates how beneficial that coalition would be if it was formed. Now, since the number of possible coalitions increases exponentially with the number of agents involved, having one agent calculate all the values is inefficient. Given this, we present a novel algorithm for distributing this calculation among agents in cooperative environments. Specifically, by using our algorithm, each agent is assigned some part of the calculation such that the agents' shares are exhaustive and disjoint. Moreover, the algorithm is decentralized, requires no communication between the agents, and has minimal memory requirements. To evaluate the effectiveness of our algorithm we compare it with the only other algorithm available in the literature (due to Shehory and Kraus). This shows that for the case of 25 agents, the distribution process of our algorithm took 0.00037% of the time, the values were calculated using 0.000006% of the memory, the calculation redundancy was reduced from 477826101 to 0, and the total number of bytes sent between the agents dropped from 674047872 to 0 (note that for larger numbers of agents, these improvements become exponentially better).","cites":"16","conferencePercentile":"61.53846154"},{"venue":"AAAI","id":"216ec9333971cdaeddce7cafac70dbfe0cfa905d","venue_1":"AAAI","year":"2006","title":"Overlapping Coalition Formation for Efficient Data Fusion in Multi-Sensor Networks","authors":"Viet Dung Dang, Rajdeep K. Dash, Alex Rogers, Nicholas R. Jennings","author_ids":"2210655, 3030770, 1793672, 1786650","abstract":"This paper develops new algorithms for coalition formation within multi-sensor networks tasked with performing wide-area surveillance. Specifically, we cast this application as an instance of coalition formation, with overlapping coalitions. We show that within this application area sub-additive coalition valuations are typical, and we thus use this structural property of the problem to derive two novel algorithms (an approximate greedy one that operates in polynomial time and has a calculated bound to the optimum, and an optimal branch-and-bound one) to find the optimal coalition structure in this instance. We empirically evaluate the performance of these algorithms within a generic model of a multi-sensor network performing wide area surveillance. These results show that the polynomial algorithm typically generated solutions much closer to the optimal than the theoretical bound, and prove the effectiveness of our pruning procedure.","cites":"45","conferencePercentile":"86.59942363"},{"venue":"AAAI","id":"75ec468e6e8a5a8d6ca4c133c02c430b1cf876a8","venue_1":"AAAI","year":"2008","title":"Coalition Structure Generation: Dynamic Programming Meets Anytime Optimization","authors":"Talal Rahwan, Nicholas R. Jennings","author_ids":"1775071, 1786650","abstract":"Coalition structure generation involves partitioning a set of agents into exhaustive and disjoint coalitions so as to maximize the social welfare. What makes this such a challenging problem is that the number of possible solutions grows exponentially as the number of agents increases. To date, two main approaches have been developed to solve this problem, each with its own strengths and weaknesses. The state of the art in the first approach is the Improved Dynamic Programming (IDP) algorithm , due to Rahwan and Jennings, that is guaranteed to find an optimal solution in O(3 n), but which cannot generate a solution until it has completed its entire execution. The state of the art in the second approach is an anytime algorithm called IP, due to Rahwan et al., that provides worst-case guarantees on the quality of the best solution found so far, but which is O(n n). In this paper, we develop a novel algorithm that combines both IDP and IP, resulting in a hybrid performance that exploits the strength of both algorithms and, at the same, avoids their main weaknesses. Our approach is also significantly faster (e.g. given 25 agents, it takes only 28% of the time required by IP, and 0.3% of the time required by IDP).","cites":"33","conferencePercentile":"89.08227848"},{"venue":"AAAI","id":"e5992c4df3945acde6646327c75ec72548b05b30","venue_1":"AAAI","year":"2010","title":"Epsilon-First Policies for Budget-Limited Multi-Armed Bandits","authors":"Long Tran-Thanh, Archie C. Chapman, Enrique Munoz de Cote, Alex Rogers, Nicholas R. Jennings","author_ids":"2757815, 1996149, 2643564, 1793672, 1786650","abstract":"We introduce the budget–limited multi–armed bandit (MAB), which captures situations where a learner's actions are costly and constrained by a fixed budget that is incommensurable with the rewards earned from the bandit machine, and then describe a first algorithm for solving it. Since the learner has a budget, the problem's duration is finite. Consequently an optimal exploitation policy is not to pull the optimal arm repeatedly , but to pull the combination of arms that maximises the agent's total reward within the budget. As such, the rewards for all arms must be estimated, because any of them may appear in the optimal combination. This di erence from existing MABs means that new approaches to maximising the total reward are required. To this end, we propose an –first algorithm, in which the first of the budget is used solely to learn the arms' rewards (exploration), while the remaining 1 is used to maximise the received reward based on those estimates (exploitation). We derive bounds on the algorithm's loss for generic and uniform exploration methods, and compare its performance with traditional MAB algorithms under various distributions of rewards and costs, showing that it out-performs the others by up to 50%.","cites":"32","conferencePercentile":"87.37201365"},{"venue":"AAAI","id":"6bb4e866d4f38ed0c1edcd3d6cc44f62cba4b85d","venue_1":"AAAI","year":"2010","title":"A Decentralised Coordination Algorithm for Mobile Sensors","authors":"Ruben Stranders, Francesco Maria Delle Fave, Alex Rogers, Nicholas R. Jennings","author_ids":"2446693, 1780619, 1793672, 1786650","abstract":"We present an on-line decentralised algorithm for coordinating mobile sensors for a broad class of information gathering tasks. These sensors can be deployed in unknown and possibly hostile environments, where uncertainty and dynamism are endemic. Such environments are common in the areas of disaster response and military surveillance. Our coordination approach itself is based on work by Stranders et al. (2009), that uses the max-sum algorithm to coordinate mobile sensors for monitoring spatial phenomena. In particular , we generalise and extend their approach to any domain where measurements can be valued. Also, we introduce a clustering approach that allows sensors to negotiate over paths to the most relevant locations, as opposed to a set of fixed directions, which results in a significantly improved performance. We demonstrate our algorithm by applying it to two challenging and distinct information gathering tasks. In the first–pursuit-evasion (PE)–sensors need to capture a target whose movement might be unknown. In the second– patrolling (P)–sensors need to minimise loss from intrusions that occur within their environment. In doing so, we obtain the first decentralised coordination algorithms for these domains. Finally, in each domain, we empirically evaluate our approach in a simulated environment, and show that it outper-forms two state of the art greedy algorithms by 30% (PE) and 44% (P), and an existing approach based on the Travelling Salesman Problem by 52% (PE) and 30% (P).","cites":"8","conferencePercentile":"43.85665529"},{"venue":"AAAI","id":"2e786cc5e807a59333e0cc0eec5e1d1505215a1d","venue_1":"AAAI","year":"2010","title":"A Distributed Algorithm for Optimising over Pure Strategy Nash Equilibria","authors":"Archie C. Chapman, Alessandro Farinelli, Enrique Munoz de Cote, Alex Rogers, Nicholas R. Jennings","author_ids":"1996149, 1690281, 2643564, 1793672, 1786650","abstract":"We develop an efficient algorithm for computing pure strategy Nash equilibria that satisfy various criteria (such as the utilitarian or Nash–Bernoulli social welfare functions) in games with sparse interaction structure. Our algorithm, called Valued Nash Propagation (VNP), integrates the optimisation problem of maximising a criterion with the constraint satisfaction problem of finding a game's equilibria to construct a criterion that defines a c–semiring. Given a suitably compact game structure, this criterion can be efficiently optimised using message–passing. To this end, we first show that VNP is complete in games whose interaction structure forms a hy-pertree. Then, we go on to provide theoretic and empirical results justifying its use on games with arbitrary structure; in particular, we show that it computes the optimum >82% of the time and otherwise selects an equilibrium that is always within 2% of the optimum on average.","cites":"5","conferencePercentile":"32.08191126"},{"venue":"AAAI","id":"248cd23dde66658d7b307934335fd37e4d5d9b3a","venue_1":"AAAI","year":"2010","title":"Convergence to Equilibria in Plurality Voting","authors":"Reshef Meir, Maria Polukarov, Jeffrey S. Rosenschein, Nicholas R. Jennings","author_ids":"1769579, 2277974, 1735970, 1786650","abstract":"Multi-agent decision problems, in which independent agents have to agree on a joint plan of action or allocation of resources , are central to AI. In such situations, agents' individual preferences over available alternatives may vary, and they may try to reconcile these differences by voting. Based on the fact that agents may have incentives to vote strategically and misreport their real preferences, a number of recent papers have explored different possibilities for avoiding or eliminating such manipulations. In contrast to most prior work, this paper focuses on convergence of strategic behavior to a decision from which no voter will want to deviate. We consider scenarios where voters cannot coordinate their actions, but are allowed to change their vote after observing the current outcome. We focus on the Plurality voting rule, and study the conditions under which this iterative game is guaranteed to converge to a Nash equilibrium (i.e., to a decision that is stable against further unilateral manipulations). We show for the first time how convergence depends on the exact attributes of the game, such as the tie-breaking scheme, and on assumptions regarding agents' weights and strategies.","cites":"48","conferencePercentile":"93.85665529"},{"venue":"AAAI","id":"306d7684fa24e0ce8eff058ed4ab809000cca3ef","venue_1":"AAAI","year":"2010","title":"Reinforcement Learning via AIXI Approximation","authors":"Joel Veness, Kee Siong Ng, Marcus Hutter, David Silver","author_ids":"1798128, 1807542, 1790857, 6143136","abstract":"This paper introduces a principled approach for the design of a scalable general reinforcement learning agent. This approach is based on a direct approximation of AIXI, a Bayesian optimality notion for general reinforcement learning agents. Previously, it has been unclear whether the theory of AIXI could motivate the design of practical algorithms. We answer this hitherto open question in the affirmative, by providing the first computationally feasible approximation to the AIXI agent. To develop our approximation, we introduce a Monte Carlo Tree Search algorithm along with an agent-specific extension of the Context Tree Weighting algorithm. Empirically, we present a set of encouraging results on a number of stochastic, unknown, and partially observable domains.","cites":"14","conferencePercentile":"63.48122867"},{"venue":"AAAI","id":"38ee12315cbb52cc297ee97a478f36b5403ec853","venue_1":"AAAI","year":"2011","title":"Constrained Coalition Formation","authors":"Talal Rahwan, Tomasz P. Michalak, Edith Elkind, Piotr Faliszewski, Jacek Sroka, Michael Wooldridge, Nicholas R. Jennings","author_ids":"1775071, 1806560, 1729566, 2469517, 8696870, 4769905, 1786650","abstract":"The conventional model of coalition formation considers every possible subset of agents as a potential coalition. However , in many real-world applications, there are inherent constraints on feasible coalitions: for instance, certain agents may be prohibited from being in the same coalition, or the coalition structure may be required to consist of coalitions of the same size. In this paper, we present the first systematic study of constrained coalition formation (CCF). We propose a general framework for this problem, and identify an important class of CCF settings, where the constraints specify which groups of agents should/should not work together. We describe a procedure that transforms such constraints into a structured input that allows coalition formation algorithms to identify, without any redundant computations, all the feasible coalitions. We then use this procedure to develop an algorithm for generating an optimal (welfare-maximizing) constrained coalition structure, and show that it outperforms existing state-of-the-art approaches by several orders of magnitude .","cites":"21","conferencePercentile":"88.65979381"},{"venue":"AAAI","id":"3b9732bb07dc99bde5e1f9f75251c6ea5039373e","venue_1":"AAAI","year":"2016","title":"Deep Reinforcement Learning with Double Q-Learning","authors":"Hado van Hasselt, Arthur Guez, David Silver","author_ids":"3226493, 2557085, 6143136","abstract":"The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such over-estimations are common, whether this harms performance, and whether they can generally be prevented. In this paper, we answer all these questions affirmatively. In particular, we first show that the recent DQN algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a specific adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized , but that this also leads to much better performance on several games. The goal of reinforcement learning (Sutton and Barto, 1998) is to learn good policies for sequential decision problems, by optimizing a cumulative future reward signal. Q-learning (Watkins, 1989) is one of the most popular reinforcement learning algorithms , but it is known to sometimes learn unrealistically high action values because it includes a maximization step over estimated action values, which tends to prefer overestimated to underestimated values. In previous work, overestimations have been attributed to insufficiently flexible function approximation (Thrun and Schwartz, 1993) and noise (van Hasselt, 2010, 2011). In this paper, we unify these views and show overestimations can occur when the action values are inaccurate, irrespective of the source of approximation error. Of course, imprecise value estimates are the norm during learning, which indicates that overestimations may be much more common than previously appreciated. It is an open question whether, if the overestimations do occur, this negatively affects performance in practice. Overoptimistic value estimates are not necessarily a problem in and of themselves. If all values would be uniformly higher then the relative action preferences are preserved and we would not expect the resulting policy to be any worse. Furthermore, it is known that sometimes it is good to be optimistic: optimism in the face of uncertainty is a well-known exploration technique (Kaelbling et al., 1996). If, however, the overestimations are not uniform and not concentrated at states about which we wish to learn more, then they might negatively affect the quality of the resulting policy. Thrun and Schwartz (1993) give specific examples in which this leads to suboptimal policies, …","cites":"57","conferencePercentile":"99.66216216"},{"venue":"AAAI","id":"b851f7190b85fdbea779c6846f1b241065986e6b","venue_1":"AAAI","year":"2012","title":"A Hybrid Algorithm for Coalition Structure Generation","authors":"Talal Rahwan, Tomasz P. Michalak, Nicholas R. Jennings","author_ids":"1775071, 1806560, 1786650","abstract":"The current state-of-the-art algorithm for optimal coalition structure generation is IDP-IP—an algorithm that combines IDP (a dynamic programming algorithm due to Rahwan and Jennings, 2008b) with IP (a tree-search algorithm due to Rah-wan et al., 2009). In this paper we analyse IDP-IP, highlight its limitations, and then develop a new approach for combining IDP with IP that overcomes these limitations.","cites":"15","conferencePercentile":"81.55487805"},{"venue":"AAAI","id":"427adb906bf1f13ad182c909c607696650a717d8","venue_1":"AAAI","year":"2012","title":"Optimizing Payments in Dominant-Strategy Mechanisms for Multi-Parameter Domains","authors":"Lachlan Dufton, Victor Naroditskiy, Maria Polukarov, Nicholas R. Jennings","author_ids":"2182482, 2149740, 2277974, 1786650","abstract":"In AI research, mechanism design is typically used to allocate tasks and resources to agents holding private information about their values for possible allocations. In this context , optimizing payments within the Groves class has recently received much attention, mostly under the assumption that agent's private information is single-dimensional. Our work tackles this problem in multi-parameter domains. Specifically, we develop a generic technique to look for a best Groves mechanism for any given mechanism design problem. Our method is based on partitioning the spaces of agent values and payment functions into regions, on each of which we are able to define a feasible linear payment function. Under certain geometric conditions on partitions of the two spaces this function is optimal. We illustrate our method by applying it to the problem of allocating heterogeneous items.","cites":"3","conferencePercentile":"30.79268293"},{"venue":"AAAI","id":"34652e1e78b8ff36854793cc9b812958529cb36e","venue_1":"AAAI","year":"2012","title":"Knapsack based Optimal Policies for Budget-Limited Multi-Armed Bandits","authors":"Long Tran-Thanh, Archie C. Chapman, Alex Rogers, Nicholas R. Jennings","author_ids":"2757815, 1996149, 1793672, 1786650","abstract":"In budget–limited multi–armed bandit (MAB) problems, the learner's actions are costly and constrained by a fixed budget. Consequently, an optimal exploitation policy may not be to pull the optimal arm repeatedly, as is the case in other variants of MAB, but rather to pull the sequence of different arms that maximises the agent's total reward within the budget. This difference from existing MABs means that new approaches to max-imising the total reward are required. Given this, we develop two pulling policies, namely: (i) KUBE; and (ii) fractional KUBE. Whereas the former provides better performance up to 40% in our experimental settings, the latter is computationally less expensive. We also prove logarithmic upper bounds for the regret of both policies, and show that these bounds are asymptotically optimal (i.e. they only differ from the best possible regret by a constant factor).","cites":"43","conferencePercentile":"96.79878049"},{"venue":"AAAI","id":"2dff877c131a56744c08906f94516d2c412d7619","venue_1":"AAAI","year":"2014","title":"Regret-Based Multi-Agent Coordination with Uncertain Task Rewards","authors":"Feng Wu, Nicholas R. Jennings","author_ids":"3516792, 1786650","abstract":"Many multi-agent coordination problems can be represented as DCOPs. Motivated by task allocation in disaster response, we extend standard DCOP models to consider uncertain task rewards where the outcome of completing a task depends on its current state, which is randomly drawn from unknown distributions. The goal of solving this problem is to find a solution for all agents that minimizes the overall worst-case loss. This is a challenging problem for centralized algorithms because the search space grows exponentially with the number of agents and is nontrivial for standard DCOP algorithms we have. To address this, we propose a novel decentralized algorithm that incorporates Max-Sum with iterative constraint generation to solve the problem by passing messages among agents. By so doing, our approach scales well and can solve instances of the task allocation problem with hundreds of agents and tasks.","cites":"7","conferencePercentile":"77.5"},{"venue":"AAAI","id":"1921f1a1f3f021f3ed92d15e94338665cd9e293e","venue_1":"AAAI","year":"2014","title":"Efficient Buyer Groups for Prediction-of-Use Electricity Tariffs","authors":"Valentin Robu, Meritxell Vinyals, Alex Rogers, Nicholas R. Jennings","author_ids":"1718021, 3351598, 1793672, 1786650","abstract":"Current electricity tariffs do not reflect the real cost that customers incur to suppliers, as units are charged at the same rate, regardless of how predictable each cus-tomer's consumption is. A recent proposal to address this problem are prediction-of-use tariffs. In such tariffs , a customer is asked in advance to predict her future consumption, and is charged based both on her actual consumption and the deviation from her prediction. Prior work (Vinyals et al. 2014) studied the cost game induced by a single such tariff, and showed customers would have an incentive to minimize their risk, by joining together when buying electricity as a grand coalition. In this work we study the efficient (i.e. cost-minimizing) structure of buying groups for the more realistic setting when multiple, competing prediction-of-use tariffs are available. We propose a polynomial time algorithm to compute efficient buyer groups, and validate our approach experimentally, using a large-scale data set of domestic electricity consumers in the UK.","cites":"1","conferencePercentile":"25.90909091"},{"venue":"AAAI","id":"27a49f9fb299d9587829ca4fbe1c09d2ac5db217","venue_1":"AAAI","year":"2015","title":"Towards Optimal Solar Tracking: A Dynamic Programming Approach","authors":"Athanasios Aris Panagopoulos, Georgios Chalkiadakis, Nicholas R. Jennings","author_ids":"2686417, 3169479, 1786650","abstract":"The power output of photovoltaic systems (PVS) increases with the use of effective and efficient solar tracking techniques. However, current techniques suffer from several drawbacks in their tracking policy: (i) they usually do not consider the forecasted or prevailing weather conditions; even when they do, they (ii) rely on complex closed-loop controllers and sophisticated instruments; and (iii) typically, they do not take the energy consumption of the trackers into account. In this paper, we propose a policy iteration method (along with specialized variants), which is able to calculate near-optimal trajectories for effective and efficient day-ahead solar tracking, based on weather forecasts coming from on-line providers. To account for the energy needs of the tracking system, the technique employs a novel and generic consumption model. Our simulations show that the proposed methods can increase the power output of a PVS considerably, when compared to standard solar tracking techniques.","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"2f4ac27bee73ef5832dc2e5a4b0316d43b492103","venue_1":"AAAI","year":"2015","title":"On the Convergence of Iterative Voting: How Restrictive Should Restricted Dynamics Be?","authors":"Svetlana Obraztsova, Evangelos Markakis, Maria Polukarov, Zinovi Rabinovich, Nicholas R. Jennings","author_ids":"1773297, 1737120, 2277974, 1756878, 1786650","abstract":"We study convergence properties of iterative voting procedures. Such a procedure is defined by a voting rule and a (restricted) iterative process, where at each step one agent can modify his vote towards a better outcome for himself. It has already been observed in previous works that if voters are allowed to make arbitrary moves (or even only best responses), such processes may not converge for most common voting rules. It is therefore important to investigate whether and which natural restrictions on the dynamics of iterative voting procedures can guarantee convergence. To this end, we provide two general conditions on dynamics based on iterative myopic improvements , each of which is sufficient for convergence. We then identify several classes of voting rules, along with their corresponding iterative processes, for which at least one of these conditions hold. Our work generalizes recent results and relaxes a number of restrictive assumptions made in previous research.","cites":"9","conferencePercentile":"91.96850394"},{"venue":"AAAI","id":"5a857219a57eafac2f9bdfff670c25f4dfacaf7a","venue_1":"AAAI","year":"2016","title":"An Algorithm to Coordinate Measurements Using Stochastic Human Mobility Patterns in Large-Scale Participatory Sensing Settings","authors":"Alexandros Zenonos, Sebastian Stein, Nicholas R. Jennings","author_ids":"3179108, 3452529, 1786650","abstract":"Participatory sensing is a promising new low-cost approach for collecting environmental data. However, current large-scale environmental participatory sensing campaigns typically do not coordinate the measurements of participants, which can lead to gaps or redundancy in the collected data. While some work has considered this problem, it has made several unrealis-tic assumptions. In particular, it assumes that complete and accurate knowledge about the participants future movements is available and it does not consider constraints on the number of measurements a user is willing to take. To address these shortcomings, we develop a computationally-efficient coordination algorithm (Best-match) to suggest to users where and when to take measurements. Our algorithm exploits human mobility patterns , but explicitly considers the inherent uncertainty of these patterns. We empirically evaluate our algorithm on a real-world human mobility and air quality dataset and show that it outperforms the state-of-the-art greedy and pull-based proximity algorithms in dynamic environments .","cites":"1","conferencePercentile":"40.70945946"},{"venue":"AAAI","id":"1c8f5a8d10cba2e4d8034560b8600d5365cbb143","venue_1":"AAAI","year":"2006","title":"The Role of Context in Head Gesture Recognition","authors":"Louis-Philippe Morency, Candace L. Sidner, Christopher Lee, Trevor Darrell","author_ids":"1767184, 2668280, 1921963, 1753210","abstract":"Head pose and gesture offer several key conversational grounding cues and are used extensively in face-to-face interaction among people. We investigate how dialog context from an embodied conversational agent (ECA) can improve visual recognition of user gestures. We present a recognition framework which (1) extracts contextual features from an ECA's dialog manager, (2) computes a prediction of head nod and head shakes, and (3) integrates the contextual predictions with the visual observation of a vision-based head gesture recognizer. We found a subset of lexical, punctuation and timing features that are easily available in most ECA architec-tures and can be used to learn how to predict user feedback. Using a discriminative approach to contextual prediction and multi-modal integration, we were able to improve the performance of head gesture detection even when the topic of the test set was significantly different than the training set.","cites":"4","conferencePercentile":"31.26801153"},{"venue":"AAAI","id":"126ac3ef219ed4dd3ef6a120a3e3f93f58eb1571","venue_1":"AAAI","year":"2006","title":"From the Programmer's Apprentice to Human-Robot Interaction: Thirty Years of Research on Human-Computer Collaboration","authors":"Charles Rich, Candace L. Sidner","author_ids":"7315974, 2668280","abstract":"We summarize the continuous thread of research we have conducted over the past thirty years on human-computer collaboration. This research reflects many of the themes and issues in operation in the greater field of AI over this period, such as knowledge representation and reasoning, planning and intent recognition, learning, and the interplay of human theory and computer engineering. Figure 1 illustrates our overall research methodology, which has been to model human-computer collaboration on what is known about human-human collaboration. Furthermore we have focused almost exclusively on the special case of two copresent collaborators, i.e., where each collaborator is able both to communicate with and observe the actions of the other. Examples of such collaborations include two mechanics working on a car engine together or two computer users working on a spreadsheet together. To a first approximation, our approach has been simply to substitute a computer agent for one of the human collaborators, keeping as much else the same as possible. Due to space limitations, we will not attempt to review all research on human-computer collaboration, but limit ourselves to viewing this topic through the lens of our own work and that of our immediate collaborators. Consistent with this, note that bibliography below contains only publications by ourselves and our immediate collaborators. The chronology of our research begins in 1976 with the publication of Rich and Shrobe's joint M.S. thesis on the Pro-grammer's Apprentice [1,3]: \" As compared to automatic programming research, the programmer's apprentice emphasizes a cooperative relationship between the computer and the human programmer... \" Shortly thereafter, Sidner began work on modeling how natural language is used in the context of pairs (and later groups) of people achieving tasks together. Her first paper on this topic dealt with the interpretation of discourse purposes in the Personal Assistant Language Understanding Program [2]. Under the direction of Rich and Shrobe, and later Waters, the Programmer's Apprentice project [4,15,16] lived at the MIT AI Lab from 1976 until Rich and Waters left MIT in 1991. Even though the concept of human-computer collaboration was the bedrock of the project, we never developed a focus of attention SharedPlans mutual beliefs communicate observe Shared Object(s) manipulate observe manipulate Figure 1: Modeling human-computer collaboration on human-human collaboration. deep theoretical understanding of what collaboration meant. Instead, most of the Programmer's Apprentice research concentrated on how to represent and reason with the shared knowledge necessary for successful human-computer …","cites":"1","conferencePercentile":"14.4092219"},{"venue":"AAAI","id":"9a55a63ce8fc4d9723db92f2f27bcd900e93d1da","venue_1":"AAAI","year":"2011","title":"A Simple and Effective Unsupervised Word Segmentation Approach","authors":"Songjian Chen, Yabo Xu, HuiYou Chang","author_ids":"2209363, 1721610, 2291217","abstract":"In this paper, we propose a new unsupervised approach for word segmentation. The core idea of our approach is a novel word induction criterion called WordRank, which estimates the goodness of word hypotheses (character or phoneme sequences). We devise a method to derive exterior word boundary information from the link structures of adjacent word hypotheses and incorporate interior word boundary information to complete the model. In light of WordRank, word segmentation can be modeled as an optimization problem. A Viterbi-styled algorithm is developed for the search of the optimal segmentation. Extensive experiments conducted on phonetic transcripts as well as standard Chinese and Japanese data sets demonstrate the effectiveness of our approach. On the standard Brent version of Bernstein-Ratner corpora, our approach outperforms the state-of-the-art Bayesian models by more than 3%. Plus, our approach is simpler and more efficient than the Bayesian methods. Consequently, our approach is more suitable for real-world applications.","cites":"0","conferencePercentile":"5.841924399"},{"venue":"AAAI","id":"a284b977c57ed6192aa2c09f51167447b82c4381","venue_1":"AAAI","year":"2005","title":"DiamondHelp: A Collaborative Task Guidance Framework for Complex Devices","authors":"Charles Rich, Candace L. Sidner, Neal Lesh, Andrew Garland, Shane Booth, Markus Chimani","author_ids":"7315974, 2668280, 3012739, 1713500, 3036966, 1684840","abstract":"DiamondHelp is a reusable Java framework for building collaborative task guidance systems for complex devices, such as digitally enabled home appliances. DiamondHelp combines a generic conversational interface , adapted from online chat programs, with an application-specific direct manipulation interface. Di-amondHelp provides \" a things to say \" mechanism for use without spoken language understanding; it also supports extensions to take advantage of speech technology. DiamondHelp's software architecture factors all application-specific content into two modular plug-ins, one of which includes Collagen and a task model. DiamondHelp (Rich et al. 2005) is an offshoot of the Col-lagen project (Rich, Sidner, & Lesh 2001), focusing on net-worked home appliances. We believe DiamondHelp is applicable to building collaborative task-guidance systems for any complex device which can be controlled (or simulated, for training) through a software interface. We are currently investigating military and industrial applications. The DiamondHelp framework consists of three components: • an interaction paradigm based on task-oriented human collaboration, • a graphical user interface design which combines conversational and direct manipulation interfaces, • and a software architecture of reusable Java Beans. The SharedPlan model of collaborative discourse (Grosz & Sidner 1986) is the foundation of the Collagen project and therefore also of DiamondHelp. In this model, communication and collaboration between two people (or in the case of DiamondHelp, a person and a computer system) is mediated by their mutual understanding of the shared task. Furthermore, the collaborative discourse model spans a very broad range of human-computer interaction, from intelligent tutoring (in which the computer is the expert) to intelligent assistance (in which the user is the expert), all of which are supported by DiamondHelp. The screen shots at the right illustrate DiamondHelp's user interface design applied to three different home appliances (from top to bottom): a combination washer-dryer, a programmable thermostat, and a DVD recorder. Notice that DiamondHelp provides a consistent \" look and feel \" across appliances, while also providing for the necessary differences between appliances.","cites":"10","conferencePercentile":"43.53146853"},{"venue":"AAAI","id":"3b5b02d24e2c85e64f5c96d0a9afdbf34072e1d9","venue_1":"AAAI","year":"2016","title":"Instructable Intelligent Personal Agent","authors":"Amos Azaria, Jayant Krishnamurthy, Tom M. Mitchell","author_ids":"1746466, 2884955, 1779250","abstract":"Unlike traditional machine learning methods, humans often learn from natural language instruction. As users become increasingly accustomed to interacting with mobile devices using speech, their interest in instructing these devices in natural language is likely to grow. We introduce our Learning by Instruction Agent (LIA), an intelligent personal agent that users can teach to perform new action sequences to achieve new commands, using solely natural language interaction. LIA uses a CCG semantic parser to ground the semantics of each command in terms of primitive executable procedures defining sensors and effectors of the agent. Given a natural language command that LIA does not understand, it prompts the user to explain how to achieve the command through a sequence of steps, also specified in natural language. A novel lexicon induction algorithm enables LIA to generalize across taught commands, e.g., having been taught how to \" forward an email to Alice, \" LIA can correctly interpret the command \" forward this email to Bob. \" A user study involving email tasks demonstrates that users voluntarily teach LIA new commands, and that these taught commands significantly reduce task completion time. These results demonstrate the potential of natural language instruction as a significant, under-explored paradigm for machine learning.","cites":"3","conferencePercentile":"72.63513514"},{"venue":"AAAI","id":"07420243853985ed77cdd761394d413bc1ef259d","venue_1":"AAAI","year":"2015","title":"Towards a Programmer's Apprentice (Again)","authors":"Howard E. Shrobe, Boris Katz, Randall Davis","author_ids":"1716356, 1680209, 1735802","abstract":"Programmers are loathe to interrupt their workflow to document their design rationale, leading to frequent errors when software is modified—often much later and by different programmers. A Programmer's Assistant could interact with the programmer to capture and preserve design rationale, in a natural way that would make rationale capture \" cost less than it's worth \" , and could also detect common flaws in program design. Such a programmer's assistant was not practical when it was first proposed decades ago, but advances over the years make now the time to revisit the concept, as our prototype shows. Gerry Sussman), proposed the idea of a Programmer's Apprentice , an intelligent assistant that would help a programmer write, debug and evolve software (Rich et al. Part of the vision was the idea that software systems always evolve over their lifetimes and that our failure to capture and preserve design rationale makes it difficult to extend and evolve systems without introducing new errors. But in practice, capturing rationale is often a burdensome and thankless task. Writing down the reason for a design choice involves a disruption of the normal flow of activity, one that causes the programmer to switch from programming to explaining and then back again. Furthermore , this effort is of benefit to somebody else, in the future. Even if that somebody else turns out to be yourself, the benefit is still in the (perhaps distant) future and its current value is minimal. To make rationale capture work, one has to make it cost less than it's worth. To solve this problem, the apprentice was envisioned to be a knowledgeable junior programmer, one that would understand the basic patterns and clichés of programming and that would only ask questions about unusual aspects of a system's design, ones that the programmer would actually be willing to chat about. These unusual elements might involve not only mistakes and oversights but also clever hacks; this would allow the apprentice both to catch blunders and to capture the rationale for unusual programming choices. Interactions with the Apprentice were also envisioned to be \" natural \" , i.e., largely indistinguishable from those one would have with a colleague. They would, therefore, include natural language, both spoken and written, and the use of diagrams and other informal drawings. In retrospect, the idea was at least as wildly optimistic as it was visionary. Making the vision a reality …","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"67db5ff338035c26c9197718ff78709035f197b8","venue_1":"AAAI","year":"2015","title":"Distributing Coalition Value Calculations to Coalition Members","authors":"Luke Riley, Katie Atkinson, Paul E. Dunne, Terry R. Payne","author_ids":"2145341, 1699473, 1728757, 1740601","abstract":"Within characteristic function games, agents have the option of joining one of many different coalitions, based on the utility value of each candidate coalition. However, determining this utility value can be computationally complex since the number of coalitions increases exponentially with the number of agents available. Various approaches have been proposed that mediate this problem by distributing the computational load so that each agent calculates only a subset of coalition values. However, current approaches are either highly inefficient due to redundant calculations, or make the benevolence assumption (i.e. are not suitable for adversarial environments). We introduce DCG, a novel algorithm that distributes the calculations of coalition utility values across a community of agents, such that: (i) no inter-agent communication is required; (ii) the coalition value calculations are (approximately) equally partitioned into shares, one for each agent; (iii) the utility value is calculated only once for each coalition , thus redundant calculations are eliminated; (iv) there is an equal number of operations for agents with equal sized shares; and (v) an agent is only allocated those coalitions in which it is a potential member. The DCG algorithm is presented and illustrated by means of an example. We formally prove that our approach allocates all of the coalitions to the agents, and that each coalition is assigned once and only once.","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"9f829eb41c2ecb850fe20329e7da06eb369151f9","venue_1":"AAAI","year":"2015","title":"Deep Representation Learning with Target Coding","authors":"Shuo Yang, Ping Luo, Chen Change Loy, Kenneth W. Shum, Xiaoou Tang","author_ids":"4573336, 1693209, 1717179, 1731849, 1741901","abstract":"We consider the problem of learning deep representation when target labels are available. In this paper, we show that there exists intrinsic relationship between target coding and feature representation learning in deep networks. Specifically, we found that distributed binary code with error correcting capability is more capable of encouraging discriminative features, in comparison to the 1-of-K coding that is typically used in supervised deep learning. This new finding reveals additional benefit of using error-correcting code for deep model learning , apart from its well-known error correcting property. Extensive experiments are conducted on popular visual benchmark datasets.","cites":"5","conferencePercentile":"80.31496063"},{"venue":"AAAI","id":"13878d4ec3a28bdae4e43017d5c12b7089a36196","venue_1":"AAAI","year":"2007","title":"Discovering Multivariate Motifs using Subsequence Density Estimation and Greedy Mixture Learning","authors":"David Minnen, Charles Lee Isbell, Irfan A. Essa, Thad Starner","author_ids":"3144223, 1787816, 1714295, 1738894","abstract":"The problem of locating motifs in real-valued, multivariate time series data involves the discovery of sets of recurring patterns embedded in the time series. Each set is composed of several non-overlapping subsequences and constitutes a motif because all of the included subsequences are similar. The ability to automatically discover such motifs allows intelligent systems to form endogenously meaningful representations of their environment through unsupervised sensor analysis. In this paper, we formulate a unifying view of motif discovery as a problem of locating regions of high density in the space of all time series subsequences. Our approach is efficient (sub-quadratic in the length of the data), requires fewer user-specified parameters than previous methods, and naturally allows variable length motif occurrences and non-linear temporal warping. We evaluate the performance of our approach using four data sets from different domains including on-body inertial sensors and speech.","cites":"28","conferencePercentile":"78.93175074"},{"venue":"AAAI","id":"5f64ee7aab4949e4b56f4e12ef2d7d944cc8cc8a","venue_1":"AAAI","year":"2012","title":"Quality Expectation-Variance Tradeoffs in Crowdsourcing Contests","authors":"Xi Alice Gao, Yoram Bachrach, Peter B. Key, Thore Graepel","author_ids":"2629809, 1698412, 7217471, 1686971","abstract":"We examine designs for crowdsourcing contests, where participants compete for rewards given to superior solutions of a task. We theoretically analyze tradeoffs between the expectation and variance of the principal's utility (i.e. the best solu-tion's quality), and empirically test our theoretical predictions using a controlled experiment on Amazon Mechanical Turk. Our evaluation method is also crowdsourcing based and relies on the peer prediction mechanism. Our theoretical analysis shows an expectation-variance tradeoff of the principal's utility in such contests through a Pareto efficient frontier. In particular, we show that the simple contest with 2 authors and the 2-pair contest have good theoretical properties. In contrast , our empirical results show that the 2-pair contest is the superior design among all designs tested, achieving the highest expectation and lowest variance of the principal's utility.","cites":"14","conferencePercentile":"79.72560976"},{"venue":"AAAI","id":"aadf7378bfbaba9768ce97118f3e83ea251b3e1f","venue_1":"AAAI","year":"2010","title":"Constrained Metric Learning Via Distance Gap Maximization","authors":"Wei Liu, Xinmei Tian, Dacheng Tao, Jianzhuang Liu","author_ids":"3406279, 3076952, 7761803, 7137861","abstract":"Vectored data frequently occur in a variety of fields, which are easy to handle since they can be mathematically abstracted as points residing in a Euclidean space. An appropriate distance metric in the data space is quite demanding for a great number of applications. In this paper, we pose robust and tractable metric learning under pairwise constraints that are expressed as similarity judgements between data pairs. The major features of our approach include: 1) it maximizes the gap between the average squared distance among dissimilar pairs and the average squared distance among similar pairs; 2) it is capable of propagating similar constraints to all data pairs; and 3) it is easy to implement in contrast to the existing approaches using expensive optimization such as semidefi-nite programming. Our constrained metric learning approach has widespread applicability without being limited to particular backgrounds. Quantitative experiments are performed for classification and retrieval tasks, uncovering the effectiveness of the proposed approach.","cites":"12","conferencePercentile":"58.02047782"},{"venue":"AAAI","id":"c21c2a41074a045724ae92c86018ccac2099d661","venue_1":"AAAI","year":"2008","title":"Clustering via Random Walk Hitting Time on Directed Graphs","authors":"Mo Chen, Jianzhuang Liu, Xiaoou Tang","author_ids":"1733987, 7137861, 1741901","abstract":"In this paper, we present a general data clustering algorithm which is based on the asymmetric pairwise measure of Markov random walk hitting time on directed graphs. Unlike traditional graph based clustering methods , we do not explicitly calculate the pairwise similarities between points. Instead, we form a transition matrix of Markov random walk on a directed graph directly from the data. Our algorithm constructs the probabilis-tic relations of dependence between local sample pairs by studying the local distributions of the data. Such dependence relations are asymmetric, which is a more general measure of pairwise relations than the similarity measures in traditional undirected graph based methods in that it considers both the local density and geometry of the data. The probabilistic relations of the data naturally result in a transition matrix of Markov random walk. Based on the random walk viewpoint, we compute the expected hitting time for all sample pairs, which explores the global information of the structure of the underlying directed graph. An asymmetric measure based clustering algorithm, called K-destinations, is proposed for partitioning the nodes of the directed graph into disjoint sets. By utilizing the local distribution information of the data and the global structure information of the directed graph, our method is able to conquer some limitations of traditional pairwise similarity based methods. Experimental results are provided to validate the effectiveness of the proposed approach.","cites":"17","conferencePercentile":"73.41772152"},{"venue":"AAAI","id":"4ebd87b5be3b2aacd0442ae6f9ef9baadbeb9003","venue_1":"AAAI","year":"2006","title":"Hand Grip Pattern Recognition for Mobile User Interfaces","authors":"Kee-Eung Kim, Wook Chang, Sung-Jung Cho, Junghyun Shim, Hyunjeong Lee, Joonah Park, Youngbeom Lee, Sangryoung Kim","author_ids":"1741330, 6806438, 2988439, 8246764, 2398663, 3049375, 2255106, 2361940","abstract":"This paper presents a novel user interface for handheld mobile devices by recognizing hand grip patterns. Particularly , we consider the scenario where the device is provided with an array of capacitive touch sensors underneath the exterior cover. In order to provide the users with intuitive and natural manipulation experience, we use pattern recognition techniques for identifying the users' hand grips from the touch sensors. Preliminary user studies suggest that filtering out unintended user hand grip is one of the most important issues to be resolved. We discuss the details of the prototype implementation , as well as engineering challenges for practical deployment.","cites":"31","conferencePercentile":"79.39481268"},{"venue":"AAAI","id":"bb7d7c81cd15333511013b479977848c55b4d297","venue_1":"AAAI","year":"2010","title":"Towards an Intelligent Code Search Engine","authors":"Jinhan Kim, Sanghoon Lee, Seung-won Hwang, Sunghun Kim","author_ids":"2534696, 2417993, 1716415, 6098375","abstract":"Software developers increasingly rely on information from the Web, such as documents or code examples on Application Programming Interfaces (APIs), to facilitate their development processes. However, API documents often do not include enough information for developers to fully understand the API usages, while searching for good code examples requires non-trivial effort. To address this problem, we propose a novel code search engine, combining the strength of browsing documents and searching for code examples, by returning documents embedded with high-quality code example summaries mined from the Web. Our evaluation results show that our approach provides code examples with high precision and boosts programmer productivity.","cites":"22","conferencePercentile":"78.49829352"},{"venue":"AAAI","id":"3a878439cd1ad1e9beb0ecb16b486b0767e5e985","venue_1":"AAAI","year":"2011","title":"CosTriage: A Cost-Aware Triage Algorithm for Bug Reporting Systems","authors":"Jin-Woo Park, Mu-Woong Lee, Jinhan Kim, Seung-won Hwang, Sunghun Kim","author_ids":"1704437, 1696114, 2534696, 1716415, 6098375","abstract":"Who can fix this bug?' is an important question in bug triage to \" accurately \" assign developers to bug reports. To address this question, recent research treats it as a optimizing recommendation accuracy problem and proposes a solution that is essentially an instance of content-based recommendation (CBR). However, CBR is well-known to cause over-specialization, recommending only the types of bugs that each developer has solved before. This problem is critical in practice, as some experienced developers could be overloaded , and this would slow the bug fixing process. In this paper, we take two directions to address this problem: First, we reformulate the problem as an optimization problem of both accuracy and cost. Second, we adopt a content-boosted collaborative filtering (CBCF), combining an existing CBR with a collaborative filtering recommender (CF), which enhances the recommendation quality of either approach alone. However, unlike general recommendation scenarios, bug fix history is extremely sparse. Due to the nature of bug fixes, one bug is fixed by only one developer, which makes it challenging to pursue the above two directions. To address this challenge, we develop a topic-model to reduce the sparseness and enhance the quality of CBCF. Our experimental evaluation shows that our solution reduces the cost efficiently by 30% without seriously compromising accuracy.","cites":"25","conferencePercentile":"91.58075601"},{"venue":"AAAI","id":"1a2a308fb8a6bb24f3bfdb8131556b5504f7d555","venue_1":"AAAI","year":"1994","title":"Acting Optimally in Partially Observable Stochastic Domains","authors":"Anthony R. Cassandra, Leslie Pack Kaelbling, Michael L. Littman","author_ids":"2453007, 1709512, 1735162","abstract":"In this paper, we describe the partially observable Markov decision process pomdp approach to nding optimal or near-optimal control strategies for partially observable stochastic environments, given a complete model of the environment. The pomdp approach w as originally developed in the operations research community and provides a formal basis for planning problems that have been of interest to the AI community. We found the existing algorithms for computing optimal control strategies to be highly computationally ineecient and have developed a new algorithm that is empirically more eecient. We s k etch this algorithm and present preliminary results on several small problems that illustrate important properties of the pomdp approach.","cites":"369","conferencePercentile":"98.6784141"},{"venue":"AAAI","id":"8208c3a26a6baf160508103117fe4ab2b102266e","venue_1":"AAAI","year":"2004","title":"An Instance-Based State Representation for Network Repair","authors":"Michael L. Littman, Nishkam Ravi, Eitan Fenson, Richard E. Howard","author_ids":"1735162, 3226186, 2566706, 2526402","abstract":"We describe a formal framework for diagnosis and repair problems that shares elements of the well known partially observable MDP and cost-sensitive classification models. Our cost-sensitive fault remediation model is amenable to implementation as a reinforcement-learning system, and we describe an instance-based state representation that is compatible with learning and planning in this framework. We demonstrate a system that uses these ideas to learn to efficiently restore network connectivity after a failure.","cites":"14","conferencePercentile":"56.88622754"},{"venue":"AAAI","id":"9883d390db83105545b408c3ff026c0244dc6723","venue_1":"AAAI","year":"2005","title":"Lazy Approximation for Solving Continuous Finite-Horizon MDPs","authors":"Lihong Li, Michael L. Littman","author_ids":"1811156, 1735162","abstract":"Solving Markov decision processes (MDPs) with continuous state spaces is a challenge due to, among other problems, the well-known curse of dimensionality. Nevertheless, numerous real-world applications such as transportation planning and telescope observation scheduling exhibit a critical dependence on continuous states. Current approaches to continuous-state MDPs include discretizing their transition models. In this paper , we propose and study an alternative, discretization-free approach we call lazy approximation. Empirical study shows that lazy approximation performs much better than discretization, and we successfully applied this new technique to a more realistic planetary rover planning problem.","cites":"40","conferencePercentile":"86.18881119"},{"venue":"AAAI","id":"20cb9de9921d7efbc1add2848239d7916bf158b2","venue_1":"AAAI","year":"2005","title":"Activity Recognition from Accelerometer Data","authors":"Nishkam Ravi, Nikhil Dandekar, Preetham Mysore, Michael L. Littman","author_ids":"3226186, 2831882, 1861947, 1735162","abstract":"Activity recognition fits within the bigger framework of context awareness. In this paper, we report on our efforts to recognize user activity from accelerometer data. Activity recognition is formulated as a classification problem. Performance of base-level classifiers and meta-level classifiers is compared. Plurality Voting is found to perform consistently well across different settings .","cites":"387","conferencePercentile":"100"},{"venue":"AAAI","id":"0694ed4fadd00fdc92d13f6957c90d780c477d8d","venue_1":"AAAI","year":"2007","title":"Efficient Reinforcement Learning with Relocatable Action Models","authors":"Bethany R. Leffler, Michael L. Littman, Timothy Edmunds","author_ids":"1700606, 1735162, 1803510","abstract":"Realistic domains for learning possess regularities that make it possible to generalize experience across related states. This paper explores an environment-modeling framework that represents transitions as state-independent outcomes that are common to all states that share the same type. We analyze a set of novel learning problems that arise in this framework, providing lower and upper bounds. We single out one particular variant of practical interest and provide an efficient algorithm and experimental results in both simulated and robotic environments.","cites":"42","conferencePercentile":"88.1305638"},{"venue":"AAAI","id":"15ba832dbb1882b2c516e06cb0f8f002d16bc4cf","venue_1":"AAAI","year":"2007","title":"Efficient Structure Learning in Factored-State MDPs","authors":"Alexander L. Strehl, Carlos Diuk, Michael L. Littman","author_ids":"1990806, 1681946, 1735162","abstract":"We consider the problem of reinforcement learning in factored-state MDPs in the setting in which learning is conducted in one long trial with no resets allowed. We show how to extend existing efficient algorithms that learn the conditional probability tables of dynamic Bayesian networks (DBNs) given their structure to the case in which DBN structure is not known in advance. Our method learns the DBN structures as part of the reinforcement-learning process and provably provides an efficient learning algorithm when combined with fac-tored Rmax.","cites":"55","conferencePercentile":"93.17507418"},{"venue":"AAAI","id":"8a64afa79394f746f791b8cf72025726d039e1b3","venue_1":"AAAI","year":"2008","title":"Efficient Learning of Action Schemas and Web-Service Descriptions","authors":"Thomas J. Walsh, Michael L. Littman","author_ids":"7194262, 1735162","abstract":"This work addresses the problem of efficiently learning action schemas using a bounded number of samples (interactions with the environment). We consider schemas in two languages— traditional STRIPS, and a new language STRIPS+WS that extends STRIPS to allow for the creation of new objects when an action is executed. This modification allows STRIPS+WS to model web services and can be used to describe web-service composition (planning) problems. We show that general STRIPS operators cannot be efficiently learned through raw experience, though restricting the size of action preconditions yields a positive result. We then show that efficient learning is possible without this restriction if an agent has access to a \" teacher \" that can provide solution traces on demand. We adapt this learning algorithm to efficiently learn web-service descriptions in STRIPS+WS.","cites":"26","conferencePercentile":"84.17721519"},{"venue":"AAAI","id":"8d6a5a3cf11650756c655efbc76e70e9fd8da581","venue_1":"AAAI","year":"2008","title":"Potential-based Shaping in Model-based Reinforcement Learning","authors":"John Asmuth, Michael L. Littman, Robert Zinkov","author_ids":"3056176, 1735162, 2277899","abstract":"Potential-based shaping was designed as a way of introducing background knowledge into model-free reinforcement-learning algorithms. By identifying states that are likely to have high value, this approach can decrease experience complexity—the number of trials needed to find near-optimal behavior. An orthogonal way of decreasing experience complexity is to use a model-based learning approach, building and exploiting an explicit transition model. In this paper, we show how potential-based shaping can be redefined to work in the model-based setting to produce an algorithm that shares the benefits of both ideas.","cites":"30","conferencePercentile":"87.97468354"},{"venue":"AAAI","id":"bdc9bfb6ecc6fb5afb684df03d7220c46ebdbf4e","venue_1":"AAAI","year":"2010","title":"Integrating Sample-Based Planning and Model-Based Reinforcement Learning","authors":"Thomas J. Walsh, Sergiu Goschin, Michael L. Littman","author_ids":"7194262, 3065264, 1735162","abstract":"Recent advancements in model-based reinforcement learning have shown that the dynamics of many structured domains (e.g. DBNs) can be learned with tractable sample complexity , despite their exponentially large state spaces. Unfortunately , these algorithms all require access to a planner that computes a near optimal policy, and while many traditional MDP algorithms make this guarantee, their computation time grows with the number of states. We show how to replace these over-matched planners with a class of sample-based planners—whose computation time is independent of the number of states—without sacrificing the sample-efficiency guarantees of the overall learning algorithms. To do so, we define sufficient criteria for a sample-based planner to be used in such a learning system and analyze two popular sample-based approaches from the literature. We also introduce our own sample-based planner, which combines the strategies from these algorithms and still meets the criteria for integration into our learning system. In doing so, we define the first complete RL solution for compactly represented (exponentially sized) state spaces with efficiently learnable dynamics that is both sample efficient and whose computation time does not grow rapidly with the number of states.","cites":"46","conferencePercentile":"93.17406143"},{"venue":"AAAI","id":"3747b605f931fd1009f262f30c3c75c922cc0f9d","venue_1":"AAAI","year":"2012","title":"Covering Number as a Complexity Measure for POMDP Planning and Learning","authors":"Zongzhang Zhang, Michael L. Littman, Xiaoping Chen","author_ids":"2079174, 1735162, 4173593","abstract":"Finding a meaningful way of characterizing the difficulty of partially observable Markov decision processes (POMDPs) is a core theoretical problem in POMDP research. State-space size is often used as a proxy for POMDP difficulty, but it is a weak metric at best. Existing work has shown that the covering number for the reachable belief space, which is a set of belief points that are reachable from the initial belief point, has interesting links with the complexity of POMDP planning, theoretically. In this paper, we present empirical evidence that the covering number for the reachable belief space (or just \" covering number \" , for brevity) is a far better complexity measure than the state-space size for both planning and learning POMDPs on several small-scale benchmark problems. We connect the covering number to the complexity of learning POMDPs by proposing a provably convergent learning algorithm for POMDPs without reset given knowledge of the covering number.","cites":"3","conferencePercentile":"30.79268293"},{"venue":"AAAI","id":"50e5d1c8ab49ea2b069c278b3685a020c1ab6b0f","venue_1":"AAAI","year":"2013","title":"An Ensemble of Linearly Combined Reinforcement-Learning Agents","authors":"Vukosi N. Marivate, Michael L. Littman","author_ids":"1875175, 1735162","abstract":"Reinforcement-learning (RL) algorithms are often tweaked and tuned to specific environments when applied , calling into question whether learning can truly be considered autonomous in these cases. In this work, we show how more robust learning across environments is possible by adopting an ensemble approach to reinforcement learning. Our approach learns a weighted linear combination of Q-values from multiple independent learning algorithms. In our evaluations in generalized RL environments, we find that the algorithm compares favorably to the best tuned algorithm. Our work provides a promising basis for further study into the use of ensemble methods in RL. The task of creating a single reinforcement-learning (RL) agent that can learn in many possible environments without modification is not a simple one. It is typical for algorithm designers to modify state representations, learning protocols, or parameter values to obtain good performance on novel environments. However, the more problem-specific tuning needed, the less \" autonomous \" an RL system is, eroding some of the value of RL systems in practice. Often, the process of tuning itself requires agents to repeatedly learn and relearn in the target environment—an approach that simply cannot be used in practice. Across a wide range of computational domains, ensemble learning methods have proven extremely valuable for reliably tackling complex problems. Ensemble (or sometimes modular or portfolio) methods harness multiple, perhaps quite disparate, algorithms for a problem class to greatly expand the range of specific instances that can be addressed. They have emerged as state-of-the-art approaches for word sense disambiguation (Florian and Yarowsky 2002), crossword solving (Littman, Keim, and Shazeer 2002), satisfia-bility testing (Xu, Hoos, and Leyton-Brown 2010), movie recommendation (Bell, Koren, and Volinsky 2010) and question answering (Ferrucci et al. 2010). We believe the success of ensemble methods on these problems stems from the fact that they can deal with a range of instances that require different low-level approaches. RL instances share this attribute , suggesting that an ensemble approach could be valuable there as well. In this work, we present an approach to ensemble-based RL using a linear Temporal Difference (TD) learning algorithm as a meta learner to combine the value estimates from multiple base RL algorithm agents. Our approach goes beyond earlier efforts in ensemble RL (Wiering and van Hasselt 2008) in that we develop a fusion method that is adjusted given the performance of the base agents in the ensemble instead of combining low-level agents …","cites":"5","conferencePercentile":"62.54545455"},{"venue":"AAAI","id":"14d2f4b8bb7c2ecb14c0072d9e25ba4c9ee59b68","venue_1":"AAAI","year":"2013","title":"Open-Loop Planning in Large-Scale Stochastic Domains","authors":"Ari Weinstein, Michael L. Littman","author_ids":"2087737, 1735162","abstract":"We focus on effective sample-based planning in the face of underactuation, high-dimensionality, drift, discrete system changes, and stochasticity. These are hallmark challenges for important problems, such as hu-manoid locomotion. In order to ensure broad applicability , we assume domain expertise is minimal and limited to a generative model. In order to make the method responsive, computational costs that scale linearly with the amount of samples taken from the generative model are required. We bring to bear a concrete method that satisfies all these requirements; it is a receding-horizon open-loop planner that employs cross-entropy optimization for policy construction. In simulation, we empirically demonstrate near-optimal decisions in a small domain and effective locomotion in several challenging humanoid control tasks. Humanoid locomotion tasks are difficult to plan in effectively due to a number of properties. Because humanoids have high-dimensional state and action spaces, methods that are effective in smaller domains may fail due to the curse of dimensionality. Dynamic legged walking has characteristics that violate assumptions made by traditional motion planning approaches (Ladd and Kavraki 2005). Discrete system changes are common in locomotion and occur in any domain where hard contacts or joint limits exist, which produces nonsmooth and nondifferentiable dynamics. In addition to the properties listed above, we are also concerned with the setting where stochasticity exists in the system dynamics, which violates any assumption of determinism. Characteristics of the policy space defining behavior in humanoid locomotion tasks introduce further difficulties, as the sub-space of effective policies is very small in the entire space of policies (Erez 2011), and the landscape of policies with respect to their quality has many local optima (Erez, Tassa, and Todorov 2011). Many planning algorithms require large amounts of expert knowledge to function. Common examples are knowledge of inverse kinematics, or shaping functions that approximate a value function. Aside from limiting applicability , these requirements may introduce fragility as failure is risked if the provided information is inaccurate. To make these planning algorithms general, simple to implement , and robust, we are concerned with approaches that require minimal domain knowledge, limited to a generative model (equivalent to a simulator). Because time sensitivity is important, we consider methods that parallelize simply and have computational cost linear in the number of samples taken from the generative model. The approach used here plans in an open-loop manner, using cross-entropy (Rubinstein 1997) to optimize a sequence of actions with respect to …","cites":"5","conferencePercentile":"62.54545455"},{"venue":"AAAI","id":"78a00be0d5505de2263cfa9c45b74b60268d153d","venue_1":"AAAI","year":"2012","title":"Congestion Games with Agent Failures","authors":"Reshef Meir, Moshe Tennenholtz, Yoram Bachrach, Peter B. Key","author_ids":"1769579, 1708847, 1698412, 7217471","abstract":"We propose a natural model for agent failures in congestion games. In our model, each of the agents may fail to participate in the game, introducing uncertainty regarding the set of active agents. We examine how such uncertainty may change the Nash equilibria (NE) of the game. We prove that although the perturbed game induced by the failure model is not always a congestion game, it still admits at least one pure Nash equilibrium. Then, we turn to examine the effect of failures on the maximal social cost in any NE of the perturbed game. We show that in the limit case where failure probability is negligible new equilibria never emerge, and that the social cost may decrease but it never increases. For the case of non-negligible failure probabilities, we provide a full characterization of the maximal impact of failures on the social cost under worst-case equilibrium outcomes.","cites":"10","conferencePercentile":"67.83536585"},{"venue":"AAAI","id":"513167c08db5139162710aad9b2c217b344df2c4","venue_1":"AAAI","year":"2016","title":"Numerical Relation Extraction with Minimal Supervision","authors":"Aman Madaan, Ashish Mittal, Mausam, Ganesh Ramakrishnan, Sunita Sarawagi","author_ids":"2132956, 2863654, 2674444, 1697088, 1770124","abstract":"We study a novel task of numerical relation extraction with the goal of extracting relations where one of the arguments is a number or a quantity (e.g., atomic number(Aluminium, 13), inflation rate(India, 10.9%)). This task presents peculiar challenges not found in standard Information Extraction (IE), such as the difficulty of matching numbers in distant supervision and the importance of units. We design two extraction systems that require minimal human supervision per relation: (1) NumberRule, a rule based extractor, and (2) Num-berTron, a probabilistic graphical model. We find that both systems dramatically outperform MultiR, a state-of-the-art non-numerical IE model, obtaining up to 25 points F-score improvement.","cites":"3","conferencePercentile":"72.63513514"},{"venue":"AAAI","id":"8afa238b5fd8b925cff1b64f33a1828757e867ba","venue_1":"AAAI","year":"2015","title":"Using Qualitative Spatial Logic for Validating Crowd-Sourced Geospatial Data","authors":"Heshan Du, Hai H. Nguyen, Natasha Alechina, Brian Logan, Michael Jackson, John Goodwin","author_ids":"1683682, 8308578, 1680562, 1741067, 1681453, 2636587","abstract":"We describe a tool, MatchMaps, that generates sameAs and partOf matches between spatial objects (such as shops, shopping centres, etc.) in crowd-sourced and authoritative geospatial datasets. MatchMaps uses reasoning in qualitative spatial logic, description logic and truth maintenance techniques, to produce a consistent set of matches. We report the results of an initial evaluation of MatchMaps by experts from Ordnance Survey (Great Britain's National Mapping Authority). In both the case studies considered, MatchMaps was able to correctly match spatial objects (high precision and recall) with minimal human intervention.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"a1fa2b015f6da6d9c7883767161d75cb331c0c41","venue_1":"AAAI","year":"2015","title":"Using Social Relationships to Control Narrative Generation","authors":"Julie Porteous, Fred Charles, Marc Cavazza","author_ids":"1768788, 1776150, 1696638","abstract":"Narrative generation represents an application domain for AI planning where plan quality is related to properties such as shape of plan trajectory. In our work we have developed a plan-based approach to narrative generation that uses character relationships as a key determinant in controlling plan shape (relationships are key in genres such as serial dramas and soaps). Our approach is implemented in a demonstration Interactive Narrative, called NETWORKING, set in the medical drama genre. The system features a user-friendly mechanism for specifying relationships between virtual characters, via a social network and real-time visualisa-tion of generated narratives on a 3D stage.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"75484c7bc179b735e6d2363fb7443fe7e28c41dd","venue_1":"AAAI","year":"2013","title":"Multi-Cycle Query Caching in Agent Programming","authors":"Natasha Alechina, Tristan M. Behrens, Mehdi Dastani, Koen V. Hindriks, Jomi Fred Hübner, Brian Logan, Hai H. Nguyen, Marc van Zee","author_ids":"1680562, 2256200, 1707738, 1751831, 1798785, 1741067, 8308578, 2807540","abstract":"In many logic-based BDI agent programming languages, plan selection involves inferencing over some underlying knowledge representation. While context-sensitive plan selection facilitates the development of flexible, declarative programs, the overhead of evaluating repeated queries to the agent's beliefs and goals can result in poor run time performance. In this paper we present an approach to multi-cycle query caching for logic-based BDI agent programming languages. We extend the abstract performance model presented in (Alechina et al. 2012) to quantify the costs and benefits of caching query results over multiple deliberation cycles. We also present results of experiments with prototype implementations of both single-and multi-cycle caching in three logic-based BDI agent platforms, which demonstrate that significant performance improvements are achievable in practice.","cites":"2","conferencePercentile":"37.09090909"},{"venue":"AAAI","id":"60cd8792c2406a449e8e68551bff58deffe1f69a","venue_1":"AAAI","year":"2013","title":"Effective Bilingual Constraints for Semi-Supervised Learning of Named Entity Recognizers","authors":"Mengqiu Wang, Wanxiang Che, Christopher D. Manning","author_ids":"3034293, 2256319, 1812612","abstract":"Most semi-supervised methods in Natural Language Processing capitalize on unannotated resources in a single language; however, information can be gained from using parallel resources in more than one language, since translations of the same utterance in different languages can help to disam-biguate each other. We demonstrate a method that makes effective use of vast amounts of bilingual text (a.k.a. bi-text) to improve monolingual systems. We propose a factored probabilistic sequence model that encourages both cross-language and intra-document consistency. A simple Gibbs sampling algorithm is introduced for performing approximate inference. Experiments on English-Chinese Named Entity Recognition (NER) using the OntoNotes dataset demonstrate that our method is significantly more accurate than state-of-the-art monolingual CRF models in a bilingual test setting. Our model also improves on previous work by Burkett et al. (2010), achieving a relative error reduction of 10.8% and 4.5% in Chinese and English, respectively. Furthermore, by annotating a moderate amount of unlabeled bi-text with our bilingual model, and using the tagged data for uptraining, we achieve a 9.2% error reduction in Chinese over the state-of-the-art Stanford monolingual NER system.","cites":"8","conferencePercentile":"76.54545455"},{"venue":"AAAI","id":"4024e445d30186c10771329def8a3177506e1bab","venue_1":"AAAI","year":"2013","title":"Hotspotting - A Probabilistic Graphical Model For Image Object Localization Through Crowdsourcing","authors":"Mahyar Salek, Yoram Bachrach, Peter B. Key","author_ids":"3223663, 1698412, 7217471","abstract":"Object localization is an image annotation task which consists of finding the location of a target object in an image. It is common to crowdsource annotation tasks and aggregate responses to estimate the true annotation. While for other kinds of annotations consensus is simple and powerful, it cannot be applied to object local-ization as effectively due to the task's rich answer space and inherent noise in responses. We propose a probabilistic graphical model to localize objects in images based on responses from the crowd. We improve upon natural aggregation methods such as the mean and the median by simultaneously estimating the difficulty level of each question and skill level of every participant. We empirically evaluate our model on crowdsourced data and show that our method outperforms simple ag-gregators both in estimating the true locations and in ranking participants by their ability. We also propose a simple adaptive sourcing scheme that works well for very sparse datasets.","cites":"8","conferencePercentile":"76.54545455"},{"venue":"AAAI","id":"11a6f68459a70b003810581052cf6ec04a46c580","venue_1":"AAAI","year":"2006","title":"Algorithms for Rationalizability and CURB Sets","authors":"Michael Benisch, George B. Davis, Tuomas Sandholm","author_ids":"2742523, 2647822, 1732422","abstract":"Significant work has been done on computational aspects of solving games under various solution concepts, such as Nash equilibrium, subgame perfect Nash equilibrium , correlated equilibrium, and (iterated) dominance. However, the fundamental concepts of rationalizability and CURB (Closed Under Rational Behavior) sets have not, to our knowledge, been studied from a computational perspective. First, for rationalizability we describe an LP-based polynomial algorithm that finds all strategies that are rationalizable against a mixture over a given set of opponent strategies. Then, we describe a series of increasingly sophisticated polynomial algorithms for finding all minimal CURB sets, one minimal CURB set, and the smallest minimal CURB set. Finally, we give theoretical results regarding the relationships between CURB sets and Nash equilibria, showing that finding a Nash equilibrium can be exponential only in the size of the smallest CURB set. We show that this can lead to an arbitrarily large reduction in the complexity of finding a Nash equilibrium. On the downside, we also show that the smallest CURB set can be arbitrarily larger than the supports of the enclosed Nash equilibrium. We thank Vincent Conitzer and Andrew Gilpin for their helpful input and guidance.","cites":"17","conferencePercentile":"65.56195965"},{"venue":"AAAI","id":"62723f39ff24330270d5753f49605d72416d7245","venue_1":"AAAI","year":"2006","title":"Kernel Methods for Word Sense Disambiguation and Acronym Expansion","authors":"Mahesh Joshi, Ted Pedersen, Richard Maclin, Serguei V. S. Pakhomov","author_ids":"2720376, 1768844, 1709927, 2474514","abstract":"The scarcity of manually labeled data for supervised machine learning methods presents a significant limitation on their ability to acquire knowledge. The use of kernels in Support Vector Machines (SVMs) provides an excellent mechanism to introduce prior knowledge into the SVM learners, such as by using unlabeled text or existing ontologies as additional knowledge sources. Our aim is to develop three kernels – one that makes use of knowledge derived from unlabeled text, the second using semantic knowledge from ontologies, and finally a third, additive kernel consisting of the first two kernels – and study their effect on the tasks of word sense disambiguation and automatic expansion of ambiguous acronyms.","cites":"4","conferencePercentile":"31.26801153"},{"venue":"AAAI","id":"7390c2cceccddbf1b18be9c31831713ccfc6be19","venue_1":"AAAI","year":"2006","title":"An End-to-End Supervised Target-Word Sense Disambiguation System","authors":"Mahesh Joshi, Serguei V. S. Pakhomov, Ted Pedersen, Richard Maclin, Christopher G. Chute","author_ids":"2720376, 2474514, 1768844, 1709927, 1792682","abstract":"We present an extensible supervised Target-Word Sense Disambiguation system that leverages upon GATE (General Architecture for Text Engineering), NSP (Ngram Statistics Package) and WEKA (Waikato Environment for Knowledge Analysis) to present an end-to-end solution that integrates feature identification, feature extraction, preprocessing and classification.","cites":"3","conferencePercentile":"26.5129683"},{"venue":"AAAI","id":"0000f6be0456dac3939fc1f60070f7059f5ae76c","venue_1":"AAAI","year":"2016","title":"Learning Continuous-Time Bayesian Networks in Relational Domains: A Non-Parametric Approach","authors":"Shuo Yang, Tushar Khot, Kristian Kersting, Sriraam Natarajan","author_ids":"4573336, 2236429, 1746871, 1707169","abstract":"Many real world applications in medicine, biology, communication networks, web mining, and economics, among others, involve modeling and learning structured stochastic processes that evolve over continuous time. Existing approaches, however, have focused on propo-sitional domains only. Without extensive feature engineering , it is difficult—if not impossible—to apply them within relational domains where we may have varying number of objects and relations among them. We therefore develop the first relational representation called Relational Continuous-Time Bayesian Networks (RCTBNs) that can address this challenge. It features a nonparametric learning method that allows for efficiently learning the complex dependencies and their strengths simultaneously from sequence data. Our experimental results demonstrate that RCTBNs can learn as effectively as state-of-the-art approaches for proposi-tional tasks while modeling relational tasks faithfully.","cites":"0","conferencePercentile":"14.18918919"},{"venue":"AAAI","id":"c92b4dd2d227c6cbe175de43f629bd74c0d50af1","venue_1":"AAAI","year":"2010","title":"Constraint Programming for Data Mining and Machine Learning","authors":"Luc De Raedt, Tias Guns, Siegfried Nijssen","author_ids":"1740042, 1834512, 1702481","abstract":"Machine learning and data mining have become aware that using constraints when learning patterns and rules can be very useful. To this end, a large number of special purpose systems and techniques have been developed for solving such constraint-based mining and learning problems. These techniques have, so far, been developed independently of the general purpose tools and principles of constraint programming known within the field of artificial intelligence. This paper shows that off-the-shelf constraint programming techniques can be applied to various pattern mining and rule learning problems (cf. This does not only lead to methodologies that are more general and flexible , but also provides new insights into the underlying mining problems that allow us to improve the state-of-the-art in data mining. Such a combination of constraint programming and data mining raises a number of interesting new questions and challenges.","cites":"20","conferencePercentile":"76.45051195"},{"venue":"AAAI","id":"e49684d64643fb1c77a7f65e2e7f265d1d7a285a","venue_1":"AAAI","year":"2013","title":"Formalizing Hierarchical Clustering as Integer Linear Programming","authors":"Sean Gilpin, Siegfried Nijssen, Ian Davidson","author_ids":"2330548, 1702481, 1712716","abstract":"Hierarchical clustering is typically implemented as a greedy heuristic algorithm with no explicit objective function. In this work we formalize hierarchical clustering as an integer linear programming (ILP) problem with a natural objective function and the dendrogram properties enforced as linear constraints. Though exact solvers exists for ILP we show that a simple randomized algorithm and a linear programming (LP) relaxation can be used to provide approximate solutions faster. Formalizing hierarchical clustering also has the benefit that relaxing the constraints can produce novel problem variations such as overlapping clusterings. Our experiments show that our formulation is capable of outperforming standard ag-glomerative clustering algorithms in a variety of settings, including traditional hierarchical clustering as well as learning overlapping clusterings.","cites":"4","conferencePercentile":"55.45454545"},{"venue":"AAAI","id":"11b6bdfe36c48b11367b27187da11d95892f0361","venue_1":"AAAI","year":"2008","title":"Maximum Entropy Inverse Reinforcement Learning","authors":"Brian D. Ziebart, Andrew L. Maas, J. Andrew Bagnell, Anind K. Dey","author_ids":"1753269, 2339658, 1756566, 1703700","abstract":"Recent research has shown the benefit of framing problems of imitation learning as solutions to Markov Decision Problems. This approach reduces learning to the problem of recovering a utility function that makes the behavior induced by a near-optimal policy closely mimic demonstrated behavior. In this work, we develop a probabilistic approach based on the principle of maximum entropy. Our approach provides a well-defined, globally normalized distribution over decision sequences, while providing the same performance guarantees as existing methods. We develop our technique in the context of modeling real-world navigation and driving behaviors where collected data is inherently noisy and imperfect. Our probabilistic approach enables modeling of route preferences as well as a powerful new approach to inferring destinations and routes based on partial trajectories.","cites":"233","conferencePercentile":"100"},{"venue":"AAAI","id":"072d496525290af93164b6d0c50857e8e70fdc2b","venue_1":"AAAI","year":"2015","title":"Shift-Pessimistic Active Learning Using Robust Bias-Aware Prediction","authors":"Anqi Liu, Lev Reyzin, Brian D. Ziebart","author_ids":"7762477, 1798267, 1753269","abstract":"Existing approaches to active learning are generally optimistic about their certainty with respect to data shift between labeled and unlabeled data. They assume that unknown datapoint labels follow the inductive biases of the active learner. As a result, the most useful data-point labels—ones that refute current inductive biases— are rarely solicited. We propose a shift-pessimistic approach to active learning that assumes the worst-case about the unknown conditional label distribution. This closely aligns model uncertainty with generalization error, enabling more useful label solicitation. We investigate the theoretical benefits of this approach and demonstrate its empirical advantages on probabilistic binary classification tasks.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"1ae155a1a227db2c141bfa68d4de41c63b1e2eba","venue_1":"AAAI","year":"2015","title":"Intent Prediction and Trajectory Forecasting via Predictive Inverse Linear-Quadratic Regulation","authors":"Mathew Monfort, Anqi Liu, Brian D. Ziebart","author_ids":"2526653, 7762477, 1753269","abstract":"To facilitate interaction with people, robots must not only recognize current actions, but also infer a person's intentions and future behavior. Recent advances in depth camera technology have significantly improved human motion tracking. However , the inherent high dimensionality of interacting with the physical world makes efficiently forecasting human intention and future behavior a challenging task. Predictive methods that estimate uncertainty are therefore critical for supporting appropriate robotic responses to the many ambiguities posed within the human-robot interaction setting. We address these two challenges, high dimensionality and uncertainty, by employing predictive inverse optimal control methods to estimate a probabilistic model of human motion trajectories. Our inverse optimal control formulation estimates quadratic cost functions that best rationalize observed trajectories framed as solutions to linear-quadratic regular-ization problems. The formulation calibrates its uncertainty from observed motion trajectories, and is efficient in high-dimensional state spaces with linear dynamics. We demonstrate its effectiveness on a task of anticipating the future tra-jectories, target locations and activity intentions of hand motions .","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"5926970bba7c6b9da8e928f806fccad719f9277a","venue_1":"AAAI","year":"2007","title":"Recognition of Hand Drawn Chemical Diagrams","authors":"Tom Y. Ouyang, Randall Davis","author_ids":"3182344, 1735802","abstract":"Chemists often use hand-drawn structural diagrams to capture and communicate ideas about organic compounds. However, the software available today for specifying these structures to a computer relies on a traditional mouse and keyboard interface, and as a result lacks the ease of use, naturalness, and speed of drawing on paper. In response, we have developed a novel sketch-based system capable of interpreting hand-drawn organic chemistry diagrams, allowing users to draw molecules with a pen-based input device in much the same way that they would on paper. The system's ability to interpret a sketch is based on knowledge about both chemistry and chemical drawing conventions. The system employs a trainable symbol recognizer incorporating both feature-based and image-based methods to locate and identify symbols in the sketch. Analysis of the spatial context around each symbol allows the system to choose among competing interpretations and determine an initial structure for the molecule. Finally , knowledge of chemistry (in particular chemical valence) enables the system to check the validity of its interpretation and, when necessary, refine it to recover from inconsistencies. We demonstrate that the system is capable of recognizing diagrams of common organic molecules and show that using domain knowledge produces a noticeable improvement in recognition accuracy .","cites":"24","conferencePercentile":"74.92581602"},{"venue":"AAAI","id":"b7d1a1b763355c7a4f2422f60397f9bc5503f460","venue_1":"AAAI","year":"2015","title":"A Mechanism Design Approach to Measure Awareness","authors":"Diodato Ferraioli, Carmine Ventre, Gabor Aranyi","author_ids":"1766012, 1798664, 1786905","abstract":"In this paper, we study protocols that allow to discern conscious and unconscious decisions of human beings; i.e., protocols that measure awareness. Consciousness is a central research theme in Neuroscience and AI, which remains, to date, an obscure phenomenon of human brains. Our starting point is a recent experiment, called Post Decision Wagering (PDW) (Persaud, McLeod, and Cowey 2007), that attempts to align experimenters' and subjects' objectives by leverag-ing financial incentives. We note a similarity with mechanism design, a research area which aims at the design of protocols that reconcile often divergent objectives through incentive-compatibility. We look at the issue of measuring awareness from this perspective. We abstract the setting underlying the PDW experiment and identify three factors that could make it ineffective: rationality, risk attitude and bias of subjects. Using mechanism design tools, we study the barrier between possibility and impossibility of incentive compatibility with respect to the aforementioned characteristics of subjects. We complete this study by showing how to use our mechanisms to potentially get a better understanding of consciousness.","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"23319dfe6652eb6bcdb678cb56ea3318443881f9","venue_1":"AAAI","year":"2007","title":"Using Eye-Tracking Data for High-Level User Modeling in Adaptive Interfaces","authors":"Cristina Conati, Christina Merten, Saleema Amershi, Kasia Muldner","author_ids":"1692714, 1881817, 1719124, 1757189","abstract":"In recent years, there has been substantial research on exploring how AI can contribute to Human-Computer Interaction by enabling an interface to understand a user's needs and act accordingly. Understanding user needs is especially challenging when it involves assessing the user's high-level mental states not easily reflected by interface actions. In this paper, we present our results on using eye-tracking data to model such mental states during interaction with adaptive educational software. We then discuss the implications of our research for Intelligent User Interfaces.","cites":"2","conferencePercentile":"19.43620178"},{"venue":"AAAI","id":"279d1176a3602dd6a58d9c4dcb15035e5e4f30bb","venue_1":"AAAI","year":"2015","title":"Constructing Models of User and Task Characteristics from Eye Gaze Data for User-Adaptive Information Highlighting","authors":"Matthew Gingerich, Cristina Conati","author_ids":"1959537, 1692714","abstract":"A user-adaptive information visualization system capable of learning models of users and the visualization tasks they perform could provide interventions optimized for helping specific users in specific task contexts. In this paper, we investigate the accuracy of predicting visualization tasks, user performance on tasks, and user traits from gaze data. We show that predictions made with a logistic regression model are significantly better than a baseline classifier, with particularly strong results for predicting task type and user performance. Furthermore, we compare classifiers built with interface-independent and interface-dependent features, and show that the interface-independent features are comparable or superior to interface-dependent ones. Finally, we discuss how the accuracy of predictive models is affected if they are trained with data from trials that had highlighting interventions added to the visualization.","cites":"2","conferencePercentile":"51.65354331"},{"venue":"AAAI","id":"758e90f36e6b69e004256c935ff5bb0daf22ed7a","venue_1":"AAAI","year":"2004","title":"Automatically Transforming Symbolic Shape Descriptions for Use in Sketch Recognition","authors":"Tracy Anne Hammond, Randall Davis","author_ids":"2662321, 1735802","abstract":"Sketch recognition systems are currently being developed for many domains, but can be time consuming to build if they are to handle the intricacies of each domain. This paper presents the first translator that takes symbolic shape descriptions (written in the LADDER sketch language) and automatically transforms them into shape recognizers, editing recognizers, and shape exhibitors for use in conjunction with a domain independent sketch recognition system. This transformation allows us to build a single domain independent recognition system that can be customized for multiple domains. We have tested our framework by writing several domain descriptions and automatically created a domain specific sketch recognition system for each domain .","cites":"27","conferencePercentile":"73.35329341"},{"venue":"AAAI","id":"2def47989c6f9143184b5eaaf3aca3f2833f3e05","venue_1":"AAAI","year":"2014","title":"Learning from Unscripted Deictic Gesture and Language for Human-Robot Interactions","authors":"Cynthia Matuszek, Liefeng Bo, Luke S. Zettlemoyer, Dieter Fox","author_ids":"2674440, 1766509, 1982950, 1776234","abstract":"As robots become more ubiquitous, it is increasingly important for untrained users to be able to interact with them intuitively. In this work, we investigate how people refer to objects in the world during relatively un-structured communication with robots. We collect a corpus of deictic interactions from users describing objects, which we use to train language and gesture models that allow our robot to determine what objects are being indicated. We introduce a temporal extension to state-of-the-art hierarchical matching pursuit features to support gesture understanding, and demonstrate that combining multiple communication modalities more effectively capture user intent than relying on a single type of input. Finally, we present initial interactions with a robot that uses the learned models to follow commands.","cites":"16","conferencePercentile":"94.65909091"},{"venue":"AAAI","id":"55d168f00dd5055fa49c3783d3b2f4105fea24d2","venue_1":"AAAI","year":"1994","title":"Using Knowledge Acquisition and Representation Tools to Support Scientific Communities","authors":"Brian R. Gaines, Mildred L. G. Shaw","author_ids":"1723015, 1715862","abstract":"Widespread access to the Internet has led to the formation of geographically dispersed scientific communities collaborating through the network. The tools supporting such collaboration currently are based primarily on electronic mail through mailing list servers, and access to archives of research reports through ftp, gopher and world wide web. However, electronic communication can support the knowledge processes of scientific communities more directly through overtly represented knowledge structures. This paper describes some experiments in the use of knowledge acquisition (KA) and representation (KR) tools to define and analyze major policy and technical issues in an international research community responsible for one of the test cases in the Intelligent Manufacturing Systems (IMS) research program. It is concluded that distributed knowledge support systems in routine use by world-class scientific communities collaborating through the Internet will provide a major impetus to artificial intelligence research.","cites":"40","conferencePercentile":"80.39647577"},{"venue":"AAAI","id":"493194b18394e0b44c4859818b77c40ed6493997","venue_1":"AAAI","year":"2008","title":"Lifted Probabilistic Inference with Counting Formulas","authors":"Brian Milch, Luke S. Zettlemoyer, Kristian Kersting, Michael Haimes, Leslie Pack Kaelbling","author_ids":"3226208, 1982950, 1746871, 2501712, 1709512","abstract":"Lifted inference algorithms exploit repeated structure in prob-abilistic models to answer queries efficiently. Previous work such as de Salvo Braz et al.'s first-order variable elimination (FOVE) has focused on the sharing of potentials across interchangeable random variables. In this paper, we also exploit interchangeability within individual potentials by introducing counting formulas, which indicate how many of the random variables in a set have each possible value. We present a new lifted inference algorithm, C-FOVE, that not only handles counting formulas in its input, but also creates counting formulas for use in intermediate potentials. C-FOVE can be described succinctly in terms of six operators, along with heuristics for when to apply them. Because counting formulas capture dependencies among large numbers of variables compactly, C-FOVE achieves asymptotic speed improvements compared to FOVE.","cites":"113","conferencePercentile":"98.25949367"},{"venue":"AAAI","id":"93e138aea8fbafbc61db7c01ad555619c59e5b1b","venue_1":"AAAI","year":"1992","title":"Using Deep Structure to Locate Hard Problems","authors":"Colin P. Williams, Tad Hogg","author_ids":"2599842, 1766745","abstract":"One usually writes A.I. programs to be used on a range of examples which, although similar in kind, differ in detail. This paper shows how to predict where, in a space of problem instances, the hardest problems are to be found and where the fluctuations in difficulty are greatest. Our key insight is to shift emphasis from modelling sophisticated algorithms directly to modelling a search space which captures their principal effects. This allows us to analyze complex A.I. problems in a simple and intuitive way. We present a sample analysis, compare our model's quantitative predictions with data obtained independently and describe how to exploit the results to estimate the value of preprocessing. Finally, we circumscribe the kind problems to which the methodology is suited.","cites":"54","conferencePercentile":"75.89285714"},{"venue":"AAAI","id":"32576a53b4f3ec2f0fae106b411ebb013ffe16b3","venue_1":"AAAI","year":"2007","title":"Supporting Feedback and Assessment of Digital Ink Answers to In-Class Exercises","authors":"Kimberle Koile, Kevin Chevalier, Michel Rbeiz, Adam Rogal, David Singer, Jordan Sorensen, Amanda Jane Coles, Kah Seng Tay, Kenneth Wu","author_ids":"2105944, 3153758, 2025215, 2623993, 1951855, 1862056, 5342780, 2750935, 2057818","abstract":"Effective teaching involves treating the presentation of new material and the assessment of students' mastery of this material as part of a seamless and continuous feedback cycle. We have developed a computer system, called Classroom Learning Partner (CLP), that supports this methodology, and we have used it in teaching an introductory computer science course at MIT over the past year. Through evaluation of controlled classroom experiments, we have demonstrated that this approach reaches students who would have otherwise been left behind, and that it leads to greater attentiveness in class, greater student satisfaction, and better interactions between the instructor and student. The current CLP system consists of a network of Tablet PCs, and software for posing questions to students, interpreting their handwritten answers, and aggregating those answers into equivalence classes, each of which represents a particular level of understanding or misconception of the material. The current system supports a useful set of recognizers for specific types of answers, and employs AI techniques in the knowledge representation and reasoning necessary to support interpretation and aggregation of digital ink answers.","cites":"16","conferencePercentile":"64.9851632"},{"venue":"AAAI","id":"3b017deca3839f0387e85155ad280da44fbae491","venue_1":"AAAI","year":"2007","title":"TeamTalk: A Platform for Multi-Human-Robot Dialog Research in Coherent Real and Virtual Spaces","authors":"Thomas K. Harris, Alexander I. Rudnicky","author_ids":"2252807, 1783635","abstract":"Performing experiments with human-robot interfaces often requires the allocation of expensive and complex hardware and large physical spaces. Those costs constrain development and research to the currently affordable resources, and they retard the testing-and-redevelopment cycle. In order to explore research free from mundane allocation constraints and speed-up our platform development cycle, we have developed a platform for research of multi-human-robot spoken dialog in coherent real and virtual spaces. We describe the system , and speculate on how it will further research in this domain.","cites":"7","conferencePercentile":"42.58160237"},{"venue":"AAAI","id":"59487025b6afe86f9949e46d3c9130cc05c2d858","venue_1":"AAAI","year":"2015","title":"Sampling Representative Users from Large Social Networks","authors":"Jie Tang, Chenhui Zhang, Keke Cai, Li Zhang, Zhong Su","author_ids":"1750766, 2915439, 3171259, 1712838, 1703625","abstract":"Finding a subset of users to statistically represent the original social network is a fundamental issue in Social Network Analysis (SNA). The problem has not been extensively studied in existing literature. In this paper, we present a formal definition of the problem of sampling representative users from social network. We propose two sampling models and theoretically prove their NP-hardness. To efficiently solve the two models, we present an efficient algorithm with provable approximation guarantees. Experimental results on two datasets show that the proposed models for sampling representative users significantly outperform (+6%-23% in terms of Precision@100) several alternative methods using authority or structure information only. The proposed algorithms are also effective in terms of time complexity. Only a few seconds are needed to sampling 300 representative users from a network of 100,000 users. All data and codes are publicly available.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"6e4d29fc4ac85255058831bcd39f4a0630264200","venue_1":"AAAI","year":"2016","title":"Towards Optimal Binary Code Learning via Ordinal Embedding","authors":"Hong Liu, Rongrong Ji, Yongjian Wu, Wei Liu","author_ids":"2407200, 1725599, 2252731, 3406279","abstract":"Binary code learning, a.k.a., hashing, has been recently popular due to its high efficiency in large-scale similarity search and recognition. It typically maps high-dimensional data points to binary codes, where data similarity can be efficiently computed via rapid Hamming distance. Most existing unsupervised hash-ing schemes pursue binary codes by reducing the quan-tization error from an original real-valued data space to a resulting Hamming space. On the other hand, most existing supervised hashing schemes constrain binary code learning to correlate with pairwise similarity labels. However, few methods consider ordinal relations in the binary code learning process, which serve as a very significant cue to learn the optimal binary codes for similarity search. In this paper, we propose a novel hashing scheme, dubbed Ordinal Embedding Hashing (OEH), which embeds given ordinal relations among data points to learn the ranking-preserving binary codes. The core idea is to construct a directed unweighted graph to capture the ordinal relations, and then train the hash functions using this ordinal graph to preserve the permutation relations in the Hamming space. To learn such hash functions effectively, we further relax the discrete constraints and design a stochastic gradient decent algorithm to obtain the optimal solution. Experimental results on two large-scale benchmark datasets demonstrate that the proposed OEH method can achieve superior performance over the state-of-the-arts approaches. At last, the evaluation on query by humming dataset demonstrates the OEH also has good performance for music retrieval by using user's humming or singing.","cites":"1","conferencePercentile":"40.70945946"},{"venue":"AAAI","id":"149d1fa11d81a18ed5c3a84f37f35a8e8be1dae4","venue_1":"AAAI","year":"2015","title":"Optimizing Bag Features for Multiple-Instance Retrieval","authors":"Zhouyu Fu, Feifei Pan, Cheng Deng, Wei Liu","author_ids":"3296782, 3291074, 1715156, 3406279","abstract":"Multiple-Instance (MI) learning is an important supervised learning technique which deals with collections of instances called bags. While existing research in MI learning mainly focused on classification, in this paper we propose a new approach for MI retrieval to enable effective similarity retrieval of bags of instances, where training data is presented in the form of similar and dissimilar bag pairs. An embedded scheme is devised as encoding each bag into a single bag feature vector by exploiting a similarity-based transformation. In this way, the original MI problem is converted into a single-instance version. Furthermore, we develop a principled approach for optimizing bag features specific to similarity retrieval through leveraging pairwise label information at the bag level. The experimental results demonstrate the effectiveness of the proposed approach in comparison with the alternatives for MI retrieval.","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"00cfcfc365dbbe30bfbee6b4f04d068a539a7d97","venue_1":"AAAI","year":"2015","title":"Low-Rank Similarity Metric Learning in High Dimensions","authors":"Wei Liu, Cun Mu, Rongrong Ji, Shiqian Ma, John R. Smith, Shih-Fu Chang","author_ids":"3406279, 2083816, 1725599, 2730864, 1788270, 1735547","abstract":"Metric learning has become a widespreadly used tool in machine learning. To reduce expensive costs brought in by increasing dimensionality, low-rank metric learning arises as it can be more economical in storage and computation. However, existing low-rank metric learning algorithms usually adopt nonconvex objectives, and are hence sensitive to the choice of a heuristic low-rank basis. In this paper, we propose a novel low-rank metric learning algorithm to yield bilinear similarity functions. This algorithm scales linearly with input dimensionali-ty in both space and time, therefore applicable to high-dimensional data domains. A convex objective free of heuristics is formulated by leveraging trace norm regu-larization to promote low-rankness. Crucially, we prove that all globally optimal metric solutions must retain a certain low-rank structure, which enables our algorithm to decompose the high-dimensional learning task into two steps: an SVD-based projection and a metric learning problem with reduced dimensionality. The latter step can be tackled efficiently through employing a linearized Alternating Direction Method of Multipliers. The efficacy of the proposed algorithm is demonstrated through experiments performed on four benchmark datasets with tens of thousands of dimensions.","cites":"2","conferencePercentile":"51.65354331"},{"venue":"AAAI","id":"75dc5dafcc61c1a9413d535713c2b652129ae1fd","venue_1":"AAAI","year":"2007","title":"Enabling Intelligent Content Discovery on the Mobile Internet","authors":"Barry Smyth, Paul Cotter, Stephen Oman","author_ids":"1701131, 2155750, 2380897","abstract":"The mobile Internet is a massive opportunity for mobile operators and content providers, but despite significant improvements in handsets, infrastructure, content , and charging models, mobile users are still struggling to access and locate relevant content and services. The core of this so-called content discovery problem is the navigation effort that users must invest in browsing and searching for mobile content. In this paper we describe one successfully deployed solution, which uses personalization technology to profile subscriber interests in order to automatically adapt mobile portals to their learned preferences. We present summary results, from our deployment experiences with more than 40 mobile operators and millions of subscribers around the world, which demonstrate how this solution can have a significant impact on portal usability, subscriber usage, and mobile operator revenues.","cites":"5","conferencePercentile":"34.71810089"},{"venue":"AAAI","id":"46c648637200556f1ddb4471eeacc0eff8ab7e6e","venue_1":"AAAI","year":"2005","title":"On the Evaluation of Dynamic Critiquing: A Large-Scale User Study","authors":"Kevin McCarthy, Lorraine McGinty, Barry Smyth, James Reilly","author_ids":"1748265, 2610734, 1701131, 2739272","abstract":"Critiquing is an important form of feedback in conversational recommender systems. However, in these systems the user is usually limited to critiquing a single product feature at a time. Recently dynamic critiquing has been proposed to address this shortcoming, by automatically generating compound critiques over multiple features that may be presented to the user at recommendation time. To date a number of different versions of dynamic critiquing have been evaluated in isolation, and with reference to artificial users. In this paper we bring together the main flavors of dynamic critiquing and perform a large-scale comparative evaluation as part of an extensive real-user trial. This evaluation reveals some interesting facts about the way real users interact with critique-based recommenders.","cites":"9","conferencePercentile":"39.86013986"},{"venue":"AAAI","id":"0556695f904446e5c2ae0517798ec888deaa2d68","venue_1":"AAAI","year":"2007","title":"Learning by Combining Observations and User Edits","authors":"Vittorio Castelli, Lawrence D. Bergman, Daniel Oblinger","author_ids":"2879453, 3022115, 2104782","abstract":"We introduce a new collaborative machine learning paradigm in which the user directs a learning algorithm by manually editing the automatically induced model. We identify a generic architecture that supports seamless interweaving of automated learning from training samples and manual edits of the model, and we discuss the main difficulties that the framework addresses. We describe Augmentation-Based Learning (ABL), the first learning algorithm that supports interweaving of edits and learning from training samples. We use examples based on ABL to outline selected advantages of the approach—dealing with bad data by manually removing their effects from the model, and learning a model with fewer training samples.","cites":"0","conferencePercentile":"5.489614243"},{"venue":"AAAI","id":"572477abe13140e9b78298938262571854db1855","venue_1":"AAAI","year":"2010","title":"Trust Models and Con-Man Agents: From Mathematical to Empirical Analysis","authors":"Amirali Salehi-Abari, Tony White","author_ids":"1829355, 1768982","abstract":"Recent work has demonstrated that several trust and reputation models can be exploited by malicious agents with cyclical behaviour. In each cycle, the malicious agent with cyclical behaviour first regains a high trust value after a number of cooperations and then abuses its gained trust by engaging in a bad transaction. Using a game theoretic formulation, Salehi-Abari and White have proposed the AER model that is resistant to exploitation by cyclical behaviour. Their simulation results imply that FIRE, Regret, and a model due to Yu and Singh, can always be exploited with an appropriate value for the period of cyclical behaviour. Furthermore, their results demonstrate that this is not so for the proposed adaptive scheme. This paper provides a mathematical analysis of the properties of five trust models when faced with cyclical behaviour of malicious agents. Three main results are proven. First, malicious agents can always select a cycle period that allows them to exploit the four models of FIRE, Regret, Prob-abilistic models, and Yu and Singh indefinitely. Second, malicious agents cannot select a single, finite cycle period that allows them to exploit the AER model forever. Finally, the number of cooperations required to achieve a given trust value increases monotonically with each cycle. In addition to the mathematical analysis, this paper empirically shows how malicious agents can use the theorems proven in this paper to mount efficient attacks on trust models.","cites":"5","conferencePercentile":"32.08191126"},{"venue":"AAAI","id":"1fb00a9a3c06413f6fb1831cd3e123d9ddb89834","venue_1":"AAAI","year":"2005","title":"Clustering and Classifying Person Names by Origin","authors":"Fei Huang, Stephan Vogel, Alexander H. Waibel","author_ids":"2166643, 1684854, 4500589","abstract":"In natural language processing, information about a person's geographical origin is an important feature for name entity transliteration and question answering. We propose a language-independent name origin clustering and classification framework. Provided with a small amount of bilingual name translation pairs with labeled origins, we measure origin similarities based on the perplexities of name character language and translation models. We group similar origins into clusters, then train a Bayesian classifier with different features. It achieves 84% classification accuracy with source names only, and 91% with both source and target name pairs. We apply the origin clustering and classification technique to a name transliteration task. The cluster-specific transliteration model dramatically improves the transliteration accuracy from 3.8% to 55%, reducing the transliteration character error rate from 50.3 to 13.5. Adding more unlabeled name pairs to the cluster-specific name transliteration model further improves the transliteration accuracy.","cites":"4","conferencePercentile":"23.25174825"},{"venue":"AAAI","id":"1173000a8e5a94f770b812082bd05a544bc1d6de","venue_1":"AAAI","year":"2005","title":"Learning Planning Rules in Noisy Stochastic Worlds","authors":"Luke S. Zettlemoyer, Hanna M. Pasula, Leslie Pack Kaelbling","author_ids":"1982950, 3202401, 1709512","abstract":"We present an algorithm for learning a model of the effects of actions in noisy stochastic worlds. We consider learning in a 3D simulated blocks world with realistic physics. To model this world, we develop a planning representation with explicit mechanisms for expressing object reference and noise. We then present a learning algorithm that can create rules while also learning derived predicates, and evaluate this algorithm in the blocks world simulator, demonstrating that we can learn rules that effectively model the world dynamics.","cites":"40","conferencePercentile":"86.18881119"},{"venue":"AAAI","id":"2cdb1dd96930ae75138729e39710149cffc9fd2d","venue_1":"AAAI","year":"1991","title":"Integrating Rules in Term Subsumption Knowledge Representation Servers","authors":"Brian R. Gaines","author_ids":"1723015","abstract":"This paper addresses the integration of services for rule-based reasoning in knowledge representation servers based on term subsumption languages. As an alternative to previous constructions of rules as concept→concept links, a mechanism is proposed based on intensional roles implementing the axiom of comprehension in set theory. This has the benefit of providing both rules as previously defined, and set aggregation, using a simple mechanism that is of identical computational complexity to that for rules alone. The extensions proposed have been implemented as part of KRS, a knowledge representation server written as a class library in C++. The paper gives an example of their application to the ripple-down rule technique for large-scale knowledge base operation, acquisition and maintenance.","cites":"18","conferencePercentile":"48.86363636"},{"venue":"AAAI","id":"1e8f3691d55fbca5f67421af48f9e06f8458762e","venue_1":"AAAI","year":"2005","title":"Controlling Tiny Multi-Scale Robots for Nerve Repair","authors":"Tad Hogg, David W. Sretavan","author_ids":"1766745, 3198730","abstract":"We designed and evaluated multiagent control for microscopic robots (\" nanorobots \") aiding the surgical repair of damaged nerve cells. This repair operates on both nerves as a whole, at scales of hundreds of microns, and individual nerve cell axons, at scales of about a micron. We match the robots to these sizes using a combination of microelectomechanical (MEMS) machines for the larger operations and nanorobots for operations on individual cells. Multiagent control allows accurate and rapid repair with such robots, with only modest computational and communication requirements for the nanorobots, a significant benefit due to their physical limitations. Our simulations, using physical parameters dictated by nerve biology and plausible nanorobotic capabilities, show how specific control choices lead to trade-offs in clinical outcome. Beyond the specific example of nerve repair treated here, multi-scale robots could aid a variety of medical and biological tasks involving both the large scale of organs or tissues and the microscopic scale of individual cells.","cites":"7","conferencePercentile":"32.69230769"},{"venue":"AAAI","id":"799bf092a6c550c544fb4c8e6f3561bf32f5bc56","venue_1":"AAAI","year":"1991","title":"An Efficient Reactive Planner for Synthesizing Reactive Plans","authors":"Patrice Godefroid, Froduald Kabanza","author_ids":"1707506, 2132916","abstract":"We present a nonlinear forward-search method suitable for planning the reactions of an agent operating in a highly unpredictable environment. We show that this method is more eecient than existing linear methods. We then introduce the notion of safety and liveness rules. This makes possible a sharper exploitation of the information retrieved when exploring the future of the agent.","cites":"40","conferencePercentile":"72.72727273"},{"venue":"AAAI","id":"4e4fa167d772f34dfffc374e021ab3044566afc3","venue_1":"AAAI","year":"2014","title":"Learning Low-Rank Representations with Classwise Block-Diagonal Structure for Robust Face Recognition","authors":"Yong Li, Jing Liu, Zechao Li, Yangmuzi Zhang, Hanqing Lu, Songde Ma","author_ids":"1689181, 5661757, 3233021, 2438629, 1694235, 1711796","abstract":"Face recognition has been widely studied due to its importance in various applications. However, the case that both training images and testing images are corrupted is not well addressed. Motivated by the success of low-rank matrix recovery, we propose a novel semi-supervised low-rank matrix recovery algorithm for robust face recognition. The proposed method can learn robust discriminative representations for both training images and testing images simultaneously by exploiting the classwise block-diagonal structure. Specifically, low-rank matrix approximation can handle the possible contamination of data. Moreover, the classwise block-diagonal structure is exploited to promote discrimination of representations for robust recognition. The above issues are formulated into a unified objective function and we design an efficient optimization procedure based on augmented Lagrange multiplier method to solve it. Extensive experiments on three public databases are performed to validate the effectiveness of our approach. The strong identification capability of representations with block-diagonal structure is verified.","cites":"3","conferencePercentile":"49.43181818"},{"venue":"AAAI","id":"4ac1183a42ebd661acbaf3350797bf79b8083180","venue_1":"AAAI","year":"2014","title":"Agent Behavior Prediction and Its Generalization Analysis","authors":"Fei Tian, Haifang Li, Wei Chen, Tao Qin, Enhong Chen, Tie-Yan Liu","author_ids":"8049661, 7178622, 1728624, 8193913, 1703319, 1744859","abstract":"Machine learning algorithms have been applied to predict agent behaviors in real-world dynamic systems, such as advertiser behaviors in sponsored search and worker behaviors in crowdsourcing. Behavior data in these systems are generated by live agents: once systems change due to the adoption of prediction models learnt from behavior data, agents will observe and respond to these changes by changing their own behaviors accordingly. Therefore, the evolving behavior data will not be identically and independently distributed, posing great challenges to theoretical analysis. To tackle this challenge, in this paper, we propose to use Markov Chain in Random Environments (MCRE) to describe the behavior data, and perform generalization analysis of machine learning algorithms on its basis. We propose a novel technique that transforms the original time-variant MCRE into a higher-dimensional time-homogeneous Markov chain, which is easier to deal with. We prove the convergence of the new Markov chain when time approaches infinity. Then we obtain a generalization bound for the machine learning algorithms on the behavior data generated by the new Markov chain. To the best of our knowledge, this is the first work that performs the generalization analysis on data generated by complex processes in real-world dynamic systems.","cites":"3","conferencePercentile":"49.43181818"},{"venue":"AAAI","id":"0f020b65569ab27018f5796114332f0e22377df9","venue_1":"AAAI","year":"2006","title":"AI Support for Building Cognitive Models","authors":"Robert St. Amant, Sean P. McBride, Frank E. Ritter","author_ids":"1736796, 2870108, 1701118","abstract":"Cognitive modeling techniques provide a way of evaluating user interface designs, based on what is known about human cognitive strengths and limitations. Cognitive modelers face a tradeoff, however: more detailed models require disproportionately more time and effort to develop than coarser models. In this paper we describe a system, G2A, that automatically produces translations from abstract GOMS models into more detailed ACT-R models. G2A demonstrates how even simple AI techniques can facilitate the construction of cognitive models and suggests new directions for improving modeling tools.","cites":"4","conferencePercentile":"31.26801153"},{"venue":"AAAI","id":"df787a974fff59f557ed1ec620fc345568aec491","venue_1":"AAAI","year":"2014","title":"Learning Deep Representations for Graph Clustering","authors":"Fei Tian, Bin Gao, Qing Cui, Enhong Chen, Tie-Yan Liu","author_ids":"8049661, 1678646, 2323679, 1703319, 1744859","abstract":"Recently deep learning has been successfully adopted in many applications such as speech recognition and image classification. In this work, we explore the possibility of employing deep learning in graph clustering. We propose a simple method, which first learns a non-linear embedding of the original graph by stacked au-toencoder, and then runs k-means algorithm on the embedding to obtain clustering result. We show that this simple method has solid theoretical foundation, due to the similarity between autoencoder and spectral clustering in terms of what they actually optimize. Then, we demonstrate that the proposed method is more efficient and flexible than spectral clustering. First, the computational complexity of autoencoder is much lower than spectral clustering: the former can be linear to the number of nodes in a sparse graph while the latter is super quadratic due to eigenvalue decomposition. Second, when additional sparsity constraint is imposed, we can simply employ the sparse autoencoder developed in the literature of deep learning; however, it is non-straightforward to implement a sparse spectral method. The experimental results on various graph datasets show that the proposed method significantly outperforms conventional spectral clustering, which clearly indicates the effectiveness of deep learning in graph clustering.","cites":"20","conferencePercentile":"97.04545455"},{"venue":"AAAI","id":"5a2b9f58127453207ea94f27f4eb0f37e9105241","venue_1":"AAAI","year":"2005","title":"Tool Use for Autonomous Agents","authors":"Robert St. Amant, Alexander B. Wood","author_ids":"1736796, 2137039","abstract":"The intelligent use of tools is a general and important human competence that AI research has not yet examined in depth. Other fields have studied the topic, however , with results we can compile into a broad characterization of habile (tool-using) agents. In this paper we give an overview of research on the use of physical tools, using this information to motivate the development of artificial habile agents. Specifically, we describe how research goals and methods in animal cog-nition overlap with those in artificial intelligence. We argue that analysis of activities of tool-using agents offers an informative way to evaluate intelligence.","cites":"23","conferencePercentile":"72.72727273"},{"venue":"AAAI","id":"596a356c6e75bede80711c874360f96f2f8828c9","venue_1":"AAAI","year":"2015","title":"A Nonconvex Relaxation Approach for Rank Minimization Problems","authors":"Xiaowei Zhong, Linli Xu, Yitan Li, Zhiyuan Liu, Enhong Chen","author_ids":"2722291, 2213331, 2454087, 1990595, 1703319","abstract":"Recently, solving rank minimization problems by leverag-ing nonconvex relaxations has received significant attention. Some theoretical analyses demonstrate that it can provide a better approximation of original problems than convex re-laxations. However, designing an effective algorithm to solve nonconvex optimization problems remains a big challenge. In this paper, we propose an Iterative Shrinkage-Thresholding and Reweighted Algorithm (ISTRA) to solve rank minimization problems using the nonconvex weighted nuclear norm as a low rank regularizer. We prove theoretically that under certain assumptions our method achieves a high-quality local optimal solution efficiently. Experimental results on synthetic and real data show that the proposed ISTRA algorithm out-performs state-of-the-art methods in both accuracy and efficiency .","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"d754bd4572f2dcd4c74ace8c668105bae1c604d6","venue_1":"AAAI","year":"2015","title":"Temporally Adaptive Restricted Boltzmann Machine for Background Modeling","authors":"Linli Xu, Yitan Li, Yubo Wang, Enhong Chen","author_ids":"2213331, 2454087, 7709215, 1703319","abstract":"We examine the fundamental problem of background modeling which is to model the background scenes in video sequences and segment the moving objects from the background. A novel approach is proposed based on the Restricted Boltzmann Machine (RBM) while exploiting the temporal nature of the problem. In particular , we augment the standard RBM to take a window of sequential video frames as input and generate the background model while enforcing the background smoothly adapting to the temporal changes. As a result, the augmented temporally adaptive model can generate stable background given noisy inputs and adapt quickly to the changes in background while keeping all the advantages of RBMs including exact inference and effective learning procedure. Experimental results demonstrate the effectiveness of the proposed method in mod-eling the temporal nature in background.","cites":"0","conferencePercentile":"11.73228346"},{"venue":"AAAI","id":"78618983dec4a92a9c5a1909e31bc8b95a5705a5","venue_1":"AAAI","year":"2016","title":"Exponential Recency Weighted Average Branching Heuristic for SAT Solvers","authors":"Jia Hui Liang, Vijay Ganesh, Pascal Poupart, Krzysztof Czarnecki","author_ids":"1910102, 2971783, 1807041, 1726889","abstract":"Modern conflict-driven clause-learning SAT solvers routinely solve large real-world instances with millions of clauses and variables in them. Their success crucially depends on effective branching heuristics. In this paper, we propose a new branching heuristic inspired by the exponential recency weighted average algorithm used to solve the bandit problem. The branching heuristic, we call CHB, learns online which variables to branch on by leveraging the feedback received from conflict analysis. We evaluated CHB on 1200 instances from the SAT Competition 2013 and 2014 instances, and showed that CHB solves significantly more instances than VSIDS, currently the most effective branching heuris-tic in widespread use. More precisely, we implemented CHB as part of the MiniSat and Glucose solvers, and performed an apple-to-apple comparison with their VSIDS-based variants. CHB-based MiniSat (resp. CHB-based Glucose) solved approximately 16.1% (resp. 5.6%) more instances than their VSIDS-based variants. Additionally, CHB-based solvers are much more efficient at constructing first preimage attacks on step-reduced SHA-1 and MD5 cryptographic hash functions , than their VSIDS-based counterparts. To the best of our knowledge, CHB is the first branching heuristic to solve significantly more instances than VSIDS on a large, diverse benchmark of real-world instances.","cites":"1","conferencePercentile":"40.70945946"},{"venue":"AAAI","id":"11187158d6777c4c884dfdf54c6cbfdeaee975e1","venue_1":"AAAI","year":"2015","title":"SoF: Soft-Cluster Matrix Factorization for Probabilistic Clustering","authors":"Han Zhao, Pascal Poupart, Yongfeng Zhang, Martin Lysy","author_ids":"1742487, 1807041, 3737473, 3281790","abstract":"We propose SoF (Soft-cluster matrix Factorization), a prob-abilistic clustering algorithm which softly assigns each data point into clusters. Unlike model-based clustering algorithms, SoF does not make assumptions about the data density distribution. Instead, we take an axiomatic approach to define 4 properties that the probability of co-clustered pairs of points should satisfy. Based on the properties, SoF utilizes a distance measure between pairs of points to induce the conditional co-cluster probabilities. The objective function in our framework establishes an important connection between probabilistic clustering and constrained symmetric Nonneg-ative Matrix Factorization (NMF), hence providing a theoretical interpretation for NMF-based clustering algorithms. To optimize the objective, we derive a sequential minimization algorithm using a penalty method. Experimental results on both synthetic and real-world datasets show that SoF significantly outperforms previous NMF-based algorithms and that it is able to detect non-convex patterns as well as cluster boundaries.","cites":"3","conferencePercentile":"62.91338583"},{"venue":"AAAI","id":"164f1802d58e2e9dd8764036290f063e8e29c563","venue_1":"AAAI","year":"2015","title":"Approximate Linear Programming for Constrained Partially Observable Markov Decision Processes","authors":"Pascal Poupart, Aarti Malhotra, Pei Pei, Kee-Eung Kim, Bongseok Goh, Michael H. Bowling","author_ids":"1807041, 2054645, 3694600, 1741330, 2717154, 1687780","abstract":"In many situations, it is desirable to optimize a sequence of decisions by maximizing a primary objective while respecting some constraints with respect to secondary objectives. Such problems can be naturally modeled as constrained partially observable Markov decision processes (CPOMDPs) when the environment is partially observable. In this work, we describe a technique based on approximate linear programming to optimize policies in CPOMDPs. The optimization is performed offline and produces a finite state controller with desirable performance guarantees. The approach outper-forms a constrained version of point-based value iteration on a suite of benchmark problems.","cites":"5","conferencePercentile":"80.31496063"},{"venue":"AAAI","id":"d0d7671c816ed7f37b16be86fa792a1b29ddd79b","venue_1":"AAAI","year":"2015","title":"Exploring Semantic Inter-Class Relationships (SIR) for Zero-Shot Action Recognition","authors":"Chuang Gan, Ming Lin, Yi Yang, Yueting Zhuang, Alexander G. Hauptmann","author_ids":"2551285, 2578453, 1698559, 1755711, 7661726","abstract":"Automatically recognizing a large number of action categories from videos is of significant importance for video understanding. Most existing works focused on the design of more discriminative feature representation , and have achieved promising results when the positive samples are enough. However, very limited efforts were spent on recognizing a novel action without any positive exemplars, which is often the case in the real settings due to the large amount of action classes and the users' queries dramatic variations. To address this issue, we propose to perform action recognition when no positive exemplars of that class are provided , which is often known as the zero-shot learning. Different from other zero-shot learning approaches, which exploit attributes as the intermediate layer for the knowledge transfer, our main contribution is SIR, which directly leverages the semantic inter-class relationships between the known and unknown actions followed by label transfer learning. The inter-class semantic relationships are automatically measured by continuous word vectors, which learned by the skip-gram model using the large-scale text corpus. Extensive experiments on the UCF101 dataset validate the superiority of our method over fully-supervised approaches using few positive exemplars.","cites":"10","conferencePercentile":"93.07086614"},{"venue":"AAAI","id":"b9ebbfe9f7b6180a7982cf9d490359721726b33f","venue_1":"AAAI","year":"2014","title":"A Novel Single-DBN Generative Model for Optimizing POMDP Controllers by Probabilistic Inference","authors":"Igor Kiselev, Pascal Poupart","author_ids":"2211782, 1807041","abstract":"As a promising alternative to using standard (often intractable) planning techniques with Bellman equations, we propose an interesting method of optimizing POMDP controllers by probabilistic inference in a novel equivalent single-DBN generative model. Our inference approach to POMDP planning allows for (1) for application of various techniques for probabilistic inference in single graphical models, and (2) for exploiting the factored structure in a controller architecture to take advantage of natural structural constrains of planning problems and represent them compactly. Our contributions can be summarized as follows: (1) we designed a novel single-DBN generative model that ensures that the task of probabilistic inference is equivalent to the original problem of optimizing POMDP controllers, and (2) we developed several inference approaches to approximate the value of the policy when exact inference methods are not tractable to solve large-size problems with complex graphical models. Inference in R-mixture model of reward likelihood The challenge of planning problems in partially observable settings (POMDP) is to find a control policy for selecting actions when the precise state of the environment is unknown and the agent can only perceive partial observations, which convey incomplete information about the world's state. We can represent POMDP control policies compactly by restricting the space of control policies being considered and representing the policy explicitly as a stochastic finite-state controller (FSC). However, the task of optimizing controllers is a notoriously difficult problem as the search space of all possible controller parameters is exponentially large. To address the scalability issues of solving large-scale planning problems, the community has been making significant progress in developing approximate planning algorithm to solve increasingly large problems. As a promising alternative to using standard (often intractable) planning techniques with Bellman equations , an interesting method of optimizing POMDP controllers by probabilistic inference in the equivalent mixture-DBN generative model with exponentiated rewards as observation likelihoods has been previously proposed (Tous-R-mixture (\" reward \" mixture) model with broken correlations between the reward variables at consecutive time periods is defined in a special way, where for each time period there is only one length-T mixture-DBN component, modeling a single binary stochastic reward with Pr(R = true | A T , S T , T = t) ∝ r(a t , s t), emitted only at its final termination step T (from the last state and action A T and S T) with Pr(T = t) = γ t. The fact that …","cites":"0","conferencePercentile":"9.431818182"},{"venue":"AAAI","id":"9785429538389146c8061ec856e74e957a246f2d","venue_1":"AAAI","year":"2016","title":"DARI: Distance metric And Representation Integration for Person Verification","authors":"Guangrun Wang, Liang Lin, Shengyong Ding, Ya Li, Qing Wang","author_ids":"2749191, 1737218, 2442939, 7137640, 7135234","abstract":"The past decade has witnessed the rapid development of feature representation learning and distance metric learning, whereas the two steps are often discussed separately. To explore their interaction, this work proposes an end-to-end learning framework called DARI, i.e. Distance metric And Representation Integration, and validates the effectiveness of DARI in the challenging task of person verification. Given the training images annotated with the labels, we first produce a large number of triplet units, and each one contains three images, i.e. one person and the matched/mismatch references. For each triplet unit, the distance disparity between the matched pair and the mismatched pair tends to be maximized. We solve this objective by building a deep architecture of convolutional neural networks. In particular, the Ma-halanobis distance matrix is naturally factorized as one top fully-connected layer that is seamlessly integrated with other bottom layers representing the image feature. The image feature and the distance metric can be thus simultaneously optimized via the one-shot backward propagation. On several public datasets, DARI shows very promising performance on re-identifying individuals cross cameras against various challenges , and outperforms other state-of-the-art approaches.","cites":"1","conferencePercentile":"40.70945946"},{"venue":"AAAI","id":"6a3f4a421466d3f83ec02da847d57598acd25347","venue_1":"AAAI","year":"1994","title":"Best-First Minimax Search: Othello Results","authors":"Richard E. Korf, David Maxwell Chickering","author_ids":"1682627, 1724065","abstract":"We present a very simple selective search algorithm for two-player games. It always expands next the frontier node that determines the minimax value of the root. The algorithm requires no information other than a static evaluation function, and its time overhead per node is similar to that of alpha-beta minimax. We also present an implementation of the algorithm that reduces its space complexity from exponential to linear in the search depth, at the cost of increased time complexity. In the game of Othello, using the evaluation function from BiIl (Lee & Mahajan 1990), best-first minimax outplays alpha-beta at moderate depths. A hybrid best-first extension algorithm, which combines alpha-beta and best-first minimax, performs significantly better than either pure algorithm even at greater depths. Similar results were also obtained for a class of random game trees.","cites":"13","conferencePercentile":"50.66079295"},{"venue":"AAAI","id":"36d163ac3706ff4753fb196bbe6199debcf2e56d","venue_1":"AAAI","year":"2012","title":"Hierarchical Double Dirichlet Process Mixture of Gaussian Processes","authors":"Aditya Tayal, Pascal Poupart, Yuying Li","author_ids":"3199627, 1807041, 1693211","abstract":"We consider an infinite mixture model of Gaussian processes that share mixture components between non-local clusters in data. Meeds and Osindero (2006) use a single Dirichlet process prior to specify a mixture of Gaussian processes using an infinite number of experts. In this paper, we extend this approach to allow for experts to be shared non-locally across the input domain. This is accomplished with a hierarchical double Dirich-let process prior, which builds upon a standard hierarchical Dirichlet process by incorporating local parameters that are unique to each cluster while sharing mixture components between them. We evaluate the model on simulated and real data, showing that sharing Gaus-sian process components non-locally can yield effective and useful models for richly clustered non-stationary, non-linear data.","cites":"3","conferencePercentile":"30.79268293"},{"venue":"AAAI","id":"caab0ae824a7abc8a70c370e7a6bd557e44e465b","venue_1":"AAAI","year":"2015","title":"DynaDiffuse: A Dynamic Diffusion Model for Continuous Time Constrained Influence Maximization","authors":"Miao Xie, Qiusong Yang, Qing Wang, Gao Cong, Gerard de Melo","author_ids":"1678832, 3080651, 7135234, 1737379, 1732213","abstract":"Studying the spread of phenomena in social networks is critical but still not fully solved. Existing influence max-imization models assume a static network, disregarding its evolution over time. We introduce the continuous time constrained influence maximization problem for dynamic diffusion networks, based on a novel diffusion model called DYNADIFFUSE. Although the problem is NP-hard, the influence spread functions are monotonic and submodular, enabling fast approximations on top of an innovative stochastic model checking approach. Experiments on real social network data show that our model finds higher quality solutions and our algorithm outperforms state-of-art alternatives.","cites":"1","conferencePercentile":"34.88188976"},{"venue":"AAAI","id":"3c6e646657aaf16d75bd72369f5fa6e842214567","venue_1":"AAAI","year":"2011","title":"Online Updating the Generalized Inverse of Centered Matrices","authors":"Qing Wang, Liang Zhang","author_ids":"7135234, 2257164","abstract":"In this paper, we present the exact online updating for-mulae for the generalized inverse of centered matrices. The computational cost is O(mn) for matrices of size m × n. Experimental results validate the proposed method's accuracy and efficiency.","cites":"0","conferencePercentile":"5.841924399"},{"venue":"AAAI","id":"41c0fc6f291b227159d672f7dd7ca6fa8ddbb071","venue_1":"AAAI","year":"2011","title":"Understanding Natural Language Commands for Robotic Navigation and Mobile Manipulation","authors":"Stefanie Tellex, Thomas Kollar, Steven Dickerson, Matthew R. Walter, Ashis Gopal Banerjee, Seth J. Teller, Nicholas Roy","author_ids":"2913681, 2836353, 2406615, 1733702, 3163927, 1720894, 1789920","abstract":"This paper describes a new model for understanding natural language commands given to autonomous systems that perform navigation and mobile manipulation in semi-structured environments. Previous approaches have used models with fixed structure to infer the likelihood of a sequence of actions given the environment and the command. In contrast, our framework, called Generalized Grounding Graphs (G 3), dynamically instantiates a probabilistic graphical model for a particular natural language command according to the com-mand's hierarchical and compositional semantic structure. Our system performs inference in the model to successfully find and execute plans corresponding to natural language commands such as \" Put the tire pallet on the truck. \" The model is trained using a corpus of commands collected using crowdsourcing. We pair each command with robot actions and use the corpus to learn the parameters of the model. We evaluate the robot's performance by inferring plans from natural language commands, executing each plan in a realistic robot simulator, and asking users to evaluate the system's performance. We demonstrate that our system can successfully follow many natural language commands from the corpus.","cites":"167","conferencePercentile":"100"},{"venue":"AAAI","id":"2870fcc54b1e85e3fe703eeaeaba059312532f22","venue_1":"AAAI","year":"2008","title":"Exploiting Causal Independence Using Weighted Model Counting","authors":"Wei Li, Pascal Poupart, Peter van Beek","author_ids":"2121690, 1807041, 2790783","abstract":"Previous studies have demonstrated that encoding a Bayesian network into a SAT-CNF formula and then performing weighted model counting using a backtracking search algorithm can be an effective method for exact inference in Bayesian networks. In this paper, we present techniques for improving this approach for Bayesian networks with noisy-OR and noisy-MAX relations—two relations which are widely used in practice as they can dramatically reduce the number of probabilities one needs to specify. In particular , we present two space efficient CNF encodings for noisy-OR/MAX and explore alternative search ordering heuristics. We experimentally evaluated our techniques on large-scale real and randomly generated Bayesian networks. On these benchmarks, our techniques gave speedups of up to two orders of magnitude over the best previous approaches and scaled up to networks with larger numbers of random variables .","cites":"5","conferencePercentile":"37.65822785"},{"venue":"AAAI","id":"464934d0c11cb867563b69c0a89a6c99d73f19ce","venue_1":"AAAI","year":"2006","title":"Compact, Convex Upper Bound Iteration for Approximate POMDP Planning","authors":"Tao Wang, Pascal Poupart, Michael H. Bowling, Dale Schuurmans","author_ids":"1685072, 1807041, 1687780, 1714772","abstract":"Partially observable Markov decision processes (POMDPs) are an intuitive and general way to model sequential decision making problems under uncertainty. Unfortunately, even approximate planning in POMDPs is known to be hard, and developing heuristic planners that can deliver reasonable results in practice has proved to be a significant challenge. In this paper, we present a new approach to approximate value-iteration for POMDP planning that is based on quadratic rather than piecewise linear function approximators. Specifically , we approximate the optimal value function by a convex upper bound composed of a fixed number of quadratics, and optimize it at each stage by semidefinite programming. We demonstrate that our approach can achieve competitive approximation quality to current techniques while still maintaining a bounded size representation of the function approximator. Moreover, an upper bound on the optimal value function can be preserved if required. Overall, the technique requires computation time and space that is only linear in the number of iterations (horizon time).","cites":"2","conferencePercentile":"20.31700288"},{"venue":"AAAI","id":"6ef61dd5b67cb1043ad6bec34944206fe747ec4d","venue_1":"AAAI","year":"2006","title":"Bayesian Reputation Modeling in E-Marketplaces Sensitive to Subjectivity, Deception and Change","authors":"Kevin Regan, Pascal Poupart, Robin Cohen","author_ids":"2558734, 1807041, 3486209","abstract":"We present a model for buying agents in e-marketplaces to interpret evaluations of sellers provided by other buying agents, known as advisors. The interpretation of seller evaluations is complicated by the inherent subjectivity of each advisor, the possibility that advisors may deliberately provide misleading evaluations to deceive competitors and the dynamic nature of seller and advisor behaviours that may naturally change seller evaluations over time. Using a Bayesian approach , we demonstrate how to cope with subjectivity, deception and change in a principled way. More specifically, by modeling seller properties and advisor evaluation functions as dynamic random variables, buyers can progressively learn a probabilistic model that naturally and \" correctly \" calibrates the interpretation of seller evaluations without having to resort to heuristics to explicitely detect and filter/discount unreliable seller evaluations. Our model, called BLADE, is shown empirically to achieve lower mean error in the estimation of seller properties when compared to other models for reasoning about advisor ratings of sellers in electronic maketplaces.","cites":"55","conferencePercentile":"91.93083573"},{"venue":"AAAI","id":"0026878669de71ee25e1cbb55d677a35ac72b0a1","venue_1":"AAAI","year":"2006","title":"Performing Incremental Bayesian Inference by Dynamic Model Counting","authors":"Wei Li, Peter van Beek, Pascal Poupart","author_ids":"2121690, 2790783, 1807041","abstract":"The ability to update the structure of a Bayesian network when new data becomes available is crucial for building adaptive systems. Recent work by Sang, Beame, and Kautz (AAAI 2005) demonstrates that the well-known Davis-Putnam procedure combined with a dynamic decomposition and caching technique is an effective method for exact inference in Bayesian networks with high density and width. In this paper, we define dynamic model counting and extend the dynamic decomposition and caching technique to multiple runs on a series of problems with similar structure. This allows us to perform Bayesian inference incrementally as the structure of the network changes. Experimental results show that our approach yields significant improvements over the previous model counting approaches on multiple challenging Bayesian network instances.","cites":"6","conferencePercentile":"40.20172911"},{"venue":"AAAI","id":"15811b192063f5148fb14c2e69d9e7aecafc4cf1","venue_1":"AAAI","year":"2013","title":"LA-CTR: A Limited Attention Collaborative Topic Regression for Social Media","authors":"Jeon-Hyung Kang, Kristina Lerman","author_ids":"1688319, 1782658","abstract":"Probabilistic models can learn users' preferences from the history of their item adoptions on a social media site, and in turn, recommend new items to users based on learned preferences. However, current models ignore psychological factors that play an important role in shaping online social behavior. One such factor is attention, the mechanism that integrates perceptual and cognitive features to select the items the user will consciously process and may eventually adopt. Recent research has shown that people have finite attention, which constrains their online interactions, and that they divide their limited attention non-uniformly over other people. We propose a collaborative topic regression model that incorporates limited, non-uniformly divided attention. We show that the proposed model is able to learn more accurate user preferences than state-of-art models, which do not take human cog-nitive factors into account. Specifically we analyze voting on news items on the social news aggregator and show that our model is better able to predict held out votes than alternate models. Our study demonstrates that psycho-socially motivated models are better able to describe and predict observed behavior than models which only consider latent social structure and content.","cites":"7","conferencePercentile":"73.27272727"},{"venue":"AAAI","id":"20767ca3b932cbc7b8112db21980d7b9b3ea43a3","venue_1":"AAAI","year":"2016","title":"Dynamic Concept Composition for Zero-Example Event Detection","authors":"Xiaojun Chang, Yi Yang, Guodong Long, Chengqi Zhang, Alexander G. Hauptmann","author_ids":"1729163, 1698559, 2600001, 1693677, 7661726","abstract":"In this paper, we focus on automatically detecting events in unconstrained videos without the use of any visual training exemplars. In principle, zero-shot learning makes it possible to train an event detection model based on the assumption that events (e.g. birthday party) can be described by multiple mid-level semantic concepts (e.g. \" blowing candle \" , \" birthday cake \"). Towards this goal, we first pre-train a bundle of concept classifiers using data from other sources. Then we evaluate the semantic correlation of each concept w.r.t. the event of interest and pick up the relevant concept classifiers, which are applied on all test videos to get multiple prediction score vectors. While most existing systems combine the predictions of the concept classi-fiers with fixed weights, we propose to learn the optimal weights of the concept classifiers for each testing video by exploring a set of online available videos with free-form text descriptions of their content. To validate the effectiveness of the proposed approach, we have conducted extensive experiments on the latest TRECVID MEDTest 2014, MEDTest 2013 and CCV dataset. The experimental results confirm the superiority of the proposed approach.","cites":"6","conferencePercentile":"90.2027027"},{"venue":"AAAI","id":"61614387208b9f98795513823b68f002b6a4d4e3","venue_1":"AAAI","year":"2015","title":"Exploiting Task-Feature Co-Clusters in Multi-Task Learning","authors":"Linli Xu, Aiqing Huang, Jianhui Chen, Enhong Chen","author_ids":"2213331, 3310253, 3506912, 1703319","abstract":"In multi-task learning, multiple related tasks are considered simultaneously, with the goal to improve the generalization performance by utilizing the intrinsic sharing of information across tasks. This paper presents a multi-task learning approach by modeling the task-feature relationships. Specifically, instead of assuming that similar tasks have similar weights on all the features, we start with the motivation that the tasks should be related in terms of subsets of features, which implies a co-cluster structure. We design a novel regularization term to capture this task-feature co-cluster structure. A proximal algorithm is adopted to solve the optimization problem. Convincing experimental results demonstrate the effectiveness of the proposed algorithm and justify the idea of exploiting the task-feature relationships.","cites":"4","conferencePercentile":"73.46456693"},{"venue":"AAAI","id":"4c9ecc72ded229ca344f043db45b275d8bdf4c67","venue_1":"AAAI","year":"2013","title":"Time-Dependent Trajectory Regression on Road Networks via Multi-Task Learning","authors":"Jiangchuan Zheng, Lionel M. Ni","author_ids":"3086498, 1726587","abstract":"Road travel costs are important knowledge hidden in large-scale GPS trajectory data sets, the discovery of which can benefit many applications such as intelligent route planning and automatic driving navigation. While there are previous studies which tackled this task by modeling it as a regression problem with spatial smoothness taken into account, they unreasonably assumed that the latent cost of each road remains unchanged over time. Other works on route planning and recommendation that have considered temporal factors simply assumed that the temporal dynamics be known in advance as a parametric function over time, which is not faithful to reality. To overcome these limitations, in this paper, we propose an extension to a previous static trajectory regression framework by learning the temporal dynamics of road travel costs in an innovative non-parametric manner which can effectively overcome the temporal sparsity problem. In particular , we unify multiple different trajectory regression problems in a multi-task framework by introducing a novel cross-task regularization which encourages temporal smoothness on the change of road travel costs. We then propose an efficient block coordinate descent method to solve the resulting problem by exploiting its separable structures and prove its convergence to global optimum. Experiments conducted on both synthetic and real data sets demonstrate the effectiveness of our method and its improved accuracy on travel time prediction.","cites":"13","conferencePercentile":"89.27272727"},{"venue":"AAAI","id":"10ea91e4b759404dd4e3eef36e2d38b46c69ac91","venue_1":"AAAI","year":"2010","title":"Predicting the Importance of Newsfeed Posts and Social Network Friends","authors":"Tim Paek, Michael Gamon, Scott Counts, David Maxwell Chickering, Aman Dhesi","author_ids":"3049377, 2417334, 1721345, 1724065, 3205145","abstract":"As users of social networking websites expand their network of friends, they are often flooded with newsfeed posts and status updates, most of which they consider to be \" unimportant \" and not newsworthy. In order to better understand how people judge the importance of their newsfeed, we conducted a study in which Facebook users were asked to rate the importance of their newsfeed posts as well as their friends. We learned classifiers of newsfeed and friend importance to identify predictive sets of features related to social media properties, the message text, and shared background information. For classifying friend importance, the best performing model achieved 85% accuracy and 25% error reduction. By leveraging this model for classifying newsfeed posts, the best newsfeed classifier achieved 64% accuracy and 27% error reduction.","cites":"20","conferencePercentile":"76.45051195"},{"venue":"AAAI","id":"01c4ff067657dbebe80aea9d3e4be666b42eea27","venue_1":"AAAI","year":"2014","title":"Robust Bayesian Inverse Reinforcement Learning with Sparse Behavior Noise","authors":"Jiangchuan Zheng, Siyuan Liu, Lionel M. Ni","author_ids":"3086498, 1738087, 1726587","abstract":"Inverse reinforcement learning (IRL) aims to recover the reward function underlying a Markov Decision Process from behaviors of experts in support of decision-making. Most recent work on IRL assumes the same level of trustworthiness of all expert behaviors, and frames IRL as a process of seeking reward function that makes those behaviors appear (near)-optimal. However, it is common in reality that noisy expert behaviors disobeying the optimal policy exist, which may degrade the IRL performance significantly. To address this issue , in this paper, we develop a robust IRL framework that can accurately estimate the reward function in the presence of behavior noise. In particular, we focus on a special type of behavior noise referred to as sparse noise due to its wide popularity in real-world behavior data. To model such noise, we introduce a novel latent variable characterizing the reliability of each expert action and use Laplace distribution as its prior. We then devise an EM algorithm with a novel variational inference procedure in the E-step, which can automatically identify and remove behavior noise in reward learning. Experiments on both synthetic data and real vehicle routing data with noticeable behavior noise show significant improvement of our method over previous approaches in learning accuracy, and also show its power in de-noising behavior data.","cites":"4","conferencePercentile":"59.54545455"},{"venue":"AAAI","id":"b47ec7a5402c39ee41bbfcd75d302698d9845827","venue_1":"AAAI","year":"2004","title":"Responsive Information Architect: A Context-Sensitive Multimedia Conversation Framework for Information Seeking","authors":"Michelle X. Zhou, Keith Houck, Rosario Uceda-Sosa, Shimei Pan, Min Chen, Vikram Aggarwal, James Shaw","author_ids":"1705742, 7645937, 2227675, 2728986, 1711628, 3070134, 2320417","abstract":"Information seeking, such as searching for a particular vacation package or looking for a Christmas gift online, is almost a routine task in our daily life. However the seeking process can often be very difficult and time consuming due to the following three main reasons. First users must face many choices because of the sheer volume of data that has been made available. Second, traditional GUI-based data access and navigation models are very limited when dealing with large and complex information spaces. Specifically, a pure GUI-based system is not flexible enough to allow users to express complex data queries that may involve multiple data linkages. For example, it would be very difficult to handle user queries, such as \" find me 3 days/2 nights vacation packages to a destination with an average annual temperature at least over 70F \". In addition, most current access/navigation models are context insensitive. Continuing the above example, most systems would not be able to understand any follow up queries, such as \" how about just to those cities in Europe \". Users may also get lost when facing too many choices or get stuck if there is no data satisfying their criteria. Third, existing systems normally organize and present the retrieved information in a one-size-fits-all format, which may not be easily understood or digested by the users. To address all the above issues and better aid users in their information seeking process, we are building a context sensitive framework, called Responsive Information Architect (RIA), which engages users in automatically generated multimedia conversations. Unlike existing information browsing paradigm that forces users to explore information following pre-defined paths (e.g., GUI menus), RIA allows users to express their information requests flexibly using a mixture of input modalities, including speech, text, and gesture. Using a rich context, such as conversation history and data semantics, RIA is capable of understanding user inputs, including these complex data queries (e.g., \" tell me about cities in the north along Hudson with at least 5000 people \"), abbreviated inquiries (e.g., \" what about golf courses \"), or imprecise requests (e.g., inaccurate gesture inputs). By tracking and learning from user navigation patterns, RIA is also able to aid users in navigating large and complex information space intelligently. In particular, RIA can help users to refine their queries by indicating the most effective navigation path when there is too much data retrieved, or to automatically …","cites":"0","conferencePercentile":"5.089820359"},{"venue":"AAAI","id":"c9f588d295437009994ddaabb64fd4e4c499b294","venue_1":"AAAI","year":"2013","title":"Predicting Professions through Probabilistic Model under Social Context","authors":"Ming Shao, Liangyue Li, Yun Fu","author_ids":"7554269, 2897748, 1708679","abstract":"In this paper, we investigate the problem of predicting peo-ple's professions under social context. Previous work considering clothing information as well as fore/background context preliminarily proves the feasibility of predicting professions. In this paper, we discuss this problem in a more general case — multiple people in one photo with arbitrary poses, and argue that with appropriately built partial body features, spatial relations, and background context, more appealing results are achieved by a probabilistic model. We conduct experiments on 14 representative professions with over 7000 images, and demonstrate the model's superiority with impressive results.","cites":"0","conferencePercentile":"9.090909091"},{"venue":"AAAI","id":"6785a6d2d9437be126b946ab0e0dd7f53bc1c889","venue_1":"AAAI","year":"2015","title":"On Correcting Misspelled Queries in Email Search","authors":"Abhijit Bhole, Raghavendra Udupa","author_ids":"3029768, 2360916","abstract":"We consider the problem of providing spelling corrections for misspelled queries in Email Search using user's own mail data. A popular strategy for general query spelling correction is to generate corrections from query logs. However, this strategy is not effective in Email Search for two reasons: 1) query log of any single user is typically not rich enough to provide potential corrections for a new query 2) corrections generated using query logs of other users are not particularly useful since the mail data as well as search intent are highly specific to the user. We address the challenge of designing an effective spelling correction algorithm for Email Search in the absence of query logs. We propose SpEQ, a Machine Learning based approach that generates corrections for misspelled queries directly from the user's own mail data.","cites":"2","conferencePercentile":"51.65354331"},{"venue":"AAAI","id":"7874169e19737c490cb6361115d21dee3df6596e","venue_1":"AAAI","year":"2014","title":"Intelligent System for Urban Emergency Management during Large-Scale Disaster","authors":"Xuan Song, Quanshi Zhang, Yoshihide Sekimoto, Ryosuke Shibasaki","author_ids":"3970122, 2337228, 2703973, 1721111","abstract":"The frequency and intensity of natural disasters has significantly increased over the past decades and this trend is predicted to continue. Facing these possible and unexpected disasters , urban emergency management has become the especially important issue for the whole governments around the world. In this paper, we present a novel intelligent system for urban emergency management during the large-scale disasters. The proposed system stores and manages the global positioning system (GPS) records from mobile devices used by approximately 1.6 million people throughout Japan over one year. By mining and analyzing population movements after the Great East Japan Earthquake, our system can automatically learn a probabilistic model to better understand and simulate human mobility during the emergency situations. Based on the learning model, population mobility in various urban areas impacted by the earthquake throughout Japan can be automatically simulated or predicted. On the basis of such kind of system, it is easy for us to find some new features or population mobility patterns after the recent and unprecedented composite disasters, which are likely to provide valuable experience and play a vital role for future disaster management worldwide.","cites":"4","conferencePercentile":"59.54545455"},{"venue":"AAAI","id":"2bb1706b3ddd7fbf1139a3c2039f71ee58d425e6","venue_1":"AAAI","year":"2007","title":"Modeling Contextual Factors of Click Rates","authors":"Hila Becker, Christopher Meek, David Maxwell Chickering","author_ids":"3054813, 8118396, 1724065","abstract":"In this paper, we develop and evaluate several probabilistic models of user click-through behavior that are appropriate for modeling the click-through rates of items that are presented to the user in a list. Potential applications include modeling the click-through rates of search results from a search engine, items ranked by a recommendation system, and search advertisements returned by a search engine. Our models capture contextual factors related to the presentation as well as the underlying relevance or quality of the item. We focus on two types of contextual factors for a given item; the posi-tional context of the item and the quality of the other results. We evaluate our models on a search advertising dataset from Microsoft's Live search engine and demonstrate that model-ing contextual factors improves the accuracy of click-through models.","cites":"13","conferencePercentile":"60.53412463"},{"venue":"AAAI","id":"a45b1d645595e54df38be7513befc4b761f5c732","venue_1":"AAAI","year":"2013","title":"Multiple Outcome Supervised Latent Dirichlet Allocation for Expert Discovery in Online Forums","authors":"Jose San Pedro, Alexandros Karatzoglou","author_ids":"2871028, 1713164","abstract":"This paper presents a supervised bayesian approach to model expertise in online forums with application to question routing. The proposed method extends the well-known sLDA model to the multi-task case, accounting for a supervised stage with multiple outputs per document corresponding to the users of the system. A study of the characteristics of real world data revealed a number of challenges in the practical application of this model, relevant to the research community. Online forums continue to be an active hub for information exchange on the Web. They tend to focus on specific areas and attract communities of individuals interested, and sometimes knowledgable, in the topic. An important share of the discussions in forums follow the scheme of Community Question Answering (CQA): users formulate questions to leverage the expertise of other knowledgeable users participating in the forum. While potential responders have the knowledge and motivation to submit a reply to these questions , it is often just by chance that they come across them and can therefore submit a reply. In this paper, we consider the study of question routing and present a novel approach to actively push unanswered questions to potential responders aiming at increasing their visibility and chance for getting a satisfactory response. Our approach considers a bayesian inference framework that extends over Latent Dirichlet Allocation to account for authorship of questions and answers as well as community ratings. A body of literature exists around expertise modeling in the CQA context. Link analysis approaches exploit the relationship between users in the community to infer their level of expertise. In this category we find methods based on variations of PageRank and HITS, classic in the IR literature to assess the authority of websites, adapted to the CQA setting (Jurczyk and Agichtein 2007; Zhang, Ackerman, and Adamic 2007). A related approach considers pairwise expertise comparisons between users to establish a global rank of experts (Liu, Song, and Lin 2011). None of these methods makes use of textual features or quality metrics of the answers provided by users. Textual features can be used to build user profiles based on the history of previously answered questions. A similarity metric is established and experts are detected by comparing their affinity with new questions in the system. have been proposed using this general framework. Another text-based approach poses expert detection as a classification problem where the user space is split into two classes depending …","cites":"0","conferencePercentile":"9.090909091"},{"venue":"AAAI","id":"10f6801ce3c7e821183d7a3b7f1e5a7e291d9164","venue_1":"AAAI","year":"2007","title":"Ungreedy Methods for Chinese Deterministic Dependency Parsing","authors":"Xiangyu Duan, Jun Zhao, Bo Xu","author_ids":"2109002, 1727572, 1749224","abstract":"Deterministic dependency parsing has often been regarded as an efficient algorithm while its parsing accuracy is a little lower than the best results reported by more complex methods. In this paper, we compare deterministic dependency parsers with complex parsing methods such as genera-tive and discriminative parsers on the standard data set of Penn Chinese Treebank. The results show that, for Chinese dependency parsing, deterministic parsers outper-form generative and discriminative parsers. Furthermore, basing on the observation that deterministic parsing is a greedy algorithm which chooses the most probable parsing action at every step, we propose three kinds of ungreedy deterministic dependency parsing algorithms to globally model parsing actions. We take the original determi-nistic parsers as baseline systems. Results show that ungreedy deterministic dependency parsers perform better than the base-line systems while maintaining the same time complexity, and our best result improve much over baseline.","cites":"1","conferencePercentile":"13.94658754"},{"venue":"AAAI","id":"223e926007e0fd53d64b5ab6adf5f6e6dd237d86","venue_1":"AAAI","year":"2011","title":"End-User Feature Labeling via Locally Weighted Logistic Regression","authors":"Weng-Keen Wong, Ian Oberst, Shubhomoy Das, Travis Moore, Simone Stumpf, Kevin McIntosh, Margaret M. Burnett","author_ids":"1763639, 1834297, 2438981, 7005948, 2121662, 2883545, 1737204","abstract":"Applications that adapt to a particular end user often make inaccurate predictions during the early stages when training data is limited. Although an end user can improve the learning algorithm by labeling more training data, this process is time consuming and too ad hoc to target a particular area of inaccuracy. To solve this problem, we propose a new learning algorithm based on Locally Weighted Logistic Regression for feature labeling by end users, enabling them to point out which features are important for a class, rather than provide new training instances. In our user study, the first allowing ordinary end users to freely choose features to label directly from text documents, our algorithm was more effective than others at leveraging end users' feature labels to improve the learning algorithm. Our results strongly suggest that allowing users to freely choose features to label is a promising method for allowing end users to improve learning algorithms effectively.","cites":"2","conferencePercentile":"24.05498282"},{"venue":"AAAI","id":"14748beb5255da1256873f45a4ce71052d2ba40a","venue_1":"AAAI","year":"2010","title":"Efficient Spectral Feature Selection with Minimum Redundancy","authors":"Zheng Zhao, Lei Wang, Huan Liu","author_ids":"2951051, 1743559, 2365866","abstract":"Spectral feature selection identifies relevant features by measuring their capability of preserving sample similarity. It provides a powerful framework for both supervised and unsupervised feature selection, and has been proven to be effective in many real-world applications. One common drawback associated with most existing spectral feature selection algorithms is that they evaluate features individually and cannot identify redundant features. Since redundant features can have significant adverse effect on learning performance, it is necessary to address this limitation for spectral feature selection. To this end, we propose a novel spectral feature selection algorithm to handle feature redundancy, adopting an embedded model. The algorithm is derived from a formulation based on a sparse multi-output regression with a L2,1-norm constraint. We conduct theoretical analysis on the properties of its optimal solutions, paving the way for designing an efficient path-following solver. Extensive experiments show that the proposed algorithm can do well in both selecting relevant features and removing redundancy.","cites":"58","conferencePercentile":"95.7337884"},{"venue":"AAAI","id":"3955291ec06dc1602102542e1bc606fdda5337c6","venue_1":"AAAI","year":"2016","title":"Learning Step Size Controllers for Robust Neural Network Training","authors":"Christian Daniel, Jonathan Taylor, Sebastian Nowozin","author_ids":"3310571, 7356633, 2388416","abstract":"This paper investigates algorithms to automatically adapt the learning rate of neural networks (NNs). Starting with stochastic gradient descent, a large variety of learning methods has been proposed for the NN setting. However, these methods are usually sensitive to the initial learning rate which has to be chosen by the exper-imenter. We investigate several features and show how an adaptive controller can adjust the learning rate without prior knowledge of the learning problem at hand.","cites":"2","conferencePercentile":"61.31756757"}]}