{"WACVMOTION.csv":[{"venue":"WACV/MOTION","id":"02c5c52692129ddd37741d353c12495c3a78da32","venue_1":"WACV/MOTION","year":"2005","title":"Image Registration with Uncalibrated Cameras in Hybrid Vision Systems","authors":"Datong Chen, Jie Yang","author_ids":"1784196, 1688428","abstract":"This paper addresses the problem of robust registering of images among perspective and omnidirectional cameras in a hybrid vision system (HVS). Nonlinearity in an HVS introduced by omnidirectional cameras poses challenges for computing pixel correspondences among images. In previous HVSs, cameras must be calibrated by performing registration. In this paper, we propose a non-linear approach for registering images in an HVS without requiring calibration of cameras. We first discuss the homographies between omnidirectional and perspective images under a local pla-nar assumption. We then propose a robust patch level registration algorithm by exploiting a constraint on large 3D spatial planes. The proposed approach enables an HVS for applications that require quick deployment or active cameras. Experimental results have demonstrated feasibility of the proposed approach.","cites":"5","conferencePercentile":"36.9047619"},{"venue":"WACV/MOTION","id":"6864f78a15d49c9b7806cbc4204808782872dc28","venue_1":"WACV/MOTION","year":"2005","title":"Reliable Automatic Calibration of a Marker-Based Position Tracking System","authors":"David Claus, Andrew W. Fitzgibbon","author_ids":"2575799, 1708974","abstract":"This paper describes an accurate vision-based position tracking system which is significantly more robust and reliable over a wide range of environments than existing approaches. Based on fiducial detection for robustness, we show how a machine-learning approach allows the development of significantly more reliable fiducial detection than has previously been demonstrated. We calibrate fiducial positions using a structure-from-motion solver. We then show how nonlinear optimization of the camera position during tracking gives accuracy comparable with full bundle adjustment but at significantly reduced cost.","cites":"15","conferencePercentile":"67.26190476"},{"venue":"WACV/MOTION","id":"6a8b2da9e08b1837057d60344b4e7b5dfa9bdb74","venue_1":"WACV/MOTION","year":"2005","title":"Incorporating Object Tracking Feedback into Background Maintenance Framework","authors":"Leonid Taycher, John W. Fisher, Trevor Darrell","author_ids":"2588636, 1733063, 1753210","abstract":"Adaptive background modeling/subtraction techniques are popular, in particular, because they are able to cope with background variations that are due to lighting variations. Unfortunately these models also tend to adapt to foreground objects that become stationary for a period of time; as a result such objects are no longer considered for further processing. In this paper, we propose the first (to our knowledge) statistically consistent method for incorporating feedback from high-level motion model to modify adaptation behavior. Our approach is based on formulating the background maintenance problem as inference in a continuous state Hidden Markov Model, and combining it with a similarly formulated object tracker in a multichain graphical model framework. We demonstrate that the approximate filtering algorithm in such a framework outperforms the common feed-forward system while not imposing a significant extra computational burden.","cites":"7","conferencePercentile":"43.45238095"},{"venue":"WACV/MOTION","id":"bdd4fe6a4a47fcef1f21df16b873867b45031876","venue_1":"WACV/MOTION","year":"2005","title":"A Factorization Method for Structure from Planar Motion","authors":"Jian Li, Rama Chellappa","author_ids":"1701502, 1712305","abstract":"We propose a factorization method for structure from pla-nar motion using a stationary perspective camera. Compared with [8] for general motion, our work has three major differences: a different measurement matrix specialized for planar motion is formed. The measurement matrix has a rank of at most 3, instead of 4; the measurement matrix needs similar scalings, but estimation of fundamental matrices or epipoles is not needed; we have an Euclidean reconstruction instead of a projective reconstruction. The camera is not required to be calibrated. A simple semi-automatic calibration method using vanishing points and lines is sufficient. Experimental results show that the algorithm is accurate and fairly robust to noise and inaccurate calibration.","cites":"12","conferencePercentile":"60.71428571"},{"venue":"WACV/MOTION","id":"b950268740051c5f20220a8bbb0bc62ec5fcbe65","venue_1":"WACV/MOTION","year":"2005","title":"Multi-Scale 3D Scene Flow from Binocular Stereo Sequences","authors":"Rui Li, Stan Sclaroff","author_ids":"1704992, 1749590","abstract":"Scene flow methods estimate the three-dimensional motion field for points in the world, using multi-camera video data. Such methods combine multi-view reconstruction with motion estimation approaches. This paper describes an alternative formulation for dense scene flow estimation that provides convincing results using only two cameras by fusing stereo and optical flow estimation into a single coherent framework. To handle the aperture problems inherent in the estimation task, a multi-scale method along with a novel adaptive smoothing technique is used to gain a regularized solution. This combined approach both preserves discon-tinuities and prevents over-regularization – two problems commonly associated with basic multi-scale approaches. Internally, the framework generates probability distributions for optical flow and disparity. Taking into account the uncertainty in the intermediate stages allows for more reliable estimation of the 3D scene flow than standard stereo and optical flow methods allow. Experiments with synthetic and real test data demonstrate the effectiveness of the approach .","cites":"30","conferencePercentile":"85.11904762"},{"venue":"WACV/MOTION","id":"ea4b9266769382840c40eccde29bfc358fa25be6","venue_1":"WACV/MOTION","year":"2005","title":"Requirements for Camera Calibration: Must Accuracy Come with a High Price?","authors":"Wei Sun, Jeremy R. Cooperstock","author_ids":"1712625, 2242019","abstract":"While a large number of vision applications rely on the mapping between 3D scenes and their corresponding 2D camera images, the question that occurs to most researchers is what, in practice, are the most important determinants of camera calibration accuracy and what accuracy can be achieved within the practical limits of their environments. In response, we present a thorough study investigating the effects of training data quantity, measurement error, pixel coordinate noise, and the choice of camera model, on camera calibration results. Through this effort, we seek to determine whether expensive, elaborate setups are necessary, or indeed, beneficial, to camera calibration, and whether a high complexity camera model leads to improved accuracy. The results are first provided for a simulated camera system and then verified through carefully controlled experiments using real-world measurements.","cites":"4","conferencePercentile":"29.16666667"},{"venue":"WACV/MOTION","id":"47b090627870448d78a14716f528122bf359e438","venue_1":"WACV/MOTION","year":"2005","title":"Learning the Behavior of Users in a Public Space through Video Tracking","authors":"Wei Yan, David A. Forsyth","author_ids":"6429239, 1744452","abstract":"The paper describes a video tracking system that tracks and analyzes the behavioral pattern of users in a public space. We have obtained important statistical measurements about users' behavior, which can be used to evaluate architectural design in terms of human spatial behavior and model the behavior of users in public spaces. Previously, such measurements could only be obtained through costly manual processes, e.g. behavioral mapping and time-lapse filming with human examiners. Our system has automated the process of analyzing the behavior of users. The system consists of a head detector for detecting people in each single frame of the video and data association for tracking people through frames. We compared the results obtained using our system with those obtained by manual counting, for a small data set, and found the results to be fairly accurate. We then applied the system to a large-scale data set and obtained substantial statistical measurements of parameters such as the total number of users who entered the space, the total number of users who sat by a fountain, the time that each spent by the fountain, etc. These statistics allow fundamental rethinking of the way people use a public space.","cites":"19","conferencePercentile":"73.21428571"},{"venue":"WACV/MOTION","id":"a7666e8ad4881a205e35cfb94037cd369a13c80f","venue_1":"WACV/MOTION","year":"2005","title":"Predictive and Probabilistic Tracking to Detect Stopped Vehicles","authors":"Rudy Melli, Andrea Prati, Rita Cucchiara, Lieven de Cock","author_ids":"2881572, 1733945, 1741922, 2697424","abstract":"Many techniques and models have been proposed for vehicles surveillance in highways. In the past, tracking algorithms based on Kalman filter have been largely used for their efficiency in the prediction and low computational cost. However, predictive filters can not solve long-lasting occlusions. In this paper, we propose a new mixed predic-tive and probabilistic tracking that exploits the advantages of predictive filters for moving vehicles and adopts prob-abilistic and appearance-based tracking for stopped vehicles. The proposed tracking is part of a complete video surveillance system, oriented to control tunnels and highways from cluttered views, that is implemented in an embedded DSP platform and provides background suppression, a novel shadow detection algorithm, tracking, and scene recognition module. The experimental results are obtained over several hours of videos acquired in pre-existing platforms of CCTV surveillance systems.","cites":"4","conferencePercentile":"29.16666667"},{"venue":"WACV/MOTION","id":"73fcead1995621e61ec6206f9880fe3e91bffe42","venue_1":"WACV/MOTION","year":"2005","title":"Visual Hull Construction Using Adaptive Sampling","authors":"Ali Erol, George Bebis, Richard D. Boyle, Mircea Nicolescu","author_ids":"2639694, 1808451, 5916774, 2025321","abstract":"Volumetric visual hulls have become very popular in many computer vision applications including human body pose estimation and virtualized reality. In these applications , the visual hull is used to approximate the 3D geometry of an object. Existing volumetric visual hull construction techniques, however, produce a 3-color volume data that merely serves as a bounding volume. In other words it lacks an accurate surface representation. Poly-gonization can produce satisfactory results only at high resolutions. In this study we extend the binary visual hull to an implicit surface in order to capture the geometry of the visual hull itself. In particular, we introduce an oc-tree-based visual hull specific adaptive sampling algorithm to obtain a volumetric representation that provides accuracy proportional to the level of detail. Moreover, we propose a method to process the resulting octree to extract a crack-free polygonal visual hull surface. Experimental results illustrate the performance of the algorithm.","cites":"15","conferencePercentile":"67.26190476"},{"venue":"WACV/MOTION","id":"406e130160eb49d3808af30d097defbe81ea0949","venue_1":"WACV/MOTION","year":"2005","title":"Epipolar Constraints for Vision-Aided Inertial Navigation","authors":"David D. Diel, Paul DeBitetto, Seth J. Teller","author_ids":"2536518, 7174659, 1720894","abstract":"— This paper describes a new method to improve inertial navigation using feature-based constraints from one or more video cameras. The proposed method lengthens the period of time during which a human or vehicle can navigate in GPS-deprived environments. Our approach integrates well with existing navigation systems, because we invoke general sensor models that represent a wide range of available hardware. The inertial model includes errors in bias, scale, and random walk. Any purely projective camera and tracking algorithm may be used, as long as the tracking output can be expressed as ray vectors extending from known locations on the sensor body. A modified linear Kalman filter performs the data fusion. Unlike traditional SLAM, our state vector contains only inertial sensor errors related to position. This choice allows uncertainty to be properly represented by a covariance matrix. We do not augment the state with feature coordinates. Instead, image data contributes stochastic epipolar constraints over a broad baseline in time and space, resulting in improved observability of the IMU error states. The constraints lead to a relative residual and associated relative covariance, defined partly by the state history. Navigation results are presented using high-quality synthetic data and real fisheye imagery. I. NAVIGATION PROBLEM An Inertial Measurement Unit (IMU) is a common component in modern navigation systems. A typical IMU contains three accelerometers and three gyroscopes that provide information about the motion of a moving body [1]. Unfortunately , the process of extracting body position estimates from IMU output leads to significant drift over time. The Global Positioning System (GPS) provides complementary, absolute position information. However, circumstances such as sky occlusion, hardware failure, and war may disallow GPS signals. Therefore, we turn to vision as an alternative source of information. We would like to navigate in places where people go on foot or in a wheeled vehicle. These environments happen to share some important visual characteristics: 1) Most of the scene remains stationary with respect to the planet's surface; and 2) For typical scenes, the ratio of body velocity to scene depth lies within a limited range. Other environments that meet these criteria include the sea floor and unexplored Variables t-time y ij-pixel radiance-relatively small number τ-interval of time (fixed) b b b-bias c c c ij-camera ray f f f-specific force g g g-gravity h h h-measurement gain k k k-Kalman gain n n n-white noise s s s-scale u u …","cites":"36","conferencePercentile":"91.07142857"},{"venue":"WACV/MOTION","id":"14dbbeaef8a4896ef1751284d6a665740f9b6918","venue_1":"WACV/MOTION","year":"2005","title":"Robust Metric and Alignment for Profile-Based Face Recognition: An Experimental Comparison","authors":"Gang Pan, Lei Zheng, Zhaohui Wu","author_ids":"1734380, 1744827, 1687635","abstract":"The human facial profile curve provides complementary information of the face that is not present in the frontal-view face, which has been used in face identification, face analysis and modelling. This paper addresses robust facial profile recognition. With appropriate rotation, the profile curve can be considered as a histogram, where histogram metric could be employed to measure profiles. The advantage is that no detection of fiducial points is required, which is usually unreliable and hard to implement fully automatically. This paper also introduces three methods to align profiles, and investigates four similarity measures. The experiments on two profile image databases (Bern and FERET) and a facial range data set are carried out. The comparison with two primary approaches is conducted. The experimental results demonstrate that, compared with other methods, the involved metric for profile recognition has perfect performance robustness against noise.","cites":"7","conferencePercentile":"43.45238095"},{"venue":"WACV/MOTION","id":"79b6543799142400e63708b0b1d640f6a65abee9","venue_1":"WACV/MOTION","year":"2005","title":"High-Resolution Video Synthesis from Mixed-Resolution Video Based on the Estimate-and-Correct Method","authors":"Stéphane Pelletier, Stephen P. Spackman, Jeremy R. Cooperstock","author_ids":"2759893, 3030365, 2242019","abstract":"A technique for increasing the frame rate of CMOS video cameras is presented. The method uses the non-destructive readout capabilities of CMOS imagers to obtain low-speed, high-resolution frames and high-speed, low-resolution frames simultaneously. The algorithm translates the pix-els of the full resolution images with respect to the motion dynamics observed in the low-resolution frames and corrects the result as necessary for consistency with the low-resolution frames. Noting that due to the longer exposure time required, high-resolution frames are more prone to motion blur than low-resolution frames, and thus, a motion blur reduction step is also applied. Simulations demonstrate the ability of our technique in synthesizing high-quality, high-resolution frames at modest computational expense.","cites":"0","conferencePercentile":"1.785714286"}]}