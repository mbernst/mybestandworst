{"WAIM.csv":[{"venue":"WAIM","id":"4016af2e1510143750ff8d8a67858e4de46b32b9","venue_1":"WAIM","year":"2014","title":"A Novel Knowledge Network Framework for Financial News Navigation","authors":"Lili Zhou, Hanchao Wang, Lei Zhang, Enhong Chen, Jun Chen","author_ids":"5763065, 2483642, 1684635, 1703319, 3543702","abstract":"Nowadays, various financial news retrieval platforms are provided to help users, especially for financial professionals and hobbyists to make right decisions. In those platforms, users usually get information by searching the relevant news via keywords or clicking the recommended news with the similar topic in the clicked web page. However, such ways to obtain financial information cannot effectively meet users' further needs. They are eager to obtain the relevant news with different domains in a short time. To address this problem, we propose a novel four-layers-based knowledge network framework for financial news navigation. Experiments on real data sets demonstrate the effectiveness and efficiency of our proposed framework.","cites":"0","conferencePercentile":"33.33333333"},{"venue":"WAIM","id":"8d5bea99460f83a5a915dfec8b48e94e503572da","venue_1":"WAIM","year":"2008","title":"Efficient Processing of Complex Twig Pattern Matching","authors":"Jinqing Zhu, Wei Wang, Xiaofeng Meng","author_ids":"8535539, 1706612, 1696390","abstract":"—As a de facto standard for information representation and exchange over the internet, XML has been used extensively in many applications. And XML query technology has attracted more and more attention in data management research community. Standard XML query languages, e.g. XPath and XQuery, use twig pattern as a basic unit to match relevant fragments from a given XML document. However, in most existing work, only simple containment relationships are involved in the twig pattern, which makes it infeasible in many cases. In this paper, we extend the original twig pattern to Complex Twig Pattern (CTP), which may contain ordered relationship between query nodes. We give a detailed analysis of the hard nuts that prevent us from finding an efficient solution for CTP matching, and then propose a novel holistic join algorithm, LBHJ, to handle the CTP efficiently and effectively. We show in experimental results that LBHJ can largely reduce the size of intermediate results and thus improve the query performance significantly according to various metrics when processing CTP with ordered axes. I. INTRODUCTION As a de facto standard for information representation and exchange over the internet, XML has been used extensively in many applications. Query capabilities are provided through twig pattern queries, which are the core components for standard XML query languages, e.g. XPath [2] and XQuery [3]. A twig pattern query can be naturally represented as a node-labeled tree, in which each edge represents either Parent-Child (P-C) or Ancestor-Descendant (AD) relationship. For example, the twig pattern query written in XPath [2] format, Q: A[B]//D, selects elements D, which is a descendant of A whose child elements include B. Besides the AD and P-C relationship, XPath also supports four ordered axes: following-sibling, preceding-sibling, following and preceding. While researchers have proposed many holistic twig join algorithms [4,7,9,5,10] to efficiently find all the occurrences of a twig pattern from an XML database, a key problem of these existing works that has been largely ignored is that they can not handle ordered XML twig query efficiently which contains ordered relationship between query nodes. We call such query pattern containing ordered axes Complex Twig Pattern (CTP). Naive method of CTP processing consists of three steps, (1) split a CTP into several simple twig queries which do not contain ordered relationship, (2) evaluate each twig query separately using existing state-of-the-art twig join algorithms, (3) use an ordered structural join method to merge the partial …","cites":"0","conferencePercentile":"21.42857143"},{"venue":"WAIM","id":"e9baec8370d4dc90164d2d1cb6d720e006ba271f","venue_1":"WAIM","year":"2005","title":"Using Quantitative Association Rules in Collaborative Filtering","authors":"Xiaohua Sun, Fansheng Kong, Hong Chen","author_ids":"3237699, 2941591, 5596871","abstract":"Recommender systems make information filtering for user by predicting user's preference to items. Collaborative filtering is the most popular technique in implementing a recommender system. Association rule mining is a powerful data mining method to search for interesting relationships between items by finding the items frequently appeared together in a transaction database. In this paper, we apply quantitative association rules to mining the relationships between items, and then utilize the relationships between items to alleviate the data sparsity problem in the neighborhood-based algorithms. The proposed method considers not only similarities between users, but also similarities between items. The experimental results on two publicly available datasets show that our algorithm outperforms the conventional Pearson method and adjusted cosine method.","cites":"4","conferencePercentile":"66.66666667"},{"venue":"WAIM","id":"3331dffd4364e6437af1e5930c94f004607864a5","venue_1":"WAIM","year":"2006","title":"LSM: Language Sense Model for Information Retrieval","authors":"Shenghua Bao, Lei Zhang, Erdong Chen, Min Long, Rui Li, Yong Yu","author_ids":"1702421, 2823487, 1678686, 8669504, 1704992, 3578922","abstract":"A lot of work has been done on drawing word senses into retrieval to deal with the word sense ambiguity problem, but most of them achieved negative results. In this paper, we first implement a WSD system for nouns and verbs, then the language sense model (LSM) for information retrieval is proposed. The LSM combines the terms and senses of a document seamlessly through an EM algorithm. Retrieval on TREC collections shows that the LSM outperforms both the vector space model and the traditional language model significantly for both medium and long queries (7.53%-16.90%). Based on the experiments, we can also empirically draw the conclusion that the fine-grained senses will improve the retrieval performance when they are properly used.","cites":"2","conferencePercentile":"57.14285714"},{"venue":"WAIM","id":"c964c17133d2b7f127db141e772b207348485433","venue_1":"WAIM","year":"2011","title":"Analytics for Info-plosion Including Information Diffusion Studies for the 3.11 Disaster","authors":"Masaru Kitsuregawa, Masashi Toyoda","author_ids":"1716799, 2361778","abstract":"Information explosion(Info-plosion) is one of the most substantial phenomena in 21st century. Not only the mentions in blogs and twitter, but also the data from various kinds of sensors is becoming to explode considerably. Voyage by METI(Ministry of Economy, Trade and Industry). Recently we started FIRST project. In this talk, we would like to show how info-plosion analytics, especially sensor analytics, created disruptive services. In addition, we will show the diffusion pattern analysis of twitter and blogs for the 3.11 disaster. On 9.11, we did not have real time media such as microblogging, while such media quite effectively worked on 3.11. Explosive amount of information is becoming available, especially since around the beginning of 21st century. This causes so called information overload. Although there are such negative problems, we could think that this is a first experience for human being to see such a vast amount of information. Taking advantage of such a totally new opportunity, we believe various disruptive services could be introduced which we have never imagined a decade ago. We launched info-plosion project in 2005. CPS started to get funding since 2009, while its idea was discussed in 2006. IOT, smarter planet, M2M, and Big Data etc. are targetting not necessarily exactly the same objective, but the goals are quite similar. We would like to introduce some of our experiments. We collected Japanese blogs and tweets in March 11th earthquake and tsunami disaster. Although mobile phone service stopped, the Internet was not damaged. Lots of interesting societal movement happened immediately after the earthquake such as refuge place notification, power saving etc. We examined its diffusion pattern. In addition, we also could clarify the difference of role among the media. People are using blog and microblog differently. We will report the role of IT media and its importance.","cites":"0","conferencePercentile":"25"},{"venue":"WAIM","id":"5da2554b00b721e6c9fd452dd68c376df2ea56ea","venue_1":"WAIM","year":"2008","title":"Managing Uncertain Data: Probabilistic Approaches","authors":"Wenjie Zhang, Xuemin Lin, Jian Pei, Ying Zhang","author_ids":"8031033, 1720352, 1702840, 1752812","abstract":"— Uncertain data are inherent in many important applications. Recently, considerable research efforts have been put into the field of managing uncertain data. In this paper, we summarize existing techniques to query and model uncertain data and systems that effectively manage uncertain data, mainly from a probabilistic point of view.","cites":"4","conferencePercentile":"60.71428571"},{"venue":"WAIM","id":"f825cf3c6deb63333316240049ad9fdba48eaaaf","venue_1":"WAIM","year":"2008","title":"A New Dynamic Hash Index for Flash-Based Storage","authors":"Xiang Li, Da Zhou, Xiaofeng Meng","author_ids":"1737850, 2352317, 1696390","abstract":"Compared with traditional magnetic disks, Flash memory has many advantages and has been used as external storage media for a wide spectrum of electronic devices (such as PDA, MP3, Digital Camera and Mobile Phone) in recent years. As the capacity increases and price drops, it looks like a perfect alternative for magnetic disks. However, due to hardware limitations of flash memory, techniques including storage subsystem and indexing originally designed for magnetic disks can not run smoothly in a flash memory without any modification. In this paper we explore problems of indexing flash-resided data and present a new dynamical hash index for flash memory in two schemas. The analysis and experimental results validate the efficiency of our design. I. INTRODUCTION Flash memory is a type of non-volatile storage media which has been used in a wide spectrum of computing devices such as PDA, MP3 and Mobile Phone. As the capacity increases and price drops stably these years, flash memory gradually becomes a perfect alternative for traditional magnetic disks. One of the main electronic manufacturers of the world has launched a notebook computer that is equipped with a flash disk in stead of hard disk in 2006 [1]. The capacity of the flash disk doubles every year [2], which is faster than the Moore's law. It is reported that flash chip with 128G has been released into the market at the end of last year. As a result of the widely usage of flash memory, the data stored in this type of media is increasing sharply too. Then how to manage flash-resided data becomes an important problem. Compared with traditional magnetic disk, Flash has many advantages, say, shock resistant, faster access speed, power saving, smaller size, lighter weight and less noise. So flash outperforms low-end magnetic disk under many circumstances. However, due to some other limits of flash (e.g. Erase-Before-Write and different Read/Write speed) existing software for magnetic disk could not yield the best attainable performance in flash. Many techniques (e.g. storage and indexing techniques) should be redesigned. To address these limits, many flash-specific techniques have been developed. FTL [3] is a proper software layer which makes flash appears to upper layers like a magnetic disk and conventional disk-based applications can run on it without any modification. Another class of schemas (called native flash file systems) is designed to explore the unique","cites":"4","conferencePercentile":"60.71428571"},{"venue":"WAIM","id":"bac80aeabaa9fd5fc30565ea3eb5a240d3deafd2","venue_1":"WAIM","year":"2003","title":"Compact Encoding of the Web Graph Exploiting Various Power Laws: Statistical Reason Behind Link Database","authors":"Yasuhito Asano, Tsuyoshi Ito, Hiroshi Imai, Masashi Toyoda, Masaru Kitsuregawa","author_ids":"3031482, 1792334, 6546753, 2361778, 1716799","abstract":"Compact encodings of the web graph are required in order to keep the graph on main memory and to perform operations on the graph efficiently. Link2, the second version of the Link Database by Randall et al., which is part of the Connectivity Server, represented the adjacency list of each vertex by the variable-length nybble codes of delta values. In this paper, the fact is shown that certain variables related to the web graph have power distributions, and the reason is explained why using variable-length nybble codes in Link2 led to a compact representation of the graph from the statistical viewpoint on the basis of the relationship between power distributions and generalization of the variable-length nybble code. Besides, another encoding of the web graph based on these fact and relationship is proposed, and it is compared with Link2 and the encoding proposed by Guillaume et al. in 2002. Though our encoding is slower than Link2, it is 10% more compact than Link2. And our encoding is 20% more compact than the encoding proposed by Guillaume et al. and is comparable to it in terms of extraction time.","cites":"5","conferencePercentile":"76.47058824"},{"venue":"WAIM","id":"fd7518e759888e13fd71482e36bfc232f0c11d5d","venue_1":"WAIM","year":"2010","title":"Learning to Detect Web Spam by Genetic Programming","authors":"Xiaofei Niu, Jun Ma, Qiang He, Shuaiqiang Wang, Dongmei Zhang","author_ids":"2689656, 1683601, 1720370, 2386396, 1711277","abstract":"Web spam techniques enable some web pages or sites to achieve un-deserved relevance and importance. They can seriously deteriorate search engine ranking results. Combating web spam has become one of the top challenges for web search. This paper proposes to learn a discriminating function to detect web spam by genetic programming. The evolution computation uses multi-populations composed of some small-scale individuals and combines the selected best individuals in every population to gain a possible best discriminating function. The experiments on WEBSPAM-UK2006 show that the approach can improve spam classification recall performance by 26%, F-measure performance by 11%, and accuracy performance by 4% compared with SVM.","cites":"2","conferencePercentile":"53.84615385"},{"venue":"WAIM","id":"da16677661f4bc26984527a362e11da7b5eb67e4","venue_1":"WAIM","year":"2010","title":"Clustering Coefficient Queries on Massive Dynamic Social Networks","authors":"Zhiyu Liu, Chen Wang, Qiong Zou, Huayong Wang","author_ids":"2646773, 1710899, 3020116, 2368638","abstract":"The Clustering Coefficient (CC) is a fundamental measure in social network analysis assessing the degree to which nodes tend to cluster together. While CC computation on static graphs is well studied , emerging applications have new requirements for online query of the \" global \" CC of a given subset of a graph. As social networks are widely stored in databases for easy updating and accessing, computing CC of their subset becomes a time-consuming task, especially when the network grows large and cannot fit in memory. This paper presents a novel method called \" Approximate Neighborhood Index (ANI) \" to significantly reduce the query latency for CC computation compared to traditional SQL based database queries. A Bloom-filter-like data structure is leveraged to construct ANI in front of a relational database. Experimental results show that the proposed approach can guarantee the correctness of a CC query while significantly reducing the query latency at a reasonable memory cost.","cites":"3","conferencePercentile":"73.07692308"},{"venue":"WAIM","id":"1641e3bd81f309c8b1735a5f0456b31886260b52","venue_1":"WAIM","year":"2006","title":"Error-Adaptive and Time-Aware Maintenance of Frequency Counts over Data Streams","authors":"Hongyan Liu, Ying Lu, Jiawei Han, Jun He","author_ids":"1684788, 1784404, 1722175, 4875312","abstract":"Maintaining frequency counts for items over data stream has a wide range of applications such as web advertisement fraud detection. Study of this problem has attracted great attention from both researchers and practitioners. Many algorithms have been proposed. In this paper, we propose a new method, error-adaptive pruning method, to maintain frequency more accurately. We also propose a method called fractionization to record time information together with the frequency information. Using these two methods, we design three algorithms for finding frequent items and top-k frequent items. Experimental results show these methods are effective in terms of improving the maintenance accuracy.","cites":"5","conferencePercentile":"83.33333333"},{"venue":"WAIM","id":"f044a909b1939c6c8292b4099f6b28a86824eeb0","venue_1":"WAIM","year":"2010","title":"DSI: A Method for Indexing Large Graphs Using Distance Set","authors":"Yubo Kou, Yukun Li, Xiaofeng Meng","author_ids":"2605565, 1710861, 1696390","abstract":"Recent years we have witnessed a great increase in modeling data as large graphs in multiple domains, such as XML, the semantic web, social network. In these circumstances, researchers are interested in querying the large graph like that: Given a large graph G, and a query Q, we report all the matches of Q in G. Since subgraph isomorphism checking is proved to be NP-Complete[1], it is infeasible to scan the whole large graph for answers, especially when the query's size is also large. Hence, the \" filter-verification \" approach is widely adopted. In this approach, researchers first index the neighborhood of each vertex in the large graph, then filter vertexes , and finally perform subgraph matching algorithms. Previous techniques mainly focus on efficient matching algorithms, paying little attention to indexing techniques. However, appropriate indexing techniques could help improve the efficiency of query response by generating less candidates. In this paper we investigate indexing techniques on large graphs, and propose an index structure DSI(Distance Set Index) to capture the neighborhood of each vertex. Through our distance set index, more vertexes could be pruned, resulting in a much smaller search space. Then a subgraph matching algorithm is performed in the search space. We have applied our index structure to real datasets and synthetic datasets. Extensive experiments demonstrate the efficiency and effectiveness of our indexing technique.","cites":"1","conferencePercentile":"26.92307692"},{"venue":"WAIM","id":"22faef7cb655b8e54d86e3c60f0453f9211bfc80","venue_1":"WAIM","year":"2008","title":"Name Disambiguation Using Atomic Clusters","authors":"Feng Wang, Juan-Zi Li, Jie Tang, Jing Zhang, Kehong Wang","author_ids":"1745827, 8549842, 1750766, 8714973, 1679831","abstract":"Name ambiguity is a critical problem in many applications, in particular in the online bibliography systems, such as DBLP and CiteSeer. Previously, several clustering based methods have been proposed although, the problem still presents to be a big challenge for both research and industry communities. In this paper, we present a complementary study to the problem from another point of view. We propose an approach of finding atomic clusters to improve the performance of existing clustering-based methods. We conducted experiments on a dataset from a real-world system: Arnetminer.org. Experiments results show that significant improvements can be obtained by using the proposed atomic clusters finding approach (about +8% and +27% improvements depending on different clustering methods).","cites":"8","conferencePercentile":"75"},{"venue":"WAIM","id":"8c46ef461549480fcf6d7e1a8c2349ecdc4bfb8c","venue_1":"WAIM","year":"2003","title":"Dynamic Clustering-Based Query Answering in Peer-to-Peer Systems","authors":"Weining Qian, Shuigeng Zhou, Yi Ren, Aoying Zhou, Beng Chin Ooi, Kian-Lee Tan","author_ids":"1776657, 7523147, 1695032, 1696626, 1693070, 1688848","abstract":"P2P computing has been employing in more and more application domains as the technology becomes mature. One popular and successful application area is file sharing. However, current file sharing systems support only or mainly key-and location, which is not enough to meet the requirements of more advanced applications such as information retrieval and data management. In this paper, we propose a new query answering model for P2P applications, which is termed as clustering-based query answering (CBQA). In our definition, CBQA will retrieve the data objects that are in the same cluster of the query from the global dataset distributed over peers of a P2P system. Generally, CBQA may obtain more correct answers than similarity based query can, which means higher recall may be achieved. To implement the new query model, we first present a framework that support clustering based query answering, including general algorithms, lemmas and system architecture. Then we give three concrete algorithms for different clustering criteria, namely k-nearest-neighbor, distance-based, and density-based clustering, along with detailed analyses and discussions. Finally, implementation issues, especially dynamic neighbors selection and caching techniques to enable the scalability of our method are addressed. Theoretical analysis and preliminary experiments show that our method can guarantee to find desirable objects in the interested cluster with modest bandwidth overhead.","cites":"0","conferencePercentile":"11.76470588"},{"venue":"WAIM","id":"20ee55048447c476608a6660b773a3ebbfa99ea5","venue_1":"WAIM","year":"2008","title":"PLEDS: A Personalized Entity Detection System Based on Web Log Mining Techniques","authors":"Kathleen Tsoukalas, Bin Zhou, Jian Pei, Davor Cubranic","author_ids":"2398448, 2843420, 1702840, 2271666","abstract":"— With the expansion of the internet, many specialized , high-profile sites have become available that bring very technical subject matter to readers with non-technical backgrounds. While the theme of these sites may be of interest to these readers, the posts themselves may contain terms that non-experts may be unfamiliar with and may wish to know more about. We developed PLEDS, a personalized entity detection system which identifies interesting entities and provides related information for individual users by mining web logs and query logs. The experimental results of a systemic user study shows that with PLEDS's aid, users can experience the benefits of an enriched internet surfing experience. I. INTRODUCTION With the rapid expansion of the internet, many specialized, high-profile sites have become available that bring highly technical subject matter to readers with non-technical backgrounds. For example, Gizmodo 1 , Engadget 2 , and Boing Boing 3 are all popular user-driven sites that present articles containing terms a non-technical reader might not be familiar with. As such, although readers are interested in the themes of such sites, they may get lost in such overly technical terminology, which may result in decreased readership for the site and a negative experience for the reader. For example, one post on digital cameras 4 discusses white balance, but the style of the camera is such that it is likely to be used by more amateur users who may be unfamiliar with the term. They may spend more time researching white balance on other sites, or may feel frustrated by the article and be less likely to return in future. In either case, the user is drawn away from the website and is left with a negative experience overall. It is important to provide services to readers so that they can not only find additional information about more technical terms, but find it quickly as well. In fact, usability studies have shown that this is one of the chief concerns users express when reading articles online [8]. A na¨ıve solution is to create hyperlinks for terms that contain more detailed information on a separate page, and thus allow users to navigate to those pages","cites":"1","conferencePercentile":"46.42857143"},{"venue":"WAIM","id":"1964e8194726f545d428c0fb82eda670c1625b5c","venue_1":"WAIM","year":"2003","title":"Efficient Evaluation of XML Path Queries with Automata","authors":"Bing Sun, Jianhua Lv, Guoren Wang, Ge Yu, Bo Zhou","author_ids":"1713080, 1694159, 8349792, 1723590, 3738572","abstract":"Path query is one of the most frequently used components by the various XML query languages. Most of the proposed methods compute path queries in instance space, i.e. directly facing the XML instances, such as XML tree traversal and containment join ways. As a query method based on automata technique, automata match (AM) can evaluate path expression queries in schema space so that it allows efficient computation of complex queries on vast amount of data. This paper introduces how to construct query automata in order to compute all regular expression queries including those with wildcards. Furthermore, a data structure named schema automata is proposed to evaluate containment queries that are very difficult from the conventional automata point of view. To improve the efficiency of schema automata, methods to reduce and persistent them are proposed. Finally, performance study of the proposed methods are given.","cites":"2","conferencePercentile":"41.17647059"},{"venue":"WAIM","id":"b94ccb595375bf57617575454b418fc6371b1d7c","venue_1":"WAIM","year":"2014","title":"Time Series Classification Using Multi-Channels Deep Convolutional Neural Networks","authors":"Yi Zheng, Qi Liu, Enhong Chen, Yong Ge, J. Leon Zhao","author_ids":"1789089, 1728293, 1703319, 7730759, 7817928","abstract":"Time series (particularly multivariate) classification has drawn a lot of attention in the literature because of its broad applications for different domains, such as health informatics and bioinformatics. Thus, many algorithms have been developed for this task. Among them, nearest neighbor classification (particularly 1-NN) combined with Dynamic Time Warping (DTW) achieves the state of the art performance. However, when data set grows larger, the time consumption of 1-NN with DTW grows linearly. Compared to 1-NN with DTW, the traditional feature-based classification methods are usually more efficient but less effective since their performance is usually dependent on the quality of hand-crafted features. To that end, in this paper, we explore the feature learning techniques to improve the performance of traditional feature-based approaches. Specifically, we propose a novel deep learning framework for multivariate time series classification. We conduct two groups of experiments on real-world data sets from different application domains. The final results show that our model is not only more efficient than the state of the art but also competitive in accuracy. It also demonstrates that feature learning is worth to investigate for time series classification.","cites":"19","conferencePercentile":"100"},{"venue":"WAIM","id":"984d617a3bc804a5daf72f63c43ac34df1e4adb8","venue_1":"WAIM","year":"2012","title":"Construction of Web-Based, Service-Oriented Information Networks: A Data Mining Perspective - (Abstract)","authors":"Jiawei Han","author_ids":"1722175","abstract":"Mining directly on the existing networks formed by explicit webpage links on the WorldWide Web may not be so fruitful due to the diversity and semantic heterogeneity of such web-links. However, construction of service-oriented, semi-structured information networks from the Web and mining on such networks may lead to many exciting discoveries of useful information on the Web. This talk will discuss this direction and its associated research opportunities. The WorldWide Web can be viewed as a gigantic information network, where web-pages are the nodes of the network, and links connecting those pages form an intertwined , gigantic network. However, due to the unstructured nature of such a network and semantic heterogeneity of web-links, it is difficult to mine interesting knowledge from such a network except for finding authoritative pages and hubs. Alternatively, one can also view that Web is a gigantic repository of multiple information sources, such as universities, governments, companies, news, services, sales of commodities, and so on. An interesting problem is whether this view may provide any new functions for web-based information services, and if it does, whether one can construct such kind of semi-structured information networks automatically or semi-automatically from the Web, and whether one can use such new kind of networks to derive interesting new information and expand web services. In this talk, we take this alternative view and examine the following issues: (1) what are the potential benefits if one can construct service-oriented, semi-structured information networks from the WorldWide Web and perform data mining on them, (2) whether it is possible to construct such kind of service-oriented, semi-structured information networks from the WorldWide Web automatically or semi-automatically, and (3) research problems for constructing and mining Web-Based, service-oriented, semi-structured information networks. This view is motivated from our recent work on (1) mining semi-structured heterogeneous information networks, and (2) discovery of entity Web pages and their corresponding semantic structures from parallel path structures.","cites":"1","conferencePercentile":"56.25"},{"venue":"WAIM","id":"2ed5bcb0d56c1b7b7e4805de1eeff031d68c3c96","venue_1":"WAIM","year":"2012","title":"Top-k Most Incremental Location Selection with Capacity Constraint","authors":"Yu Sun, Jin Huang, Yueguo Chen, Xiaoyong Du, Rui Zhang","author_ids":"1742506, 3579556, 1743832, 1688063, 1740520","abstract":"Bichromatic reverse nearest neighbor (BRNN) based query uses the number of reverse nearest customers to model the influence of a facility location. The query has great potential for real life applications and receives considerable attentions from spatial database studies. In real world, facilities are inevitably constrained by designed capacities. When the needs of service increase, facilities in those booming areas may suffer from overloading. In this paper, we study a new kind of BRNN related query. It aims at finding most promising candidate locations to increase the overall service quality. To efficiently answer the query, we propose an O(n log n) algorithm using pruning techniques and spatial indices. To evaluate the efficiency of proposed algorithm, we conduct extensive experiments on both real and synthetic datasets. The results show our algorithm has superior performance over the basic solution.","cites":"3","conferencePercentile":"100"},{"venue":"WAIM","id":"ba7edbf5cc5cdbcd44f29d7ca503985c29c9b2c9","venue_1":"WAIM","year":"2004","title":"Mining Web Sequential Patterns Incrementally with Revised PLWAP Tree","authors":"Christie I. Ezeife, Min Chen","author_ids":"2453787, 1711628","abstract":"Since point and click at web pages generate continuous data stream, which flow into web log data, old patterns may be stale and need to be updated. Algorithms for mining web sequential patterns from scratch include WAP, PLWAP and apriori-based GSP. An incre-mental technique for updating already mined patterns when database changes, which is based on an efficient sequential mining technique like the PLWAP is needed. This paper proposes an algorithm, Re-PL4UP, which uses the PLWAP tree structure to incrementally update web sequential patterns. Re-PL4UP scans only the new changes to the database, revises the old PLWAP tree to accommodate previous small items that have become large and previous large items that have become small in the updated database without the need to scan the old database. The approach leads to improved performance .","cites":"7","conferencePercentile":"91.66666667"},{"venue":"WAIM","id":"90b111782f27e32e304433c2ae4fc7037280b482","venue_1":"WAIM","year":"2001","title":"A Mixed Data Dissemination Strategy for Mobile Computing Systems","authors":"Guohong Cao, Yiqiong Wu, Bo Li","author_ids":"1740564, 2181045, 1713520","abstract":"Broadcasting is a very effective technique to disseminate information to a massive number of clients when the data size is small. However, if the data size is large, the broadcast cycle may be long, and hence the access delay becomes a problem. Caching frequently accessed data at the client side can reduce the access latency and improve the bandwidth utilization. However, caching techniques may not perform well when the data are frequently updated. In this paper, we propose to apply different techniques (broadcasting and caching) to deal with different components of the data based on their update frequency. Compared to previous schemes, the proposed solution not only reduces the query latency, but also improves the throughput and the bandwidth utilization.","cites":"1","conferencePercentile":"25"}]}