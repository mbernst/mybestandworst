{"WEA.csv":[{"venue":"WEA","id":"5e0dbf9c3e2b579e7c26588095e534f42ce14f40","venue_1":"WEA","year":"2008","title":"Exact Algorithms for Cluster Editing: Evaluation and Experiments","authors":"Sebastian Böcker, Sebastian Briesemeister, Gunnar W. Klau","author_ids":"1715474, 2627480, 8686734","abstract":"The CLUSTER EDITING problem is defined as follows: Given an undi-rected, loopless graph, we want to find a set of edge modifications (insertions and deletions) of minimum cardinality, such that the modified graph consists of disjoint cliques. We present empirical results for this problem using exact methods from fixed-parameter algorithmics and linear programming. We investigate parameter-independent data reduction methods and find that effective preprocessing is possible if the number of edge modifications k is smaller than some multiple of |V |, where V is the vertex set of the input graph. In particular, combining parameter-dependent data reduction with lower and upper bounds we can effectively reduce graphs satisfying k ≤ 25|V |. In addition to the fastest known fixed-parameter branching strategy for the problem , we investigate an integer linear program (ILP) formulation of the problem using a cutting plane approach. Our results indicate that both approaches are capable of solving large graphs with 1000 vertices and several thousand edge modifications. For the first time, complex and very large graphs such as biological instances allow for an Algorithmica exact solution, using a combination of the above techniques. (A preliminary version of this paper appeared under the title \" Exact algorithms for cluster editing: Evaluation and experiments \" in the","cites":"33","conferencePercentile":"78.125"},{"venue":"WEA","id":"01d30132b6b709fa162f13b7a93a39d517dc8c49","venue_1":"WEA","year":"2006","title":"Practical Construction of k-Nearest Neighbor Graphs in Metric Spaces","authors":"Rodrigo Paredes, Edgar Chávez, Karina Figueroa, Gonzalo Navarro","author_ids":"1802328, 1793108, 1795068, 1687902","abstract":"Let U be a set of elements and d a distance function defined among them. Let NN k (u) be the k elements in U − {u} having the smallest distance to u. The k-nearest neighbor graph (knng) is a weighted directed graph G(U, E) such that E = {(u, v), v ∈ NN k (u)}. Several knng construction algorithms are known, but they are not suitable to general metric spaces. We present a general methodology to construct knngs that exploits several features of metric spaces. Experiments suggest that it yields costs of the form c1n 1.27 distance computations for low and medium dimensional spaces, and c2n 1.90 for high dimensional ones.","cites":"24","conferencePercentile":"76.92307692"},{"venue":"WEA","id":"afd3ef14321a576600f097df5339fd4c92445760","venue_1":"WEA","year":"2004","title":"An Improved Time-Sensitive Metaheuristic Framework for Combinatorial Optimization","authors":"Vinhthuy T. Phan, Steven Skiena","author_ids":"3266582, 1721948","abstract":"We introduce a metaheuristic framework for combinatorial optimization. Our framework is similar to others (e.g. [1]) in that it is modular enough that important components can be independently developed. Ours is different in several aspects. It supports several built-in components such as combinatorial representations and search heuristics to facilitate the creation of a new optimizer for a wide range of combina-torial problems. The inclusion of different types of metaheuristics allows us to compose them and create a hybrid search that is on average better than each individual metaheuristic. Additionally, the system guarantees the feasibility of returned solutions for combinatorial problems that permit infeasible solutions. We, further, propose a generic method to optimize bottleneck problems efficiently under the local-search framework.","cites":"2","conferencePercentile":"23.80952381"},{"venue":"WEA","id":"41a81a60e615d782b63f7f28df85091309bc3e52","venue_1":"WEA","year":"2008","title":"Reducing Splaying by Taking Advantage of Working Sets","authors":"Timo Aho, Tapio Elomaa, Jussi Kujala","author_ids":"2925482, 1720466, 2849301","abstract":"Access requests to keys stored into a data structure often exhibit locality of reference in practice. Such a regularity can be mod-eled, e.g., by working sets. In this paper we study to what extent can the existence of working sets be taken advantage of in splay trees. In order to reduce the number of costly splay operations we monitor for information on the current working set and its change. We introduce a simple algorithm which attempts to splay only when necessary. Under worst-case analysis the algorithm guarantees an amortized logarithmic bound. In empirical experiments it is 5% more efficient than random-ized splay trees and at most 10% more efficient than the original splay tree. We also briefly analyze the usefulness of the commonly-used Zipf's distribution as a general model of locality of reference.","cites":"1","conferencePercentile":"15.625"},{"venue":"WEA","id":"00121a1f52665930391ac0a92266cbcbb3f65ae9","venue_1":"WEA","year":"2006","title":"On the Least Cost for Proximity Searching in Metric Spaces","authors":"Karina Figueroa, Edgar Chávez, Gonzalo Navarro, Rodrigo Paredes","author_ids":"1795068, 1793108, 1687902, 1802328","abstract":"Proximity searching consists in retrieving from a database those elements that are similar to a query. As the distance is usually expensive to compute, the goal is to use as few distance computations as possible to satisfy queries. Indexes use precomputed distances among database elements to speed up queries. As such, a baseline is AESA, which stores all the distances among database objects, but has been unbeaten in query performance for 20 years. In this paper we show that it is possible to improve upon AESA by using a radically different method to select promising database elements to compare against the query. Our experiments show improvements of up to 75% in document databases. We also explore the usage of our method as a probabilistic algorithm that may lose relevant answers. On a database of faces where any exact algorithm must examine virtually all elements, our probabilistic version obtains 85% of the correct answers by scanning only 10% of the database.","cites":"16","conferencePercentile":"69.23076923"},{"venue":"WEA","id":"6000da2c947614336814fd6ba14869e4197f6f58","venue_1":"WEA","year":"2008","title":"Comparing Integer Data Structures for 32 and 64 Bit Keys","authors":"Nicholas Nash, David Gregg","author_ids":"1798024, 1734249","abstract":"In this article, we experimentally compare a number of data structures operating over keys that are 32- and 64-bit integers. We examine traditional comparison-based search trees as well as data structures that take advantage of the fact that the keys are integers such as van Emde Boas trees and various trie-based data structures. We propose a variant of a burst trie that performs better in time than all the alternative data structures. In addition, even for small sets of keys, this burst trie variant occupies less space than comparison-based data structures such as red-black trees and <i>B</i>-trees. Burst tries have previously been shown to provide a very efficient base for implementing cache efficient string sorting algorithms. We find that with suitable engineering, they also perform excellently as a dynamic ordered data structure operating over integer keys. We provide experimental results when the data structures operate over uniform random data. We also present experimental results for other types of data, including datasets arising from <i>Valgrind</i>, a widely used suite of tools for the dynamic binary instrumentation of programs.","cites":"3","conferencePercentile":"28.125"},{"venue":"WEA","id":"790e80f6f6f82889fc26a85fbf495e036d26f723","venue_1":"WEA","year":"2005","title":"Don't Compare Averages","authors":"Hannah Bast, Ingmar Weber","author_ids":"1936883, 1684687","abstract":"We point out that for two sets of measurements, it can happen that the average of one set is larger than the average of the other set on one scale, but becomes smaller after a non-linear monotone transformation of the individual measurements. We show that the inclusion of error bars is no safeguard against this phenomenon. We give a theorem, however, that limits the amount of \" reversal \" that can occur; as a by-product we get two non-standard one-sided tail estimates for arbitrary random variables which may be of independent interest. Our findings suggest that in the not infrequent situation where more than one cost measure makes sense, there is no alternative other than to explicitly compare averages for each of them, much unlike what is common practice. The presentation at the workshop will have a guaranteed surprise effect!","cites":"0","conferencePercentile":"5.555555556"}]}