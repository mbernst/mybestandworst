{"WHPCFSC.csv":[{"venue":"WHPCF@SC","id":"db703cbfd4064169f935db58edbe9688861ec2d0","venue_1":"WHPCF@SC","year":"2015","title":"Optimization strategies for portable code for Monte Carlo-based value-at-risk systems","authors":"Javier Alejandro Varela, Claus Kestel, Christian de Schryver, Norbert Wehn, Sascha Desmettre, Ralf Korn","author_ids":"7582202, 3197729, 2546696, 1690688, 3027067, 2786378","abstract":"Value-at-risk (VaR) computations are one important basic element of risk analysis and management applications. On the one hand, risk management systems need to be flexible and maintainable, but on the other hand they require a very high computational power. In general, accelerators provide high speedups, but come with a limited flexibility. In this work, we investigate two approaches towards portable and fast code for VaR computations on heterogeneous platforms: operator tuning and the use of OpenCL. We show that operator tuning can save up one third of run time on CPU-based systems in the calibration step. For OpenCL, we present a detailed analysis of run time on CPU, GPU, and Xeon Phi, and evaluate its portability. We also find that the same code runs up to 12x faster in a VaR setting with an accelerator card being present, without any code changes required.","cites":"0","conferencePercentile":"50"},{"venue":"WHPCF@SC","id":"2fca90420bae7a561585ac1d3c3f8cc9f6b8bbd9","venue_1":"WHPCF@SC","year":"2014","title":"A systematic methodology for analyzing closed-form Heston pricer regarding their accuracy and runtime","authors":"Christian Brugger, Gongda Liu, Christian de Schryver, Norbert Wehn","author_ids":"7577995, 2721671, 2546696, 1690688","abstract":"Calibration methods are the heart of modeling any financial process. While for the Heston model (semi) closed-form solutions exist for calibrating to simple products, their evaluation involves complex functions and infinite integrals. So far these integrals can only be solved with time-consuming numerical methods. For that reason, calibration consumes a large portion of available compute power in the daily finance business and it is worth checking for the most optimal available methods with respect to runtime and accuracy.\n However, over the years more and more theoretical and practical subtleties have been revealed and today a large number of approaches are available, including different formulations of closed-formulas and various integration algorithms like quadrature or Fourier methods. Currently there is no clear indication which pricing method should be used for a specific calibration purpose with additional speed and accuracy constraints. With this publication we are closing this gap. We derive a novel methodology to systematically find the best methods for a well-defined accuracy target among a huge set of available methods. For a practical setup we study the available popular closed-form solutions and integration algorithms from literature. In total we compare 14 pricing methods, including adaptive quadrature and Fourier methods. For a target accuracy of 10<sup>-3</sup> we show that static Gauss-Legendre are best on CPUs for the unrestricted parameter set. Further we show that for restricted Carr-Madan formulation the methods are 3.6x faster. We also show that Fourier methods are even better when pricing at least 10 options with the same maturity but different strikes.","cites":"1","conferencePercentile":"81.25"},{"venue":"WHPCF@SC","id":"9424640534a7e4dfbd5dca22c6fcbcf1d4e2924d","venue_1":"WHPCF@SC","year":"2014","title":"Many-core programming with Asian option pricing","authors":"Shuo Li, James Lin","author_ids":"4067085, 6431436","abstract":"In this paper, we discuss the problem of pricing one exotic option, the strong path dependent Asian option using the Black--Scholes model and compare how the pricing algorithm can map into different many-core architectures and achieve equally impressive performance gains. In the end, we will show that a 2-year contract with 252 times steps and 1,000,000 samples can be priced in approximately one fifth of a second on two leading many-core architectures.\n The purpose of this paper is to understand what is required to power the numerical-intensive algorithms in quantitative finance and how to extract and express parallelism inherent in many other similar algorithms in quantitative Finance.","cites":"0","conferencePercentile":"37.5"},{"venue":"WHPCF@SC","id":"077d1ac32a7839415a85960544b32ae0bd7102d3","venue_1":"WHPCF@SC","year":"2011","title":"Algorithmic complexity in the heston model: an implementation view","authors":"Henning Marxen, Anton Kostiuk, Ralf Korn, Christian de Schryver, Stephan Wurm, Ivan Shcherbakov, Norbert Wehn","author_ids":"1993786, 2556201, 2786378, 2546696, 2214513, 2379948, 1690688","abstract":"In this paper, we present an in-depth investigation of the algorithmic parameter influence for barrier option pricing with the Heston model. For that purpose we focus on single- and multi-level Monte Carlo simulation methods. We investigate the impact of algorithmic variations on simulation time and energy consumption, giving detailed measurement results for a state-of-the-art 8-core CPU server and a Nvidia Tesla C2050 GPU. We particularly show that a naive algorithm on a powerful GPU can even increase the energy consumption and computation time, compared to a better algorithm running on a standard CPU. Furthermore we give preliminary results of a dedicated FPGA implementation and comment on the speedup and energy saving potential of this architecture.","cites":"1","conferencePercentile":"77.77777778"}]}