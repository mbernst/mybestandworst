{"WI-IAT.csv":[{"venue":"WI-IAT","id":"118f6922f7604484c9793aaf5bffb2eb59831653","venue_1":"WI-IAT","year":"2015","title":"Optimal Negotiation Decision Functions in Time-Sensitive Domains","authors":"Tim Baarslag, Enrico Gerding, Reyhan Aydogan, Monica M. C. Schraefel","author_ids":"1738050, 2985154, 2060698, 2284695","abstract":"—The last two decades have seen a growing interest in automated agents that are able to negotiate on behalf of human negotiators in a wide variety of negotiation domains. One key aspect of a successful negotiating agent is its ability to make appropriate concessions at the right time, especially when there are costs associated with the duration of the negotiation. However, so far, there is no fundamental approach on how much to concede at every stage of the negotiation in such time-sensitive domains. We introduce an efficient solution based on simultaneous search, which is able to select the optimal sequence of offers that maximizes expected payoff, given the agent's beliefs about the opponent. To this end, we show that our approach is consistent with known theoretical results and we demonstrate both its effectiveness and natural properties by applying it to a number of typical negotiation scenarios. Finally, we show in a number of experiments that our solution outperforms other state of the art strategy benchmarks.","cites":"0","conferencePercentile":"33.33333333"},{"venue":"WI-IAT","id":"4816b25434e353716eeb3502c7755f1b7b74ba37","venue_1":"WI-IAT","year":"2014","title":"Semantic Similarity Measurements for Multi-lingual Short Texts Using Wikipedia","authors":"Tatsuya Nakamura, Masumi Shirakawa, Takahiro Hara, Shojiro Nishio","author_ids":"2027905, 2657265, 1697569, 1717916","abstract":"In this paper, we propose two methods to measure the semantic similarity for multi-lingual and short texts by using Wikipedia. In recent years, people around the world have been continuously generating information about their local area in their own languages on social networking services. Measuring the similarity between the texts is challenging because they are often short and written in various languages. Our methods solve this problem by incorporating inter-language links of Wikipedia into extended naive Bayes (ENB), a probabilistic method of semantic similarity measurements for short texts. The proposed methods represent a multi-lingual short text as a vector of the English version of Wikipedia articles (entities). We conducted an experiment on clustering of tweets written in four languages (English, Spanish, Japanese and Arabic). From the experimental results, we confirmed that our methods outperformed cross-lingual explicit semantic analysis (CL-ESA), which is a method to measure the similarity between texts written in two different languages. Moreover, our methods were competitive with ENB applied to texts that have been translated into English using Google Translate. Our methods enabled similarity measurements for multi-lingual short texts without the cost of machine translations.","cites":"1","conferencePercentile":"76.96335079"},{"venue":"WI-IAT","id":"9bcbca6927d4a222f2e5b7defba6a919ca1139cd","venue_1":"WI-IAT","year":"2014","title":"Uncertainty Reasoning Based Formal Framework for Big Video Data Understanding","authors":"Shuwei Chen, Kathy M. Clawson, Min Jing, Jun Liu, Hui Wang, Bryan W. Scotney","author_ids":"4224347, 2936587, 2875955, 1843598, 1747202, 3139978","abstract":"It is worthwhile to incorporate human knowledge with conventional machine learning approaches for big data analytics. Focusing on big video data understanding, this paper presents a formal scenario recognition framework where knowledge-based logic representation and reasoning is combined with data-based learning approach to enhance scenario recognition capabilities. This is achieved via multi-layered (hierarchical) processing. This approach constructs the hierarchical representation structure based on the semantic understanding of considered scenario, and transforms the structure into logic formulas. After applying conventional computer vision methods for low-level events classification, we apply logic based uncertainty reasoning to determine scene content. Experimental results on a benchmark dataset are provided to show the rationality of the proposed approach.","cites":"0","conferencePercentile":"32.98429319"},{"venue":"WI-IAT","id":"99292bccad9d70fae72968e69ef120985dd9eab5","venue_1":"WI-IAT","year":"2014","title":"Collecting Conceptualized Relations from Terabytes of Web Texts for Understanding Unknown Terms","authors":"Masumi Shirakawa, Kotaro Nakayama, Eiji Aramaki, Takahiro Hara, Shojiro Nishio","author_ids":"2657265, 3156934, 7933645, 1697569, 1717916","abstract":"This paper describes our attempt to extract various relations between super ordinate concepts from terabytes of Web corpus for human-like speculation of the meaning of unknown terms. In order to discover various conceptualized relations, we focus on Web-scale text corpora and introduce a simple string-matching method to process them. To derive relations between concepts, our method first extracts relations between terms and next replaces each term by appropriate concepts using Wikipedia, Word Net, and YAGO knowledge. We extracted over 10 million relations between concepts in a day from more than 10TB of Web texts using 100 machines. Experimental results revealed that extracted relations by our method contained much more meaningless relations than those by NLP-based methods. Nevertheless, they were useful in an application of speculating the meaning of unknown terms, improving the recall by more than 0.06 points and decreasing the accuracy by only 0.04 points (the improvement of the F1-measure was 0.03 points). We found from the results that the coverage of conceptualized relations is important to improve the precision in the application. This is because the lack of knowledge (conceptualized relations) leads to misunderstanding of the meaning of unknown terms, as we humans misunderstand things with our insufficient knowledge.","cites":"0","conferencePercentile":"32.98429319"},{"venue":"WI-IAT","id":"1e5b0e6d29d81ff2045068c8daf30eb3efc999eb","venue_1":"WI-IAT","year":"2014","title":"SocialTrust: Adaptive Trust Oriented Incentive Mechanism for Social Commerce","authors":"Zeinab Noorian, Mohsen Mohkami, Yuan Liu, Hui Fang, Julita Vassileva, Jie Zhang","author_ids":"2994264, 2705759, 1826185, 2326573, 1681161, 2710322","abstract":"In the absence of legal authorities and enforcement mechanisms in open e-marketplaces, it is extremely challenging for a user to validate the quality of opinions (i.e. Ratings and reviews) of products or services provided by other users (referred as advisers). Rationally, advisers tend to be reluctant to share their truthful experience with others. In this paper, we propose an adaptive incentive mechanism, where advisers are motivated to share their actual experiences with their trustworthy peers (friends/neighbors in the social network) in e-marketplaces (social commerce context), and malicious users will be eventually evacuated from the systems. Experimental results demonstrate the effectiveness of our mechanism in promoting the honesty of users in sharing their past experiences.","cites":"1","conferencePercentile":"76.96335079"},{"venue":"WI-IAT","id":"c376766991bb481c200b9ebdefb073d5b610d97c","venue_1":"WI-IAT","year":"2014","title":"Natural Multi-language Interaction between Firefighters and Fire Fighting Robots","authors":"Ji Hyeon Hong, Julia M. Taylor, Eric T. Matson","author_ids":"2643372, 1755662, 8006125","abstract":"Due to rapid development of agent systems and robotics, more and more chances are available for humans to interact with agent-based robotic technology (e.g., Robotic vacuums, robotic surgery, etc.), this trend increases the importance of human-robot interaction including human-robot communication. For the robust human-robot communication, natural language processing (NLP) can be implemented, among various existing natural language processing techniques, Ontological Semantic Technology (OST), which addresses meanings in an easily comprehensible way as a human does, was selected, the OST is a system in an ontology-based structure to deal with multiple natural languages. This research specifically addresses a concept of natural language-based communication with fire fighting robots and humans, and the main domain of this study targets fire fighting situations. In order to implement ontology-based communication with different languages, Korean and English were used for this particular study. This study extends the domain of Ontological Semantic Technology, specifically for communication with robots in a fire fighting domain using Korean and English.","cites":"0","conferencePercentile":"32.98429319"},{"venue":"WI-IAT","id":"50ab9372fc688faf48e385bd87e6cd35e616f78b","venue_1":"WI-IAT","year":"2014","title":"Recursive Deep Learning for Sentiment Analysis over Social Data","authors":"Changliang Li, Bo Xu, Gaowei Wu, Saike He, Guanhua Tian, Hongwei Hao","author_ids":"2348067, 1749224, 1921574, 1785020, 1751650, 7411492","abstract":"Sentiment analysis has now become a popular research problem to tackle in NLP field. However, there are very few researches conducted on sentiment analysis for Chinese. Progress is held back due to lack of large and labelled corpus and powerful models. To remedy this deficiency, we build a Chinese Sentiment Treebank over social data. It concludes 13550 labeled sentences which are from movie reviews. Furthermore, we introduce a novel Recursive Neural Deep Model (RNDM) to predict sentiment label based on recursive deep learning. We consider the problem of classifying one sentence by overall sentiment, determining a review is positive or negative. On predicting sentiment label at sentence level, our model outperforms other commonly used baselines, such as Na&#239;ve Bayes, Maximum Entropy and SVM, by a large margin.","cites":"0","conferencePercentile":"32.98429319"},{"venue":"WI-IAT","id":"969e71f794d42842059fce4e6105281bc521cdd0","venue_1":"WI-IAT","year":"2014","title":"Online Retweet Recommendation with Item Count Limits","authors":"Xiaoqi Zhao, Keishi Tajima","author_ids":"8677263, 2792621","abstract":"Some Twitter accounts provide information to the followers not by publishing their own tweets but by retweeting (i.e., Forwarding) useful information from their friends. These accounts need to select an appropriate number of tweets that match the followers' interests. If they retweet too many or too few tweets, it annoys the followers or degrade the value of the accounts. They also need to retweet them in a timely manner. If they retweet a tweet long after they receive it, the informational value of the tweet may diminish before the followers read it. There is, however, a trade-off between these two requirements. If they select tweets after seeing all the candidates, they can select the best given number of tweets, but in order to provide timely information, they have to decide to (or not to) retweet each tweet before seeing all the following candidates. In order to help the management of such Twitter accounts, we developed a system that reads a sequence of tweets from the friends one by one, and select a given number of (or less) tweets in an online (or near-online) fashion. In this paper, we propose four algorithms for it. Two of them give priority to the timeliness, and make a decision immediately after reading a new tweet by comparing its score with a threshold. The other two give priority to the selection quality, and make a decision after seeing some following tweets: after seeing incoming tweets for a fixed length of time or after seeing a fixed number of tweets. The former two are truly online algorithms and the latter two are near-online algorithms. Our experiment shows that the near-online algorithms achieve high selection quality only with acceptable time delays.","cites":"2","conferencePercentile":"91.36125654"},{"venue":"WI-IAT","id":"65bf8512797557d0484d85fd75c6bff9d394e3e9","venue_1":"WI-IAT","year":"2014","title":"Ranking of Coordinate Terms and Hypernyms Using a Hypernym-Hyponym Dictionary","authors":"Kosetsu Tsukuda, Hiroaki Ohshima, Katsumi Tanaka","author_ids":"2179434, 1698449, 1750132","abstract":"In this paper, methods for ranking coordinate terms and hypernyms of a given query according to their appropriateness are proposed. Although previous studies have proposed methods for discovering coordinate terms or hypernyms of a query, they focused on only discovering such terms and evaluating discovered terms based on a binary evaluation: appropriate or inappropriate. Unlike these studies, we rank coordinate terms and hypernyms of a query and evaluate the terms by considering their appropriateness. In the proposed method, a bipartite graph is created based on hypernyms of a query and hyponyms of each hypernym using a hypernym-hyponym dictionary. Subsequently, we apply a HITS-based algorithm to the bipartite graph and rank coordinate terms and hypernyms based on their appropriateness. The experimental results obtained using 50 queries demonstrate that our method could rank appropriate coordinate terms and hypernyms higher than other comparable methods.","cites":"0","conferencePercentile":"32.98429319"},{"venue":"WI-IAT","id":"b250a9bd5d2761af962ec82b70068412faa8bd23","venue_1":"WI-IAT","year":"2014","title":"Optimizing Context Computation for Multiagent Simulations","authors":"Flavien Balbo, Mahdi Zargayouna, Fabien Badeig","author_ids":"1754915, 1790569, 2963588","abstract":"The execution of a multiagent-based simulation (MABS) model necessitates a scheduler that synchronizes the agents execution and simulates the simultaneity of their behaviors. In the majority of MABS frameworks the scheduler activates the agents who compute their context to decide the action to execute. This context computation process is time-consuming and is one of the barriers to increased use of MABS for large simulations. The context of an agent is computed based on all information he possesses about himself, the other agents and the objects of the environment that are accessible to him. One of the issues is to find this information and to identify the information subsets that make sense for the agent. In the majority of MABS, the context computation is hidden in the agent processes and there is no specific algorithm enabling to decrease its computing. Our proposal is the modeling of this subset of information identifying a context by a so called \"filter\" and an algorithm to find efficiently for each agent all their filters. The accessible information are given by the scheduler to the agents who browse a tree of filters to select the right information. With these filters, the agents know their context and decide which action to execute. Our algorithm is compared to a classical context identification. Promising results are presented and discussed.","cites":"0","conferencePercentile":"32.98429319"},{"venue":"WI-IAT","id":"0ec3aa10421f1f6af252bbf64139026835899408","venue_1":"WI-IAT","year":"2014","title":"Fuzzy Subjective Sentiment Phrases: A Context Sensitive and Self-Maintaining Sentiment Lexicon","authors":"Seyed Ali Bahrainian, Marcus Liwicki, Andreas Dengel","author_ids":"3091795, 1743758, 1703343","abstract":"In this paper, we present a novel self-maintaining, domain-independent, and context-sensitive Sentiment Lexicon (SL) which finds and maps opinion words and phrases to a fuzzy sentiment score ranging from strong negative to strong positive. We show that our automatically built SL has advantage over other already existing lexicons in various aspects, namely, reducing the number of word false-matches by using context information. Furthermore, through iterative learning, our lexicon not only learns the sentiment score of a target word but also the sentiment scores of phrases and top word collocations with which the target word frequently co-occurs. Our experimental results suggest that our proposed method is highly effective and can produce lexicons which outperform a standard manually built SL, such as the AFINN lexicon, which was used in our experiments.","cites":"1","conferencePercentile":"76.96335079"},{"venue":"WI-IAT","id":"6848a49652c7bc80b73dc83b2fe0fb8c0b81b36b","venue_1":"WI-IAT","year":"2015","title":"Spoilers Ahead - Personalized Web Filtering","authors":"Pascal Bissig, Philipp Brandes, Roger Wattenhofer, Roman Willi","author_ids":"3345623, 3303111, 1716440, 2407915","abstract":"—Unwanted content on web pages can take many forms, be it ads, malicious code, pointless clutter, or specific topics that the user does not want to read about (yet) Unlike most other work, we focus on the latter The user can define terms based on which we prevent the disclosure of undesired information (e.g., the latest sports result) and warn the user before it is revealed. The user can decide if and when the filtered elements should be displayed. We define this formally as the node removal problem and show its equivalence to the N P-hard knapsack problem. We developed a proof of concept Firefox extension to filter web pages based on user defined terms and our heuristic. Our evaluation shows that we correctly distinguish between wanted and unwanted content in approximately 9 out of 10 cases.","cites":"1","conferencePercentile":"73.33333333"},{"venue":"WI-IAT","id":"d9c517be2f98d8fc4f13b5c104aa8c64ab74c304","venue_1":"WI-IAT","year":"2014","title":"Swarming in the Urban Web Space to Discover the Optimal Region","authors":"Chandan Kumar, Uwe Gruenefeld, Wilko Heuten, Susanne Boll","author_ids":"5583292, 2567636, 1718577, 1714281","abstract":"People moving to a new place usually look for a suitable region with respect to their multiple criteria of interests. In this work we map this problem to the migration behavior of other species such as swarming, which is a collective behavior exhibited by animals of similar size which aggregate together, milling about the same region. Taking the swarm intelligence perspective, we present a novel method to find relevant geographic region for citizens based on Particle Swarm Optimization (PSO) framework. Particles represent geographic regions which are moving in the map space to find a region most relevant with respect to user's query. The characterization of geographic regions is based on the multi-criteria distribution of geo-located facilities or landscape structure from the Open Street Map data source. We enable end users to visualize and evaluate the regional search process of PSO via a Web interface. The proposed framework demonstrates high precision and computationally efficient performance for regional search over a vast city based dataset.","cites":"1","conferencePercentile":"76.96335079"},{"venue":"WI-IAT","id":"4007eab8e863ca677f7e3b71156eb2f1763e8b40","venue_1":"WI-IAT","year":"2014","title":"A New Method for Community Detection Using Seed Nodes","authors":"Chang Su, Yukun Wang, Lan Zhang","author_ids":"2271454, 3350681, 4514211","abstract":"Large-scale social networks emerged rapidly in recent years. Social networks have become complex networks. The structure of social networks is an important research area and has attracted much scientific interest. Community is an important structure in social networks. In this paper, we propose a community detection algorithm based on seed nodes. First, we introduce how to find seed nodes based on random walk. Then we combine the algorithm with order statistics theory to find community structure. We apply our algorithm in three classical data sets and compare to other algorithms. Our community detection algorithm is proved to be effective in the experiments. Our algorithm also has applications in data mining and recommendations.","cites":"0","conferencePercentile":"32.98429319"},{"venue":"WI-IAT","id":"906a12e17a7800060ee14a2c084517b485f2ccf7","venue_1":"WI-IAT","year":"2014","title":"A Systematic Framework for Sentiment Identification by Modeling User Social Effects","authors":"Kunpeng Zhang, Yi Yang, Aaron Sun, Hengchang Liu","author_ids":"6333335, 1698559, 1681790, 2661589","abstract":"Social media is becoming a major and popular technological platform that allows users to express personal opinions toward the subjects with shared interests. Identifying the sentiments of these social media data can help users make informed decisions. Existing research mainly focus on developing algorithms by mining textual information in social media. However, none of them collectively consider the relationships among heterogeneous social entities. Since users interact with social brands in social platforms, their opinions on specific topics are inevitably dependent on many social effects such as user preference on topics, peer influence, user profile information, etc. In this paper, we present a systematic framework to identify sentiments by incorporating user social effects besides textual information. We apply distributed item-based collaborative filtering technique to estimate user preference. Our experiments, conducted on large datasets from current major social platforms, such as Facebook, Twitter, Amazon.com, and Flyertalk.com, demonstrate that incorporating those user social effects can significantly improve sentiment identification accuracy.","cites":"0","conferencePercentile":"32.98429319"},{"venue":"WI-IAT","id":"4de7ca92f722df6cc5e6ac29689ed783ef6f14d8","venue_1":"WI-IAT","year":"2014","title":"NCDREC: A Decomposability Inspired Framework for Top-N Recommendation","authors":"Athanasios N. Nikolakopoulos, John D. Garofalakis","author_ids":"2143706, 1680221","abstract":"Building on the intuition behind Nearly Decomposable systems, we propose NCDREC, a top-N recommendation framework designed to exploit the innately hierarchical structure of the item space to alleviate Sparsity, and the limitations it imposes to the quality of recommendations. We decompose the item space to define blocks of closely related elements and we introduce corresponding indirect proximity components that try to fill in the gap left by the inherent sparsity of the data. We study the theoretical properties of the decomposition and we derive sufficient conditions that guarantee full item space coverage even in cold-start recommendation scenarios. A comprehensive set of experiments on the Movie Lens and the Yahoo!R2Music datasets, using several widely applied performance metrics, support our model's theoretically predicted properties and verify that NCDREC outperforms several state-of-the-art algorithms, in terms of recommendation accuracy, diversity and sparseness insensitivity.","cites":"4","conferencePercentile":"96.59685864"}]}