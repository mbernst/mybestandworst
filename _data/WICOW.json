{"WICOW.csv":[{"venue":"WICOW","id":"093f90468a6b70657d9d725a5ac28ba2f551f010","venue_1":"WICOW","year":"2008","title":"PodCred: a framework for analyzing podcast preference","authors":"Manos Tsagkias, Martha Larson, Wouter Weerkamp, Maarten de Rijke","author_ids":"1732056, 1748247, 1780941, 1696030","abstract":"The PodCred framework is a framework for assessing the credibility and quality of podcasts published on the internet. It consists of a series of indicators designed to support prediction of listener preference of one podcast over another, given that both carry comparable informational content. The indicators are grouped into four categories pertaining to the <i>Podcast Content</i>, the <i>Podcaster</i>, the <i>Podcast Context</i> or the <i>Technical Execution</i> of the podcast. We adopt the term \"cred\" as a designation encompassing both credibility (comprising trustworthiness and expertise) and qualitative acceptability to listeners. Our podcast analysis framework is inspired by work on credibility in blogs, another medium dominated by user generated content. The PodCred framework is derived from a review of the literature on credibility for other media, a survey of prescriptive standards for podcasting, and a detailed data analysis of award winning podcasts. The paper concludes with a discussion of future work in which the framework will be applied.","cites":"2","conferencePercentile":"38.23529412"},{"venue":"WICOW","id":"1d6a13cd73979b963ef3c07be6cacd71c236f39a","venue_1":"WICOW","year":"2010","title":"Smart marketing or bait & switch: competitors' brands as keywords in online advertising","authors":"Mark A. Rosso, Bernard J. Jansen","author_ids":"2095871, 1692872","abstract":"The business models of major Internet search engines depend on online advertising, primarily in the form of search engine keyword advertising. In recent years, a controversy surrounding keyword advertising has gained notoriety worldwide, in both the international court systems and the media. It concerns a form of potential \"bait and switch\" advertising where a consumer, searching using the brand name of one company, is presented with an advertisement by a competitor of the searched-for brand. Sometimes, this competitor's ad copy contains the name of the searched for brand as well. This practice has been referred to as \"piggybacking\". Given the particular need for consumer trust in ecommerce, one might question the overall value of piggybacking. In the U.S. in particular, the legality of this practice, and the potential liability of the search engines for contributing to trademark infringement, is unclear. However, the eventual resolutions of the issue by the U.S. and international courts could significantly and negatively impact the business model of Internet search engines. In this paper, the actual prevalence of piggybacking of major brands in U.S. search engines is investigated. One hundred search queries consisting solely of one of the 100 top global brand names were submitted to three major search engines, Google, Yahoo!, and Microsoft's. Analysis of 8,345 results from the search engine results pages showed only 4 percent of sponsored ads triggered by competitors' trademarked terms. There was even lower use of trademark terms in ads by competitors. Thus, competitive piggybacking does not appear to be a widespread phenomenon. Possible explanations for this are discussed, and suggestions for future research are given.","cites":"0","conferencePercentile":"13.63636364"},{"venue":"WICOW","id":"7766fb0e14ec62386428f987a90528c07e0e6665","venue_1":"WICOW","year":"2008","title":"Web-based evidence excavation to explore the authenticity of local events","authors":"Ryong Lee, Daisuke Kitayama, Kazutoshi Sumiya","author_ids":"2518933, 1720718, 1678794","abstract":"With the increasing employment of the Web in our daily lives, we often use it to find evidence of real-world events. The difference with normal web searches is that users want to reveal whether an event is true or false based on firm facts. In this paper, we propose a model to excavate real-world events from the Web, to manage the vestige in spatio-temporal space and to offer users reliable evidence of an event. We also describe a similarity measure between events to perform searching and clustering. A credibility estimation method, based on the trustworthiness of events and the authority of web sites, using a primary experiment is also presented.","cites":"3","conferencePercentile":"47.05882353"},{"venue":"WICOW","id":"b7080566ad6ce056bf7ebd6e87b2bf63b3d22830","venue_1":"WICOW","year":"2009","title":"A method of analyzing credibility based on LOD control of digital maps","authors":"Daisuke Kitayama, Ryong Lee, Kazutoshi Sumiya","author_ids":"1720718, 2518933, 1678794","abstract":"Digital maps are widely used and appear on all types of platforms for integrating content. Users can change display region and scale by panning, zooming in, and zooming out on a digital map. Level of detail (LOD) control for a given region at a given scale is decided by the designer of the digital map. Therefore, rules for displaying objects have limited credibility. For example, it is possible that equivalent objects do not display consistency, or nonequivalent objects do display consistency, even if users believe equivalent objects are displayed consistently. We propose a method to calculate the display validness on LOD-controlled regions and scales for increasing the credibility of digital maps. In particular, our method determines the equivalence of objects based on the display pattern at each scale and the size of the region determined to be the object's territory. In addition, we calculated the display validness using the equivalence of objects. In this paper, we describe our prototype system.","cites":"1","conferencePercentile":"15"},{"venue":"WICOW","id":"e168a0673e31cd2c412a08499ea221e8cb7f1443","venue_1":"WICOW","year":"2009","title":"The effects of source credibility ratings in a cultural heritage information aggregator","authors":"Alia Amin, Junte Zhang, Henriette Cramer, Lynda Hardman, Vanessa Evers","author_ids":"1787809, 2432167, 3297637, 1701116, 1778867","abstract":"State of the art web search applications allow the user to aggregate information from many sources. Because of this, users are confronted with having to assess the reliability of information from different sources. This paper reports on an empirical user study on the effect of displaying credibility ratings of multiple cultural heritage sources (e.g. museum websites, art blogs) on users' search performance and selection. The study investigated whether source credibility has an in uence on users' search performance when they are confronted with only a few information sources or where there are many. The results of our online interactive study (n=122) show that by presenting the source credibility information explicitly, people's confidence in their selection of information significantly increases, even though it does not necessarily make search more time efficient. Additionally, we highlight credibility issues that are applicable beyond the cultural heritage domain, such as issues related to credibility measures and choice of visualization.","cites":"8","conferencePercentile":"70"},{"venue":"WICOW","id":"94d180b30e430b79105fd8f3c2dd04a94a0f7cb2","venue_1":"WICOW","year":"2009","title":"Automatically assessing resource quality for educational digital libraries","authors":"Philipp G. Wetzler, Steven Bethard, Kirsten R. Butcher, James H. Martin, Tamara Sumner","author_ids":"2737139, 2105138, 3331833, 2046588, 2184912","abstract":"With the rise of community-generated web content, the need for automatic assessment of resource quality has grown. We demonstrate how developing a concrete characterization of quality for web-based resources can make machine learning approaches to automating quality assessment in the realm of educational digital libraries tractable. Using data from several previous studies of quality, we gathered a set of key dimensions and indicators of quality that were commonly identified by educators. We then performed a mixed-method study of digital library quality experts, showing that our characterization of quality captured the subjective processes used by the experts when assessing resource quality. Using key indicators of quality selected from a statistical analysis of our expert study data, we developed a set of annotation guidelines and annotated a corpus of 1000 digital resources for the presence or absence of the key quality indicators. Agreement among annotators was high, and initial machine learning models trained from this corpus were able to identify some indicators of quality with as much as an 18% improvement over the baseline.","cites":"3","conferencePercentile":"40"},{"venue":"WICOW","id":"2113f7ead17e792eb6a2eaf42be352cb43442c54","venue_1":"WICOW","year":"2008","title":"On the credibility of wikipedia: an accessibility perspective","authors":"Rui Lopes, Luís Carriço","author_ids":"1786757, 1805677","abstract":"User interfaces play a critical role on the credibility of authoritative information sources on the Web. Citation and referencing mechanisms often provide the required support for the independent verifiability of facts and, consequently, influence the credibility of the conveyed information. Since the quality level of these references has to be verifiable by users without any barriers, user interfaces cannot pose problems on accessing information. This paper presents a study about the influence of accessibility of user interfaces on the credibility of Wikipedia articles. We have analysed the accessibility quality level of the articles and the external Web pages used as authoritative references. This study has shown that there is a discrepancy on the accessibility of referenced Web pages, which can compromise the overall credibility of Wikipedia. Based on these results, we have analysed the article referencing lifecycle (technologies and policies) and propose a set of improvements that can help increasing the accessibility of references within Wikipedia articles.","cites":"7","conferencePercentile":"76.47058824"},{"venue":"WICOW","id":"459c09dd93adf5aa2aa7263f86370194261d16b6","venue_1":"WICOW","year":"2009","title":"Seller's credibility in electronic markets: a complex network based approach","authors":"Adriano M. Pereira, Arlei Silva, Wagner Meira, Virgílio A. F. Almeida","author_ids":"1829773, 2865070, 1691267, 7360316","abstract":"In the last decade, there has been an explosion of online commercial activity enabled by the World Wide Web. An electronic marketplace (e-market) provides an online method to perform transactions between buyers and sellers, potentially supporting all of the steps in the entire order fulfillment process. Credibility is an important requirement for the success of an e-market. In this work we model and characterize an e-market as a complex network and use the network structure to investigate the sellers' credibility.\n We propose a new algorithm, based on the structure of the negotiation network, to recommend whether the seller is trustable or not. We use real data from a online marketplace from the biggest Brazilian Internet Service Provider as case study. Besides being a prelimary work, our technique achieves good results in terms of accuracy, predicting correctly the results in more than 80%. It can be used to provide a more effective reputation system for electronic negotiations, which can be very useful as a support decision mechanism for buyers.","cites":"2","conferencePercentile":"30"},{"venue":"WICOW","id":"44f8c020bf4e6802edafe979afa0b98634daa685","venue_1":"WICOW","year":"2008","title":"Graph mining and influence propagation","authors":"Christos Faloutsos","author_ids":"1702392","abstract":"How do graphs look like? How do they evolve over time? How can we generate realistic-looking graphs? We review some static and temporal 'laws', and we describe the ``Kronecker'' graph generator, which naturally matches all of the known properties of real graphs. We also describe some case studies.\n The first is on influence and virus propagation on real graphs, where we show that the so-called ``epidemic threshold'' of a graph depends only on the first eigenvalue of the adjacency matrix. The second shows how to spot patterns in e-bay interaction graphs, indicative of the ``non-delivery'' type of fraud. The last is analysis on blog cascades and some surprising patterns there.","cites":"0","conferencePercentile":"14.70588235"},{"venue":"WICOW","id":"0c72302167867367ec4440f48c3bf3f51d1f5e05","venue_1":"WICOW","year":"2008","title":"Detecting reviewer bias through web-based association mining","authors":"Jessica Staddon, Richard Chow","author_ids":"2143669, 2227735","abstract":"Online retailers and content distributors benefit from an active community that shares credible reviews and recommendations. Today, the most popular approach to encouraging credibility in these communities is self-regulation; community members rate reviews according to their accuracy and usefulness, thus helping to weed out reviews that are inaccurate. This self-regulation, while powerful, is limited by its insularity. Community members generally base their assessments on a reviewer's comments and actions only within the community. This ignores relationships the reviewer has outside the community that may be quite relevant to evaluating the reviewer's comments; for example, a relationship between an author and reviewer. We present a simple method for mining the Web to detect many such associations. Our method, together with self-regulation, provides for more comprehensive detection of bias in reviews by alerting the user to the potential for an undisclosed relationship between a reviewer and author. We provide preliminary results using book reviews in <b>Amazon.com</b> demonstrating that our approach is a high-precision method for detecting strong relationships between reviewers and authors that may contribute to reviewer bias.","cites":"4","conferencePercentile":"55.88235294"},{"venue":"WICOW","id":"20a898130542e32c6f2d88f0238304d9ebd4f0f1","venue_1":"WICOW","year":"2010","title":"Time: a method of detecting the dynamic variances of trust","authors":"Laurian C. Vega, Yeong-Tay Sun, D. Scott McCrickard, Steve Harrison","author_ids":"2992597, 1888012, 1693753, 1725188","abstract":"Given that interactions are dynamic, we propose that trust is also a dynamic, unfolding, and a deeply contextual phenomenon that must be evaluated as such. The central argument of this paper is that there is a need to measure trust iteratively and in situ. This measurement of trust can provide a deeper insight into the construct of trust and the design elements that influence it. In this paper we present a review of trust evaluation methods. We then propose our method, the TIME Method, using repeated measures of trust across multiple pages of a website to tie design elements to increases or decreases in user trust. We then evaluate user trust with the TIME Method to demonstrate the degree of trust variability. Last, we discuss future methods for evaluating trust.","cites":"2","conferencePercentile":"31.81818182"},{"venue":"WICOW","id":"a781b2c762ce5bd0471607449fbb93b95cc9d81e","venue_1":"WICOW","year":"2008","title":"Using a sentiment map for visualizing credibility of news sites on the web","authors":"Yukiko Kawai, Yusuke Fujita, Tadahiko Kumamoto, Jianwei Zhang, Katsumi Tanaka","author_ids":"1700611, 1801139, 1689004, 1739493, 1750132","abstract":"We have developed a visualizing news system that shows the trend of the news site on the Web for credibility. If users know the trend of the news site, users can evaluate the credibility of each news topic. This system detects and uses sentiments of each news article to resolve the trend of Web site. The trend of Web sites are extracted as average sentiments of the news articles that were written concerning a topic in each Web site. The sentiments of news articles are represented by four values calculated in four sentiment scales: \"Bright &#8660; Dark\", \"Acceptance &#8660; Rejection\", \"Relaxation &#8660; Strain\", and \"Anger &#8660; Fear\". The sentiment values of news articles are calculated using the sentiment dictionary that was constructed by our previously proposed method. If a user enters one or more topic keywords, our proposed system extracts the news articles that include the keywords from each predetermined news sites. Our system also calculates the sentiment values of the news articles and their average value in each sentiment from each news Web site. The system then generates a bar graph from the four average values in each news Web site and attaches all the bar graphs on the world map using Google Map API. We call the map a sentiment map in this paper. The sentiment map helps users intuitively and efficiently understand trends among multiple Web sites concerning a given topic. In this paper, we describe how to create a sentiment map and explain how we evaluated our proposed system through several experiments.","cites":"5","conferencePercentile":"67.64705882"},{"venue":"WICOW","id":"83998122648d86652c749a5437ae4d8feec957f2","venue_1":"WICOW","year":"2009","title":"Evaluating brand value on the web","authors":"Takuya Kobayashi, Hiroaki Ohshima, Satoshi Oyama, Katsumi Tanaka","author_ids":"3127454, 1698449, 1740955, 1750132","abstract":"The value of a brand name is an important factor that consumers often take into consideration when making their purchasing decisions. However, it is difficult for users to evaluate correctly the value of a brand name, especially when they encounter it for the first time. In reality, sometimes a brand's description or its use is purposely manipulated so as to give an impression of high value. In another way, a non-existing brand name may be used to attract consumers. We call such names \"glorified terms.\" In this paper, we propose a method for evaluating a brand's value from texts on the Web. To this end, we first acquire candidates of attributes useful for evaluating whether a term is a brand name or a glorified term. The candidates are evaluated according to the idea whereby explanations about a real brand name often contain attributes describing its quality. We implemented a prototype system especially for agricultural and livestock products. The system judges whether a given one is a glorified term or a well-known brand name from several viewpoints. We conducted preliminary experiments and we achieved 74% - 85% accuracy rate.","cites":"1","conferencePercentile":"15"},{"venue":"WICOW","id":"afbc839fa7bca52945eb94b8af4f5d4b3726c879","venue_1":"WICOW","year":"2008","title":"Can social annotation support users in evaluating the trustworthiness of video clips?","authors":"Satoshi Nakamura, Makoto Shimizu, Katsumi Tanaka","author_ids":"4807127, 6804754, 1750132","abstract":"We propose a novel support system for evaluating the trustworthiness of video clips on a video sharing Web site. Our system is used for analyzing comments, posted by users, of a video clip and generating visuals for aiding a user in judging if a video clip is trustworthy or not. Our system is used for representing the changes in the positive and negative levels of comments by generating two types of time-related graphs. One is related to playback time, and the other is related to the date of a posted comment. We realized the prototype system and discussed the capability of our system.","cites":"13","conferencePercentile":"94.11764706"},{"venue":"WICOW","id":"bfe5d53b8b35923062326d41f5327f2790b45bdf","venue_1":"WICOW","year":"2008","title":"ALPACA: a lightweight platform for analyzing claim acceptability","authors":"Jeff King, Jennifer Stoll, Michael T. Hunter, Mustaque Ahamad","author_ids":"2548398, 3273018, 1806467, 1710123","abstract":"Internet users face challenges in evaluating the validity of online information. Such evaluation is not adequately supported by current tools; we outline some of the shortcomings of these tools, including centralization, lack of automation, and lack of user-centrism. We propose a set of design principles to mitigate these shortcomings and introduce ALPACA, A Lightweight Platform for Analyzing Claim Acceptability, which adheres to these design principles. ALPACA provides a graphical means of organizing the user's trust with regard to information claims and sources, as well as tools for examining the trust assumptions of others.","cites":"0","conferencePercentile":"14.70588235"},{"venue":"WICOW","id":"a17c610943364a026bc38373eeeb749061e64a5c","venue_1":"WICOW","year":"2010","title":"Modulating video credibility via visualization of quality evaluations","authors":"Nicholas Diakopoulos, Irfan A. Essa","author_ids":"2943892, 1714295","abstract":"In this work we develop and evaluate a method for the syndication and visualization of aggregate quality evaluations of informational video. We enable the sharing of knowledge between motivated media watchdogs and a wider population of casual users. We do this by developing simple visual cues which indicate aggregated activity levels and polarity of quality evaluations (i.e. positive / negative) which are presented in-line with videos as they play. In an experiment we show the potential of these visuals to engender constructive changes to the credibility of informational video under some circumstances. We discuss the limitations, and future work associated with this approach toward video credibility modulation.","cites":"2","conferencePercentile":"31.81818182"},{"venue":"WICOW","id":"7ac4bd9d033ad2c2db10c14517d8022bf3c1c7a6","venue_1":"WICOW","year":"2010","title":"Identifying spam link generators for monitoring emerging web spam","authors":"Young-joo Chung, Masashi Toyoda, Masaru Kitsuregawa","author_ids":"2613498, 2361778, 1716799","abstract":"In this paper, we address the question of how we can identify hosts that will generate links to web spam. Detecting such spam link generators is important because almost all new spam links are created by them. By monitoring spam link generators, we can quickly find emerging web spam that can be used for updating existing spam filters. In order to classify spam link generators, we investigate various linkbased features including modified PageRank scores based on white and spam seeds, and these scores of neighboring hosts. An online learning algorithm is used to handle large scale data, and the effectiveness of various features is examined. Experiments on three yearly archives of Japanese Web show that we can predict spam link generators with a reasonable performance.","cites":"4","conferencePercentile":"54.54545455"}]}