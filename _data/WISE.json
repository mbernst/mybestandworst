{"WISE.csv":[{"venue":"WISE","id":"b441eb5409895a8c1ad1caa309aa23c54786d9b2","venue_1":"WISE","year":"2000","title":"Synchronous Distance Education: Enhancing Speaking Skills via Internet-based Real Time Technology","authors":"Yuping Wang, Chengzheng Sun","author_ids":"6347974, 1688131","abstract":"This paper reports an investigation into one of the most urgent problems facing distance language education-the problem of lack of exposure to speaking practice in the target language. The Open Learning Chinese Program taught at Griffth University is used as a case study. Following a discussion of issues relating to distance education jbr languages, such as the indispensability of technology 1 ' 0 learning languages in a distance mode, and the importance of communicative competence, this paper moves on to an examination of the capabilities of Internet-based real rime technology. Two major indications can be generated from this research: real time technology can help solve the problem of insuficient exposure to speaking practice, and a historical convergence of distance and traditional campus-based education toward a networked education can be expected.","cites":"3","conferencePercentile":"46.96969697"},{"venue":"WISE","id":"62210e85aa72cfabce056d87c7e85adbd2cab1e3","venue_1":"WISE","year":"2003","title":"Semantic Web Processes: Semantics Enabled Annotation, Discovery, Composition and Orchestration of Web Scale Processes","authors":"Jorge S. Cardoso, Amit P. Sheth","author_ids":"1736432, 1709950","abstract":"This tutorial deals with the evolution of inter-Enterprise and Web scale process to support e-commerce and e-services. It taps into the promises of two of the hottest R&D and technology areas: Web services and the Semantic Web. It presents how applying semantics to each of the steps in the Semantic Web Process lifecycle can help address critical issues in reuse, integration and scalability.","cites":"6","conferencePercentile":"47.72727273"},{"venue":"WISE","id":"cfbb0fa9d500a0fe2223df3363f0bbf0abb4e6b0","venue_1":"WISE","year":"2007","title":"Wooki: A P2P Wiki-Based Collaborative Writing Tool","authors":"St√©phane Weiss, Pascal Urso, Pascal Molli","author_ids":"1848906, 3198639, 3025899","abstract":"Wiki systems are becoming an important part of the information system of many organisations and communities. This introduce the issue of the data availability in case of failure, heavy load or off-line access. We propose to replicate wiki pages across a P2P network of wiki engines. We address the problem of consistency of replicated wiki pages in the context of a P2P wiki system. In this paper, we present the architecture and the underlying algorithms of the wooki system. Compared to traditional wikis, Wooki is P2P wiki which scales, delivers better performances and allows off-line access.","cites":"43","conferencePercentile":"100"},{"venue":"WISE","id":"58d1cf66a8e31fe039d8e7d2d8e0a7917990c7d4","venue_1":"WISE","year":"2009","title":"Finding Comparative Facts and Aspects for Judging the Credibility of Uncertain Facts","authors":"Yusuke Yamamoto, Katsumi Tanaka","author_ids":"2495258, 1750132","abstract":"Users often encounter unreliable information on the Web, but there is no system to check the credibility easily and efficiently. In this paper, we propose a system to search useful information for checking the credibility of uncertain facts. The objective of our system is to help users to efficiently judge the credibility by comparing other facts related to the input uncertain fact without checking a lot of Web pages for comparison. For this purpose, the system collects comparative facts for the input fact and important aspect for comparing them from the Web and estimates the validity of each fact.","cites":"4","conferencePercentile":"46.15384615"},{"venue":"WISE","id":"906a1f867d524f32a2c57260c6cb84b9cfa1d5ef","venue_1":"WISE","year":"2002","title":"A Unified Framework for Clustering Heterogeneous Web Objects","authors":"Hua-Jun Zeng, Zheng Chen, Wei-Ying Ma","author_ids":"1741348, 1705657, 1705244","abstract":"In this paper, we introduce a novel framework for clustering web data which is often heterogeneous in nature. As most existing methods often integrate heterogeneous data into a unified feature space, their flexibilities to explore and adjust contributing effect from different heterogeneous information are compromised. In contrast, our framework enables separate clustering of homogeneous data in the entire process based on their respective features, and a layered structure with link information is used to iteratively project and propagate the clustered results between layers until it converges. Our experimental results show that such a scheme not only effectively overcomes the problem of data sparseness caused by the high dimensional link space but also improves the clustering accuracy significantly. We achieve 19% and 41% performance increases when clustering web-pages and users based on a semi-synthetic web log. Finally, we show a real clustering result based on UC Berkeley's web log.","cites":"25","conferencePercentile":"84.61538462"},{"venue":"WISE","id":"d3a351a8a54e10900dddd0597c89b5f2952f2b3d","venue_1":"WISE","year":"2008","title":"Mashing Up Context-Aware Web Applications: A Component-Based Development Approach","authors":"Florian Daniel, Maristella Matera","author_ids":"1797572, 1727982","abstract":"Context-awareness and adaptivity in web applications have been gaining momentum in web engineering over the last years, and it is nowadays recognized that, more than a mere technology aspect, they represent a first-class design concern. This acknowledgment has led to a revision of existing design methods and languages, finally resulting in runtime adaptation being considered a cross-cutting aspect throughout the whole development process. In this paper, we propose a radically new view on context-awareness and show how a well-done component-based development may allow the fast mashup of context-aware and adaptive web applications. The proposed approach comes with an intuitive graph-ical development environment, which will finally enable even end users themselves to mash up their adaptive applications.","cites":"8","conferencePercentile":"56.25"},{"venue":"WISE","id":"cf86551b0e3203e10d375bdbea225cc6014e8d9a","venue_1":"WISE","year":"2014","title":"Comparing the Predictive Capability of Social and Interest Affinity for Recommendations","authors":"Alexandra Olteanu, Anne-Marie Kermarrec, Karl Aberer","author_ids":"2001549, 1723331, 1751802","abstract":"The advent of online social networks created new prediction opportunities for recommender systems: instead of relying on past rating history through the use of collaborative filtering (CF), they can leverage the social relations among users as a predictor of user tastes similarity. Alas, little effort has been put into understanding when and why (e.g., for which users and what items) the social affinity (i.e., how well connected users are in the social network) is a better predictor of user preferences than the interest affinity among them as algorithmically determined by CF, and how to better evaluate recommendations depending on, for instance , what type of users a recommendation application targets. This overlook is explained in part by the lack of a systematic collection of datasets including both the explicit social network among users and the collaborative annotated items. In this paper, we conduct an extensive empirical analysis on six real-world publicly available datasets, which dissects the impact of user and item attributes, such as the density of social ties or item rating patterns, on the performance of recommendation strategies relying on either the social ties or past rating similarity. Our findings represent practical guidelines that can assist in future deployments and mixing schemes.","cites":"0","conferencePercentile":"32.5"},{"venue":"WISE","id":"b40619f5c4f8a10eb216c0ba9b63444579b35178","venue_1":"WISE","year":"2004","title":"Opportunistic Search with Semantic Fisheye Views","authors":"Paul Janecek, Pearl Pu","author_ids":"3178987, 1781996","abstract":"Figure 1: Reducing visual complexity with semantic fisheye view techniques. ABSTRACT Search goals are often too complex or poorly defined to be solved in a single query. While refining their search goals, users are likely to apply a variety of strategies, such as searching for more general or more specific concepts in reaction to the information and structures they encounter in the results. This is called opportunistic search. In this paper we describe how semantic fisheye views (SFEV) can be designed to effectively support this search process by enabling rapid, interactive exploration of the multiple contexts that are useful for different opportunistic search strategies. Similar to other focus + context techniques, SFEVs visually emphasize and increase the detail of information related to the focus and de-emphasize or filter less important information. The contribution of the SFEV approach is the flexible definition of context as a combination of interest met-rics, which can be reconfigured and combined to support a wide range of information visualizations and leading to the discovery of diverse new search goals. To further characterize the effectiveness of this technique for op-portunistic search, we have developed a visual information retrieval interface for a large collection of annotated images that implements two distinctly different SFEVs; the first one uses similarity metrics to guide exploration over the images and keywords in the collection , and the second uses metrics that derive conceptual distance from an external general semantic model, WordNet. The results of a formal user experiment suggest that semantic-guided search is significantly more effective than similarity based search for complex opportunistic search and sensemaking tasks.","cites":"6","conferencePercentile":"68.75"},{"venue":"WISE","id":"02944195c3e3e81b6950b0bed15e8248528a5706","venue_1":"WISE","year":"2009","title":"Multi-synchronous Collaborative Semantic Wikis","authors":"Charbel Rahhal, Hala Skaf-Molli, Pascal Molli, St√©phane Weiss","author_ids":"2877824, 1830003, 3025899, 1848906","abstract":"Semantic wikis have opened an interesting way to mix Web 2.0 advantages with the Semantic Web approach. However, compared to other collaborative tools, wikis do not support all collaborative editing mode such as offline work or multi-synchronous editing. The lack of multi-synchronous supports in wikis is a problematic, especially, when working with semantic wikis. In these systems, it is often important to change multiple pages simultaneous in order to refactor the semantic wiki structure. In this paper, we present a new model of semantic wiki called Multi-Synchronous Semantic Wiki (MS2W). This model extends semantic wikis with multi-synchronous support that allows to create a P2P network of semantic wikis. Semantic wiki pages can be replicated on several semantic servers. The MS2W ensures CCI consistency on these pages relying on the Logoot algorithm.","cites":"20","conferencePercentile":"96.15384615"},{"venue":"WISE","id":"ca745d46887a306f5b58aa410ba651484073c4c1","venue_1":"WISE","year":"2009","title":"Seeing Past Rivals: Visualizing Evolution of Coordinate Terms over Time","authors":"Hiroaki Ohshima, Adam Jatowt, Satoshi Oyama, Katsumi Tanaka","author_ids":"1698449, 1774986, 1740955, 1750132","abstract":"In this paper, we describe an approach for detection and visualization of coordinate term relationships over time and their evolution using temporal data available on the Web. Coordinate terms are terms with the same hypernym and they often represent rival or peer relationships of underlying objects. We have built a system that portrays the evolution of coordinate terms in an easy and intuitive way based on data in an online news archive collection spanning more than 100 years. With the proposed method, it is possible to see the changes in the peer relationships between objects over time together with the context of these relationships. The experimental results proved quite high precision of our method and indicated high usefulness for particular knowledge discovery tasks.","cites":"0","conferencePercentile":"5.769230769"},{"venue":"WISE","id":"118d281f9120a34ef98bcf05decc85421576235e","venue_1":"WISE","year":"2005","title":"Xebu: A Binary Format with Schema-Based Optimizations for XML Data","authors":"Jaakko Kangasharju, Sasu Tarkoma, Tancred Lindholm","author_ids":"2383982, 1759241, 2826704","abstract":"XML is currently being used as the message syntax for Web services. To enable small mobile devices to use Web services, this XML use must not be too resource-consuming. Due to several measurements indicating otherwise, alternate serialization formats for XML data have been proposed. We present here a format for XML data designed from the ground up for the mobile environment. The format is simple, yet gives acceptable document sizes and is efficiently pro-cessable. An automaton-based approach gives further improvements when full or partial schema information is available. We provide performance measurements verifying these claims and also consider some issues arising from the use of an alternate XML serialization format.","cites":"16","conferencePercentile":"85.52631579"},{"venue":"WISE","id":"f415baf73cf1f3ac71e2d0a35d3609169e79250f","venue_1":"WISE","year":"2004","title":"Towards Next Generation Web Information Retrieval","authors":"Wei-Ying Ma, HongJiang Zhang, Hsiao-Wuen Hon","author_ids":"1705244, 1718558, 2089692","abstract":"Today search engines have become one of the most critical applications on the Web, driving many important online businesses that connect people to information. As the Web continues to grow its size with a variety of new data and penetrate into every aspect of people's life, the need for developing a more intelligent search engine is increasing. In this talk, we will briefly review the current status of search engines, and then present some of our recent works on building next generation web search technologies. Specifically, we will talk about how to extract data records from web pages using vision-based approach, and introduce new research opportunities in exploring the complementary properties between the surface Web and the deep Web to mutually facilitate the processes of web information extraction and deep web crawling. We will also present a search prototype that data-mines deep web structure to enable one-stop search of multiple online web databases. In contrast with current web search that is essentially document-level ranking and retrieval, an old paradigm in IR for more than 25 years, we will introduce our works in building a new paradigm called object-level web search that aims to automatically discover sub-topics (or taxonomy) for any given query and put retrieved web documents into a meaningful organization. We are developing techniques to provide object-level ranking, trend analysis, and business intelligence when the search is intended to find web objects such as people, papers, conferences, and interest groups. We will also talk about vertical search opportunities in some emerging new areas such as mobile search and media search. In addition to providing information adaptation on mobile devices, we believe location-based and context-aware search is going to be important for mobile search. We also think that by bridging physical world search to digital world search, many new user scenarios that do not yet exist on desktop search can potentially make a huge impact on the mobile Internet. For media search, we will present those new opportunities in analyzing the multi-typed interrelationship between media objects and other content such as text, hyperlinks, deep web structure, and user interactions for better semantic understanding and indexing of media objects. We will also discuss our goal of continually advancing web search to next level by applying data mining, machine learning, and knowledge discovery techniques into the process of information analysis, organization, retrieval, and visualization.","cites":"2","conferencePercentile":"36.25"},{"venue":"WISE","id":"97e6fe973cb50b462297315c896f0bae13be675a","venue_1":"WISE","year":"2013","title":"GEAM: A General and Event-Related Aspects Model for Twitter Event Detection","authors":"Yue You, Guangyan Huang, Jian Cao, Enhong Chen, Jing He, Yanchun Zhang, Liang Hu","author_ids":"8063480, 2074183, 1720596, 1703319, 1730277, 1722358, 1766665","abstract":"Event detection on Twitter has become a promising research direction due to Twitter's popularity, up-to-date feature, free writing style and so on. Unfortunately, it's a challenge to analyze Twitter dataset for event detection, since the informal expressions of short messages comprise many abbreviations, Internet buzzwords, spelling mistakes, meaningless contents etc. Previous techniques proposed for Twitter event detection mainly focus on clustering bursty words related to the events, while ignoring that these words may not be easily interpreted to clear event descriptions. In this paper, we propose a General and Event-related Aspects Model (GEAM), a new topic model for event detection from Twitter that associates General topics and Event-related Aspects with events. We then introduce a collapsed Gibbs sampling algorithm to estimate the word distributions of General topics and Event-related Aspects in GEAM. Our experiments based on over 7 million tweets demonstrate that GEAM outperforms the state-of-the-art topic model in terms of both Precision and DERate (measuring Duplicated Events Rate detected). Particularly, GEAM can get better event representation by providing a 4-tuple (T ime, Locations, Entities, Keywords) structure of the detected events. We show that GEAM not only can be used to effectively detect events but also can be used to analyze event trends.","cites":"2","conferencePercentile":"63.46153846"},{"venue":"WISE","id":"e7f29dd8d0ed44764a12c77ee8bf99801350decf","venue_1":"WISE","year":"2000","title":"Conflict Control Locking in Distributed Cooperative Graphics Editors","authors":"Liyin Xue, Kang Zhang, Chengzheng Sun","author_ids":"2016179, 1714511, 1688131","abstract":"The communication latency presents a major challenge to achieving high responsiveness for Internet-based cooperative editing systems. In this paper, we propose conflict control locking (post-locking) schemes for conflict resolution in real-time object-based cooperative graphics editors. With these schemes, no locking request is needed before applying an editing operation to an object, instead, a lock will automatically be generated by the system i f a conflict occurs. Lock ownership assigning rules ure devised for the schemes. With a spec$c post-locking approach, algorithms and implementation techniques, such as, lock synchronisation detection, voting, and group intention realisation, are discussed in detail.","cites":"4","conferencePercentile":"57.57575758"},{"venue":"WISE","id":"64b117cadfcd12fda689d533da7f14bf0752f903","venue_1":"WISE","year":"2004","title":"Temporal Web Page Summarization","authors":"Adam Jatowt, Mitsuru Ishizuka","author_ids":"1774986, 1687719","abstract":"In the recent years the Web has become an important medium for communication and information storage. As this trend is predicted to continue, it is necessary to provide efficient solutions for retrieving and processing information found in WWW. In this paper we present a new method for temporal web page summarization based on trend and variance analysis. In the temporal summarization web documents are treated as dynamic objects that have changing contents and characteristics. The sequential versions of a single web page are retrieved during predefined time interval for which the summary is to be constructed. The resulting summary should represent the most popular, evolving concepts which are found in web document versions. The proposed method can be also used for summarization of dynamic collections of topically related web pages.","cites":"4","conferencePercentile":"51.25"},{"venue":"WISE","id":"7531b66a2a606f26e58f95a036829876849a00c3","venue_1":"WISE","year":"2000","title":"Optional and Responsive Locking in Distributed Collaborative Object Graphics Editing Systems","authors":"David Chen, Chengzheng Sun","author_ids":"3698743, 1688131","abstract":"Object-based collaborative graphics editing systems allow multiple users to edit the same graphics document at the same time from multiple sites. This paper examines the use of locking to prevent the generation of conflicting operations in this type of systems. Two types of locks are examined: object and region. A locking scheme which preserves the intentions of all operations is proposed. Furthermore, the problems of lock ownership caused by concurrent operations are resolved.","cites":"2","conferencePercentile":"37.87878788"},{"venue":"WISE","id":"6bbad9b415509230427aa5ecb3daaaaff80806cf","venue_1":"WISE","year":"2009","title":"An Architecture for Open Cross-Media Annotation Services","authors":"Beat Signer, Moira C. Norrie","author_ids":"1725701, 1685670","abstract":"The emergence of new media technologies in combination with enhanced information sharing functionality offered by the Web provides new possibilities for cross-media annotations. This in turn raises new challenges in terms of how a true integration across different types of media can be achieved and how we can develop annotation services that are sufficiently flexible and extensible to cater for new document formats as they emerge. We present a general model for cross-media annotation services and describe how it was used to define an architecture that supports extensibility at the data level as well as within authoring and visualisation tools.","cites":"5","conferencePercentile":"59.61538462"},{"venue":"WISE","id":"71e3e232ef6ef55dd9ab557ffe9f4811e856f42e","venue_1":"WISE","year":"2009","title":"Spatio-Temporal-Thematic Analysis of Citizen Sensor Data: Challenges and Experiences","authors":"Meena Nagarajan, Karthik Gomadam, Amit P. Sheth, Ajith Ranabahu, Raghava Mutharaju, Ashutosh Jadhav","author_ids":"3041479, 2009665, 1709950, 2977897, 3163243, 2558007","abstract":"We present work in the spatio-temporal-thematic analysis of citizen-sensor observations pertaining to real-world events. Using Twitter as a platform for obtaining crowd-sourced observations, we explore the interplay between these 3 dimensions in extracting insightful summaries of social perceptions behind events. We present our experiences in building a web mashup application, Twitris[1] that extracts and facilitates the spatio-temporal-thematic exploration of event descriptor summaries.","cites":"41","conferencePercentile":"100"},{"venue":"WISE","id":"6e6ae4e2e04d7d74365c7acfa9da2e71c0b113a5","venue_1":"WISE","year":"2004","title":"Extraction of Cognitively-Significant Place Names and Regions from Web-Based Physical Proximity Co-occurrences","authors":"Taro Tezuka, Yusuke Yokota, Mizuho Iwaihara, Katsumi Tanaka","author_ids":"2726182, 4993750, 1811678, 1750132","abstract":"The cognitive significances of geographic objects play an important role in optimizing a set of place names presented on a map interface. The aim of this research is to assign a value for cognitive significance to each place name in GIS, based on regional documents collected from the Web. The assigned values could be used in GIS applications including regional information searches, path findings, and car navigation systems. We will compare different criteria for cognitive significance and discuss a system already in use, before presenting our experimental results.","cites":"11","conferencePercentile":"83.75"},{"venue":"WISE","id":"4a67ddb6c14fdca65c941af29fe4288f0c114b96","venue_1":"WISE","year":"2005","title":"Maintaining Consistency Under Isolation Relaxation of Web Services Transactions","authors":"Seunglak Choi, Hyukjae Jang, Hangkyu Kim, Jungsook Kim, Su Myeon Kim, Junehwa Song, Yoon-Joon Lee","author_ids":"3183486, 3005509, 2439213, 2080796, 2511639, 1789470, 1751540","abstract":"For efficiently managing Web Services (WS) transactions which are executed across multiple loosely-coupled autonomous organizations, isolation is commonly relaxed. A Web services operation of a transaction releases locks on its resources once its jobs are completed without waiting for the completions of other operations. However, those early unlocked resources can be seen by other transactions , which can spoil data integrity and causes incorrect outcomes. Existing WS transaction standards do not consider this problem. In this paper, we propose a mechanism to ensure the consistent executions of isolation-relaxing WS transactions. The mechanism effectively detects inconsistent states of transactions with a notion of a completion dependency and recovers them to consistent states. We also propose a new Web services Transaction Dependency management Protocol (WTDP). WTDP helps organizations manage the WS transactions easily without data inconsistency. WTDP is designed to be compliant with a representative WS transaction standard, the Web Services Transactions specifications, for easy integration into existing WS transaction systems. We prototyped a WTDP-based WS transaction management system to validate our protocol.","cites":"10","conferencePercentile":"68.42105263"},{"venue":"WISE","id":"a1d7f7a0bc5de1cedce762d50425f9e53791ab3d","venue_1":"WISE","year":"2008","title":"Can Social Tagging Improve Web Image Search?","authors":"Makoto P. Kato, Hiroaki Ohshima, Satoshi Oyama, Katsumi Tanaka","author_ids":"2877085, 1698449, 1740955, 1750132","abstract":"Conventional Web image search engines can return reasonably accurate results for queries containing concrete terms, but the results are less accurate for queries containing only abstract terms, such as \" spring \" or \" peace. \" To improve the recall ratio without drastically degrading the precision ratio, we developed a method that replaces an abstract query term given by a user with a set of concrete terms and that uses these terms in queries input into Web image search engines. Concrete terms are found for a given abstract term by making use of social tagging information extracted from a social photo sharing system, such as Flickr. This information is rich in user impressions about the objects in the images. The extraction and replacement are done by (1) collecting social tags that include the abstract term, (2) clustering the tags in accordance with the term co-occurrence of images, (3) selecting concrete terms from the clusters by using WordNet, and (4) identifying sets of concrete terms that are associated with the target abstract term by using a technique for association rule mining. Experimental results show that our method improves the recall ratio of Web image searches.","cites":"9","conferencePercentile":"68.75"},{"venue":"WISE","id":"8dd9415921cd3894f72615c8800aaf552378e5a7","venue_1":"WISE","year":"2005","title":"Blog Map of Experiences: Extracting and Geographically Mapping Visitor Experiences from Urban Blogs","authors":"Takeshi Kurashima, Taro Tezuka, Katsumi Tanaka","author_ids":"3104659, 2726182, 1750132","abstract":"The prevalence of weblogs (blogs) has enabled people to share the personal experiences of tourists at specific locations and times. Such information was traditionally unavailable, except indirectly through local newspapers and periodicals. This paper describes a method of spatially and temporally obtaining specific experiences by extracting association rules from the content of blog articles. For example, we can read about visitors' activities and evaluations of sightseeing spots. By geographically mapping their experiences, the proposed system enables observation of tourist activities and impressions of specific locations, which can often be more diverse than local guidebooks and more trustworthy than advertisements.","cites":"7","conferencePercentile":"57.89473684"},{"venue":"WISE","id":"801266a615544cfc294b3b020fd2c23cc7859210","venue_1":"WISE","year":"2000","title":"Logging and Signing Document-Transfers on the WWW-A Trusted Third Party Gateway","authors":"Andreas Heuer, Frank Losemann, Christoph Meinel","author_ids":"2370248, 1918860, 1708312","abstract":"In this work we discuss a service that aims to make quoting of online documents, \" web contents \" easy and provable. For that reason we report the conception of a gateway that works as a Trusted Third Party (TTP) service which is based on a public key infrastructure (PKI). The developed service consists of the signing of any data-transmission that was done via the TTP-gateway. After the data-transfer a set of data can be requested from the used gateway that is signed with the TTP-gateways private key. This signed set of data contains for each request that was processed by the gateway at least three components. Those are the request from the client, the reply from the server and finally the signature of the (TTP-)server. Storing this signed data the recipient at the client side can provide it to other parties suitable for a latter verification of the data-transfer. The TTP-server generates automatically verifiable statements of the kind \" this request resulted in that response \". Now anyone that trusts the chosen TTP-gateways statements will be able to verify the data-transfer by the use of the trusted third parties certified public key. Furthermore this paper describes a prototype implementation of such a service using HTTP. Finally a possible employment of the TTP-gateway is discussed.","cites":"1","conferencePercentile":"21.21212121"},{"venue":"WISE","id":"9b067397fee3f6c1fba1b97da539c1964a65bc98","venue_1":"WISE","year":"2011","title":"Trust as a Service: A Framework for Trust Management in Cloud Environments","authors":"Talal H. Noor, Quan Z. Sheng","author_ids":"1827750, 1713128","abstract":"Trust is one of the most concerned obstacles for the adoption and growth of cloud computing. Although several solutions have been proposed recently in managing trust feedbacks in cloud environments, how to determine the credibility of trust feedbacks is mostly neglected. In addition, managing trust feedbacks in cloud environments is a difficult problem due to unpredictable number of cloud service consumers and highly dynamic nature of cloud environments. In this paper, we propose the \" Trust as a Service \" (TaaS) framework to improve ways on trust management in cloud environments. In particular, we introduce an adap-tive credibility model that distinguishes between credible trust feedbacks and malicious feedbacks by considering cloud service consumers' capability and majority consensus of their feedbacks. The approaches have been validated by the prototype system and experimental results.","cites":"20","conferencePercentile":"100"},{"venue":"WISE","id":"43aff57b983aeaa098b5e6021e88dd64ddb9a450","venue_1":"WISE","year":"2010","title":"Model-Driven Development of Adaptive Service-Based Systems with Aspects and Rules","authors":"Jian Yu, Quan Z. Sheng, Joshua K. Y. Swee","author_ids":"1740321, 1713128, 2268566","abstract":"Service-oriented computing (SOC) has become a dominant paradigm in developing distributed Web-based software systems. Besides the benefits such as interoperability and flexibility brought by SOC, modern service-based software systems are frequently required to be highly adaptable in order to cope with rapid changes and evolution of business goals, requirements, as well as physical context in a dynamic business environment. Unfortunately, adaptive systems are still difficult to build due to its high complexity. In this paper, we propose a novel approach called MoDAR to support the development of dynamically adaptive service-based systems (DASS). Especially in this approach, we first model the functionality of a system by two constituent parts: i) a stable part called the base model described using business processes, and ii) a volatile part called the variable model described using business rules. This model reflects the fact that business processes and rules are two significant and complementary aspects of business requirements, and business rules are usually much more volatile than business processes. We then use an aspect-oriented approach to weave the base model and variable model together so that they can evolve independently without interfering with each other. A model-driven platform has been implemented to support the development lifecycle of a DASS from specification, design, to deployment and execution. Systems developed with the MoDAR platform are running on top of a BPEL process engine and a Drools rule engine. Experimentation shows that our approach brings high adaptability and maintainability to service-based systems with reasonable performance overhead.","cites":"6","conferencePercentile":"80.95238095"},{"venue":"WISE","id":"85305c81384c73a14a51b8406dc84dfff1aee21e","venue_1":"WISE","year":"2002","title":"Applying the Site Information to the Information Retrieval from the Web","authors":"Yasuhito Asano, Hiroshi Imai, Masashi Toyoda, Masaru Kitsuregawa","author_ids":"3031482, 6546753, 2361778, 1716799","abstract":"In recent years, several information retrieval methods using information about the Web-links are developed, such as HITS and Trawling. In order to analyze the Web-links dividing into links inside each Web site (local-links) and links between Web sites (global-links) for the information retrieval, it is required that a proper model of the Web site, a phrase used ambiguously in daily life. In the existing researches , a Web server is used as a model of the Web site. This idea works relatively well in case that a Web site corresponds to a server such as public Web sites, but works poorly in case that multiple Web sites correspond to a server such as private Web sites on rental Web servers. In this paper , we propose a new model of the Web site, \" directory-based site \" to handle typical private sites, and a method to identify them using information about the URL and the Web-links. We verify the method can approximately identify about ¬± of over 110 thousands servers whether each server has multiple directory-based sites or not, and extract over 500 thousands of directory-based sites and 4 million global-links by computational experiments using jp-domain URLs and Web-links data contains over 23 million URLs and 100 million Web-links, collected from July to August 2000, by Toyoda and Kitsuregawa. We also propose a new framework of the Web-links based information retrieval that uses the directory-based sites and the global-links instead of the Web pages and the whole Web-links respectively , and examine effectiveness of our framework by comparing a result of Trawling on our framework to one on the existing framework.","cites":"6","conferencePercentile":"23.07692308"},{"venue":"WISE","id":"e4bad14d713f1a23850cde7638afb98f6754cfb9","venue_1":"WISE","year":"2005","title":"Temporal Ranking of Search Engine Results","authors":"Adam Jatowt, Yukiko Kawai, Katsumi Tanaka","author_ids":"1774986, 1700611, 1750132","abstract":"Existing search engines contain the picture of the Web from the past and their ranking algorithms are based on data crawled some time ago. However , a user requires not only relevant but also fresh information. We have developed a method for adjusting the ranking of search engine results from the point of view of page freshness and relevance. It uses an algorithm that post-processes search engine results based on the changed contents of the pages. By analyzing archived versions of web pages we estimate temporal qualities of pages, that is, general freshness and relevance of the page to the query topic over certain time frames. For the top quality web pages, their content differences between past snapshots of the pages indexed by a search engine and their present versions are analyzed. Basing on these differences the algorithm assigns new ranks to the web pages without the need to maintain a constantly updated index of web documents.","cites":"8","conferencePercentile":"61.84210526"},{"venue":"WISE","id":"99d4da3842af0cfea071af76041ab86a590887f5","venue_1":"WISE","year":"2010","title":"Domain-Specific Language for Context-Aware Web Applications","authors":"Michael Nebeling, Michael Grossniklaus, Stefania Leone, Moira C. Norrie","author_ids":"2262595, 1786155, 1755131, 1685670","abstract":"Context-awareness is a requirement in many modern web applications. \\Vhile most model-driven web engineering approaches have been extended vvith support for adaptivity, state-of-the-art dew lopment platforms generally provide only limited means for the specification of adaptation and often completely lack a notion of context. \\Ve propose a domain-specific language for context-aware web applications that builds on a simple context model and powerful context matching expressions.","cites":"3","conferencePercentile":"47.61904762"},{"venue":"WISE","id":"f975a63d89a3fed06b1f09292f0c11c7e93d8785","venue_1":"WISE","year":"2008","title":"Supporting Judgment of Fact Trustworthiness Considering Temporal and Sentimental Aspects","authors":"Yusuke Yamamoto, Taro Tezuka, Adam Jatowt, Katsumi Tanaka","author_ids":"2495258, 2726182, 1774986, 1750132","abstract":"We have developed a system for helping users to determine the trustworthiness of uncertain facts based on sentiment and temporal viewpoints by aggregating information from the Web. Our goal is not to determine whether uncertain facts are true or false, but to provide users with additional data on which the trustworthiness of the information can be determined. The system shows with what sentiment and in what context facts are mentioned on the Web and displays any temporal change in the fact's popularity. Furthermore, the system extracts counter facts and analyzes them in the same way. The majority of 1000 users who evaluated our system found it to be a useful tool for helping to determine the trustworthiness of facts from various viewpoints.","cites":"14","conferencePercentile":"87.5"},{"venue":"WISE","id":"8f2ab48b45e97ea919755fe7efae30944bdcb0de","venue_1":"WISE","year":"2008","title":"Intra/Inter-document Change Awareness for Co-authoring of Web Sites","authors":"Stavroula Papadopoulou, Claudia-Lavinia Ignat, G√©rald Oster, Moira C. Norrie","author_ids":"2279721, 2901088, 1948115, 1685670","abstract":"Systems that support the co-authoring of web sites often allow users to freely edit pages. This can result in semantic inconsistencies within and between pages. We propose a change awareness mechanism that monitors intra-and inter-document edits, taking into account changes made to a page and pages connected to it through html or tran-sclusion links. The effect of all the changes is computed based on various metrics and on different semantic levels according to user preferences. A visualisation tool indicates how much a document and documents linked to it have changed. An edit profile allows users to easily spot parts with \" interesting \" changes within web pages.","cites":"1","conferencePercentile":"18.75"},{"venue":"WISE","id":"f864ee6f2e08116928ee38e07015d171fab7b7a2","venue_1":"WISE","year":"2004","title":"Fault Resilience of Structured P2P Systems","authors":"Zhiyu Liu, Guihai Chen, Chunfeng Yuan, Sanglu Lu, Cheng-Zhong Xu","author_ids":"2646773, 1690235, 2034987, 8090592, 1732041","abstract":"A fundamental problem that confronts structured peer-to-peer system that use DHT technologies to map data onto nodes is the performance of the network under the circumstance that a large percentage of nodes join and fail frequently and simultaneously. A careful examination of some typical peer-to-peer networks will contribute a lot to choosing and using certain kind of topology in special applications. This paper analyzes the performance of Chord [7] and Koorde [2], and find out the crash point of each network through the simulation experiment.","cites":"0","conferencePercentile":"6.25"},{"venue":"WISE","id":"681396a5f84686d800f2a4f0937d57cfad62c549","venue_1":"WISE","year":"2013","title":"Feature Extraction from Micro-blogs for Comparison of Products and Services","authors":"Peng Zhao, Xue Li, Ke Wang","author_ids":"1766535, 6990205, 1751643","abstract":"Social networks are a popular place for people to express their opinions about products and services. One question would be that for two similar products (e.g., two different brands of mobile phones), can we make them comparable to each other? In this paper, we show our system namely OpinionAnalyzer, a novel social network analyser designed to collect opinions from Twitter micro-blogs about two given similar products for an effective comparison between them. The system outcome is a structure of features for the given products that people have expressed opinions about. Then the corresponding sentiment analysis on those features is performed. Our system can be used to understand user's preference to a certain product and show the reasons why users prefer this product. The experiments are evaluated based on accuracy, precision/recall, and F-score. Our experimental results show that the system is effective and efficient.","cites":"1","conferencePercentile":"38.46153846"},{"venue":"WISE","id":"5c7f700d28c9e5b5ac115c1409262ecfe89812db","venue_1":"WISE","year":"2013","title":"An Evaluation of Aggregation Techniques in Crowdsourcing","authors":"Nguyen Quoc Viet Hung, Nguyen Thanh Tam, Ngoc Tran Lam, Karl Aberer","author_ids":"2784457, 3014246, 2225993, 1751802","abstract":"As the volumes of AI problems involving human knowledge are likely to soar, crowdsourcing has become essential in a wide range of worldwide web applications. One of the biggest challenges of crowdsourcing is aggregating the answers collected from the crowd since the workers might have wide-ranging levels of expertise. In order to tackle this challenge, many aggregation techniques have been proposed. These techniques, however, have never been compared and analyzed under the same setting, rendering a 'right' choice for a particular application very difficult. Addressing this problem, this paper presents a benchmark that offers a comprehensive empirical study on the performance comparison of the aggregation techniques. Specifically, we integrated several state-of-the-art methods in a comparable manner, and measured various performance metrics with our benchmark, including computation time, accuracy, robustness to spammers, and adaptivity to multi-labeling. We then provide in-depth analysis of benchmarking results, obtained by simulating the crowdsourcing process with different types of workers. We believe that the findings from the benchmark will be able to serve as a practical guideline for crowdsourcing applications.","cites":"0","conferencePercentile":"13.46153846"},{"venue":"WISE","id":"94825300f867004b27342be1211aea35d50eb51d","venue_1":"WISE","year":"2001","title":"Web-Based Inference Rules for Processing Conceptual Geographical Relationships","authors":"Taro Tezuka, Ryong Lee, Yahiko Kambayashi, Hiroki Takakura","author_ids":"2726182, 2518933, 1736726, 2927941","abstract":"Dealing with prepositions such as \" near \" , \" between \" , and \" in front of \" is very important in Geographic Information Systems (GISs). In most systems, real world distances are used to handle these prepositions. One of the difficulties in processing these prepositions lies in the fact that their geographical range are distorted in people's cognitive maps. For example, size of an area referred by preposition \" near \" gets narrowed when there exists more famous landmark right next to the base geographical objects. This is because users are likely to choose most famous landmark when referring to certain position. Also, area referred by \" between \" is not a straight line. It curves along the most commonly used pathway between base objects. Difference in popularity of geographical objects is the main reason to cause such distortions in cognitive maps. Since there are large amount of data in the Web, we believe that such conceptual distortion can be calculated by analyzing web data. Popularity and co-occurrence rate are calculated through their frequency in the Web resources. Inference rules are set to restrict the target of conceptual prepositions using GIS and information obtained from the Web.","cites":"13","conferencePercentile":"80.43478261"},{"venue":"WISE","id":"98acd2bdc7487fe6af3dc8a4a8d027091fb563b9","venue_1":"WISE","year":"2005","title":"An Infrastructure for Reactive Information Environments","authors":"Rudi Belotti, Corsin Decurtins, Michael Grossniklaus, Moira C. Norrie","author_ids":"2453643, 1895420, 1786155, 1685670","abstract":"We introduce the concept of reactive information environments and a general infrastructure for experimentation with such systems. Its asynchronous state-based processing model is described along with the architectural requirements and main components of our infrastructure. These include a general context engine coupled together with a web publishing platform. An application for a public news service is used to motivate the requirements, explain the processing model and show how an application is implemented using the platform.","cites":"0","conferencePercentile":"6.578947368"},{"venue":"WISE","id":"1f7905b0819ec20193f599619712bd4f80816c72","venue_1":"WISE","year":"2002","title":"A Unified Framework for Web Link Analysis","authors":"Zheng Chen, Li Tao, Jidong Wang, Wenyin Liu, Wei-Ying Ma","author_ids":"1705657, 1798514, 4315466, 4163820, 1705244","abstract":"Web link analysis has been proved to provide significant enhancement to the precision of web search in practice. Among existing approaches, Kleinberg's HITS and Google's PageRank are the two most representative algorithms that employ explicit hyperlinks structure among web pages to conduct link analysis, and DirectHit represents the other extreme that takes the user's access frequency as implicit link to the web page for counting its importance. In this paper, we propose a novel link analysis algorithm which puts both explicit and implicit link structures under a unified framework, and show that HITS and DirectHit are essentially the two extreme instances of our proposed method. One important advantage of our method is its ability to analyze not only the hyperlinks between web-pages but also the interactions between the users and the Web at the same time. The importance of web-pages and users can reinforce each other to improve the Web link analysis. Compared with traditional HITS and DirectHit algorithms, our method further improves the search precision by 11.8% and 25.3%.","cites":"12","conferencePercentile":"59.61538462"},{"venue":"WISE","id":"1f879d8bb3356fbe8db20b4856e887af88229eef","venue_1":"WISE","year":"2010","title":"Refining Graph Partitioning for Social Network Clustering","authors":"Tieyun Qian, Yang Yang, Shuo Wang","author_ids":"7417209, 3432905, 5994097","abstract":"Graph partitioning is a traditional problem with many applications and a number of high-quality algorithms have been developed. Recently, demand for social network analysis arouses the new research interest on graph clustering. Social networks differ from conventional graphs in that they exhibit some key properties which are largely neglected in popular partitioning algorithms. In this paper, we propose a novel framework for finding clusters in real social networks. The framework consists of several key features. Firstly, we define a new metric which measures the small world strength between two verti-ces. Secondly, we design a strategy using this metric to greedily, yet effectively, refine existing partitioning algorithms for common objective functions. We conduct an extensive performance study. The empirical results clearly show that the proposed framework significantly improve the results of state-of-the-art methods.","cites":"1","conferencePercentile":"16.66666667"},{"venue":"WISE","id":"58f47dd2104b055774125e461538907b1e0f9222","venue_1":"WISE","year":"2004","title":"Optimizing Web Search Using Spreading Activation on the Clickthrough Data","authors":"Gui-Rong Xue, Shen Huang, Yong Yu, Hua-Jun Zeng, Zheng Chen, Wei-Ying Ma","author_ids":"1701421, 2514919, 3578922, 1741348, 1705657, 1705244","abstract":"In this paper, we propose a mining algorithm to utilize the user click-through data to improve search performance. The algorithm first explores the relationship between queries and Web pages and mine out co-visiting relationship as the virtual link among the Web pages, and then Spreading Activation mechanism is used to perform the query-dependent search. Our approach could overcome the challenges discussed above and the experimental results on a large set of MSN click-through log data show a significant improvement on search performance over the DirectHit algorithm as well as the baseline search engine.","cites":"5","conferencePercentile":"58.75"},{"venue":"WISE","id":"affe4045156801a66e9cc803c2d37014ddb733da","venue_1":"WISE","year":"2004","title":"Google's \"I'm Feeling Lucky\", Truly a Gamble?","authors":"Roelof van Zwol, Herre van Oostendorp","author_ids":"1747340, 2447073","abstract":"With huge quantities of multimedia information becoming available on the Internet everyday, our foremost mechanisms to find information still rely on text-based retrieval systems with their keyword-based query interfaces. However little to nothing is known about the retrieval performance and/or the quality of the user interface of these search engines. Often when a retrieval system is developed the evaluation focuses either on the retrieval performance analysis of the retrieval strategy, or on the usability testing of the interface offered by the retrieval system. Both experiments are time consuming to set up and often require the same preconditions to be fulfilled, i.e. a test reference collection, and in the case of usability testing respondents, to be available. The contribution of this article is twofold. It discusses a testbed for the evaluation of a wide variety of retrieval systems that allows both a us-ability and a retrieval experiment to be conducted in the same platform. Besides greatly reducing the effort needed to set up and perform such experiments , it also allows for the investigation of the relationship between usability testing and retrieval performance analysis of retrieval systems. Secondly, it presents the results of a case study with the testbed, comparing three major search engines available on the Internet.","cites":"5","conferencePercentile":"58.75"},{"venue":"WISE","id":"85b4fd3fc80ca446bee939d3c2b23c48ca36d0d3","venue_1":"WISE","year":"2013","title":"Time-Aware Travel Attraction Recommendation","authors":"Kai Wang, Richong Zhang, Xudong Liu, Xiaohui Guo, Hailong Sun, Jinpeng Huai","author_ids":"3751236, 1747018, 1767347, 8395041, 4880467, 7392431","abstract":"The increasing number of tourists uploaded photos make it possible to discover attractive locations. Existing travel recommendation models make use of the geo-related information to infer possible locations that tourists may be interested in. However, the temporal information, such as the date and time when the photo was taken, associated with these photos are not taken into account by most of existing works. We advocate that this information give us a chance to discover the best visiting time period for each location. In this paper, we exploit a 3-way tensor to integrate context information for tourists visited locations. Based on this model, we propose a time-aware recommendation approach for travel destinations. In addition, a tensor factorization-based approach by maximizing the ranking performance measure is proposed for predicting the possible temporal-spatial correlations for tourists. The experimental results on the real tourists uploaded photos at Flickr.com show that our model outperforms existing approaches in terms of the prediction precision, ranking performance and diversity.","cites":"1","conferencePercentile":"38.46153846"},{"venue":"WISE","id":"7aaefa834cc8c50b69f307748f04c90398b057c5","venue_1":"WISE","year":"2007","title":"Modeling Distributed Events in Data-Intensive Rich Internet Applications","authors":"Giovanni Toffetti Carughi, Sara Comai, Alessandro Bozzon, Piero Fraternali","author_ids":"2719144, 1742363, 1710630, 1704595","abstract":"Rich Internet applications (RIAs) enable novel usage scenarios by overcoming the traditional paradigms of Web interaction. Conventional Web applications can be seen as reactive systems in which events are 1) produced by the user acting upon the browser HTML interface, and 2) processed by the server hosting the application state and logic. In RIAs, distribution of data and computation across client and server broadens the classes and features of the produced events as they can originate , be detected, notified, and processed in a variety of ways. In this work, we investigate how events can be explicitly described and coupled to the other concepts of a Web modeling language in order to specify collaborative Rich Internet applications.","cites":"13","conferencePercentile":"88"},{"venue":"WISE","id":"fcae30ba2151712ba76377be320a0cb6006926cc","venue_1":"WISE","year":"2014","title":"Educational Forums at a Glance: Topic Extraction and Selection","authors":"Bernardo Pereira Nunes, Ricardo Kawase, Besnik Fetahu, Marco A. Casanova, Gilda Helena Bernardino de Campos","author_ids":"2988251, 1727722, 1923602, 1788336, 3034707","abstract":"Web forums play a key role in the process of knowledge creation, providing means for users to exchange ideas and to collaborate. However, educational forums, along several others online educational environments, often suffer from topic disruption. Since the contents are mainly produced by participants (in our case learners), one or few individuals might change the course of the discussions. Thus, realigning the discussed topics of a forum thread is a task often conducted by a tutor or moderator. In order to support learners and tutors to harmonically align forum discussions that are pertinent to a given lecture or course, in this paper, we present a method that combines semantic technologies and a statistical method to find and expose relevant topics to be discussed in online discussion forums. We surveyed the outcomes of our topic extraction and selection method with students, professors and university staff members. Results suggest the potential usability of the method and the potential applicability in real learning scenarios.","cites":"0","conferencePercentile":"32.5"},{"venue":"WISE","id":"427b57144c0badcaf07ed62dc2d7c9ea9898ae38","venue_1":"WISE","year":"2011","title":"Training a Named Entity Recognizer on the Web","authors":"David Urbansky, James A. Thom, Daniel Schuster, Alexander Schill","author_ids":"2978586, 1787408, 4849899, 1695086","abstract":"In this paper, we introduce an approach for training a Named Entity Recognizer (NER) from a set of seed entities on the web. Creating training data for NERs is tedious, time consuming, and becomes more difficult with a growing set of entity types that should be learned and recognized. Named Entity Recognition is a building block in natural language processing and is widely used in fields such as question answering, tagging, and information retrieval. Our NER can be trained on a set of entity names of different types and can be extended whenever a new entity type should be recognized. This feature increases the practical applications of the NER.","cites":"3","conferencePercentile":"43.33333333"},{"venue":"WISE","id":"6fff20635f05242231b4b12821f8f7e4f5d92d9b","venue_1":"WISE","year":"2005","title":"Optimization of XSLT by Compact Specialization and Combination","authors":"Ce Dong, James Bailey","author_ids":"2744467, 6263638","abstract":"In recent times, there has been an increased utilization of server-side XSLT systems as part of e-commerce and e-publishing applications. For the high volumes of data in these applications, effective optimization techniques for XSLT are particularly important. In this paper, we propose two new optimization approaches, Specialization Combination and Specialization Set Compac-tion, to help improve performance. We describe rules for combining specialized XSLT stylesheets and provide methods for generating a more compact specialization set. An experimental evaluation of our methods is undertaken, where we show our methods to be particularly effective for cases with very large XML input and different varieties of user queries.","cites":"0","conferencePercentile":"6.578947368"},{"venue":"WISE","id":"734cb41fac5133aeac98322b7a062c44104bd7cd","venue_1":"WISE","year":"2012","title":"Sentiment Analysis by Augmenting Expectation Maximisation with Lexical Knowledge","authors":"Xiuzhen Zhang, Yun Zhou, James Bailey, Kotagiri Ramamohanarao","author_ids":"5509086, 1733083, 6263638, 1720142","abstract":"Sentiment analysis of documents aims to characterise the positive or negative sentiment expressed in documents. It has been formulated as a supervised classification problem, which requires large numbers of labelled documents. Semi-supervised sentiment classification using limited documents or words labelled with sentiment-polarities are approaches to reducing labelling cost for effective learning. Expectation Maximisation (EM) has been widely used in semi-supervised sentiment classification. A prominent problem with existing EM-based approaches is that the objective function of EM may not conform to the intended classification task and thus can result in poor classification performance. In this paper we propose to augment EM with the lexical knowledge of opinion words to mitigate this problem. Extensive experiments on diverse domains show that our lexical EM algorithm achieves significantly higher accuracy than existing standard EM-based semi-supervised learning approaches for sentiment classification, and also significantly outperforms alternative approaches using the lexical knowledge.","cites":"1","conferencePercentile":"31.25"},{"venue":"WISE","id":"f456bc939ce8d0fada39e2a4e012b59cffbce814","venue_1":"WISE","year":"2003","title":"Switching Over to Paper: A New Web Channel","authors":"Moira C. Norrie, Beat Signer","author_ids":"1685670, 1725701","abstract":"We present a general web-based information infrastructure capable of supporting the rapid development of highly-interactive information environments that cater for widely varying requirements across application domains and all forms of fixed and mobile client devices. In particular, we describe how this infrastructure has been extended to support digitally augmented paper through a special transformation component that can map active areas of document pages to information objects so that user-and context-dependent interaction can be supported. Our infrastructure is sufficiently general and flexible to adapt to, not only emerging and even unanticipated technologies in the area of interactive paper, but also the rapidly expanding interaction sphere of hypermedia.","cites":"15","conferencePercentile":"75"},{"venue":"WISE","id":"d236ae99c2507e39ec2af47a6e03b8b76951dda9","venue_1":"WISE","year":"2004","title":"Multi-type Features Based Web Document Clustering","authors":"Shen Huang, Gui-Rong Xue, Benyu Zhang, Zheng Chen, Yong Yu, Wei-Ying Ma","author_ids":"2514919, 1701421, 2158301, 1705657, 3578922, 1705244","abstract":"Clustering has been demonstrated as a feasible way to explore the contents of document collection and organize search engine results. For this task, many features of Web page, such as content, anchor text, URL, hyperlink etc, can be exploited and different results can be obtained. We expect to provide a unified and even better result for end users. Some work have studied how to use several types of features together to perform clustering. Most of them focus on ensemble method or combination of similarity. In this paper, we propose a novel algorithm: Multi-type Features based Reinforcement Clustering (MFRC). This algorithm does not use a unique combine score for all feature spaces, but uses the intermediate clustering result in one feature space as additional information to gradually enhance clustering in other spaces. Finally a consensus can be achieved by such mutual reinforcement. And the experimental results show that MFRC also provides some performance improvement.","cites":"1","conferencePercentile":"20"},{"venue":"WISE","id":"6b874fc43c9df739209caa19462cae8c0a2385fb","venue_1":"WISE","year":"2015","title":"Moving Video Mapper and City Recorder with Geo-Referenced Videos","authors":"Guangqiang Zhao, Mingjin Zhang, Tao Li, Shu-Ching Chen, Ouri Wolfson, Naphtali Rishe","author_ids":"4831828, 3062588, 1726351, 1705664, 3903003, 1719172","abstract":"There has been growing interest in correlating co-visualizing a video stream to the dynamic geospatial attributes of the moving camera. Moving videos comes from various GPS-enabled video recording devices and can be uploaded to video-sharing websites. Such public website do not presently display dynamic spatial features correlated to a video player. Although some systems include map based playback products, there has been no unified platform for users to share geo-referenced videos that takes spatial characteristics into account. We present here Moving Video Mapper, which integrates both historical and live geo-referenced videos to give users an immersive experience in multidimensional perspectives. The platform has been evaluated using real data in an urban environment through several use cases.","cites":"0","conferencePercentile":"33.33333333"},{"venue":"WISE","id":"dd8090ab8ff7b3e2641558331bd30b53dda34cba","venue_1":"WISE","year":"2016","title":"Learning-Based SPARQL Query Performance Prediction","authors":"Wei Emma Zhang, Quan Z. Sheng, Kerry L. Taylor, Yongrui Qin, Lina Yao","author_ids":"3075235, 1713128, 1782060, 1766463, 2166854","abstract":"Users may access full items free of charge; copies of full text items generally can be reproduced, displayed or performed and given to third parties in any format or medium for personal research or study, educational or not¬≠for¬≠profit purposes without prior permission or charge, provided: ‚Ä¢ The authors, title and full bibliographic details is credited in any copy; ‚Ä¢ A hyperlink and/or URL is included for the original metadata page; and ‚Ä¢ The content is not changed in any way. Abstract. According to the predictive results of query performance, queries can be rewritten to reduce time cost or rescheduled to the time when the resource is not in contention. As more large RDF datasets appear on the Web recently, predicting performance of SPARQL query processing is one major challenge in managing a large RDF dataset efficiently. In this paper, we focus on representing SPARQL queries with feature vectors and using these feature vectors to train predictive models that are used to predict the performance of SPARQL queries. The evaluations performed on real world SPARQL queries demonstrate that the proposed approach can effectively predict SPARQL query performance and outperforms state-of-the-art approaches.","cites":"0","conferencePercentile":"66.66666667"},{"venue":"WISE","id":"77d1f0adfb72fd8f32aa62dccae83ceb685e5f78","venue_1":"WISE","year":"2005","title":"Identifying Value Mappings for Data Integration: An Unsupervised Approach","authors":"Jaewoo Kang, Dongwon Lee, Prasenjit Mitra","author_ids":"1751316, 1784227, 1714911","abstract":"The Web is a distributed network of information sources where the individual sources are autonomously created and maintained. Consequently, syntactic and semantic heterogeneity of data among sources abound. Most of the current data cleaning solutions assume that the data values referencing the same object bear some textual similarity. However, this assumption is often violated in practice. \" Two-door front wheel drive \" can be represented as \" 2DR-FWD \" or \" R2FD \" , or even as \" CAR TYPE 3 \" in different data sources. To address this problem, we propose a novel two-step automated technique that exploits statistical dependency structures among objects which is invariant to the tokens representing the objects. The algorithm achieved a high accuracy in our empirical study, suggesting that it can be a useful addition to the existing information integration techniques.","cites":"6","conferencePercentile":"52.63157895"},{"venue":"WISE","id":"f61feba8dca1689c3f1e95bfa748a81b4e3026b6","venue_1":"WISE","year":"2004","title":"Optimization of XML Transformations Using Template Specialization","authors":"Ce Dong, James Bailey","author_ids":"2744467, 6263638","abstract":"XSLT is the primary language for transforming and presenting XML. Effective optimization techniques for XSLT are particularly important for applications which involve high volumes of data, such as online server-side processing. This paper presents a new approach for optimizing XSLT transformations, based on the notion of template specialization. We describe a number of template specialization techniques, suitable for varying XSLT design styles and show how such specializations can be used at run time, according to user input queries. An experimental evaluation of our method is undertaken and it is shown to be particularly effective for cases with very large XML input.","cites":"5","conferencePercentile":"58.75"},{"venue":"WISE","id":"f4171210307fbdf6388d9ed5ebbb302ce6b20979","venue_1":"WISE","year":"2014","title":"On String Prioritization in Web-Based User Interface Localization","authors":"Luis A. Leiva, Vicente Alabau","author_ids":"2534139, 4132077","abstract":"We have noticed that most of the current challenges affecting user interface localization could be easily approached if string prioriti-zation would be made possible. In this paper, we tackle these challenges through Nimrod, a web-based internationalization tool that prioritizes user interface strings using a number of discriminative features. As a practical application, we investigate different prioritization strategies for different string categories from Wordpress, a popular open-source content management system with a large message catalog. Further, we contribute with WPLoc, a carefully annotated dataset so that others can reproduce our experiments and build upon this work. Strings in the WPLoc dataset are labeled as relevant and non-relevant, where relevant strings are in turn categorized as critical, informative, or navigational. Using state-of-the-art classifiers, we are able to retrieve strings in these categories with competitive accuracy. Nimrod and the WPLoc dataset are both publicly available for download.","cites":"0","conferencePercentile":"32.5"},{"venue":"WISE","id":"7d9bb8346eabefdbb7f1bae4f2076ade183f88b5","venue_1":"WISE","year":"2010","title":"Synchronising Personal Data with Web 2.0 Data Sources","authors":"Stefania Leone, Michael Grossniklaus, Alexandre de Spindler, Moira C. Norrie","author_ids":"1755131, 1786155, 1763200, 1685670","abstract":"Web 2.0 users may publish a rich variety of personal data to a number of sites by uploading personal desktop data or actually creating it on the Web 2.0 site. We present a framework and tools that address the resulting problems of information fragmentation and fragility by providing users with fine grain control over the processes of publishing and importing Web 2.0 data.","cites":"2","conferencePercentile":"33.33333333"},{"venue":"WISE","id":"03e3476789345aae1cc8871f37275a2fadc8fb9e","venue_1":"WISE","year":"2002","title":"Fuzzy Cognitive Agents for Personalized Recommendation","authors":"Chunyan Miao, Qiang Yang, Haijing Fang, Angela Goh","author_ids":"1679209, 1733090, 2516610, 1705845","abstract":"There is an increasing need for various web-service, e-commerce and e-business sites to provide personalized recommendations to on-line customers. This paper proposes a new type of personalized recommendation agents called fuzzy cognitive agents. Fuzzy cognitive agents are designed to give personalized suggestions based on the user's current personal preferences, other user's common preferences, and expert's domain knowledge. Fuzzy cognitive agents are able to represent knowledge via extended fuzzy cognitive maps, to learn users' preferences from most recent cases and to help customers make inferences and decisions through numeric computation instead of symbolic and logic deduction. A case study is included to illustrate how personalized recommendations are made by fuzzy cognitive agents in e-commerce sites. The case study demonstrates that the fuzzy cognitive agent is both flexible and effective in supporting e-commerce applications.","cites":"17","conferencePercentile":"71.15384615"},{"venue":"WISE","id":"33024c9ff7e3cc979b71bbcc492595cc14f959c4","venue_1":"WISE","year":"2002","title":"PTC : Proxies that Transcode and Cache in Heterogeneous Web Client Environments","authors":"Aameek Singh, Abhishek Trivedi, Krithi Ramamritham, Prashant J. Shenoy","author_ids":"1762348, 2176222, 1704729, 1705052","abstract":"Advances in computing and communication technologies have resulted in a wide variety of networked mobile devices that access data over the Internet. In this paper, we argue that servers by themselves may not be able to handle this diversity in client characteristics and intermediate proxies should be employed to handle the mismatch between the server-supplied data and the client capabilities. Since existing proxies are primarily designed to handle traditional wired hosts, such proxy architectures will need to be enhanced to handle mobile devices. We propose such an enhanced proxy architecture that is capable of handling the heterogeneity in client needs‚Äîspecifically the variations in client bandwidth and display capabilities. Our architecture combines transcoding (which is used to match the fidelity of the requested object to client capabilities) and caching (which is used to reduce the latency for accessing popular objects). Our proxies can intelligently adapt to prevailing system conditions using learning techniques to intelligently decide whether to transcode locally or fetch an appropriate version from the server. Our experimental results indicate that such strategies produce significant improvements in the client response times. Further, we find that even simple learning techniques can lead to significant performance improvements.","cites":"28","conferencePercentile":"94.23076923"},{"venue":"WISE","id":"12082a08377b7051360ef8be5a788adb2c024e98","venue_1":"WISE","year":"2012","title":"Diversifying User Comments on News Articles","authors":"Giorgos Giannopoulos, Ingmar Weber, Alejandro Jaimes, Timos K. Sellis","author_ids":"3180688, 1684687, 1730325, 1692933","abstract":"In this paper we present an approach for diversifying user comments on news articles. In our proposed framework, we analyse user comments w.r.t. four different criteria in order to extract the respective diversification dimensions in the form of feature vectors. These criteria involve content similarity, sentiment expressed within comments, article's named entities also found within comments and commenting behavior of the respective users. Then, we apply diversification on comments, utilizing the extracted features vectors. The outcome of this process is a subset of the initial comments that contains heterogeneous comments, representing different aspects of the news article, different sentiments expressed, as well as different user categories, w.r.t. their commenting behavior. We perform a preliminary qualitative analysis showing that the divesity criteria we introduce result in distinctively diverse subsets of comments, as opposed to a base-line of diversifying comments only w.r.t. to their content (textual similarity). We also present a prototype system that implements our diversification framework on news articles comments.","cites":"7","conferencePercentile":"91.66666667"},{"venue":"WISE","id":"9c9854bce1ac106dd8cc8d9106146062b267e849","venue_1":"WISE","year":"2000","title":"WhatNext: A Prediction System for Web Requests Using N-gram Sequence Models","authors":"Zhong Su, Qiang Yang, Ye Lu, HongJiang Zhang","author_ids":"1703625, 1733090, 2362714, 1718558","abstract":"As an increasing number of users access information on the web, there is a great opportunity to learn from the server logs to learn about the users' probable actions in the future. In this paper, we present an n-gram based model to utilize path profiles of users from very large data sets to predict the users' future requests. Since this is a prediction system, we cannot measure the recall in a traditional sense. We, therefore, present the notion of applicability to give a measure of the ability to predict the next document. Our model is based on a simple extension of existing point-based models for such predictions, but our results show for n-gram based prediction when n is greater than three, we can increase precision by 20% or more for two realistic web logs. Also we present an efficient method that can compress our model to 30% of its original size so that the model can be loaded in main memory. Our result can potentially be applied to a wide range of applications on the web, including pre-sending, pre-fetching, enhancement of recommendation systems as well as web caching policies. Our tests are based on three realistic web logs. Our algorithm is implemented in a prediction system called WhatNext, which shows a marked improvement in precision and applicability over previous approaches.","cites":"65","conferencePercentile":"100"},{"venue":"WISE","id":"52e4f0db2194dacf3ce318e3223b96173a6947db","venue_1":"WISE","year":"2007","title":"Wikipedia Mining for an Association Web Thesaurus Construction","authors":"Kotaro Nakayama, Takahiro Hara, Shojiro Nishio","author_ids":"3156934, 1697569, 1717916","abstract":"Wikipedia has become a huge phenomenon on the WWW. As a corpus for knowledge extraction, it has various impressive characteristics such as a huge amount of articles, live updates, a dense link structure, brief link texts and URL identification for concepts. In this paper, we propose an efficient link mining method pfibf (Path Frequency-Inversed Backward link Frequency) and the extension method \" forward / backward link weighting (FB weighting) \" in order to construct a huge scale association thesaurus. We proved the effectiveness of our proposed methods compared with other conventional methods such as cooccurrence analysis and TF-IDF.","cites":"36","conferencePercentile":"96"},{"venue":"WISE","id":"2112843c67102437eca768a07e5cc733630f0efe","venue_1":"WISE","year":"2010","title":"Providing Scalable Database Services on the Cloud","authors":"Chun Chen, Gang Chen, Dawei Jiang, Beng Chin Ooi, Hoang Tam Vo, Sai Wu, Quanqing Xu","author_ids":"5371645, 1697506, 4503995, 1693070, 2753282, 1765710, 2237081","abstract":"The Cloud is fast gaining popularity as a platform for deploying Software as a Service (SaaS) applications. In principle, the Cloud provides unlimited compute resources, enabling deployed services to scale seamlessly. Moreover, the pay-as-you-go model in the Cloud reduces the maintenance overhead of the applications. Given the advantages of the Cloud, it is attractive to migrate existing software to this new platform. However, challenges remain as most software applications need to be redesigned to embrace the Cloud. In this paper, we present an overview of our current ongoing work in developing epiC ‚Äì an elastic and efficient power-aware data-intensive Cloud system. We discuss the design issues and the implementation of epiC's storage system and processing engine. The storage system and the processing engine are loosely coupled, and have been designed to handle two types of workload simultaneously, namely data-intensive analytical jobs and online transactions (commonly referred as OLAP and OLTP respectively). The processing of large-scale analytical jobs in epiC adopts a phase-based processing strategy, which provides a fine-grained fault tolerance, while the processing of queries adopts indexing and filter-and-refine strategies.","cites":"11","conferencePercentile":"95.23809524"},{"venue":"WISE","id":"18d1324a0bbaa33243d7d9cb909e6addafef9de3","venue_1":"WISE","year":"2002","title":"Cluster-Based Delta Compression of a Collection of Files","authors":"Zan Ouyang, Nasir D. Memon, Torsten Suel, Dimitre Trendafilov","author_ids":"3235759, 1719861, 1691664, 2775081","abstract":"Delta compression techniques are commonly used to succinctly represent an updated version of a file with respect to an earlier one. In this paper, we study the use of delta compression in a somewhat different scenario, where we wish to compress a large collection of (more or less) related files by performing a sequence of pairwise delta compressions. The problem of finding an optimal delta encoding for a collection of files by taking pairwise deltas can be reduced to the problem of computing a branching of maximum weight in a weighted directed graph, but this solution is inefficient and thus does not scale to larger file collections. This motivates us to propose a framework for cluster-based delta compression that uses text clustering techniques to prune the graph of possible pairwise delta encodings. To demonstrate the efficacy of our approach, we present experimental results on collections of web pages. Our experiments show that cluster-based delta compression of collections provides significant improvements in compression ratio as compared to individually compressing each file or using tar+gzip, at a moderate cost in efficiency.","cites":"26","conferencePercentile":"88.46153846"},{"venue":"WISE","id":"de61daa489605d7344ba352c665f4856f77c9de2","venue_1":"WISE","year":"2003","title":"Traversing the Web: Mobility Heuristics for Visually Impaired Surfers","authors":"Simon Harper, Carole A. Goble, Robert Stevens","author_ids":"3739189, 1701008, 1702360","abstract":"‚Äî Movement, or mobility, is key to the accessibility, design, and usability of many websites. While some peripheral mobility issues have been addressed few have centered on the mobility problems of visually impaired users. We use our past work to address these issues and derive mobility heuristics from mobility models, use these heuristics to place mobility objects within a web page, and describe the construction of a prototype mobility instrument, in the form of a Netscape plug-in, to process these objects. Our past work extends the notion of movement to include environment, feedback and the purpose of the current travel task. Specifically, we likened web use to travelling in a virtual space, compared it to travelling in a physical space, and introduced the idea of mobility-the ease of travel-as opposed to travel opportunity.","cites":"8","conferencePercentile":"56.81818182"},{"venue":"WISE","id":"05eaf275586b0c59f7d0ae6df300c5e3921ad828","venue_1":"WISE","year":"2005","title":"Document Re-ranking by Generality in Bio-medical Information Retrieval","authors":"Xin Yan, Xue Li, Dawei Song","author_ids":"2368158, 6990205, 1738127","abstract":"Document ranking is well known to be a crucial process in information retrieval (IR). It presents retrieved documents in an order of their estimated degrees of relevance to query. Traditional document ranking methods are based on different measurements of similarity between documents and query. Due to information explosion and the popularity of WWW information retrieval, the increased variety of information and users makes it insufficient to consider similarity alone in the ranking process. In some cases, there is a need for user to retrieve documents which are generally or broadly describing a certain topic. This is particularly the case in some specific domains such as bio-medical IR. To satisfy the stringent requirement of generality based retrieval, we propose a novel approach to re-rank the retrieved documents by considering their generality as a compliment. By analyzing the semantic cohesion of text, document generality can be quantified. The retrieved documents are then re-ranked by their combined scores of similarity and the closeness of documents' generality to the query's. Results show an encouraging performance on a large scale bio-medical text corpus, OHSUMED, which is a subset of MEDLINE collection containing 348,566 medical journal references and 101 test queries.","cites":"2","conferencePercentile":"25"},{"venue":"WISE","id":"3d6d08d4a896d29460801b50bea7d9f3ab3d7f77","venue_1":"WISE","year":"2000","title":"Database and Modelling Strategy: A Compliant Way for Display Optimisation","authors":"Nathalie Farenc, Frederic Sidler, Albert Ferrando, Daniel Thalmann","author_ids":"1852937, 2603179, 3249653, 1689760","abstract":"In order to display huge scenes with virtual human inhabitants evolving inside a virtual city, we propose a methodology to create and manage different Level of Detail for a well-segmented scene without \"re-meshing\" the scene during simulation. A database dedicated to urban life simulation providing data for planning human actions and behaviour is completed in such a way to furnish also information about the most adapted displayed representation. In this article we propose a methodology for scene modelling. The scene is analysed and completed in order to create a database containing information needed for urban life simulation. Designers need and create rules for scene creation and some tools for database visualisation and manipulation are presented in this article. 1. Introduction As visual computer science is growing up, the visual scene structures are more and more complex and their sizes tend also to take more and more space memory. This problem can be partially handled using different optimisation strategies. The first one is to simplify the model of the scene by reducing the vertices number and/or the texture number and size. The display can be also optimised using hidden part of the scene, with Z-buffer technology [Catmull(1978)] e.g. The last option is to have different representations of the same scene according to a relative location of the camera (point of view in the scene). This is the level of detail concept (LOD) as existing in the VRML standard. The user builds his scene using various versions of a part of the scene according to the optimum camera distance. These tools and methodologies are sometimes not efficient enough. For simulations of virtual humans in a city we have very large scenes and the memory to display polygons and textures is dedicated both for the scene and for the virtual humans. Using a database associated to the scene for urban human behaviours [Farenc(1999)] providing geometrical data, we want to improve the simulation display. Our methodology is based on LOD concepts and a hierarchical scene decomposition in order to create the most adapted scene to our simulation. The field of LOD research is active and we can find several nice works generating different LOD for a polygonal model during a simulation. There are a lot of methods to refine a mesh model during or before its display. A progressive mesh method presented by H. Hoppe [Hoppe(1996)], or simplification of envelopes by J. Cohen [Cohen(1996)] ‚Ä¶","cites":"0","conferencePercentile":"4.545454545"},{"venue":"WISE","id":"fdf7d2c151c40b980d08fc0dc445e35710aa9016","venue_1":"WISE","year":"2010","title":"Relevant Answers for XML Keyword Search: A Skyline Approach","authors":"Khanh Nguyen, Jinli Cao","author_ids":"1745517, 7468348","abstract":"Identifying relevant results is a key task in XML keyword search (XKS). Although many approaches have been proposed for this task, effectively identifying results for XKS is still an open problem. In this paper, we propose a novel approach for identifying relevant results for XKS by adopting the concept of Mutual Information and skyline semantics. Specifically, we introduce a measurement to effectively quantify the relevance of a candidate by using the concept of Mutual Information and provide an effective mechanism to identify the most relevant results amongst a large number of candidates by using skyline semantics. Extensive experimental studies show that in overall our approach is more effective than existing approaches and can identify relevant results and top k results in acceptable computational costs.","cites":"1","conferencePercentile":"16.66666667"},{"venue":"WISE","id":"671d0c4f98c8d4e8fc9fe27f2f6e448106bfcbde","venue_1":"WISE","year":"2013","title":"Recommending Tripleset Interlinking through a Social Network Approach","authors":"Giseli Rabello Lopes, Luiz Andr√© P. Paes Leme, Bernardo Pereira Nunes, Marco A. Casanova, Stefan Dietze","author_ids":"1892548, 2756827, 2988251, 1788336, 3081683","abstract":"Tripleset interlinking is one of the main principles of Linked Data. However, the discovery of existing triplesets relevant to be linked with a new tripleset is a non-trivial task in the publishing process. Without prior knowledge about the entire Web of Data, a data publisher must perform an exploratory search, which demands substantial effort and may become impracticable, with the growth and dissemination of Linked Data. Aiming at alleviating this problem, this paper proposes a recommendation approach for this scenario, using a Social Network perspective. The experimental results show that the proposed approach obtains high levels of recall and reduces in up to 90% the number of triplesets to be further inspected for establishing appropriate links.","cites":"7","conferencePercentile":"100"},{"venue":"WISE","id":"1ef3b9688c2d14e5c3ddfa18ee465c26a986925b","venue_1":"WISE","year":"2006","title":"Design and Implementation of Preference-Based Search","authors":"Paolo Viappiani, Boi Faltings","author_ids":"2188691, 1735128","abstract":"Preference-based search is the problem of finding an item that matches best with a user's preferences. User studies show that example-based tools for preference-based search can achieve significantly higher accuracy when they are complemented with suggestions chosen to inform users about the available choices. We present FlatFinder, an implementation of an example-based tool and discuss how such a tool as well as suggestions can be efficiently implemented even for large product databases.","cites":"6","conferencePercentile":"87.5"},{"venue":"WISE","id":"2f4081a17210e233306b7c7a3d59b2970c8092f8","venue_1":"WISE","year":"2014","title":"Event Processing over a Distributed JSON Store: Design and Performance","authors":"Miki Enoki, J√©r√¥me Sim√©on, Hiroshi Horii, Martin Hirzel","author_ids":"1796110, 1753075, 1789153, 1728836","abstract":"Web applications are increasingly built to target both desktop and mobile users. As a result, modern Web development infrastructure must be able to process large numbers of events (e.g., for location-based features) and support analytics over those events, with applications ranging from banking (e.g., fraud detection) to retail (e.g., just-in-time personalized promotions). We describe a system specifically designed for those applications, allowing high-throughput event processing along with analytics. Our main contribution is the design and implementation of an in-memory JSON store that can handle both events and analytics workloads. The store relies on the JSON model in order to serve data through a common Web API. Thanks to the flexibility of the JSON model, the store can integrate data from systems of record (e.g., customer profiles) with data transmitted between the server and a large number of clients (e.g., location-based events or transactions). The proposed store is built over a distributed, trans-actional, in-memory object cache for performance. Our experiments show that our implementation handles high throughput and low latency without sacrificing scalability.","cites":"1","conferencePercentile":"75"},{"venue":"WISE","id":"fec4b18622e68bb7b1a80e77d9d26020ab6446d9","venue_1":"WISE","year":"2015","title":"A Dynamically Extensible Open Cross-Document Link Service","authors":"Ahmed A. O. Tayeh, Beat Signer","author_ids":"2629718, 1725701","abstract":"Since the introduction of the term hypertext in the early 1960s, the goal has been to link, annotate as well as transclude parts of documents. However, most existing document linking approaches show some shortcomings in terms of the offered link granularity and cannot easily be extended to support new document formats. More recently, we see new document formats such as the Office Open XML (OOXML) standard which facilitate the linking to parts of certain document formats. We present a dynamically extensible open cross-document link service enabling the linking and integration of arbitrary documents and multimedia content. In our link browser, emerging document formats are supported via visual plug-ins or by integrating third-party applications via gateways. The presented concepts and architecture for dynamic extensibility improve the document life cycle in so-called cross-media information spaces and enable future-proof cross-document linking.","cites":"0","conferencePercentile":"33.33333333"},{"venue":"WISE","id":"d45515df8b11bd4010c363f19465684a644e4488","venue_1":"WISE","year":"2001","title":"New Organizations for IT-related R&D at Osaka University","authors":"Masayuki Murata, Shojiro Nishio","author_ids":"1742539, 1717916","abstract":"In this article, we introduce two new organizations for IT (Information Technology)-related research and development at Osaka University. One is the Cybermedia Center, started in April 2000, which plays a role of the strategic center of information-related technology for supporting research and educational activities carried out at Osaka University. The other is a new graduate school for information-related education and research, called the Graduate School of Information Science and Technology, which is now planned to start in April 2002. We introduce the missions, roles, and the current status of those new organizations.","cites":"2","conferencePercentile":"30.43478261"},{"venue":"WISE","id":"05c3a13895e06713da3bd5bceb5b22e2ee29758c","venue_1":"WISE","year":"2004","title":"Exploiting PageRank at Different Block Level","authors":"Xue-Mei Jiang, Gui-Rong Xue, Wen-Guan Song, Hua-Jun Zeng, Zheng Chen, Wei-Ying Ma","author_ids":"6077920, 1701421, 2085309, 1741348, 1705657, 1705244","abstract":"In recent years, information retrieval methods focusing on the link analysis have been developed; The PageRank and HITS are two typical ones According to the hierarchical organization of Web pages, we could partition the Web graph into blocks at different level, such as page level, directory level, host level and domain level. On the basis of block, we could analyze the different hyperlinks among pages. Several approaches proposed that the intra-hyperlink in a host maybe less useful in computing the PageRank. However, there are no reports on how concretely the intra-or inter-hyperlink affects the PageRank. Furthermore, based on different block level, inter-hyperlink and in-tra-hyperlink can be two relative concepts. Thus which level should be optimal to distinguish the intra-or inter-hyperlink? And how the ratio set between the intra-hyperlink and inter-hyperlink could ultimately improve performance of the PageRank algorithm? In this paper, we analyze the link distribution at the different block level and evaluate the importance of the intra-and inter-hyperlink to PageRank on the TREC Web Track data set. Experiment shows that, if we set the block at host level and the ratio of the weight between the in-tra-hyperlink and inter-hyperlink is 1:4, the retrieval could achieve the best performance .","cites":"10","conferencePercentile":"78.75"},{"venue":"WISE","id":"043d983ce9c70d929d8e062a99823a9f64360846","venue_1":"WISE","year":"2014","title":"MindXpres: An Extensible Content-Driven Cross-Media Presentation Platform","authors":"Reinout Roels, Beat Signer","author_ids":"1946370, 1725701","abstract":"Existing presentation tools and document formats show a number of shortcomings in terms of the management, visualisation and navigation of rich cross-media content. While slideware was originally designed for the production of physical transparencies, there is an increasing need for richer and more interactive media types. We investigate innovative forms of organising, visualising and navigating presentations. This includes the introduction of a new document format supporting the integration or transclusion of content from different presentations and cross-media sources as well as the non-linear navigation of presentations. We present MindXpres, a web technology-based extensible platform for content-driven cross-media presentations. The modular architecture and plug-in mechanism of MindXpres enable the reuse or integration of new visualisation and interaction components. Our MindXpres prototype forms a platform for the exploration and rapid prototyping of innovative concepts for presentation tools. Its support for multi-device user interfaces further enables an active participation of the audience which should ultimately result in more dynamic, engaging presentations and improved knowledge transfer.","cites":"1","conferencePercentile":"75"},{"venue":"WISE","id":"f94fbc1cff93aad4030e8018f5b30a0a98150baf","venue_1":"WISE","year":"2014","title":"Open Cross-Document Linking and Browsing Based on a Visual Plug-in Architecture","authors":"Ahmed A. O. Tayeh, Beat Signer","author_ids":"2629718, 1725701","abstract":"Digital documents often do not exist in isolation but are implicitly or explicitly linked to parts of other documents. Nevertheless, most existing document formats only support links to web resources but not to parts of third-party documents. An open cross-document link service should address the multitude of existing document formats and be extensible to support emerging document formats and models. We present an architecture and prototype of an open cross-document link service and browser that is based on the RSL hypermedia metamodel. A main contribution is the specification and development of a visual plug-in solution that enables the integration of new document formats without requiring changes to the cross-document browser's main user interface component. The presented visual plug-in mechanism makes use of the Open Service Gateway initiative (OSGi) specification for modularisation and plug-in extensibility and has been validated by developing data as well as visual plug-ins for a number of existing document formats.","cites":"1","conferencePercentile":"75"},{"venue":"WISE","id":"5aa019ac2f68b96e3b95cb6718c1e3d0f7b2e463","venue_1":"WISE","year":"2006","title":"2D/3D Web Visualization on Mobile Devices","authors":"Yi Wang, Lizhu Zhou, Jianhua Feng, Lei Xie, Chun Yuan","author_ids":"3275881, 2635715, 8242094, 4043707, 1794683","abstract":"Visualization is able to make the result of Web search and Web mining more intuitive and make the search/mining more productive. However, the technical limitations of mobile devices make it difficult to port visualization methods from desktop computers to mobile devices. In this paper, we present what we learned on engineering 3D Web visualization on both high-end and low-end mobile devices as the MWeb3D framework, which forms a distributed pipeline that move intensive computation from the mobile devices to server systems. Some important issues of this strategy includes: (1) separating visualization from graphics rendering, (2) encoding visual presentation for transmitting via bandwidth-limited wireless connections, (3) user interaction on mobile devices, and (4) highly efficient graphics rendering on the mobile devices. We will show fruitful experiments on both PDA and mobile phone with photos taken from both simulator and real mobile devices.","cites":"2","conferencePercentile":"57.5"}]}