{"WMT.csv":[{"venue":"WMT","id":"feef7ea14013e9e93b9f1219795b3b1a78bb5a8f","venue_1":"WMT","year":"2016","title":"The QT21/HimL Combined Machine Translation System","authors":"Jan-Thorsten Peter, Tamer Alkhouli, Hermann Ney, Matthias Huck, Fabienne Braune, Alexander M. Fraser, Ales Tamchyna, Ondřej Bojar, Barry Haddow, Rico Sennrich, Frédéric Blain, Lucia Specia, Jan Niehues, Alexander H. Waibel, Alexandre Allauzen, Lauriane Aufrant, Franck Burlot, Elena Knyazeva, Thomas Lavergne, François Yvon, Marcis Pinnis, Stella Frank","author_ids":"2437182, 3169217, 1685956, 1839533, 3346335, 2277248, 2211536, 1767887, 2259100, 2082372, 7490096, 1702974, 2920247, 4500589, 2311059, 3448404, 3456893, 3205029, 3321150, 1846431, 2161780, 2089970","abstract":"This paper describes the joint submission of the QT21 and HimL projects for the English→Romanian translation task of the ACL 2016 First Conference on Machine Translation (WMT 2016). The submission is a system combination which combines twelve different statistical machine translation systems provided by the different groupsterdam, Tilde). The systems are combined using RWTH's system combination approach. The final submission shows an improvement of 1.0 BLEU compared to the best single system on newstest2016.","cites":"4","conferencePercentile":"90.77669903"},{"venue":"WMT","id":"f8c31e4eeee688f305e318d53d42a4ee8f6c37fb","venue_1":"WMT","year":"2016","title":"Using Factored Word Representation in Neural Network Language Models","authors":"Jan Niehues, Thanh-Le Ha, Eunah Cho, Alexander H. Waibel","author_ids":"2920247, 3348286, 8115904, 4500589","abstract":"Neural network language and translation models have recently shown their great potentials in improving the performance of phrase-based machine translation. At the same time, word representations using different word factors have been translation quality and are part of many state-of-the-art machine translation systems. used in many state-of-the-art machine translation systems, in order to support better translation quality. In this work, we combined these two ideas by investigating the combination of both techniques. By representing words in neu-ral network language models using different factors, we were able to improve the models themselves as well as their impact on the overall machine translation performance. This is especially helpful for morphologically rich languages due to their large vocabulary size. Furthermore, it is easy to add additional knowledge, such as source side information, to the model. Using this model we improved the translation quality of a state-of-the-art phrase-based machine translation system by 0.7 BLEU points. We performed experiments on three language pairs for the news translation task of the WMT 2016 evaluation.","cites":"0","conferencePercentile":"6.310679612"},{"venue":"WMT","id":"4a559c3fcc9af1e4cbdbd9eb4a87c909df4a974b","venue_1":"WMT","year":"2016","title":"The Karlsruhe Institute of Technology Systems for the News Translation Task in WMT 2016","authors":"Thanh-Le Ha, Eunah Cho, Jan Niehues, Mohammed Mediani, Matthias Sperber, Alexandre Allauzen, Alexander H. Waibel","author_ids":"3348286, 8115904, 2920247, 1861148, 3011998, 2311059, 4500589","abstract":"In this paper, we present the KIT translation systems as well as the KIT-LIMSI systems for the ACL 2016 First Conference on Machine Translation. We participated in the shared task Machine Translation of News and submitted translation systems for three different directions: English→German, German→English and English→Romanian. We used a phrase-based machine translation system and investigated several models to rescore the system. We used neu-ral network language and translation models. Using these models, we could improve the translation performance in all language pairs we participated.","cites":"2","conferencePercentile":"74.27184466"}]}