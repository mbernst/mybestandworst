{"WMTACL.csv":[{"venue":"WMT@ACL","id":"5b8603b177e2e4240710ac4e57e6d4cb28a7c3ab","venue_1":"WMT@ACL","year":"2014","title":"EU-BRIDGE MT: Combined Machine Translation","authors":"Markus Freitag, Stephan Peitz, Joern Wuebker, Hermann Ney, Matthias Huck, Rico Sennrich, Nadir Durrani, Maria Nadejde, Philip Williams, Philipp Koehn, Teresa Herrmann, Eunah Cho, Alexander H. Waibel","author_ids":"1680950, 1700238, 2046393, 1685956, 1839533, 2082372, 3183204, 3456844, 3139511, 1755162, 2244151, 8115904, 4500589","abstract":"This paper describes one of the col-laborative efforts within EU-BRIDGE to further advance the state of the art in machine translation between two Euro-pean language pairs, German→English and English→German. Three research institutes involved in the EU-BRIDGE project combined their individual machine translation systems and participated with a joint setup in the shared translation task of the evaluation campaign at the ACL 2014 Eighth Workshop on Statistical Machine Translation (WMT 2014). We combined up to nine different machine translation engines via system combination. RWTH Aachen University, the University of Edinburgh, and Karlsruhe Institute of Technology developed several individual systems which serve as system combination input. We devoted special attention to building syntax-based systems and combining them with the phrase-based ones. The joint setups yield empirical gains of up to 1.6 points in BLEU and 1.0 points in TER on the WMT news-test2013 test set compared to the best single systems.","cites":"12","conferencePercentile":"87.09677419"},{"venue":"WMT@ACL","id":"003d5d53e36074a595783542c80bed0fece734be","venue_1":"WMT@ACL","year":"2014","title":"The Karlsruhe Institute of Technology Translation Systems for the WMT 2014","authors":"Teresa Herrmann, Mohammed Mediani, Eunah Cho, Thanh-Le Ha, Jan Niehues, Isabel Slawik, Yuqi Zhang, Alexander H. Waibel","author_ids":"2244151, 1861148, 8115904, 3348286, 2920247, 3456180, 2617419, 4500589","abstract":"In this paper, we present the KIT systems participating in the Shared Translation Task translating between English↔German and English↔French. All translations are generated using phrase-based translation systems, using different kinds of word-based, part-of-speech-based and cluster-based language models trained on the provided data. Additional models include bilingual language models, reordering models based on part-of-speech tags and syntactic parse trees, as well as a lexicalized reordering model. In order to make use of noisy web-crawled data, we apply filtering and data selection methods for language modeling. A discriminative word lexicon using source context information proved beneficial for all translation directions.","cites":"2","conferencePercentile":"24.19354839"},{"venue":"WMT@ACL","id":"5cbee1074b7160fa8878678948510f4de871a730","venue_1":"WMT@ACL","year":"2013","title":"An MT Error-Driven Discriminative Word Lexicon using Sentence Structure Features","authors":"Jan Niehues, Alexander H. Waibel","author_ids":"2920247, 4500589","abstract":"The Discriminative Word Lexicon (DWL) is a maximum-entropy model that predicts the target word probability given the source sentence words. We present two ways to extend a DWL to improve its ability to model the word translation probability in a phrase-based machine translation (PBMT) system. While DWLs are able to model the global source information, they ignore the structure of the source and target sentence. We propose to include this structure by modeling the source sentence as a bag-of-n-grams and features depending on the surrounding target words. Furthermore , as the standard DWL does not get any feedback from the MT system, we change the DWL training process to explicitly focus on addressing MT errors. By using these methods we are able to improve the translation performance by up to 0.8 BLEU points compared to a system that uses a standard DWL.","cites":"11","conferencePercentile":"76.2295082"},{"venue":"WMT@ACL","id":"82c7d4ffdfe4388e94bcc558328ef0babbc72580","venue_1":"WMT@ACL","year":"2014","title":"The KIT-LIMSI Translation System for WMT 2014","authors":"Quoc-Khanh Do, Teresa Herrmann, Jan Niehues, Alexandre Allauzen, François Yvon, Alexander H. Waibel","author_ids":"3054647, 2244151, 2920247, 2311059, 1846431, 4500589","abstract":"This paper describes the joined submission of LIMSI and KIT to the Shared Translation Task for the German-to-English direction. The system consists of a phrase-based translation system using a pre-reordering approach. The base-line system already includes several models like conventional language models on different word factors and a discriminative word lexicon. This system is used to generate a k-best list. In a second step, the list is reranked using SOUL language and translation models (Le et al., 2011). Originally, SOUL translation models were applied to n-gram-based translation systems that use tuples as translation units instead of phrase pairs. In this article, we describe their integration into the KIT phrase-based system. Experimental results show that their use can yield significant improvements in terms of BLEU score.","cites":"1","conferencePercentile":"6.451612903"},{"venue":"WMT@ACL","id":"74493bec9084b16c72a84dc41174304cb2c9244d","venue_1":"WMT@ACL","year":"2013","title":"Positive Diversity Tuning for Machine Translation System Combination","authors":"Daniel M. Cer, Christopher D. Manning, Daniel Jurafsky","author_ids":"3208422, 1812612, 1746807","abstract":"We present Positive Diversity Tuning, a new method for tuning machine translation models specifically for improved performance during system combination. System combination gains are often limited by the fact that the translations produced by the different component systems are too similar to each other. We propose a method for reducing excess cross-system similarity by optimizing a joint objective that simultaneously rewards models for producing translations that are similar to reference translations, while also punishing them for translations that are too similar to those produced by other systems. The formulation of the Positive Diversity objective is easy to implement and allows for its quick integration with most machine translation tuning pipelines. We find that individual systems tuned on the same data to Positive Diversity can be even more diverse than systems built using different data sets, while still obtaining good BLEU scores. When these individual systems are used together for system combination, our approach allows for significant gains of 0.8 BLEU even when the combination is performed using a small number of otherwise identical individual systems.","cites":"5","conferencePercentile":"50"},{"venue":"WMT@ACL","id":"17b56259fad04c7b378d8a051972b2f446c4aaee","venue_1":"WMT@ACL","year":"2014","title":"An Empirical Comparison of Features and Tuning for Phrase-based Machine Translation","authors":"Spence Green, Daniel M. Cer, Christopher D. Manning","author_ids":"1896775, 3208422, 1812612","abstract":"Scalable discriminative training methods are now broadly available for estimating phrase-based, feature-rich translation models. However, the sparse feature sets typically appearing in research evaluations are less attractive than standard dense features such as language and translation model probabilities: they often overfit, do not generalize , or require complex and slow feature extractors. This paper introduces extended features, which are more specific than dense features yet more general than lexicalized sparse features. Large-scale experiments show that extended features yield robust BLEU gains for both Arabic-English (+1.05) and Chinese-English (+0.67) relative to a strong feature-rich baseline. We also specialize the feature set to specific data domains, identify an objective function that is less prone to overfitting, and release fast, scalable, and language-independent tools for implementing the features.","cites":"13","conferencePercentile":"89.51612903"},{"venue":"WMT@ACL","id":"0e433f7527f5d269c4eeebdada9a97fc5d4f44b9","venue_1":"WMT@ACL","year":"2014","title":"Phrasal: A Toolkit for New Directions in Statistical Machine Translation","authors":"Spence Green, Daniel M. Cer, Christopher D. Manning","author_ids":"1896775, 3208422, 1812612","abstract":"We present a new version of Phrasal, an open-source toolkit for statistical phrase-based machine translation. This revision includes features that support emerging research trends such as (a) tuning with large feature sets, (b) tuning on large datasets like the bitext, and (c) web-based interactive machine translation. A direct comparison with Moses shows favorable results in terms of decoding speed and tuning time.","cites":"11","conferencePercentile":"83.87096774"},{"venue":"WMT@ACL","id":"9f6ca9e096a3e9c35568e5281ee05d551e924c5c","venue_1":"WMT@ACL","year":"2014","title":"LIMSI $@$ WMT'14 Medical Translation Task","authors":"Nicolas Pécheux, Li Gong, Quoc-Khanh Do, Benjamin Marie, Yulia Ivanishcheva, Alexandre Allauzen, Thomas Lavergne, Jan Niehues, Aurélien Max, François Yvon","author_ids":"1741889, 1703194, 3054647, 2080380, 3456223, 2311059, 3321150, 2920247, 1734827, 1846431","abstract":"This paper describes LIMSI's submission to the first medical translation task at WMT'14. We report results for English-French on the subtask of sentence translation from summaries of medical articles. Our main submission uses a combination of NCODE (n-gram-based) and MOSES (phrase-based) output and continuous-space language models used in a post-processing step for each system. Other characteristics of our submission include: the use of sampling for building MOSES' phrase table; the implementation of the vector space model proposed by Chen et al. (2013); adaptation of the POS-tagger used by NCODE to the medical domain ; and a report of error analysis based on the typology of Vilar et al. (2006).","cites":"1","conferencePercentile":"6.451612903"},{"venue":"WMT@ACL","id":"337df2e666ac3112adaf0f4e112fcb764708fa83","venue_1":"WMT@ACL","year":"2013","title":"Feature-Rich Phrase-based Translation: Stanford University's Submission to the WMT 2013 Translation Task","authors":"Spence Green, Daniel M. Cer, Kevin Reschke, Rob Voigt, John Bauer, Sida I. Wang, Natalia Silveira, Julia Neidert, Christopher D. Manning","author_ids":"1896775, 3208422, 1772645, 1878212, 2150083, 2465119, 2150849, 3457156, 1812612","abstract":"We describe the Stanford University NLP Group submission to the 2013 Workshop on Statistical Machine Translation Shared Task. We demonstrate the effectiveness of a new adaptive, online tuning algorithm that scales to large feature and tuning sets. For both English-French and English-German, the algorithm produces feature-rich models that improve over a dense baseline and compare favorably to models tuned with established methods.","cites":"5","conferencePercentile":"50"},{"venue":"WMT@ACL","id":"0cfcb2eb0134bb4bad8477745a872733bbd2b940","venue_1":"WMT@ACL","year":"2013","title":"The CNGL-DCU-Prompsit Translation Systems for WMT13","authors":"Raphaël Rubino, Antonio Toral, Santiago Cortes Vaíllo, Jun Xie, Xiaofeng Wu, Stephen Doherty, Qun Liu","author_ids":"1731383, 1713270, 3457558, 1786096, 4417713, 2222497, 5090422","abstract":"This paper presents the experiments conducted by the Machine Translation group at DCU and Prompsit Language Engineering for the WMT13 translation task. Three language pairs are considered: Spanish-English and French-English in both directions and German-English in that direction. For the Spanish-English pair, the use of linguistic information to select parallel data is investigated. For the French-English pair, the usefulness of the small in-domain parallel corpus is evaluated, compared to an out-of-domain parallel data sub-sampling method. Finally, for the German-English system, we describe our work in addressing the long distance reordering problem and a system combination strategy.","cites":"7","conferencePercentile":"63.1147541"},{"venue":"WMT@ACL","id":"391335ec19c054ae2dca8647fc34a8465e4d09cf","venue_1":"WMT@ACL","year":"2014","title":"The DCU-ICTCAS MT system at WMT 2014 on German-English Translation Task","authors":"Liangyou Li, Xiaofeng Wu, Santiago Cortes Vaíllo, Jun Xie, Andy Way, Qun Liu","author_ids":"1989344, 4417713, 3457558, 1786096, 7358121, 5090422","abstract":"This paper describes the DCU submission to WMT 2014 on German-English translation task. Our system uses phrase-based translation model with several popular techniques, including Lexicalized Reordering Model, Operation Sequence Model and Language Model interpolation. Our final submission is the result of system combination on several systems which have different pre-processing and alignments .","cites":"5","conferencePercentile":"57.25806452"},{"venue":"WMT@ACL","id":"795fab8d8bb9dea861cab5da38ac5c12f08942ce","venue_1":"WMT@ACL","year":"2013","title":"MT Quality Estimation: The CMU System for WMT'13","authors":"Silja Hildebrand, Stephan Vogel","author_ids":"3457562, 1684854","abstract":"In this paper we present our entry to the WMT'13 shared task: Quality Estimation (QE) for machine translation (MT). We participated in the 1.1, 1.2 and 1.3 sub-tasks with our QE system trained on features from diverse information sources like MT decoder features, n-best lists, mono-and bilingual corpora and giza training models. Our system shows competitive results in the workshop shared task.","cites":"2","conferencePercentile":"24.59016393"},{"venue":"WMT@ACL","id":"20fa7e443d93a09adcb63f7cf1c8a3f19b849258","venue_1":"WMT@ACL","year":"2014","title":"Stanford University's Submissions to the WMT 2014 Translation Task","authors":"Julia Neidert, Sebastian Schuster, Spence Green, Kenneth Heafield, Christopher D. Manning","author_ids":"3457156, 2322050, 1896775, 1702066, 1812612","abstract":"We describe Stanford's participation in the French-English and English-German tracks of the 2014 Workshop on Statistical Machine Translation (WMT). Our systems used large feature sets, word classes, and an optional unconstrained language model. Among constrained systems, ours performed the best according to uncased BLEU: 36.0% for French-English and 20.9% for English-German.","cites":"4","conferencePercentile":"49.19354839"},{"venue":"WMT@ACL","id":"3cd149c5dea5b7a5556fce5597c5359f05820ec9","venue_1":"WMT@ACL","year":"2013","title":"Towards Efficient Large-Scale Feature-Rich Statistical Machine Translation","authors":"Vladimir Eidelman, Ke Wu, Ferhan Türe, Philip Resnik, Jimmy Lin","author_ids":"2332594, 1760921, 2851411, 1680292, 4733461","abstract":"We present the system we developed to provide efficient large-scale feature-rich discriminative training for machine translation. We describe how we integrate with MapReduce using Hadoop streaming to allow arbitrarily scaling the tuning set and utilizing a sparse feature set. We report our findings on German-English and Russian-English translation, and discuss benefits, as well as obstacles, to tuning on larger development sets drawn from the parallel training data.","cites":"2","conferencePercentile":"24.59016393"}]}