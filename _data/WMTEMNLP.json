{"WMTEMNLP.csv":[{"venue":"WMT@EMNLP","id":"42618c59e755eb726c341c8e7218156fd0ea7f56","venue_1":"WMT@EMNLP","year":"2015","title":"The KIT-LIMSI Translation System for WMT 2015","authors":"Thanh-Le Ha, Quoc-Khanh Do, Eunah Cho, Jan Niehues, Alexandre Allauzen, François Yvon, Alexander H. Waibel","author_ids":"3348286, 3054647, 8115904, 2920247, 2311059, 1846431, 4500589","abstract":"This paper presented the joined submission of KIT and LIMSI to the English to German translation task of WMT 2015. In this year submission, we integrated a neu-ral network-based translation model into a phrase-based translation model by rescor-ing the n-best lists. Since the computation complexity is one of the main issues for continuous space models, we compared two techniques to reduce the computation cost. We investigated models using a structured output layer as well as models trained with noise contrastive estimation. Furthermore, we evaluated a new method to obtain the best log-linear combination in the rescoring phase. Using these techniques, we were able to improve the BLEU score of the baseline phrase-based system by 1.4 BLEU points.","cites":"2","conferencePercentile":"36.84210526"},{"venue":"WMT@EMNLP","id":"0630ba822a084e08a5719af79df873a5c84f2e3d","venue_1":"WMT@EMNLP","year":"2015","title":"ListNet-based MT Rescoring","authors":"Jan Niehues, Quoc-Khanh Do, Alexandre Allauzen, Alexander H. Waibel","author_ids":"2920247, 3054647, 2311059, 4500589","abstract":"The log-linear combination of different features is an important component of SMT systems. It allows for the easy in-tegartion of models into the system and is used during decoding as well as for n-best list rescoring. With the recent success of more complex models like neural network-based translation models, n-best list rescoring attracts again more attention. In this work, we present a new technique to train the log-linear model based on the ListNet algorithm. This technique scales to many features, considers the whole list and not single entries during learning and can also be applied to more complex models than a log-linear combination. Using the new learning approach, we improve the translation quality of a large-scale system by 0.8 BLEU points during rescoring and generate translations which are up to 0.3 BLEU points better than other learning techniques such as MERT or MIRA.","cites":"0","conferencePercentile":"5.263157895"},{"venue":"WMT@EMNLP","id":"0d2e8880d27ddfaf73f73f7999629cc8fb0779b3","venue_1":"WMT@EMNLP","year":"2015","title":"The Karlsruhe Institute of Technology Translation Systems for the WMT 2015","authors":"Eunah Cho, Thanh-Le Ha, Jan Niehues, Teresa Herrmann, Mohammed Mediani, Yuqi Zhang, Alexander H. Waibel","author_ids":"8115904, 3348286, 2920247, 2244151, 1861148, 2617419, 4500589","abstract":"In this paper, the KIT systems submitted to the Shared Translation Task are presented. We participated in two translation directions: from German to English and from English to German. Both translations are generated using phrase-based translation systems. The performance of the systems was boosted by using language models built based on different tokens such as word, part-of-speech, and automacally generated word clusters. The difference in word order between German and English is addressed by part-of-speech and syntactic tree-based reordering models. In addition to a discriminative word lexicon, we used hypothesis rescoring using the ListNet algorithm after generating the translation with the phrase-based system. We evaluated the rescoring using only the baseline features as well as using additional computational complex features.","cites":"2","conferencePercentile":"36.84210526"},{"venue":"WMT@EMNLP","id":"0641384752da179b89aff718b7c373a51af02789","venue_1":"WMT@EMNLP","year":"2015","title":"How do Humans Evaluate Machine Translation","authors":"Francisco Guzmán, Ahmed Abdelali, Irina P. Temnikova, Hassan Sajjad, Stephan Vogel","author_ids":"1838579, 1683403, 2216191, 2824204, 1684854","abstract":"In this paper, we take a closer look at the MT evaluation process from a glass-box perspective using eye-tracking. We analyze two aspects of the evaluation task – the background of evaluators (monolin-gual or bilingual) and the sources of information available, and we evaluate them using time and consistency as criteria. Our findings show that monolinguals are slower but more consistent than bilinguals, especially when only target language information is available. When exposed to various sources of information, evaluators in general take more time and in the case of monolinguals, there is a drop in consistency. Our findings suggest that to have consistent and cost effective MT evaluations , it is better to use monolinguals with only target language information.","cites":"4","conferencePercentile":"71.92982456"},{"venue":"WMT@EMNLP","id":"d0b228b10ce2504b049b6abef690eff9b34ba68e","venue_1":"WMT@EMNLP","year":"2015","title":"Data Selection With Fewer Words","authors":"Amittai Axelrod, Philip Resnik, Xiaodong He, Mari Ostendorf","author_ids":"1963981, 1680292, 7792183, 1745016","abstract":"We present a method that improves data selection by combining a hybrid word/part-of-speech representation for corpora, with the idea of distinguishing between rare and frequent events. We validate our approach using data selection for machine translation, and show that it maintains or improves BLEU and TER translation scores while substantially improving vocabulary coverage and reducing data selection model size. Paradoxically, the coverage improvement is achieved by abstracting away over 97% of the total training corpus vocabulary using simple part-of-speech tags during the data selection process.","cites":"3","conferencePercentile":"54.38596491"}]}