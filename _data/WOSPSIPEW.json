{"WOSPSIPEW.csv":[{"venue":"WOSP/SIPEW","id":"eb8391b589e1b458b1eee26f5a2fb6587f0eb096","venue_1":"WOSP/SIPEW","year":"2010","title":"Software knows best: portable parallelism requires standardized measurements of transparent hardware","authors":"David A. Patterson","author_ids":"1701130","abstract":"The hardware trend of the last 15 years of dynamically trying to improve performance with little software visibility is not only irrelevant today, its counterproductive; adaptivity must be at the software level if parallel software is going to be portable, fast, and energy-efficient. A portable parallel program is an oxymoron today; there is no reason to be parallel if it's slow, and parallel can't be fast if it's portable. Hence, portable parallel programs of the future must be able to understand and measure /any/ computer on which it runs so that it can adapt effectively, which suggests that hardware measurement should be standardized and processor performance and energy consumption should become transparent.\n In addition to software-controlled adaptivity for execution efficiency by using techniques like autotuning and dynamic scheduling, modern software environments adapt to improve /programmer/ efficiency [1]. Classic examples include dynamic linking, dynamic memory allocation, garbage collection, interpreters, just-in-time compilers, and debugger-support. Examples that are more recent are selective embedded just in time specialization (SEJITS) [2] for highly productive languages like Python and Ruby. Thus, the future of programming is likely to involve program generators at many levels of the hierarchy tailoring the application to the machine. These productivity advances via adaptivity should be reflected in modern benchmarks: virtually no one writes the statically linked, highest-level-optimized C programs that are the foundation of most benchmark suites.\n The dream is to improve productivity without sacrificing too much performance. Indeed, how often have you heard the claim that a new productive environment is now \"almost as fast as C\" or \"almost as fast as Java?\" The implication of the necessary tie between productivity and performance in the manycore era is that these modern environments must be able to utilize manycore well, or the gap between highly efficient code and highly productive code will grow with the number of cores.\n For industry's bet on manycore to win, therefore, both very high level and very low level programming environments will need to be able to understand and measure their underlying hardware and adapt their execution so as to be portable, relatively fast, and energy-efficient.\n Hence, we argue that a standard of accurate hardware operation trackers (SHOT) would have a huge positive impact on making parallel software portable with good performance and energy efficiency, similar to the impact of the IEEE-754 standard had on portability of numerical software. In particular, we believe SHOT will lead to much larger improvements in portability, performance, energy efficiency of parallel codes than recent architectural fads like opportunistic \"turbo modes,\" transactional memory, or reconfigurable computing.","cites":"1","conferencePercentile":"11.84210526"},{"venue":"WOSP/SIPEW","id":"47d0bae66d9a1ba5c66fe0922d3e8108eaf2d215","venue_1":"WOSP/SIPEW","year":"2010","title":"A framework for utility-based service oriented design in SASSY","authors":"Daniel A. Menascé, John M. Ewing, Hassan Gomaa, Sam Malek, João Pedro Sousa","author_ids":"1758079, 3061692, 1730863, 1732601, 1688217","abstract":"The architecture of a software system has a significant impact on its quality of service (QoS) as measured by several performance metrics such as execution time, availability, throughput, and security. This paper presents a framework that is part of a large project called SASSY (Self-Architecting Software Systems), whose goal is to allow domain experts to specify the system requirements using a visual activity-based language. The SASSY framework automatically generates a base architecture that corresponds to the requirements. Then SASSY generates a new architecture, derived from the base architecture, that optimizes a utility function for the entire system. The utility function is a multivariate function of several QoS metrics. The paper shows a complete example and illustrates how SASSY automatically adapts to changes in the environment's QoS features.","cites":"34","conferencePercentile":"94.73684211"},{"venue":"WOSP/SIPEW","id":"1e58c98ebd38e0d024554fcf7bb8f57aab35ad13","venue_1":"WOSP/SIPEW","year":"2010","title":"SLA-driven planning and optimization of enterprise applications","authors":"Hui Li, Giuliano Casale, Tariq N. Ellahi","author_ids":"1750828, 1737740, 8643906","abstract":"We propose a model-based methodology to size and plan enterprise applications subject to Service Level Agreements (SLAs). Our approach is illustrated using a real-world Enterprise Resource Planning (ERP) application, namely SAP ERP. Firstly, we develop a closed queueing network model with finite capacity regions describing the SAP ERP application performance and show that this model is effective and robust in capturing measured response times and utilizations. Secondly, we propose an analytical cost model that jointly accounts for fixed hardware costs and dynamic operational costs related to power consumption.\n Based on the developed performance and cost models, we propose to use multi-objective optimization to find the Pareto-optimal solutions that describe the best trade-off solutions between conflicting performance and cost-saving goals. Experimental validation demonstrates the accuracy of the proposed models and shows that the attained Pareto-optimal solutions can be efficiently used by service providers for SLA-driven planning decisions, thus making a strong case in favor of the applicability of our methodology for deployment decisions subject to different SLA requirements.","cites":"18","conferencePercentile":"89.47368421"}]}