{"WSA.csv":[{"venue":"WSA","id":"313db039938c0a15b044b453253a4085773d92ad","venue_1":"WSA","year":"2012","title":"Performance analysis of LTE downlink under Symbol Timing Offset","authors":"Qi Wang, Michal Simko, Markus Rupp","author_ids":"4849112, 2506633, 1729118","abstract":"—In this paper, we evaluate the performance of a standardized OFDM system, namely Long Term Evolution (LTE) downlink, with imperfect symbol timing. A closed form expression of the post-equalization Signal to Interference and Noise Ratio (SINR) is derived and compared with results obtained from a standard compliant simulator. Also, we analyzed the channel estimation performance when Symbol Timing Offset (STO) occurs. This work reveals the impact of imperfect synchronization on the link performance. It also allows an accurate and realistic modeling of the physical layer behavior, which can be applied to reproduce results from time-consuming link level simulations. I. INTRODUCTION Orthogonal Frequency Division Multiplexing (OFDM) has become a dominant physical layer technique of modern wireless communication systems thanks to its high spectrum efficiency and robustness to frequency selective fading channels [1]. In order to eliminate Inter-Symbol Interference (ISI), a guard interval Cyclic Prefix (CP) is appended at the beginning of each OFDM symbol. This, to some extent, provides the system a certain tolerance to symbol timing errors. However, the valid symbol timing region shrinks as the maximum channel delay increases. Plenty of techniques can be found in literature on symbol timing error estimation [2–5]. Their estimation performance are usually evaluated in terms of lock-in probability, namely the probability that the estimated symbol timing falls within the valid symbol timing region. In [6], a mathematical analysis of the impact of timing synchronization error was presented. However, the evaluation is in terms of the SINR after the Fast Fourier Transform (FFT) at the receiver. Although this metric reflects the performance loss, in order to evaluate the link performance of a realistic communications system, other aspects in the receiver need to be considered, e.g., channel estimation and equalization. In this work, we consider the downlink of LTE with a STO at sampling period level and analytically derive a closed form expression of the post-equalization SINR as a function of the symbol timing error. Additionally, the impact of the STO on the channel estimation performance is investigated. Afterwards, these results are validated using standard compliant simulations [7]. The paper is organized as follows. In Section II, we describe a mathematical model as a basis of the analysis. A post","cites":"2","conferencePercentile":"67.64705882"}]}