{"WSM_09.csv":[{"venue":"WSM '09","id":"0060d00b27211ee5b4e69f068a03de7b9b4cb21b","venue_1":"WSM '09","year":"2009","title":"From usage to annotation: analysis of personal photo albums for semantic photo understanding","authors":"Philipp Sandhaus, Susanne Boll","author_ids":"2581283, 1714281","abstract":"With photo albums we aim to capture personal events such as weddings, vacations, and parties of family and friends. By arranging photo prints, captions and paper souvenirs such as tickets over the pages of a photo book we tell a story to capture and share our memories. The photo memories captured in such a photo book tell us a lot about the content and the relevance of the photos for the user. The way in which we select photos and arrange them in the photo book reveal a lot about the events, persons and places on the photos: captions describe content, closeness and arrangement of photos express relations between photos and their content. These semantics of our personal stories, however, are canned in the photo book but would form a very valuable asset for understanding and annotating our personal media collection.\n In this paper, we present the results of the analysis of a large repository of digitally mastered photo books to learn about the usage of digital photos. From our analysis of the books' content we derive additional semantics for photos, groups of photos and entire photo albums. With this semantic knowledge not only additional metadata can be provided for the organization of the personal photo collection. Also, we can characterize photo books and support users to create even more handsome photo books from large media collections.","cites":"2","conferencePercentile":"29.16666667"},{"venue":"WSM '09","id":"822d5adb054edeffe59a31f4a8292bfca3e12b60","venue_1":"WSM '09","year":"2009","title":"Implicit emotional tagging of multimedia using EEG signals and brain computer interface","authors":"Ashkan Yazdani, Jong-Seok Lee, Touradj Ebrahimi","author_ids":"3135384, 5722542, 1681498","abstract":"In multimedia content sharing social networks, tags assigned to content play an important role in search and retrieval. In other words, by annotating multimedia content, users can associate a word or a phrase (tag) with that resource such that it can be searched for efficiently. Implicit tagging refers to assigning tags by observing subjects behavior during consumption of multimedia content. This is an alternative to traditional explicit tagging which requires an explicit action by subjects. In this paper we propose a brain-computer interface (BCI) system based on P300 evoked potential, for implicit emotional tagging of multimedia content. We show that our system can successfully perform implicit emotional tagging and na&#239;ve subjects who have not participated in training of the system can also use it efficiently. Moreover, we introduce a subjective metric called \"emotional taggability\" to analyze the recognition performance of the system, given the degree of ambiguity that exists in terms of emotional values associated with a multimedia content.","cites":"16","conferencePercentile":"83.33333333"},{"venue":"WSM '09","id":"3e8f99514a816cfc0a6149c0c6c69b65aa4c7761","venue_1":"WSM '09","year":"2009","title":"Tweet the debates: understanding community annotation of uncollected sources","authors":"David A. Shamma, Lyndon Kennedy, Elizabeth F. Churchill","author_ids":"1760364, 4591648, 1801572","abstract":"We investigate the practice of sharing short messages (microblogging) around live media events. Our focus is on Twitter and its usage during the 2008 Presidential Debates. We find that analysis of Twitter usage patterns around this media event can yield significant insights into the semantic structure and content of the media object. Specifically, we find that the level of Twitter activity serves as a predictor of changes in topics in the media event. Further we find that conversational cues can identify the key players in the media object and that the content of the Twitter posts can somewhat reflect the topics of discussion in the media object, but are mostly evaluative, in that they express the poster's reaction to the media. The key contribution of this work is an analysis of the practice of microblogging live events and the core metrics that can leveraged to evaluate and analyze this activity. Finally, we offer suggestions on how our model of segmentation and node identification could apply towards any live, real-time arbitrary event.","cites":"113","conferencePercentile":"100"},{"venue":"WSM '09","id":"26e9508027794877f0890eea352e647f88a119cc","venue_1":"WSM '09","year":"2009","title":"Motivating contributors in social media networks","authors":"Vivek K. Singh, Ramesh Jain, Mohan S. Kankanhalli","author_ids":"4685302, 4521564, 1744045","abstract":"Despite recent advancements in user-driven social media platforms, tools for studying user behavior patterns and motivations remain primitive. We highlight the voluntary nature of user contributions and that users can choose when (and when not) to contribute to the common media pool. We use a Game theoretic framework to study the dynamics of a social media network wherein contribution costs are individual but gains are common. We model users as rational selfish agents, and consider domain attributes like voluntary participation, virtual reward structure and public-sharing to model the dynamics of this interaction. The created model describes the most appropriate contribution strategy from each user's perspective. Next, we consider the problem of mechanism design from a system designer's perspective who is interested in finding the optimal incentive levels to influence the selfish end-users so that the overall system utility is maximized. We demonstrate how a system administrator can exploit the selfishness of its users, to design incentive mechanisms which help in improving the overall task completion probability and system performance, while possibly still benefiting the individual users.","cites":"15","conferencePercentile":"70.83333333"},{"venue":"WSM '09","id":"869f10f6d7e6ca44e6a25ecc6d4f956733ec4a5e","venue_1":"WSM '09","year":"2009","title":"The role of tags and image aesthetics in social image search","authors":"Pere Obrador, Xavier Anguera, Rodrigo de Oliveira, Nuria Oliver","author_ids":"2953301, , 2249709, 1692808","abstract":"In recent years, there has been a proliferation of consumer digital photographs taken and stored in both personal and online repositories. As the amount of user-generated digital photos increases, there is a growing need for efficient ways to search for relevant images to be shared with friends and family. Text-query based search approaches rely heavily on the similarity between the input textual query and the tags added by users to the digital content. Unfortunately, text-query based search results might include a large number of relevant photos, all of them containing very similar tags, but with varying levels of image quality and aesthetic appeal. In this paper we introduce an image re-ranking algorithm that takes into account the aesthetic appeal of the images retrieved by a consumer image sharing site search engine (Google's Picasa Web Album). In order to do so, we extend a state-of-the-art image aesthetic appeal algorithm by incorporating a set of features aimed at consumer photographs. The results of a controlled user study with 37 participants reveal that image aesthetics play a varying role on the selected images depending on the query type and on the user preferences.","cites":"3","conferencePercentile":"41.66666667"},{"venue":"WSM '09","id":"9721d78a4788394e77068b24ed5ec42ae0fab965","venue_1":"WSM '09","year":"2009","title":"Multimodal video copy detection applied to social media","authors":"Xavier Anguera, Pere Obrador, Nuria Oliver","author_ids":", 2953301, 1692808","abstract":"Reliable content-based copy detection algorithms (CBCD) are at the core of effective multimedia data management and copyright enforcement systems. CBCD techniques focus on detecting videos that are identical to or transformed versions of an original video. The fast growth of online video sharing services challenges state-of-the-art copy detection algorithms as they need to be: able to deal with vast amounts of data, computationally efficient and robust to a wide range of image and audio transformations. In this paper, we present two related multimodal CBCD algorithms that effectively fuse audio and video information by means of a compact multimodal signature based on audio and video global descriptors. We validate our algorithms with a benchmark database (MUSCLE-VCD) and obtain over a 14% relative improvement with respect to state-of-the-art systems. In addition, we illustrate the performance of our approach in a video view-count re-ranking task with YouTube data.","cites":"4","conferencePercentile":"54.16666667"},{"venue":"WSM '09","id":"752aa935cc025062eae4b6967ef4c38212acd7f6","venue_1":"WSM '09","year":"2009","title":"Social reader: following social networks in the wilds of the blogosphere","authors":"Brett Adams, Dinh Phung, Svetha Venkatesh","author_ids":"1760106, 1749657, 1679520","abstract":"The social interactions manifest in blogs by the network of comments left by owners and readers are an under-used resource, both for blog pundits and industry. We present a web-based feed reader that renders these relationships with a graph representation, and enables exploration by displaying people and blogs who are proximate to a user's network. Social Reader is an example of Casual Information Visualization, and aims to help the user understand and explore blog-based social networks in a daily, real-life setting. A six week study of the software involving 20 users confirmed the usefulness of the novel visual display, via a quantitative analysis of use logs, and an exit survey.","cites":"4","conferencePercentile":"54.16666667"}]}