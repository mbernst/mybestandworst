{"Web_Intelligence.csv":[{"venue":"Web Intelligence","id":"02cb47bf00641d542705d3e6266f1a8de4170fb3","venue_1":"Web Intelligence","year":"2004","title":"Type-2 Fuzzy Web Shopping Agents","authors":"Menglei Tang, Yanqing Zhang, Gang Zhang","author_ids":"2074311, 1688104, 2371090","abstract":"In this paper, we create an online shopping system \"hotstore.com\" using type-2 fuzzy reasoning. The type-2 fuzzy logic agent has 5 components: fuzzifier, fuzzy rule, fuzzy inference, type reducer and defuzzifier. The antecendent and consequent in the fuzzy rule use type-2 fuzzy sets and the type reducer is used to map a type-2 fuzzy set into a type-1 fuzzy set. All the merchandise information is stored in the database. Based on the merchandise shopping history, a manager can rate the merchandise data using type-2 fuzzy data mining technology. Implementation techniques include ASP.NET + SQL 2000 + IIS 2000, VB, ASP.NET, HTML, and CSS.","cites":"2","conferencePercentile":"48.74213836"},{"venue":"Web Intelligence","id":"2f4a648a47e66e85a3f876b76a8cf60922737640","venue_1":"Web Intelligence","year":"2008","title":"Resource Planning Heuristics for Service-Oriented Workflows","authors":"Julian Eckert, Deniz Ertogrul, André Miede, Nicolas Repp, Ralf Steinmetz","author_ids":"1782412, 2455422, 1860209, 3104557, 1725298","abstract":"Resource allocation and resource planning, especially in a SOA and Grid environment, become crucial. Particularly, in an environment with a huge number of workflow consumers requesting a decentralized cross-organizational workflow, performance evaluation and execution-management of service-oriented workflows gain in importance. The need for an effective and efficient workflow management forces enterprises to use intelligent optimization models and heuristics to compose workflows out of several services under real-time conditions. This paper introduces the required architecture Workflow Performance Extension - WPX.KOM for resource planning and workload prediction purposes. Furthermore, optimization approaches and a high-performance heuristic solving the addressed resource planning problem with low computational overhead are presented.","cites":"7","conferencePercentile":"78.18181818"},{"venue":"Web Intelligence","id":"a406e131df3955a4917c65c62a7d327ef8c5b1fa","venue_1":"Web Intelligence","year":"2003","title":"Future View: Web Navigation Based on Learning User?s Browsing Patterns","authors":"Norikatsu Nagino, Seiji Yamada","author_ids":"3140191, 1679243","abstract":"In this paper, we propose a Future View system that assists user's usual Web browsing. The Future View will prefetch Web pages based on user's browsing strategies and present them to a user in order to assist Web browsing. To learn user's browsing patterns, the Future View uses two types of learning classifier systems: a content-based clas-sifier system for contents change patterns and an action-based classifier system for user's action patterns. The results of learning is applied to crawling by Web robot, and gathered Web pages are presented to a user through a Web browser. We experimentally show effectiveness of navigation using the Future View.","cites":"3","conferencePercentile":"39.79591837"},{"venue":"Web Intelligence","id":"40897757a4985e619550c49665544d36eb8b31a0","venue_1":"Web Intelligence","year":"2007","title":"Contextual Prediction of Communication Flow in Social Networks","authors":"Munmun De Choudhury, Hari Sundaram, Ajita John, Dorée D. Seligmann","author_ids":"2583473, 8607462, 2984639, 2034307","abstract":"We present a formal framework for media interpretation that leverages low-level information extraction to a higher level of abstraction in order to support semantics-based information retrieval for the Semantic Web. The overall goal of the framework is to provide high-level content descriptions of documents for maximizing precision and recall of semantics-based information retrieval.","cites":"11","conferencePercentile":"88.51851852"},{"venue":"Web Intelligence","id":"51188cf3be85a3bb319b47aa1ff990581b024379","venue_1":"Web Intelligence","year":"2008","title":"A Flexible Partitioning Tool for Large Ontologies","authors":"Anne Schlicht, Heiner Stuckenschmidt","author_ids":"1696045, 1698459","abstract":"The benefits of modular ontologies in terms of easier creation and maintenance as well as better computational properties have been recognized by different researchers. As most real world ontologies, however, are still designed in a monolithic way, there is a need for methods that partition an existing ontology into a set of modules. Currently, existing work suffers from the fact that the notion of modularization is not as well understood in the context of ontologies as it is in software engineering. In this paper we present a flexible partitioning tool for large ontologies that can be adapted to the needs of different applications based on criteria that the resulting modular ontology should satisfy.","cites":"9","conferencePercentile":"84.24242424"},{"venue":"Web Intelligence","id":"d91168ef84726a58798bff8c2cb823cef8065399","venue_1":"Web Intelligence","year":"2008","title":"Towards Distributed Ontology Reasoning for the Web","authors":"Anne Schlicht, Heiner Stuckenschmidt","author_ids":"1696045, 1698459","abstract":"The use of description logics as one of the primary logical languages for knowledge representation on the Web has created new challenges with respect to reasoning in these logics. In order to support the vision of a semantic web of interrelated ontologies, reasoning procedures have to be highly scalable and able to deal with physically distributed knowledge models. A natural way of addressing these problems is to rely on distributed inference procedures that can distribute the load between different solvers, thus reducing potential bottlenecks both in terms of memory and computation time. In this paper, we propose a distributed resolution approach that solves the problem by local resolution and propagation of derived axioms between different reasoners. The method is complete for first order logic, terminates for ALC ontologies and avoids duplication of axioms and inferences. The work can be seen as a building block for a large scale distributed reasoning infrastructure for the semantic web as envisioned in recent activities such as the Large Knowledge Collider (LarKC) project.","cites":"5","conferencePercentile":"68.48484848"},{"venue":"Web Intelligence","id":"354f07467b0242d46d7ad399f0866e895bd83c2d","venue_1":"Web Intelligence","year":"2008","title":"The Emergence of Web Science","authors":"Nigel Shadbolt","author_ids":"1705314","abstract":"There is a growing realization among many researchers that if we want to model the Web and understand its future trajectory; if we want to understand the architectural principles that have provided for its growth; and if we want to be sure that it supports the basic social values of trustworthiness, privacy, and respect for social boundaries, then we must chart out a research agenda that targets the Web as a primary focus of attention. This is Web Science and this invited talk will discuss the emergence of this exciting new discipline.","cites":"0","conferencePercentile":"10.60606061"},{"venue":"Web Intelligence","id":"953cfcb3dfbc7adc29a63bf1cbb14dff807d765b","venue_1":"Web Intelligence","year":"2008","title":"Dynamic Change Evaluation for Ontology Evolution in the Semantic Web","authors":"Ignazio Palmisano, Valentina A. M. Tamma, Luigi Iannone, Terry R. Payne, Paul Doran","author_ids":"1710940, 8559323, 1749184, 1740601, 1738505","abstract":"Changes in an ontology may have a disruptive impact on any system using it. This impact may depend on structural changes such as introduction or removal of concept definitions, or it may be related to a change in the expected performance of the reasoning tasks. As the number of systems using ontologies is expected to increase, and given the open nature of the Semantic Web, introduction of new ontologies and modifications to existing ones are to be expected. Dynamically handling such changes, without requiring human intervention, becomes crucial. This paper presents a framework that isolates groups of related axioms in an OWL ontology, so that a change in one or more axioms can be automatically localised to a part of the ontology.","cites":"4","conferencePercentile":"61.81818182"},{"venue":"Web Intelligence","id":"aacd9a05942c32e6335272d6559425ff8e6526b2","venue_1":"Web Intelligence","year":"2013","title":"MeDetect: A LOD-Based System for Collective Entity Annotation in Biomedicine","authors":"Li Tian, Weinan Zhang, Antonis Bikakis, Haofen Wang, Yong Yu, Yuan Ni, Feng Cao","author_ids":"1733354, 8031058, 1703632, 7643792, 3578922, 1771583, 1789781","abstract":"With the ever-growing use of textual biomedical data, domain entity annotation has become very important in biomedicine. Previous works on annotating domain entities from biomedical references suffer from several issues, such as a data flexibility problem, language dependency, and limitations with respect to word sense disambiguation. Meanwhile, the Linked Open Data (LOD) Initiative aims at interlinking data from various open knowledge bases. The numbers of entities and properties describing semantic relationships between entities within the linked data cloud have become very large. In this paper, we propose a knowledge-incentive approach for entity annotation in biomedicine, and present Me Detect, a prototype system that we developed based on this approach. With this approach, we over-come the problems of previous works using LOD-based collective annotation. Finally, we present the results of experiments that verify the effectiveness and efficiency of our approach.","cites":"1","conferencePercentile":"48.23529412"},{"venue":"Web Intelligence","id":"04252ecf1e5c90b6e78c4862ff72845dd3de7722","venue_1":"Web Intelligence","year":"2008","title":"Evaluating Ontology Modules Using an Entropy Inspired Metric","authors":"Paul Doran, Valentina A. M. Tamma, Ignazio Palmisano, Terry R. Payne, Luigi Iannone","author_ids":"1738505, 8559323, 1710940, 1740601, 1749184","abstract":"The focus of ontology modularization to date has largely been on the creation of techniques to carry out ontology modularization. This creates a problem in evaluating the results of the different techniques. Ontology modularization techniques cannot solely be evaluated by examining their logical properties. Certain applications of ontology modularization, such as ontology reuse, require a new objective way to evaluate the results. This paper motivates the use of an entropy inspired measure to evaluate ontology modules by arguing that current objective measures of evaluation do not reconcile with the subjective measures employed by Ontology Engineers. Experiments are conducted to show that an entropy based evaluation of ontology modules is beneficial to an Ontology Engineer evaluating the results of ontology module extraction techniques.","cites":"1","conferencePercentile":"29.39393939"},{"venue":"Web Intelligence","id":"0b9540e130071d22c26e96b608b40a4b306f8eb0","venue_1":"Web Intelligence","year":"2011","title":"Interweaving Trend and User Modeling for Personalized News Recommendation","authors":"Qi Gao, Fabian Abel, Geert-Jan Houben, Ke Tao","author_ids":"1773611, 1714362, 1703821, 2981519","abstract":"In this paper, we study user modeling on Twitter and investigate the interplay between personal interests and public trends. To generate semantically meaningful user profiles, we present a framework that allows us to enrich the semantics of individual Twitter messages and features user modeling as well as trend modeling strategies. These profiles can be re-used in other applications for (trend-aware) personalization. Given a large Twitter dataset, we analyze the characteristics of user and trend profiles and evaluate the quality of the profiles in the context of a personalized news recommendation system. We show that personal interests are more important for the recommendation process than public trends and that by combining both types of profiles we can further improve recommendation quality.","cites":"8","conferencePercentile":"93.60465116"},{"venue":"Web Intelligence","id":"12bee422b816e7e86ce7a40e4eeba8a89027f433","venue_1":"Web Intelligence","year":"2010","title":"Domain-Specific Backlinking Services in the Web of Data","authors":"Manuel Salvadores, Gianluca Correndo, Martin Szomszor, Yang Yang, Nicholas Gibbins, Ian Millard, Hugh Glaser, Nigel Shadbolt","author_ids":"1709857, 3132568, 2099518, 1708973, 1708456, 2642047, 2907424, 1705314","abstract":"This paper describes an Open Linked Data backlinking service, a generic architecture component to support the discovery of useful links between items across highly connected data sets. Using Public Sector Information (PSI) currently available as Linked Data, we demonstrate that contemporary publishing practices do not adequately support the ability to navigate or automatically traverse between resources published by different vendors, or the capacity to discover information relevant to a particular URI. Although some useful services in this area have been developed, such as large triple indexes of published data, and the collection of same. As relationships between individuals, we believe that an important component is missing: a mechanism to discover the backlinks to relevant resources that cannot be found by direct URI resolution. We present the implementation of such a component, integrating data from various PSI sources.","cites":"4","conferencePercentile":"70.33898305"},{"venue":"Web Intelligence","id":"050c221413f4d49abd131e7813ef7507cb8f4d5b","venue_1":"Web Intelligence","year":"2008","title":"A k-Nearest-Neighbour Method for Classifying Web Search Results with Data in Folksonomies","authors":"Ching-man Au Yeung, Nicholas Gibbins, Nigel Shadbolt","author_ids":"1797101, 1708456, 1705314","abstract":"Traditional Web search engines mostly adopt a keyword-based approach. When the keyword submitted by the user is ambiguous, search result usually consists of documents related to various meanings of the keyword, while the user is probably interested in only one of them. In this paper we attempt to provide a solution to this problem using a k-nearest-neighbour approach to classify documents returned by a search engine, by building classifiers using data collected from collaborative tagging systems. Experiments on search results returned by Google show that our method is able to classify the documents returned with high precision.","cites":"7","conferencePercentile":"78.18181818"},{"venue":"Web Intelligence","id":"44b5cc31b1eb8c483668c77afe4e2845d8cc8364","venue_1":"Web Intelligence","year":"2004","title":"Web Service Cooperation Ideology","authors":"Shaohua Liu, Jun Wei, Yinglong Ma, Yu Liu","author_ids":"3717061, 1693790, 2461290, 1752717","abstract":"As the Internet environment becomes more and more dynamic, open and mutable, future software have to be more autonomic, reactive, adaptive, cooperative, and evolvable. To meet the need, we introduce emerging service cooperation middleware providing such infrastructure support. Derived from Chinese ancient five-elements ideology, a similar service cooperation philosophy is developed. Complying the idea, we develop a workflow system, PI, supporting Process Intelligence. We believe that the service cooperation will become a feasible solution to the future complex environment.","cites":"2","conferencePercentile":"48.74213836"},{"venue":"Web Intelligence","id":"416308a89c5df0d5f82ff18b6bf927c6e407faba","venue_1":"Web Intelligence","year":"2012","title":"Construction of Chinese A-shares Network Using Latent Dirichlet Allocation","authors":"Mingmin Chi, Jun Liu, Huijun He, Jiangfeng Bao, Yangyong Zhu","author_ids":"2308592, 1843598, 2164239, 2746615, 8247706","abstract":"Currently, there are more than 2,400 stocks in Chinese A-shares market and there is almost one IPO share coming into the emerging market per day. The rapid growth of Chinese stock market makes investors difficult to manage portfolio. In the paper, a Chinese A-shares Network (CAN) is constructed using a topic model (i.e., Latent Dirichlet Allocation) to efficiently divide all the A-shares to individual sectors in a probabilistic way in terms of the Business Scope Descriptions (BSD) of the listed companies until December 31, 2011. In the meanwhile, a novel visualization profile is proposed to friendly show stock-sectors relationships. Experimental results validate the effectiveness of the CAN system: the stocks in the same ``sector\" defined by the CAN have higher pair wise correlations than those by the experts.","cites":"0","conferencePercentile":"20.78651685"},{"venue":"Web Intelligence","id":"7fd5b129c028be4a79c21d87ffe8bb49aae099aa","venue_1":"Web Intelligence","year":"2010","title":"The Ethicality of Web Crawlers","authors":"Yang Sun, Isaac G. Councill, C. Lee Giles","author_ids":"3136781, 3291696, 1749125","abstract":"Search engines largely rely on web crawlers to collect information from the web. This has led to an enormous amount of web traffic generated by crawlers alone. To minimize negative aspects of this traffic on websites, the behaviors of crawlers may be regulated at an individual web server by implementing the Robots Exclusion Protocol in a file called &#8220;robots.txt&#8221;. Although not an official standard, the Robots Exclusion Protocol has been adopted to a greater or lesser extent by nearly all commercial search engines and popular crawlers. As many web site administrators and policy makers have come to rely on the informal contract set forth by the Robots Exclusion Protocol, the degree to which web crawlers respect robots.txt policies has become an important issue of computer ethics. In this research, we investigate and define rules to measure crawler ethics, referring to the extent to which web crawlers respect the regulations set forth in robots.txt configuration files. We test the behaviors of web crawlers in terms of ethics by deploying a crawler honeypot: a set of websites where each site is configured with a distinct regulation specification using the Robots Exclusion Protocol in order to capture specific behaviors of web crawlers.We propose a vector space model to represent crawler behavior and a set of models to measure the ethics of web crawlers based on their behaviors. The results show that ethicality scores vary significantly among crawlers. Most commercial web crawlers receive fairly low ethicality violation scores which means most of the crawlers&#8217; behaviors are ethical; however, many commercial crawlers still consistently violate or misinterpret certain robots.txt rules.","cites":"9","conferencePercentile":"91.10169492"},{"venue":"Web Intelligence","id":"091576a7fe0154953b9a6d560656673230a1de8a","venue_1":"Web Intelligence","year":"2008","title":"Towards Click-Based Models of Geographic Interests in Web Search","authors":"Ziming Zhuang, Cliff Brunk, Prasenjit Mitra, C. Lee Giles","author_ids":"3017391, 2806904, 1714911, 1749125","abstract":"With the recent surge in the volume of search queries that explicitly or implicitly express users' geographical interests, to accurately infer users' locality preference becomes an increasingly important yet challenging issue. We study two click-based models of the distribution of such geographical interests by mining the user click stream data in the search engine logs, addressing three important issues in spatial Web search. First, search queries and documents can be classified by the models according to their spatial specificity. Second, the geographic center(s) of interests for queries and documents can be inferred. Finally, the model can be applied to generate relevance features for search ranking. We evaluated our proposals on a large dataset with about 10,000 unique queries sampled from the Yahoo! Search query logs, and about 450 million user clicks on 1.4 million unique Web pages over a six-months period. We report about 90% accuracy and about 3% false positive rate in identifying search queries with or without specific geographical interests, as well as statistically significant improvement in relevance ranking over a strong baseline.","cites":"3","conferencePercentile":"51.51515152"},{"venue":"Web Intelligence","id":"ec53c214864a2552c01a76975af175cb80e47cf0","venue_1":"Web Intelligence","year":"2001","title":"Interactive Web Page Filtering with Relational Learning","authors":"Masayuki Okabe, Seiji Yamada","author_ids":"1791789, 1679243","abstract":"This paper describes a system for collecting Web pages that are relevant to a particular topic through an interactive approach. Indicated some relevant pages by a user, this system automatically constructs a set of rules to find new relevant pages. The purpose of the system is to reduce users' browsing cost by filtering non-relevant pages automatically. Such an approach can be useful when users do not know how to describe their requirements to search engines. We describe the representation and the learning algorithm, and also show the experiments comparing its performance with a search engine.","cites":"2","conferencePercentile":"27.27272727"},{"venue":"Web Intelligence","id":"12bff085bf645a56dbf76e6bfe5afa923ee8cbd2","venue_1":"Web Intelligence","year":"2011","title":"Pistis: A Privacy-Preserving Content Recommender System for Online Social Communities","authors":"Dongsheng Li, Qin Lv, Huanhuan Xia, Li Shang, Tun Lu, Ning Gu","author_ids":"7379433, 2345189, 8302923, 1791640, 1711569, 1750146","abstract":"With the explosive growth of online social communities and massive user-generated content, privacy-preserving recommender systems, which identify information of interest to individual users without disclosing personal interests to other parties, have become increasingly important. Collaborative filtering (CF), a widely used recommendation technique, recommends content that similar users have liked. As a result, CF-based recommender systems may expose sensitive personal interest information. This is demonstrated by a privacy attack model we present that targets online social communities. To solve this problem, we propose an interest group based privacy-preserving recommender system called Pistis. By identifying inherent item-user interest groups and separating users' private interests from their public interests, Pistis can make recommendations based on aggregated judgments of group members and local personalization, thus avoiding the disclosure of personal interest information. Pistis has been deployed and evaluated in an online social community with over 63,000 users, 20,000 daily posts, and 180,000 daily reads. Compared with two representative CF-based methods, our evaluation results demonstrate that Pistis achieves better performance in privacy preservation, recommendation quality, and efficiency.","cites":"7","conferencePercentile":"89.53488372"},{"venue":"Web Intelligence","id":"63c9baf149c2aa9105d20a99ed48e6428b3b2c50","venue_1":"Web Intelligence","year":"2012","title":"Fusing Text and Frienships for Location Inference in Online Social Networks","authors":"Hansu Gu, Haojie Hang, Qin Lv, Dirk Grunwald","author_ids":"1759997, 2064522, 2345189, 1748465","abstract":"Location information is becoming prevalent in today's online social networks (OSNs), which raises special privacy concerns with regard to both location sharing and its applications. Even when no explicit location is disclosed by a user, it is possible to geolocate the user through his/her social context, e.g., status updates and social relationships in OSNs. To demonstrate this, we propose GeoFind, which accurately identifies users' geographic regions through effective fusion (re-ranking) of (1) text-based ranking using geo-sensitive textual features and (2) structure-based ranking using maximum likelihood estimation (MLE) of geotagged friends. Evaluation results using 0.8 million geotagged Twitter users over a 3-month period demonstrate that GeoFind outperforms state-of-the-art techniques, with significant reduction of estimation error (25% of average error, 66% of median error). The potential of improving location accuracy through the fusion of multiple data types calls for a re-examination of existing privacy protection policies and mechanisms.","cites":"2","conferencePercentile":"73.03370787"},{"venue":"Web Intelligence","id":"84092582626855cee5944bfeaa3cfa5b08dbc8ce","venue_1":"Web Intelligence","year":"2004","title":"Fuzzy Neural Agents for Online NBA Scouting","authors":"Mourad Atlas, Yanqing Zhang","author_ids":"2889659, 1688104","abstract":"Internet is the focus of the intelligent agent applications. The current status of intelligent agent for the World Wide Web is still in its infancy, but like the Web itself, is evolving constantly. Several agents are being designed and implemented for a variety of tasks in diverse range of applications: managing e-mail, navigating and retrieving information from the Internet, online shopping, electronic business, monitoring stock prices or currency exchanges, etc. In this paper, we present and describe an intelligent service agent that assists an NBA scouting agent in his/her work. The particularity of our agent is not only it retrieves relevant information about NBA players from the Internet for the scouting agent but also it derives metadata from that information, which consist of player performance evaluation and player statistics prediction.","cites":"2","conferencePercentile":"48.74213836"},{"venue":"Web Intelligence","id":"3a2be998dd659cae17df36d1a12805759368a6c2","venue_1":"Web Intelligence","year":"2011","title":"ETree: Effective and Efficient Event Modeling for Real-Time Online Social Media Networks","authors":"Hansu Gu, Xing Xie, Qin Lv, Yaoping Ruan, Li Shang","author_ids":"1759997, 1687677, 2345189, 1757729, 1791640","abstract":"Outline social media networks (OSMNs) such as Twitter provide great opportunities for public engagement and event information dissemination. Event-related discussions occur in real time and at the worldwide scale. However, these discussions are in the form of short, unstructured messages and dynamically woven into daily chats and status updates. Compared with traditional news articles, the rich and diverse user-generated content raises unique new challenges for tracking and analyzing events. Effective and efficient event modeling is thus essential for real-time information-intensive OSMNs. In this work, we propose ETree, an effective and efficient event modeling solution for social media network sites. Targeting the unique challenges of this problem, ETree consists of three key components: (1) an n-gram based content analysis technique for identifying core information blocks from a large number of short messages, (2) an incremental and hierarchical modeling technique for identifying and constructing event theme structures at different granularities, and (3) an enhanced temporal analysis technique for identifying inherent causalities between information blocks. Detailed evaluation using 3.5 million tweets over a 5-month period demonstrates that ETree can efficiently generate high-quality event structures and identify inherent causal relationships with high accuracy.","cites":"7","conferencePercentile":"89.53488372"},{"venue":"Web Intelligence","id":"7cba830b038290ec60f49a317544f1f552b86909","venue_1":"Web Intelligence","year":"2004","title":"Improving Efficiency and Relevance Ranking in Information Retrieval","authors":"Lei Dong, Carolyn R. Watters","author_ids":"1762192, 1759624","abstract":"The increasing amount of data available on the Internet has made it more important to create efficient IR (Information Retrieval) systems than ever before. However, the execution efficiency of IR tasks under a given scheme is rarely discussed in research. This paper addresses this particular issue by proposing a method that reduces the complexity in both similarity computation and ranking procedures. With the algorithms proposed, the similarity computation may be completed in linear time and the ranking may take near linear time to be finished. Also, it has the potential to improve relevancy analysis in the ranking procedure.","cites":"0","conferencePercentile":"14.4654088"},{"venue":"Web Intelligence","id":"395542dee47d877de45e125886d268322a73ad7b","venue_1":"Web Intelligence","year":"2004","title":"Examining Table Variations on Small Screen Devices","authors":"Rui Zhang, Carolyn R. Watters, Jack Duffy","author_ids":"1740520, 1759624, 1761125","abstract":"We are concerned with users who have already used data on a larger screen and have migrated to a smaller device and wish to continue working with that data. Earlier studies concentrated on the dynamic transformation of text content, lists, and forms embedded in web pages for access on a range of devices from desktop to handheld. In this paper, we focus on the display and manipulation of large tables on small mobile devices. We report on a project to design and evaluate a transformational model for large tables onto small screens that is both effective and efficient.","cites":"3","conferencePercentile":"59.74842767"},{"venue":"Web Intelligence","id":"8a85cd560909cbb9e313ee4eac5e635f79c6abbf","venue_1":"Web Intelligence","year":"2007","title":"K-SVMeans: A Hybrid Clustering Algorithm for Multi-Type Interrelated Datasets","authors":"Levent Bolelli, Seyda Ertekin, Ding Zhou, C. Lee Giles","author_ids":"1743426, 1769472, 1728871, 1749125","abstract":"To support standardization and tool support of OWL-S, a formal semantics of the language is highly desirable. In this paper, we present a formal Object-Z semantics of OWL-S. This model not only provides a formal unambiguous model which can be used to develop tools and facilitate future development, but as demonstrated in the paper, can be used to identify and eliminate errors in the current documentation.","cites":"5","conferencePercentile":"67.03703704"},{"venue":"Web Intelligence","id":"76a3417d68011dd00fd067a5f5aa833b58e22a35","venue_1":"Web Intelligence","year":"2008","title":"A Study on the Granularity of User Modeling for Tag Prediction","authors":"Enrique Frías-Martínez, Manuel Cebrián, Alejandro Jaimes","author_ids":"1706334, 1709539, 1730325","abstract":"One of the characteristics of tag prediction mechanisms is that, typically, all user models are constructed with the same granularity. In this paper we hypothesize and empirically demonstrate that in order to increase tag prediction accuracy, the granularity of each user model has to be adapted to the level of usage of each particular user. We have constructed user models for tag prediction using association rules in Bibsonomy, a popular social bookmark and publication sharing system, at three granularity levels: (1) canonical, (2) stereotypical and (3) individual. Our experiments show that prediction accuracy improves if the level of granularity matches the level of participation of the user in the community (i.e., amount of tagging in Bibsonomy).","cites":"0","conferencePercentile":"10.60606061"},{"venue":"Web Intelligence","id":"fddc16574fdeb277765f3510d24a8c13a382bd21","venue_1":"Web Intelligence","year":"2010","title":"An Approach to Model and Predict the Popularity of Online Contents with Explanatory Factors","authors":"Jong Gun Lee, Sue B. Moon, Kavé Salamatian","author_ids":"2759629, 2478185, 1725388","abstract":"In this paper, we propose a methodology to predict the popularity of online contents. More precisely, rather than trying to infer the popularity of a content itself, we infer the likelihood that a content will be popular. Our approach is rooted in survival analysis where predicting the precise lifetime of an individual is very hard and almost impossible but predicting the likelihood of one's survival longer than a threshold or another individual is possible. We position ourselves in the standpoint of an external observer who has to infer the popularity of a content only using publicly observable metrics, such as the lifetime of a thread, the number of comments, and the number of views. Our goal is to infer these observable metrics, using a set of explanatory factors, such as the number of comments and the number of links in the first hours after the content publication, which are observable by the external observer. We use a Cox proportional hazard regression model that divides the distribution function of the observable popularity metric into two components: a) one that can be explained by the given set of explanatory factors (called risk factors) and b) a baseline distribution function that integrates all the factors not taken into account. To validate our proposed approach, we use data sets from two different online discussion forums: dpreview.com, one of the largest online discussion groups providing news and discussion forums about all kinds of digital cameras, and myspace.com, one of the representative online social networking services. On these two data sets we model two different popularity metrics, the lifetime of threads and the number of comments, and show that our approach can predict the lifetime of threads from Dpreview (Myspace) by observing a thread during the first 5~6 days (24 hours, respectively) and the number of comments of Dpreview threads by observing a thread during first 2~3 days.","cites":"23","conferencePercentile":"98.30508475"},{"venue":"Web Intelligence","id":"53bd363392437ae5d5e6ef7b6407525f921d1ce7","venue_1":"Web Intelligence","year":"2005","title":"Time Based Segmentation of Log Data for User Navigation Prediction in Personalization","authors":"Martin Halvey, Mark T. Keane, Barry Smyth","author_ids":"1767534, 1733913, 1701131","abstract":"There are many systems that attempt to predict user navigation on the Internet through the use of past behavior, preferences and environmental factors. We believe that many of these models have shortcomings, in that they do not take into account that users may have many different sets of preferences, specifically, we investigate time as an environmental factor in making predictions about user navigation. We present a method for segmenting log files in order to learn time dependent models to predict user navigation patterns and show the benefits of these models over traditional methods. An analysis is carried out on a sample of usage logs for Wireless Application Protocol (WAP) browsing, and the results of this analysis verify our hypothesis.","cites":"5","conferencePercentile":"61.11111111"},{"venue":"Web Intelligence","id":"dddc077253d3842c266a05726769aed7083f5d26","venue_1":"Web Intelligence","year":"2012","title":"Understanding the Regularity and Variability of Human Mobility from Geo-trajectory","authors":"Yunji Liang, Xingshe Zhou, Bin Guo, Zhiwen Yu","author_ids":"1710232, 1743113, 1836820, 1705015","abstract":"Over the last few years, many efforts have been devoted to revealing human mobility patterns. However, the regularity and variability of human mobility from a microscopic view, i.e., what factors affect human mobility patterns, has yet not been investigated. In this paper, we aim to study the impact factors that may affect the regularity and variability of human mobility patterns using social network analysis. Specifically, we introduce the spatial interaction matrix to represent the interaction strength and interaction semantics among spatial regions. Based on the spatial interaction matrix, we investigate the factors that impact the mobility patterns, including temporal factors, occupational factors and age factors. Our experimental results demonstrate that lots of factors such as environmental, temporal and age factors contribute to the shape of human mobility patterns.","cites":"0","conferencePercentile":"20.78651685"},{"venue":"Web Intelligence","id":"2dc5775548dca1d009e5b0ecd14229ddd26f0ce0","venue_1":"Web Intelligence","year":"2004","title":"GE-CKO: A Method to Optimize Composite Kernels for Web Page Classification","authors":"Jian-Tao Sun, Benyu Zhang, Zheng Chen, Yuchang Lu, Chunyi Shi, Wei-Ying Ma","author_ids":"2084926, 2158301, 1705657, 2710377, 6267209, 1705244","abstract":"Most of current researches on Web page classification focus on leveraging heterogeneous features such as plain text, hyperlinks and anchor texts in an effective and efficient way. Composite kernel method is one topic of interest among them. It first selects a bunch of initial kernels, each of which is determined separately by a certain type of features. Then a classifier is trained based on a linear combination of these kernels. In this paper, we propose an effective way to optimize the linear combination of kernels. We proved that this problem is equivalent to solving a generalized eigenvalue problem. And the weight vector of the kernels is the eigenvector associated with the largest eigen-value. A support vector machine (SVM) classifier is then trained based on this optimized combination of kernels. Our experiment on the WebKB dataset has shown the effectiveness of our proposed method.","cites":"7","conferencePercentile":"77.98742138"},{"venue":"Web Intelligence","id":"456708b3cd44e88b901fb7434e958c1f7f9a9cd6","venue_1":"Web Intelligence","year":"2001","title":"Automatic Web-Page Classification by Using Machine Learning Methods","authors":"Makoto Tsukada, Takashi Washio, Hiroshi Motoda","author_ids":"1702480, 1704749, 1748072","abstract":"This paper describes automatic Web-page classification by using machine learning methods. Recently, the importance of portal site services is increasing including the search engine function on World Wide Web. Especially, the portal site such as for Yahoo! service which hierarchically classifies Web-pages into many categories is becoming popular. However, the classification of Web-page into each category exclusively relies on man power which costs much time and care. To alleviate this problem, we propose techniques to generate attributes by using co-occurrence analysis and to classify Web-page automatically based on machine learning. We apply these techniques to Web-pages on Yahoo! JAPAN and construct decision trees which determine appropriate category for each Web-page. The performance of this proposed method is evaluated in terms of error rate, recall, and precision. The experimental evaluation demonstrates that this method provides high accuracy with the classification of Web-page into top level categories on Yahoo! JAPAN.","cites":"13","conferencePercentile":"90.90909091"},{"venue":"Web Intelligence","id":"105833e43b476dd5a4d0b04416d18e5e0bfb01e3","venue_1":"Web Intelligence","year":"2010","title":"Predicting the Future with Social Media","authors":"Sitaram Asur, Bernardo A. Huberman","author_ids":"1806968, 8579301","abstract":"In recent years, social media has become ubiquitous and important for social networking and content sharing. And yet, the content that is generated from these websites remains largely untapped. In this paper, we demonstrate how social media content can be used to predict real-world outcomes. In particular, we use the chatter from Twitter.com to forecast box-office revenues for movies. We show that a simple model built from the rate at which tweets are created about particular topics can outperform market-based predictors. We further demonstrate how sentiments extracted from Twitter can be utilized to improve the forecasting power of social media.","cites":"419","conferencePercentile":"100"},{"venue":"Web Intelligence","id":"567c839864a6380a8ed3473af984ccd7b2958fba","venue_1":"Web Intelligence","year":"2004","title":"Tree-Structured Template Generation for Web Pages","authors":"Shui-Lung Chuang, Jane Yung-jen Hsu","author_ids":"1819655, 1717095","abstract":"As the web becomes an increasingly important source of information, tools for modeling, searching, and extracting information from Web pages are indispensable. By modeling the structure of a Web page defined by its markup tags, one can easily extract target information using structural templates. This paper introduces the Tree Template Automatic Generator (TTAG) that learns tree-structured templates from training Web pages. TTAG was applied to both query-based and frequently updated Web sites, and produced effective templates from a small number of examples. The experiments show that TTAG is a powerful extraction tool for semi-structured information sources.","cites":"10","conferencePercentile":"87.42138365"},{"venue":"Web Intelligence","id":"51c2bd7bb6c888bb1253a4586fde07df41b3cd4c","venue_1":"Web Intelligence","year":"2005","title":"Integrating Element and Term Semantics for Similarity-Based XML Document Clustering","authors":"Jianwu Yang, William Kwok-Wai Cheung, Xiaoou Chen","author_ids":"1743923, 1749915, 1803841","abstract":"Structured link vector model (SLVM} is a recently proposed document representation that takes into account both structural and semantic information for measuring XML document similarity. Its formulation includes an element similarity matrix for capturing the semantic similarity between XML elements - the structural components of XML documents. In this paper, instead of applying heuristics to define the similarity matrix, we proposed to learn the matrix using pair-wise similar training data in an iterative manner. In addition, we extended SLVM to SLVM-LSI by incorporating term semantics into SL VM using latent semantic indexing, with the element similarity related properties of the original SLVM preserved. For performance evaluation, we applied SLVM-LSI to similarity-based clustering af two XMZ. datasets and the proposed SLVM-LSI was found to significant(y outpeform the conventional vector space model and the edit-distance based methods. The similarity matrix. obtained as a by-product via the learning, can provide higher-level knowledge about the semantic relationship between the XML elements.","cites":"7","conferencePercentile":"73.20261438"},{"venue":"Web Intelligence","id":"17468c434e45d8975b98057e56c45a54c4ce2af9","venue_1":"Web Intelligence","year":"2007","title":"Web Application Orchestration Using Excel","authors":"Jun Fujima, Shohei Yoshihara, Yuzuru Tanaka","author_ids":"2490602, 2786488, 1720508","abstract":"Collaborative filtering (CF) is one of the most successful approaches for recommendation. In this paper, we propose two hybrid CF algorithms, sequential mixture CF and joint mixture CF, each combining advice from multiple experts for effective recommendation. These proposed hybrid CF models work particularly well in the common situation when data are very sparse. By combining multiple experts to form a mixture CF, our systems are able to cope with sparse data to obtain satisfactory performance. Empirical studies show that our algorithms outperform their peers, such as memory-based, pure model-based, pure content-based CF algorithms, and the contentboosted CF (a representative hybrid CF algorithm), especially when the underlying data are very sparse.","cites":"1","conferencePercentile":"23.7037037"},{"venue":"Web Intelligence","id":"53ed0d3393fd7678fcbccac9804fed4aa3b59cf4","venue_1":"Web Intelligence","year":"2005","title":"Webpage Importance Analysis Using Conditional Markov Random Walk","authors":"Tie-Yan Liu, Wei-Ying Ma","author_ids":"1744859, 1705244","abstract":"In this paper, we propose a novel method to calculate the webpage importance based on a conditional Markov random walk model. The main assumption in this model is that given the hyperlinks in a webpage, users are not really randomly clicking one of them. Instead, many factors may bias their behaviors, for example, the anchor text, the content relevance and the previous experiences when visiting the website that a destination pages belongs to. As one of the results, the user might tend to visit those pages in high-quality websites with higher probability. To implement this idea, we reformulate the Web graph to be a two-layer structure, and the webpage importance is calculated by conditional random walk in this new Web graph. Experiments on the topic distillation task of TREC 2003 Web track showed that our new method can achieve about 18% improvement on mean average precision (MAP) and 16% on precision at 10 (P@10) over the PageRank algorithm.","cites":"8","conferencePercentile":"79.08496732"},{"venue":"Web Intelligence","id":"1ed8d055f24e60db967a84600eb5cd0d01af5180","venue_1":"Web Intelligence","year":"2007","title":"Blog Community Discovery and Evolution Based on Mutual Awareness Expansion","authors":"Yu-Ru Lin, Hari Sundaram, Yun Chi, Jun'ichi Tatemura, Belle L. Tseng","author_ids":"2133006, 8607462, 1749829, 2784291, 8595363","abstract":"Question-Answering Bulletin Boards (QABB), such as Yahoo! Answers and Windows Live QnA, are gaining popularity recently. Communications on QABB connect users, and the overall connections can be regarded as a social network. If the evolution of social networks can be predicted, it is quite useful for encouraging communications among users. This paper describes an improved method for predicting links based on weighted proximity measures of social networks. The method is based on an assumption that proximities between nodes can be estimated better by using both graph proximity measures and the weights of existing links in a social network. In order to show the effectiveness of our method, the data of Yahoo! Chiebukuro (Japanese Yahoo! Answers) are used for our experiments. The results show that our method outperforms previous approaches, especially when target social networks are sufficiently dense.","cites":"40","conferencePercentile":"98.14814815"},{"venue":"Web Intelligence","id":"62db032129b23f2e4a96aeb88e1c6fa33d37dae0","venue_1":"Web Intelligence","year":"2004","title":"TSSP: A Reinforcement Algorithm to Find Related Papers","authors":"Shen Huang, Gui-Rong Xue, Benyu Zhang, Zheng Chen, Yong Yu, Wei-Ying Ma","author_ids":"2514919, 1701421, 2158301, 1705657, 3578922, 1705244","abstract":"Content analysis and citation analysis are two common methods in recommending system. Compared with content analysis, citation analysis can discover more implicitly related papers. However, the citation-based methods may introduce more noise in citation graph and cause topic drift. Some work combine content with citation to improve similarity measurement. The problem is that the two features are not used to reinforce each other to get better result. To solve the problem, we propose a new algorithm, Topic Sensitive Similarity Propagation (TSSP), to effectively integrate content similarity into similarity propagation. TSSP has two parts: citation context based propagation and iterative reinforcement. First, citation contexts provide clues for which papers are topic related to and filter out less irrelevant citations. Second, iteratively integrating content and citation similarity enable them to reinforce each other during the propagation. The experimental results of a user study show TSSP outperforms other algorithms in almost all cases.","cites":"8","conferencePercentile":"81.76100629"},{"venue":"Web Intelligence","id":"29ba2c4c65441b1958ab9da21faeb025d535fbc4","venue_1":"Web Intelligence","year":"2005","title":"An Editor Labeling Model for Training Set Expansion in Web Categorization","authors":"Tie-Yan Liu, Hao Wan, Wei-Ying Ma","author_ids":"1744859, 2604863, 1705244","abstract":"Automatically classifying web pages is an effective way to manage the massive information on the Web. However, our experiments show that the state-of-the-art text categorization technologies can not achieve a satisfactory classification performance in this task. The major reason is the existence of large proportion of rare categories in Web taxonomies. The failure in such categories is simply because there is not enough information to train reliable classifiers. To tackle this problem, we propose to expand the training set of the rare categories, by simulating the labeling behavior of the human editors of Web directories. Experimental results show that in such a way, we achieved significant (relatively 93%) improvement in classification accuracy, which is highly encouraging for high-performance Web classification.","cites":"0","conferencePercentile":"9.477124183"},{"venue":"Web Intelligence","id":"ae4e8f10bd2b74094c2eb0fdeb78244127bf13da","venue_1":"Web Intelligence","year":"2010","title":"DSP: Robust Semi-supervised Dimensionality Reduction Using Dual Subspace Projections","authors":"Su Yan, Sofien Bouaziz, Dongwon Lee","author_ids":"2880962, 1755579, 1784227","abstract":"High-dimensional data usually incur learning deficiencies and computational difficulties. We present a novel semi-supervised dimensionality reduction technique that embeds high-dimensional data in an optimal low-dimensional subspace, which is learned with a few user supplied constraints as well as the structure of input data. We study two types of constraints that indicate whether or not pairs of data points originate from the same class. Data partitions that satisfy both types of constraints may be conflicting. To solve this problem, our method projects data into two different subspaces, one in the kernel space and one in the original input space, each is designed for enforcing one type of constraints. Projections in the two spaces interact and data are embedded in an optimal low-dimensional subspace where constraints are maximally satisfied. Besides constraints, our method also preserves the intrinsic data structure, such that nearby/far away data points in the original space are still near to/far from each other in the embedded space. Compared to existing techniques, our method has the following advantages: 1) It can benefit from constraints even when only a few are available. 2) It is robust and does not suffer from over fitting. 3) It handles nonlinearly separable data, but learns a linear data transformation. Thus the method can be easily generalized to new data points and is efficient in dealing with large data sets. Experiments on real data from multiple domains clearly demonstrate that significant improvements in learning accuracy can be achieved after dimensionality reduction by employing only a few constraints.","cites":"0","conferencePercentile":"12.71186441"},{"venue":"Web Intelligence","id":"06d0ba669803817b73f01e0a9c3d8ef56ceb231a","venue_1":"Web Intelligence","year":"2011","title":"Dynamically Modeling Semantic Dependencies in Web Forum Threads","authors":"Zhaochun Ren, Jun Ma, Gang Wang, Chaoran Cui, Xiaohui Han","author_ids":"2780667, 1683601, 4148672, 3180412, 2033527","abstract":"The huge amount of knowledge in web forums has motivated great research interests in recent years. However, tracking semantic dependencies in each thread in web forums has posed a challenging problem for researchers. In this paper, we explore an unsupervised topic model to burst through this issue by simultaneously modeling the semantics and the reply relationship in a thread. The proposed model is a dynamic extension of Latent Dirichlet Allocation (LDA) for the structure of web forum threads, where each post is considered as a mixture of topics that vary along the asynchronous conversation. The experimental results on two different forum data sets show encouraging performance of our proposed PPM in ranking the influence of posts.","cites":"1","conferencePercentile":"31.39534884"},{"venue":"Web Intelligence","id":"02e85734d1f99bc107aa15489282c048bff5c700","venue_1":"Web Intelligence","year":"2012","title":"Detecting Places of Interest Using Social Media","authors":"Steven Van Canneyt, Steven Schockaert, Olivier Van Laere, Bart Dhoedt","author_ids":"2741039, 2265382, 2219806, 1733741","abstract":"Place recommender systems are increasingly being used to find places of a given type that are close to a user-specified location. As it is important for these systems to use an up-to-date database with a wide coverage, there is a need for techniques that are capable of expanding place databases in an automated way. On the other hand, social media are a rich source of geographically distributed information. In this paper, we therefore propose an approach to discover new instances of a given place type by exploiting correlations between terms and locations in geotagged social media. For a variety of place types, our approach is able to find places which are not yet included in popular place databases such as Foursquare or Google Places.","cites":"6","conferencePercentile":"94.38202247"},{"venue":"Web Intelligence","id":"8976d9866feeb050e6f4f1c3b1427180d087f085","venue_1":"Web Intelligence","year":"2005","title":"Big Blackboard: On a Large Web Page by Using a Fast Page Loading Method","authors":"Takeshi Konagaya, Toramatsu Shintani, Tadachika Ozono, Takayuki Ito, Kentaro Nishi","author_ids":"2454964, 1895121, 2843264, 1679044, 8674595","abstract":"Recently, the World Wide Web (WWW) has been attracting much attention as the predominant method of sharing information using multimedia contents. However, when users want to provide multimedia contents on the Web, they must learn how to use authoring software or how to write HTML documents. In this paper, we propose a Web information-sharing system called \"Big Blackboard,\" which is based on a large Web page. The large Web page can act as a metaphor for real-world bulletin boards to realize not only a one-dimensional message board but also a two-dimensional message board on the Web. Any user can easily provide multimedia contents using unlimited layout through a Web browser without needing to know HTML. In the case of displaying on a large Web page, loading Web page contents onto a Web browser may require users to wait a long time. We propose a novel method that reduces transmission cost by only loading the contents within the scope at which a user is looking at an entire Web page. The experimental results demonstrate that our method can effectively reduce user waiting time for loading a Web page.","cites":"0","conferencePercentile":"9.477124183"},{"venue":"Web Intelligence","id":"3bda055c700413c6a25c755e4929a184d9c8b865","venue_1":"Web Intelligence","year":"2013","title":"A Method for Discovering Dynamic Network Motifs by Encoding Topic Propagation","authors":"Vladimir Barash, Natasa Milic-Frayling, Marc A. Smith","author_ids":"2548642, 1780840, 1688863","abstract":"Marketing campaigns using social media services aim to exploit social connections to propagate messages to potential customers. However, social activities often give rise to multiple network structures and some may be more effective in achieving the communication objectives than others. This led us to investigate a problem: given an observed sequence of messages and a social network that includes individuals involved in messaging, does the network structure 'explain' the observed propagation. To facilitate this investigation, we designed a method for encoding propagation events relative to the structure of a given network. The resulting transmission codes capture both the temporal and the structural characteristics of the propagation. We analyze the codes for maximal repeats and k-common sub strings to uncover dynamic network motifs within the propagation trace. By considering the dynamic motifs and the connected graph components, we can determine how the propagation events relate to the specific network. As a case study, we applied our method to rumor topics in Twitter and analyzed their propagation trails relative to the 'follower' network. The study demonstrates the computational feasibility of our approach and illustrates the use of dynamic motifs to reason about the impact of follower relationship rumor propagation in Twitter.","cites":"0","conferencePercentile":"19.41176471"},{"venue":"Web Intelligence","id":"198f761acbce4926ffbb84ebb7fdcbba3b8975fa","venue_1":"Web Intelligence","year":"2005","title":"Kernel Principle Component Analysis in Pixels Clustering","authors":"Jing Li, Dacheng Tao, Weiming Hu, Xuelong Li","author_ids":"1742253, 7761803, 1696704, 1720243","abstract":"We propose two new methods in the nonlinear kernel feature space for pixel clustering based on the traditional KMeans and Gaussian Mixture Model (GMM). Unlike the previous work on the kernel machines, we give out a new perspective on the new developed kernel machines. That is, kernel principle component analysis (KPCA) combined with the KMeans and the GMM are kernel KMeans (KKMeans) and kernel GMM (KGMM), respectively. In this paper, we prove the new perspective on KKMeans and give out a clear statement on the KGMM as well. Based on this new perspectives, we can implement the KKMeans and the KGMM conveniently. At the end of the paper, we utilize these new algorithms on the problem of the colour image segmentation. Based on a series of experimental results on Corel Colour Images, we find that the KKMeans and KGMM can outperform the traditional KMeans and GMM consistently, respectively.","cites":"6","conferencePercentile":"66.99346405"},{"venue":"Web Intelligence","id":"7a4e844aab7389deb68d9c932a0021b95ce779a3","venue_1":"Web Intelligence","year":"2008","title":"Dynamic Self-Healing for Service Flows with Semantic Web Services","authors":"Wei Ren, Gang Chen, Haifeng Shen, Zhonghua Yang, Jing-Bing Zhang, Chor Ping Low, David Chen, Chengzheng Sun","author_ids":"1725968, 2259565, 2227739, 2196937, 3113649, 2798142, 3698743, 1688131","abstract":"With an increasing complexity of business processes, self-healing capability is becoming an important issue in order to support robust service flow execution. In this paper, a dynamic self-healing mechanism is proposed, which can dynamically identify suitable alternatives and replace faulty services such that a service flow can be performed successfully despite of unexpected exceptions. This mechanism explicitly utilizes Semantic Web services for service matching and selection of a composite service in business service flow, and Semantic web services are equipped with rich business rules in a domain-dependent manner. We explore the self-healing mechanism for supporting self-healable service flow execution which is modeled in BPEL4WS. A demo system of self-healing capable Service Flow Execution is built to validate its effectiveness by a concrete scenario, PC manufacturing application.","cites":"1","conferencePercentile":"29.39393939"},{"venue":"Web Intelligence","id":"edcc0ec03d29c66ba06f93087126358665fc35ce","venue_1":"Web Intelligence","year":"2012","title":"Polarity Analysis for Food and Disease Relationships","authors":"Qingliang Miao, Shu Zhang, Yao Meng, Hao Yu","author_ids":"1772481, 6585802, 1803963, 1745355","abstract":"The explosive growth of published articles in biomedical science field has led more research to focus on biomedical relationship extraction. However, there is relatively little investigation conducted on polarity analysis of these relationships, such as food (or nutrition) and disease relationships. In this paper, we investigate how to automatically identify the polarity of relationships between food and disease in biomedical text. In particular, we first analyze the characteristics and challenges of relation polarity analysis, and then propose an integrated approach, which utilizes background knowledge in terms of relation word and polarity class association, and refines this association by using any available domain specific training data. In addition, we propose several novel learning features and a computational approach to construct background knowledge base. Empirical results on real world datasets show that the proposed method is effective.","cites":"0","conferencePercentile":"20.78651685"},{"venue":"Web Intelligence","id":"a65799e2afc78e321e787109e210eab8c97823c1","venue_1":"Web Intelligence","year":"2004","title":"Popularity-Based Selective Markov Model","authors":"Lei Shi, Zhimin Gu, Lin Wei, Yun Shi","author_ids":"4608232, 1804833, 8634681, 5667810","abstract":"Web prefetching is a promising solution used to reduce user's latency and improve the QOS.This paper presents a popularity-based selective Markov prefetching model for predicting the forthcoming Web pages.We make use of teh Zipf's law to model the Web objects' popularity.An experimental evaluation of the prefetching mechanism is presented using real server logs.Our trace-driven simulation results show that the popularity-based selective.Markov prefetching model can achieve a good hit ratio with reducing the traffic load to some degree.","cites":"2","conferencePercentile":"48.74213836"},{"venue":"Web Intelligence","id":"2605f3e966294f2c08c537244c388f00d20a32dc","venue_1":"Web Intelligence","year":"2012","title":"Recommending Inexperienced Products via Learning from Consumer Reviews","authors":"Feng Wang, Li Chen","author_ids":"1745827, 1725490","abstract":"—Most products in e-commerce are with high cost (e.g., digital cameras, computers) and hence less likely experienced by users (so they are called \" inexperienced products \"). The traditional recommender techniques (such as user-based collaborative filtering and content-based methods) are thus not effectively applicable in this environment, because they largely assume that the users have prior experiences with the items. In this paper, we have particularly incorporated product reviews to solve the recommendation problem. We first studied how to utilize the reviewer-level weighted feature preferences (as learnt from their written product reviews) to generate recommendations to the current buyer, followed by exploring the impact of Latent Class Regression Models (LCRM) based cluster-level feature preferences (that represent the common preferences of a group of reviewers). Motivated by their respective advantages, a hybrid method that combines both reviewer-level and cluster-level preferences is introduced and experimentally compared to the other methods. The results reveal that the hybrid method is superior to the other variations in terms of recommendation accuracy, especially when the current buyer states incomplete feature preferences.","cites":"4","conferencePercentile":"86.51685393"},{"venue":"Web Intelligence","id":"018162afda46895b9919cf83312831378013a868","venue_1":"Web Intelligence","year":"2008","title":"Ant Colony Inspired Self-Healing for Resource Allocation in Service-Oriented Environment Considering Resource Breakdown","authors":"Rong Zhou, Ren Wei, Gang Chen, Zhonghua Yang, Haifeng Shen, Jing-Bing Zhang, Ming Luo","author_ids":"2552035, 3032204, 2259565, 2196937, 2227739, 3113649, 1720362","abstract":"The ant colony optimization (ACO) algorithm is a metaheuristic inspired from the behavior of foraging ants. Instead of exploring its ability in finding optimal solutions, the current study investigates another unique property &#8211; self-healing mechanism for resource allocation in a service-oriented environment where unexpected resource breakdown can occur. A system architecture is first proposed to detect, diagnose and react to disturbances. Then the performance of the ACO self-healing mechanism is tested and compared based on a modified benchmark problem. The experimental results show that the self-healing mechanism can promptly recover an obsolete schedule with high quality solutions.","cites":"2","conferencePercentile":"41.81818182"},{"venue":"Web Intelligence","id":"f00c47b328b01b0ce71f7bfc9adbccd6cdd06041","venue_1":"Web Intelligence","year":"2009","title":"OrdRank: Learning to Rank with Ordered Multiple Hyperplanes","authors":"Heli Sun, Jianbin Huang, Boqin Feng, Tao Li, Yingliang Zhao, Jun Liu","author_ids":"2258126, 8192456, 1768968, 1726351, 2012678, 1843598","abstract":"Ranking is a central problem for information retrieval systems, because the performance of an information retrieval system is mainly evaluated by the effectiveness of its ranking results. Learning to rank has received much attention in recent years due to its importance in information retrieval. This paper focuses on learning to rank in document retrieval and presents a ranking model named OrdRank that ranks documents with ordered multiple hyperplanes. Comparison of OrdRank with other state-of-the-art ranking techniques is conducted and several evaluation criteria are employed to evaluate its performance. Experimental results on the OHSUMED dataset show that OrdRank outperforms other methods, both in terms of quality of ranking results and efficiency.","cites":"0","conferencePercentile":"8.974358974"},{"venue":"Web Intelligence","id":"a6cf4ca4cfe052add73b4b9e4a2d65e9af817322","venue_1":"Web Intelligence","year":"2004","title":"Applying Collaborative Filtering for Efficient Document Search","authors":"Seikyung Jung, Juntae Kim, Jonathan L. Herlocker","author_ids":"1720410, 2377289, 2658798","abstract":"This paper presents the SERF (System for Electronic Recommendation Filtering) which is a collaborative filtering system that recommends context-sensitive, high-quality information sources for document search. Collaborative filtering systems remove the limitation of traditional content-based search by using individual's ratings to evaluate and recommend information sources. SERF uses collaborative filtering algorithms to predict the relevance and quality of each document with respect to each particular user and their specific information need. In our system, users specify their need in the form of a natural language query, and are provided with recommended documents based on ratings by other users with similar questions. Preliminary experiments show that the collaborative filtering recommendations increase the efficiency of the document search process. We also discuss some key challenges of designing a collaborative filtering system for document search.","cites":"4","conferencePercentile":"66.98113208"},{"venue":"Web Intelligence","id":"753ab2d201c432fbab4f321d94f86a9d1a9aa812","venue_1":"Web Intelligence","year":"2011","title":"Cognitive Resource Aware Service Provisioning","authors":"Angel Jiménez Molina, In-Young Ko","author_ids":"1954443, 2532033","abstract":"The vision of spontaneously delivering ubiquitous services to mobile users stands on the tradition of reflecting functional and non-functional requirements. Nevertheless, existing approaches do not reason in advance about the potential conflicts of mobility activities with human-computer interaction based tasks. These conflicts may burden the user with unexpected interruptions that overload the central human-cognitive capacity. This paper introduces a novel cognitive engineering mechanism to optimize service functionality co ordinations during runtime in accordance with situational demands of cognitive resources. We base our resource aware approach for service coordination optimization on two theories from cognitive psychology--the human-processing system theory of Navon and the multiple resource theory of Wickens. On top of this psychological background, we introduce a specific mechanism for varying service co ordinations.","cites":"2","conferencePercentile":"50"},{"venue":"Web Intelligence","id":"6da0bf6c1bc43225ce2e416c7fc638fe978b8501","venue_1":"Web Intelligence","year":"2015","title":"Top-N recommendations in the presence of sparsity: An NCD-based approach","authors":"Athanasios N. Nikolakopoulos, John D. Garofalakis","author_ids":"2143706, 1680221","abstract":"Making recommendations in the presence of sparsity is known to present one of the most challenging problems faced by collaborative filtering methods. In this work we tackle this problem by exploiting the innately hierarchical structure of the item space following an approach inspired by the theory of Decomposability. We view the itemspace as a Nearly Decomposable system and we define blocks of closely related elements and corresponding indirect proximity components. We study the theoretical properties of the decomposition and we derive sufficient conditions that guarantee full item space coverage even in cold-start recommendation scenarios. A comprehensive set of experiments on the MovieLens and the Yahoo!R2Music datasets, using several widely applied performance metrics, support our model's theoretically predicted properties and verify that NCDREC outperforms several state-of-the-art algorithms, in terms of recommendation accuracy, diversity and sparseness insensitivity.","cites":"1","conferencePercentile":"100"},{"venue":"Web Intelligence","id":"26725234bf65b28ad0090ea5ed54d2357d161656","venue_1":"Web Intelligence","year":"2007","title":"Determining Bias to Search Engines from Robots.txt","authors":"Yang Sun, Ziming Zhuang, Isaac G. Councill, C. Lee Giles","author_ids":"3136781, 3017391, 3291696, 1749125","abstract":"Semantic web approach seems interesting for supporting content mining of millions of patents accessible through the Web. In this paper, we describe our approach for generating semantic annotations on patents, by relying on the structure and on a semantic representation of patent documents. We use both the structure of the patent documents and their textual contents processed by Natural Language Processing (NLP) tools. This method, primarily aimed at helping biologists use patent information can be generalized to all kinds of domains or of structured documents.","cites":"3","conferencePercentile":"50.74074074"},{"venue":"Web Intelligence","id":"fec6de46b01a09c670d37c5f2bcf065551f518b6","venue_1":"Web Intelligence","year":"2007","title":"An Exploratory Cognitive Business Intelligence System","authors":"Li Niu, Jie Lu, Eng Chew, Guangquan Zhang","author_ids":"8426438, 1685235, 2479057, 1715857","abstract":"We propose a hierarchical approach to document categorization that requires no pre-configuration and maps the semantic document space to a predefined taxonomy. The utilization of search engines to train a hierarchical classifier makes our approach more flexible than existing solutions which rely on (human) labeled data and are bound to a specific domain. We show that the structural information given by the taxonomy allows for a context aware construction of search queries and leads to higher tagging accuracy. We test our approach on different benchmark datasets and evaluate its performance on the single- and multi-tag assignment tasks. The experimental results show that our solution is as accurate as supervised classifiers for web page classification and still performs well when categorizing domain specific documents.","cites":"4","conferencePercentile":"60.37037037"},{"venue":"Web Intelligence","id":"48cae714187c89afcfa609715eda10608e7d0cfc","venue_1":"Web Intelligence","year":"2010","title":"Relations Expansion: Extracting Relationship Instances from the Web","authors":"Haibo Li, Yutaka Matsuo, Mitsuru Ishizuka","author_ids":"2249172, 1692267, 1687719","abstract":"In this paper, we propose a Relation Expansion framework, which uses a few seed sentences marked up with two entities to expand a set of sentences containing target relations. During the expansion process, label propagation algorithm is used to select the most confident entity pairs and context patterns. The label propagation algorithm is a graph based semi-supervised learning method which models the entire data set as a weighted graph and the label score is propagated on this graph. We test the proposed framework with four relationships, the results show that the label propagation is quite competitive comparing with existing methods.","cites":"0","conferencePercentile":"12.71186441"},{"venue":"Web Intelligence","id":"5a2a4b84237d8f249254796f50e682a32830b96f","venue_1":"Web Intelligence","year":"2010","title":"Ant-Based Simulation of Opinion Spreading in Online Social Networks","authors":"Carolin Kaiser, Johannes Kröckel, Freimut Bodendorf","author_ids":"2600172, 2203749, 1714522","abstract":"An increasing number of people are socializing within online networks. By means of interaction, network members influence one another&#8217;s opinion. For companies, it is important to know how opinions spread throughout networks in order to be able to take appropriate marketing actions. A new approach is presented which simulates the spread of opinions within online social networks. The principles of opinion formation are first revealed by ant mining algorithms coming from swarm intelligence and then applied to simulate the spread of opinions.","cites":"0","conferencePercentile":"12.71186441"},{"venue":"Web Intelligence","id":"158ad2f982e2b684dd2e5d6b34c57462f1d9036b","venue_1":"Web Intelligence","year":"2009","title":"Opinion and Relationship Mining in Online Forums","authors":"Carolin Kaiser, Freimut Bodendorf","author_ids":"2600172, 1714522","abstract":"The Internet contains an increasing number of online forums where consumers exchange product opinions. It is important for companies to know how consumers judge their products and how these opinions are spread by interactions throughout online forums. With this knowledge it is possible to recognize risks and chances. However, classical opinion research is very time consuming and only possible to a certain extent. This paper introduces a system which automatically extracts opinions and communication relationships in forums by text mining and identifies influential users and trends by social network analysis.","cites":"2","conferencePercentile":"48.29059829"},{"venue":"Web Intelligence","id":"5378843aab616e03f12cab60b48c38a67d3dac0a","venue_1":"Web Intelligence","year":"2005","title":"Modelling and Simulating Chained Negotiation to Enable Sharing of Notifications","authors":"Richard A. Lawley, Michael Luck, Luc Moreau","author_ids":"2817002, 1721762, 1773775","abstract":"Notification services (NSs) are middleware components providing asynchronous message delivery between publishers and consumers. Multiple interconnected NSs form a distributed NS, with each NS routing notifications between publishers and consumers at different locations, enabling consumers to share subscriptions, reducing the number of messages sent. Consumers can specify Quality of Service (QoS) levels when subscribing to a NS, using negotiation to find QoS levels acceptable to both parties. However, if consumers specify sufficiently different QoS levels,notifications cannot be shared and new subscriptions must be made. Chained negotiation can be used to negotiate QoS levels through intermediate NSs, enabling the reuse of existing subscriptions for additional consumers. In this paper, we present a chained negotiation engine, evaluating its performance and behaviour, showing that it enables negotiation over QoS while still sharing notifications, and that it provides better results for a consumer by negotiation directly with the publisher.","cites":"0","conferencePercentile":"9.477124183"},{"venue":"Web Intelligence","id":"ad4ad68af15de2db6037e87626b6f784c9995e85","venue_1":"Web Intelligence","year":"2008","title":"Bridging the Gap between Qualitative and Quantitative Analysis of Opinion Forums","authors":"Carolin Kaiser, Birinder S. Tiwana, Freimut Bodendorf","author_ids":"2600172, 2231297, 1714522","abstract":"An increasing number of users of opinion forums provide us with rich sources of data about customer opinions. Several fields of research deal with the analysis of qualitative or quantitative data. While affective text mining research explores qualitative data, social network analysis focuses on quantitative mining methods. A combined analysis of both information classes is still missing. However, this combined analysis is necessary for identifying the process of opinion formation in opinion forums. In this paper, we attempt to bridge this gap by applying new methods which are required for network analysis of opinion forum data. We are also presenting a plug-in for the popular biological research tool Cytoscape. This plug-in combined with visualization features of Cytoscape implements the key features described in this paper. Our approach will provide companies with information about chances and risks concerning their products.","cites":"0","conferencePercentile":"10.60606061"},{"venue":"Web Intelligence","id":"c41acbec9082eec760000442f9e1e414cf34b3fb","venue_1":"Web Intelligence","year":"2011","title":"A Hybrid Multi-criteria Semantic-Enhanced Collaborative Filtering Approach for Personalized Recommendations","authors":"Qusai Shambour, Jie Lu","author_ids":"2593703, 1685235","abstract":"Recommender systems aim to assist web users to find only relevant information to their needs rather than an undifferentiated mass of information. Collaborative filtering (CF) techniques are probably the most popular and widely adopted techniques in recommender systems. Despite of their success in various applications, CF-based techniques still encounter two major limitations, namely sparsity and cold-start problems. More recently, semantic information of items has been successfully used in recommender systems to alleviate such problems. Moreover, the incorporation of multi-criteria ratings in recommender systems can help to produce more accurate recommendations. Thereby, in this paper, we propose a hybrid Multi-Criteria Semantic-enhanced CF (MC-SeCF) approach. The MC-SeCF approach integrates the enhanced MC item-based CF and the item-based semantic filtering approaches to alleviate current limitations of the item-based CF techniques. Experimental results demonstrate the effectiveness of the proposed MC-SeCF approach in terms of improving accuracy, as well as in dealing with very sparse data sets or cold-start items compared to benchmark item-based CF techniques.","cites":"4","conferencePercentile":"75.58139535"},{"venue":"Web Intelligence","id":"21986062c2e99911f954ddfa40eb84561badb717","venue_1":"Web Intelligence","year":"2012","title":"Rating Prediction by Correcting User Rating Bias","authors":"Masanao Ochi, Yutaka Matsuo, Makoto Okabe, Rikio Onai","author_ids":"2731242, 1692267, 3102663, 2086194","abstract":"We propose a novel method to improve the prediction accuracy on the rating prediction task by correcting the bias of user ratings. We demonstrate that the manner of user rating and review is biased and that it is necessary to correct this difference for more accurate prediction. Our proposed method comprises approaches based on the detection of each user value to ratings: The bias of the rating is detected using entropy of user rating and by updating word weights only when the words appear in the review, the problem of bias is reduced. We implement this idea by extending the Prank algorithm. We apply a review -- item matrix as a feature matrix instead of a user -- item matrix because of its volume of information. Our quantitative evaluation shows that our method improves the prediction accuracy (the Rank Loss measurement) significantly by 8.70 % compared with the normal Prank algorithm. Our proposed method helps users find out what they care about when buying something, and is applicable to newer variants of the Prank algorithm. Moreover, it is useful to most review sites because we use only rating and review data.","cites":"0","conferencePercentile":"20.78651685"},{"venue":"Web Intelligence","id":"b80dca37600426c4078b3c2d1890c7330ade982d","venue_1":"Web Intelligence","year":"2012","title":"Approximating Linear Order Inference in OWL 2 DL by Horn Compilation","authors":"Jianfeng Du, Guilin Qi, Jeff Z. Pan, Yi-Dong Shen","author_ids":"2849559, 1730054, 1704953, 1744468","abstract":"In order to directly reason over inconsistent OWL 2 DL ontologies, this paper considers linear order inference which comes from propositional logic. Consequences of this inference in an inconsistent ontology are defined as consequences in a certain consistent sub-ontology. This paper proposes a novel framework for compiling an OWL 2 DL ontology to a Horn propositional program so that the intended consistent sub-ontology for linear order inference can be approximated from the compiled result in polynomial time. A tractable method is proposed to realize this framework. It guarantees that the compiled result has a polynomial size. Experimental results show that the proposed method computes the exact intended sub-ontology for almost all test cases, while it is significantly more efficient and scalable than state-of-the-art exact methods.","cites":"0","conferencePercentile":"20.78651685"},{"venue":"Web Intelligence","id":"53ada0f6ea0affc2e488566bcee308c8c956b3a9","venue_1":"Web Intelligence","year":"2009","title":"Model for Voter Scoring and Best Answer Selection in Community Q&A Services","authors":"Chung Tong Lee, Eduarda Mendes Rodrigues, Gabriella Kazai, Natasa Milic-Frayling, Aleksandar Ignjatovic","author_ids":"2412890, 1704549, 1688470, 1780840, 3188770","abstract":"Community Question Answering (cQA) services, such as Yahoo! Answers and MSN QnA, facilitate knowledge sharing through question answering by an online community of users. These services include incentive mechanisms to entice participation and self-regulate the quality of the content contributed by the users. In order to encourage quality contributions, community members are asked to nominate the &#8216;best&#8217; among the answers provided to a question. The service then awards extra points to the author who provided the winning answer and to the voters who cast their vote for that answer. The best answers are typically selected by plurality voting, a scheme that is simple, yet vulnerable to random voting and collusion. We propose a weighted voting method that incorporates information about the voters&#8217; behavior. It assigns a score to each voter that captures the level of agreement with other voters. It uses the voter scores to aggregate the votes and determine the best answer. The mathematical formulation leads to the application of the Brouwer Fixed Point Theorem which guarantees the existence of a voter scoring function that satisfies the starting axiom. We demonstrate the robustness of our approach through simulations and analysis of real cQA service data.","cites":"9","conferencePercentile":"85.47008547"},{"venue":"Web Intelligence","id":"4047e9ba3cdbc11a703fd0b3026ee66333d1f46c","venue_1":"Web Intelligence","year":"2005","title":"Providing Expert Advice by Analogy for On-Line Help","authors":"Henry Lieberman, Ashwani Kumar","author_ids":"1695083, 1771372","abstract":"One of the principal problems of online help is the mismatch between the specialized knowledge and technical vocabulary of experts who are providing the help, and the relative na&#239;vet&#233; of novices, who usually are often not in a position to understand solutions expressed by the expert in their own terms. Most of the interfaces are plagued by recurrent key problems: 1) elicitation ¿ how to ask questions that enable the helper to make decisions, and at the same time, are understandable to the novice, and 2) explanation ¿ how to explain rationale behind expert decisions in terms that the user can understand. One of the best ways to do this is for the expert to provide analogies in terms of Commonsense knowledge, which provide metaphors that help novices learn problem-solving skills. SuggestDesk is a system that acts as an advisor to an online technical support person. It uses a large Commonsense knowledge base to search for analogies between known technical problem-solution pairs, and situations and events in everyday life that can be used to explain them.","cites":"13","conferencePercentile":"88.23529412"},{"venue":"Web Intelligence","id":"5a2caef8981dbd5dc09b29a36ae29c36f8f29a65","venue_1":"Web Intelligence","year":"2005","title":"Opportunities from Open Source Search","authors":"Wray L. Buntine, Karl Aberer, Ivana Podnar Zarko, Martin Rajman","author_ids":"1854608, 1751802, 1700129, 1763338","abstract":"Internet search has a strong business model that permits a free service to users, so it is difficult to see why, if at all, there should be open source offerings as well. This paper first discusses open source search, and a rationale for the computer science community at large to get involved. Because there is no shortage of core open source components for at least some of the tasks involved, the Alvis Consortium is building infrastructure for open source search engines using peer-to-peer and subject specific technology as its core, based on this rationale. We view open source search as a rich future playground in which information extraction and retrieval components can be used and intelligent agents can operate.","cites":"8","conferencePercentile":"79.08496732"},{"venue":"Web Intelligence","id":"8c15c3b7d9ac861f19e20d0e22a8044b788be619","venue_1":"Web Intelligence","year":"2015","title":"On the emergence of semantic agreement among rational agents","authors":"Golnaz Vakili, Thanasis G. Papaioannou, Karl Aberer","author_ids":"2807948, 1766169, 1751802","abstract":"Today's complex online applications often require the interaction of multiple (web) services that belong to potentially different business entities. Interoperability is a core element of such an environment, yet not a straightforward one due to the lack of common data semantics. The problem is often approached by means of standardization procedures in a top-down manner with limited adoption in practice. (De facto) standards for semantic interoperability most commonly emerge in a bottom-up approach, i.e., involving the interaction and information exchange among self-interested industrial agents. In this paper, we argue that the emergence of semantic interoperability can be seen as an economic process among rational agents and, although interoperability can be mutually beneficial for the involved parties, it may also be costly and might fail to emerge. As a sample scenario, we consider the emergence of semantic interoperability among rational web service agents in service-oriented architectures (SOAs), and we analyze their individual economic incentives with respect to utility, risk and cost. We model this process as a positive-sum game and study its equilibrium and evolutionary dynamics. According to our analysis, which is also experimentally verified, certain conditions on the communication cost, the cost of technological adaptation, the expected mutual benefit from interoperability, as well as the expected loss from isolation, drive the process.","cites":"0","conferencePercentile":"50"},{"venue":"Web Intelligence","id":"c28882863d9970d491fa3ffbbf6aeaf9dc00da56","venue_1":"Web Intelligence","year":"2005","title":"Learning from Ontologies for Common Meaningful Structures","authors":"Liu Yang, Guojie Li, Zhongzhi Shi","author_ids":"1745614, 5480774, 7947558","abstract":"We put forward a hypothesis that there exist common meaningful structures among ontologies whose domains are analogous to each other. The initial motivation of our hypothesis is to make full use of the structural information in existing ontologies, in order to benefit the domain of ontology. To verify the hypothesis we give a precise definition of the candidate of the common meaningful structure called MICISO (Maximum Isomorphic Common Induced Sub-Ontology). Based on the hypothesis and the definition we present a novel data mining problem called MICISO mining, whose aim is learning from ontologies to find out MICISOs and further recommend the common meaningful structures. We also provide an algorithm for MICISO mining, based on which we have developed a practical tool for mining and checking such structures. With the tool, the algorithm is implemented with quite a few pairs of existing ontologies, and the interesting meaningful results support our hypothesis. Thus we consider that the hypothesis is preliminarily verified. We suppose that our work will spark a novel promising thinking for the domain of ontology ¿ to study existing ontologies for useful things.","cites":"0","conferencePercentile":"9.477124183"},{"venue":"Web Intelligence","id":"938540c957f3613fa2fc84741957a32dbafbd6af","venue_1":"Web Intelligence","year":"2006","title":"Geographic Named Entity Disambiguation with Automatic Profile Generation","authors":"Yefei Peng, Daqing He, Ming Mao","author_ids":"1740361, 1725184, 1844146","abstract":"Knowledge rich approach of processing documents has been viewed as a method to improve over simple bag-of-word representation. Extracting location information from documents and link them to some ontology such as world gazetteer through a disambiguation process becomes an interesting and important topic. Lacking of training data is a problem in disambiguation method. In this paper we described a method to automatically extract training data from large collection of documents based on local context disambiguation, and then sense profiles are generated automatically for disambiguation use. Another topic of this paper is to describe a linear combination method to combine different types of evidences of disambiguation. We explored three different evidences including location sense context in training documents, local neighbor context, and the popularity of individual location sense. Our results show that combining the three evidences generates reasonable results.","cites":"3","conferencePercentile":"27.5"},{"venue":"Web Intelligence","id":"c6bce51e62262e14a6a83b850cc4e8587c33c50a","venue_1":"Web Intelligence","year":"2008","title":"Overlapping Community Detection in Bipartite Networks","authors":"Nan Du, Bai Wang, Bin Wu, Yi Wang","author_ids":"1714086, 1735282, 6023931, 3321023","abstract":"Recent researches have discovered that rich interactions among entities in nature and human society bring about complex networks with community structures. In this paper, we propose a novel algorithm BiTector (Bi-community DeTector) to mine the overlapping communities in large-scale sparse bipartite networks. We apply the algorithm to various real-world datasets, showing that BiTector can identify the overlapping community structures in the bipartite networks efficiently and effectively.","cites":"14","conferencePercentile":"93.63636364"},{"venue":"Web Intelligence","id":"2e46d04aa677db82174bf309fe5e6f3b7f35a780","venue_1":"Web Intelligence","year":"2007","title":"Backbone Discovery in Social Networks","authors":"Nan Du, Bin Wu, Bai Wang","author_ids":"1714086, 6023931, 1735282","abstract":"Although using ontologies to assist information retrieval and text document processing has recently attracted more and more attention, existing ontologybased approaches have not shown advantages over the traditional keywords-based Latent Semantic Indexing (LSI) method. This paper proposes an algorithm to extract a concept forest (CF) from a document with the assistance of a natural language ontology, the WordNet lexical database. Using concept forests to represent the semantics of text documents, the semantic similarities of these documents are then measured as the commonalities of their concept forests. Performance studies of text document clustering based on different document similarity measurement methods show that the CF-based similarity measurement is an effective alternative to the existing keywords-based methods. In particular, this CFbased approach has obvious advantages over the existing keywords-based methods, including LSI, in processing short text documents or in P2P or live news environments where it is impractical to collect the entire document corpus for analysis.","cites":"2","conferencePercentile":"38.14814815"},{"venue":"Web Intelligence","id":"e2ff9d079f40661972e8d4c7a1ea53a9d8873c89","venue_1":"Web Intelligence","year":"2007","title":"Using Novel IR Measures to Learn Optimal Cluster Structures for Web Information Retrieval","authors":"Martin Mehlitz, Jérôme Kunegis, Sahin Albayrak","author_ids":"1963887, 1697769, 1722170","abstract":"We present in this article a theoretical framework for customizable Web services description, discovery and composition based on an attributive formalism.","cites":"1","conferencePercentile":"23.7037037"},{"venue":"Web Intelligence","id":"8b53aef52482a4cfd80cdfbbac39c08273e26672","venue_1":"Web Intelligence","year":"2007","title":"An unsupervised hierarchical approach to document categorization","authors":"Robert Wetzker, Tansu Alpcan, Christian Bauckhage, Winfried Umbrath, Sahin Albayrak","author_ids":"3184596, 1736599, 1692283, 2518435, 1722170","abstract":"We propose Perseus, a personalized reputation system. In Perseus, reputations comprise of three aspects: how much I personally trust another individual, how trustworthy others think the individual is, and how much I trust the opinions of others. Perseus is adaptive in the sense that user feedback is used to modify the way the different aspects are considered. We also present simulation experiments, which indicate that Perseus is robust and able to survive under extreme conditions of misbehavior. In addition, Perseus encourages individuals to rate the other party and give fair ratings. We also compare Perseus against other well-known reputation systems.","cites":"6","conferencePercentile":"71.85185185"},{"venue":"Web Intelligence","id":"35208e55c6f014032d0c632b317426bb9d61629d","venue_1":"Web Intelligence","year":"2008","title":"Relation Classification for Semantic Structure Annotation of Text","authors":"Yulan Yan, Yutaka Matsuo, Mitsuru Ishizuka, Toshio Yokoi","author_ids":"1786972, 1692267, 1687719, 1784765","abstract":"Confronting the challenges of annotating naturally occurring text into a semantically structured form to facilitate automatic information extraction, current Semantic Role Labeling (SRL) systems have been specifically examining a semantic predicate-argument structure. Based on the Concept Description Language for Natural Language (CDL.nl) which is intended to describe the concept structure of text using a set of pre-defined semantic relations, we develop a parser to add a new layer of semantic annotation of natural language sentences as an extension of SRL. With the assumption that all relation instances are detected, we present a relation classification approach facing the challenges of CDL.nl relation extraction. Preliminary evaluation on a manual dataset, using Support Vector Machine, shows that CDL.nl relations can be classified with good performance.","cites":"4","conferencePercentile":"61.81818182"},{"venue":"Web Intelligence","id":"379316f0411f1c7cb685fcccb38de95398de733f","venue_1":"Web Intelligence","year":"2007","title":"An Augmented Tagging Scheme with Triple Tagging and Collective Filtering","authors":"Jie Yang, Yutaka Matsuo, Mitsuru Ishizuka","author_ids":"2081112, 1692267, 1687719","abstract":"Online transactional activities that involve establishment of trust between participating individual seem to require a reputation function for the reputation estimation framework (REF). They are often vulnerable to various kinds of attacks. Also it seems we do not evaluate reputation in the same way in all situations. Using Occam's razor we propose a generalized set-theoretic reputation function with customizable components that can be changed to meet the reputation requirements in wide variety of reputation assessment scenarios. Further we identify several canonical classes of the functions. The resilience of the framework is then analyzed by subjecting it to various reputation attacks such as gang attacks, vendetta and Dr Jekyll &amp; Mr. Hyde.","cites":"1","conferencePercentile":"23.7037037"},{"venue":"Web Intelligence","id":"923d7a99e0778526f2bb6e6a0c70c0cd1738d7d9","venue_1":"Web Intelligence","year":"2003","title":"Mining Social Network of Conference Participants from the Web","authors":"Yutaka Matsuo, Hironori Tomobe, Kôiti Hasida, Mitsuru Ishizuka","author_ids":"1692267, 2884208, 1752952, 1687719","abstract":"In a ubiquitous computing environment, it is desirable to provide a user with information depending on a user's situation, such as time, location, user behavior, and social context. At conventions, such as academic conferences and exhibitions, where participants must register in advance, the social context of participants can be extracted from the Web using their names and affiliations without asking the participants many questions. In this paper, we attempt to extract the social network of participants from the Web, where a node represents a participant and an edge represents the relationship of two participants. Each edge is added using the number of pages retrieved by a search engine which include both participants names. Moreover, each edge has a label such as \" co-authors \" and \" members of the same project \" by applying classification rules to the page content. We show an example of the extracted network and make a preliminery evaluation. This network can be used in many information services, such as finding an appropriate introducer or negotiater, and who one should talk to in order to efficiently expand his/her network.","cites":"16","conferencePercentile":"77.55102041"},{"venue":"Web Intelligence","id":"e24057948861ebb6172ab760a3da8515ae06d7ab","venue_1":"Web Intelligence","year":"2011","title":"Measuring Comprehensibility of Web Pages Based on Link Analysis","authors":"Kouichi Akamatsu, Nimit Pattanasri, Adam Jatowt, Katsumi Tanaka","author_ids":"1760522, 3318133, 1774986, 1750132","abstract":"We put forward a hypothesis that if there is a link from one page to another, it is likely that comprehensibility of the two pages is similar. To investigate whether this hypothesis is true or not, we conduct experiments using existing readability measures. We investigate the relationship between links and readability of text extracted from web pages for two datasets, set of English and Japanese pages. We could find that links and readability of text extracted from web pages are correlated. Based on the hypothesis, we propose a link analysis algorithm to measure comprehensibility of web pages. Our method is based on the Trust Rank algorithm which is originally used for combating web spam. We use link structure to propagate readability scores from source pages selected based on their comprehensibility. The results of experimental evaluation demonstrate that our method could improve estimation of comprehensibility of pages.","cites":"5","conferencePercentile":"83.72093023"},{"venue":"Web Intelligence","id":"0a70342c7b72ab35404d27af620efffd865bb742","venue_1":"Web Intelligence","year":"2009","title":"The Geographical Life of Search","authors":"Ricardo A. Baeza-Yates, Christian Middleton, Carlos Castillo","author_ids":"1747635, 2351596, 3747087","abstract":"This article describes a geographical study on the usage of a search engine, focusing on the traffic details at the level of countries and continents. The main objective is to understand from a geographic point of view, how the needs of the users are satisfied, taking into account the geographic location of the host in which the search originates, and the host that contains the Web page that was selected by the user in the answers. Our results confirm that the Web is a cultural mirror of society and shed light on the implicit social network behind search. These results are also useful as input for the design of distributed search engines.","cites":"6","conferencePercentile":"75.64102564"},{"venue":"Web Intelligence","id":"2418b8e9265a65099bf7a99add2f138a153e26fb","venue_1":"Web Intelligence","year":"2007","title":"Ontology-based Integration and Retrieval over Multiple Quantities - What if \"Ovate leaves and often blue to purple flowers\"","authors":"Shenghui Wang, Jeff Z. Pan","author_ids":"3328645, 1704953","abstract":"Many information retrieval and machine learning methods have not evolved in order to be applied to the Web. Two main problems in applying some machine learning techniques for Web mining are the dynamic and ever-changing nature of Web data and the sheer size of possible dimensions that this data could portray. One such technique, self-organizing maps (SOMs), have been enhanced to deal with these two problems individually. The growing hierarchical self-organizing map can adapt to the dynamic data present on the Web by changing its topology according to the amount of change in input size. In addition, it reduces local dimensionality by splitting features into levels. We extend this model by including bidirectional update propagation over the levels of the hierarchy. We demonstrate the effectiveness of the new approach with a Web-based news coverage example.","cites":"0","conferencePercentile":"7.777777778"},{"venue":"Web Intelligence","id":"9e0b65ae709e5da586db0452b9ea0593c68d0c24","venue_1":"Web Intelligence","year":"2005","title":"Cache Replacement for Transcoding Proxy Caching","authors":"Keqiu Li, Keishi Tajima, Hong Shen","author_ids":"2668171, 2792621, 1729670","abstract":"In this paper, we address the problem of cache replacement for transcoding proxy caching. First, an efficient cache replacement algorithm is proposed. Our algorithm considers both the aggregate effect of caching multiple versions of the same multimedia object and cache consistency. Second, a complexity analysis is presented to show the efficiency of our algorithm. Finally, some preliminary simulation experiments are conducted to compare the performance of our algorithm with some existing algorithms. The results show that our algorithm outperforms others in terms of the various performance metrics.","cites":"8","conferencePercentile":"79.08496732"},{"venue":"Web Intelligence","id":"0d1af6e2a95a149352f04c3714d0d05a16a5b96a","venue_1":"Web Intelligence","year":"2010","title":"The Effects of Query Bursts on Web Search","authors":"Ilija Subasic, Carlos Castillo","author_ids":"2448620, 3747087","abstract":"A query burst is a period of heightened interest of users on a topic which yields a higher frequency of the search queries related to it. In this paper we examine the behavior of search engine users during a query burst, compared to before and after this period. The purpose of this study is to get insights about how search engines and content providers should respond to a query burst. We analyze one year of web-search logs, looking at query bursts from two perspectives. First, we adopt the user's perspective describing changes in user's effort and interest while searching. Second, we look at the burst from the general content providers' view, answering the question of under which conditions a content provider should ``ride'' a wave of increased interest to obtain a significant share of clicks.","cites":"9","conferencePercentile":"91.10169492"},{"venue":"Web Intelligence","id":"2c881db95cb3d69d3ce34c0acb7cf038866395cc","venue_1":"Web Intelligence","year":"2008","title":"Unsupervised Discovery of Coordinate Terms for Multiple Aspects from Search Engine Query Logs","authors":"Masashi Yamaguchi, Hiroaki Ohshima, Satoshi Oyama, Katsumi Tanaka","author_ids":"5738181, 1698449, 1740955, 1750132","abstract":"A method is described for discovering coordinate terms, such as \"Honda'' and \"Nissan,'' for a given term, such as \"Toyota,'' as well as their common topic terms, from the query logs of a Web search engine. Coordinate terms are good candidates for use in making comparisons. A HITS-based algorithm is applied to a bipartite graph between coordinate term candidates and co-occurrence patterns to identify coordinate and topic terms. Spectral analysis is used to distinguish coordinate terms corresponding to different aspects of the search term. As a result, we can discover terms related to the terms in a search engine query that reflect the needs and interests of the user.","cites":"5","conferencePercentile":"68.48484848"},{"venue":"Web Intelligence","id":"b1fa5ad9d12581d830d678cf955525d379517e1c","venue_1":"Web Intelligence","year":"2009","title":"Magrathea: Building and Analyzing Ubiquitous and Social Systems","authors":"Jukka Perkiö, Petri Myllymäki","author_ids":"2813281, 1699156","abstract":"Ubiquitous systems are rapidly becoming a more and more commonplace part of our everyday life. These systems may contain different classes of very heterogeneous components that have to function seamlessly together. A prime example of a class of ubiquitous components is given by the personal mobile devices. They are all pervasive and emerge in many forms: mobile handsets, PDAs, etc. Their features and computational powers make them a very capable platform. We present a pervasive agent- and sensing platform Magrathea that can be run on different kinds of computational devices. Magrathea can be used to build complex pervasive systems. As a practical example of the usage of this platform, we use it on top of personal mobile devices to investigate the structure of social networks of different individuals and to simulate viral behavior of agents. We also discuss analytical tools to further investigate, model and simulate the data obtained through our platform.","cites":"0","conferencePercentile":"8.974358974"},{"venue":"Web Intelligence","id":"7520f46ab84ceaafa5e1490bd0eaa748e4c28b58","venue_1":"Web Intelligence","year":"2006","title":"Temporal Analysis of the Wikigraph","authors":"Luciana S. Buriol, Carlos Castillo, Debora Donato, Stefano Leonardi, Stefano Millozzi","author_ids":"2959698, 3747087, 2485865, 1695327, 2040285","abstract":"— Wikipedia (www.wikipedia.org) is an online encyclopedia , available in more than 100 languages and comprising over 1 million articles in its English version. If we consider each Wikipedia article as a node and each hyperlink between articles as an arc we have a \" Wikigraph \" , a graph that represents the link structure of Wikipedia. The Wikigraph differs from other Web graphs studied in the literature by the fact that there are timestamps associated with each node. The timestamps indicate the creation and update dates of each page, and this allows us to do a detailed analysis of the Wikipedia evolution over time. In the first part of this study we characterize this evolution in terms of users, editions and articles; in the second part, we depict the temporal evolution of several topological properties of the Wikigraph. The insights obtained from the Wikigraphs can be applied to large Web graphs from which the temporal data is usually not available.","cites":"53","conferencePercentile":"98.33333333"},{"venue":"Web Intelligence","id":"31a2304156c04028c0a75d36c3feedd221cd21c0","venue_1":"Web Intelligence","year":"2008","title":"Extracting Concept Hierarchy Knowledge from the Web Based on Property Inheritance and Aggregation","authors":"Shun Hattori, Katsumi Tanaka","author_ids":"2917219, 1750132","abstract":"Concept hierarchy knowledge, such as hyponymy and meronymy, is very important for various natural language processing systems. While WordNet and Wikipedia are being manually constructed and maintained as lexical ontologies, many researchers have tackled how to extract concept hierarchies from very large corpora of text documents such as the Web not manually but automatically. However, their methods are mostly based on lexico-syntactic patterns as not necessary but sufficient conditions of hyponymy and meronymy, so they can achieve high precision but low recall when using stricter patterns or they can achieve high recall but low precision when using looser patterns. Therefore, we need necessary conditions of hyponymy and meronymy to achieve high recall and not low precision. In this paper, not only \"Property Inheritance'' from a target concept to its hyponyms but also \"Property Aggregation'' from its hyponyms to the target concept is assumed to be necessary and sufficient conditions of hyponymy, and we propose a method to extract concept hierarchy knowledge from the Web based on property inheritance and property aggregation.","cites":"8","conferencePercentile":"82.12121212"},{"venue":"Web Intelligence","id":"61a14dc0efbefd19cefc36eac1fbe67d130f1792","venue_1":"Web Intelligence","year":"2007","title":"An Approach to Web Page Classification based on Granules","authors":"Qiguo Duan, Duoqian Miao, Ruizhi Wang, Min Chen","author_ids":"2225548, 1796776, 3325594, 1711628","abstract":"Human Computer Interaction (HCI) challenges in mobile computing can be addressed by tailoring access and use of mobile services to user preferences. Our investigation of existent approaches to personalisation in context-aware computing found that user preferences are assumed to be static across different context descriptions, whilst in reality some user preferences are transient and vary with the change in context. Furthermore, existent preference models do not give an intuitive interpretation of a preference and lack user expressiveness. To tackle these issues, this paper presents a user preference model and mining framework for a context-aware m-services environment based on an intuitive quantitative preference measure and a strict partial order preference representation. Experimental evaluation of the user preference mining framework in a simulated m-Commerce environment showed that it is very promising. The preference mining algorithms were found to scale well with increases in the volumes of data.","cites":"2","conferencePercentile":"38.14814815"},{"venue":"Web Intelligence","id":"c3edb5f31cb911d1891c47776ab0ee9297ecde88","venue_1":"Web Intelligence","year":"2007","title":"Distance Measures in Query Space: How Strongly to Use Feedback From Past Queries","authors":"Nicolas Neubauer, Christian Scheel, Sahin Albayrak, Klaus Obermayer","author_ids":"2768316, 1757966, 1722170, 1743272","abstract":"At this point, restricted to rather specialized areas, and even there must be taken with a grain of salt. But at the same time you can't afford not to know it; there is currently no better underpinning for understanding multiagent systems. I will elaborate using experience in both academia and industry.","cites":"2","conferencePercentile":"38.14814815"},{"venue":"Web Intelligence","id":"855a48c806c8d7a9a90a497a2d8284ecdc39fa02","venue_1":"Web Intelligence","year":"2010","title":"Agent-Based Online Quality Measurement Approach in Cloud Computing Environment","authors":"Zhenyu Liu, Tiejiang Liu, Tun Lu, Lizhi Cai, Genxing Yang","author_ids":"1785273, 1880229, 1711569, 2078139, 2198315","abstract":"This paper studies online quality measurement in cloud computing environment. The paper analyzes concentration measure evaluation method of the current software quality evaluation system. As is known to all, the existing evaluation technology uses concentrated evaluation before run-time. By testing and analyzing results, the quality is obtained. In this paper, by analyzing the features in cloud computing environment, we consider that service-oriented evaluation should be mainly based on runtime online measurement. The paper puts forward agent-based online measure infrastructure, which is evaluated by distributed assessment in service computing environment A quality model and corresponding online data collection strategy are described. In this approach, the previous quality evaluation, which is concentrated and simulating in a simulated environment, is substituted. Then, a novel measure method of quality data acquisition, which is based on distributed agent technology, is established. So, during online service operation, the obtained data can make measurement results to be accurate and credible.","cites":"2","conferencePercentile":"51.27118644"},{"venue":"Web Intelligence","id":"b555121498388620300ed6263f8361a46fe011c0","venue_1":"Web Intelligence","year":"2012","title":"Statistical and Structural Analysis of Web-Based Collaborative Knowledge Bases Generated from Wiki Encyclopedia","authors":"Yi Zeng, Hao Wang, Hongwei Hao, Bo Xu","author_ids":"3482173, 1728073, 7411492, 1749224","abstract":"Web-based collaborative knowledge bases collect human knowledge through the Web. They can be used for answering questions or support different knowledge intensive applications on the Web. From a statistical point of view, they usually reveal some interesting characteristics, which can be acquired through statistical analysis to get deeper understanding of these kinds of knowledge bases. In this paper, we build a semantic knowledge base using the triples extracted from a Chinese wiki Web site called Baidu Baike. We make an investigation on the statistical results on the building process and structural characteristics of this knowledge base. We explain what we have observed and inferred and how the conclusion can help to understand the process of building large scale Web based collaborative knowledge bases and how to make them better.","cites":"0","conferencePercentile":"20.78651685"},{"venue":"Web Intelligence","id":"68ed4f34b16c9e917df3f7f105d81c047347a5db","venue_1":"Web Intelligence","year":"2012","title":"From DBpedia to Wikipedia: Filling the Gap by Discovering Wikipedia Conventions","authors":"Diego Torres, Pascal Molli, Hala Skaf-Molli, Alicia Díaz","author_ids":"8048128, 3025899, 1830003, 2813225","abstract":"Many relations existing in DBpedia are missing in Wikipedia yielding up an information gap between the semantic web and the social web. Inserting these missing relations requires to automatically discover Wikipedia conventions. From pairs linked by a property p in DBpedia, we find path queries that link the same pairs in Wikipedia. We make the hypothesis that the shortest path query with maximal containment captures the Wikipedia convention for p. We computed missing links and conventions for different DBpedia queries. Next, we inserted some missing links according to computed conventions in Wikipedia and evaluated Wikipedians feedback. Nearly all contributions has been accepted. In this paper, we detail the path indexing algorithms, the results of evaluations and give some details about social feedback.","cites":"1","conferencePercentile":"53.93258427"},{"venue":"Web Intelligence","id":"015a28032f15d551e91a9aebba2d20274ce1940b","venue_1":"Web Intelligence","year":"2005","title":"Recommending Trade Exhibitions by Integrating Semantic Information with Collaborative Filtering","authors":"Xuetao Guo, Jie Lu","author_ids":"1865377, 1685235","abstract":"Recommender systems have gained successfully applications for the past ten years, particular in E-commerce domain. However, existing recommendation approaches can not effectively deal with recommendation issue of one-and-only items occurred in government-to-business services, e.g. recommendation of trade exhibitions. Thus, in this study, we propose a novel approach by integrating semantic information with the traditional item-based collaborative filtering, and attempt to help the businesses choose the right trade exhibitions at the right time. The outcome of this study will have tremendous significance in overcoming the &#253;new item&#253; problem of existing recommendation approaches.","cites":"1","conferencePercentile":"25.81699346"},{"venue":"Web Intelligence","id":"6b37b6ad46046e1e517a34119193511e39d48a1d","venue_1":"Web Intelligence","year":"2010","title":"Estimating News Coverage of Web Search Results","authors":"Adam Jatowt, Yukiko Kawai, Katsumi Tanaka","author_ids":"1774986, 1700611, 1750132","abstract":"The abundance of content on the web and the lack of quality control require more refined approaches in analyzing online information. In this paper, we propose evaluating the extent to which web search results cover important and recent news related to real-world objects. Our method allows for identifying search results that provide comprehensive overviews of major events related to user queries or that contain most recent information.","cites":"1","conferencePercentile":"34.3220339"},{"venue":"Web Intelligence","id":"3d6f5e78ac4f0f572ca3561b7ce2d528d42b5681","venue_1":"Web Intelligence","year":"2011","title":"Semdrops: A Social Semantic Tagging Approach for Emerging Semantic Data","authors":"Diego Torres, Alicia Díaz, Hala Skaf-Molli, Pascal Molli","author_ids":"8048128, 2813225, 1830003, 3025899","abstract":"This paper proposes a collective intelligence strategy for emerging semantic data. It presents a combination of social web practices with semantic web technologies to enrich existing web resources with semantic data. The paper introduces a social semantic tagging approach called Semdrops. Semdrops defines a conceptual model which is an extension of the Gruber's tag model where the tag concept is extended to semantic tag. Semdrops is implemented as a Firefox add-on tool that turns the web browser into a collaborative semantic data editor. To validate Semdrops's approach, we conducted an evaluation and usability studies and compared the results with automatic generation methods of semantic data such as DBpedia. The studies demonstrated that Semdrops is an effective and complementary approach to produce adequate semantic data on the Web.","cites":"5","conferencePercentile":"83.72093023"},{"venue":"Web Intelligence","id":"af457e095799ff38b2e338ac34a038b90d03263a","venue_1":"Web Intelligence","year":"2011","title":"Improving Retrieval of Future-Related Information in Text Collections","authors":"Kensuke Kanazawa, Adam Jatowt, Katsumi Tanaka","author_ids":"1780505, 1774986, 1750132","abstract":"People often want to know expected future events related to given real world entities. For supporting users in the process of future scenario analysis, we propose several methods that enable to retrieve and analyze future-related opinions from large text collections. In particular, we focus on time-unreferenced predictions, which do not contain any explicit future time reference and hence are more difficult to be retrieved. As a second contribution, we propose estimating validity of predictions by automatically searching for real world events corresponding to the predictions. This kind of analysis aims to help detect predictions that are no longer valid as well as help estimating prediction accuracy of information sources.","cites":"3","conferencePercentile":"64.53488372"},{"venue":"Web Intelligence","id":"5f4a2f0f7ca904e1c054fbc3249a742aa75ac1dc","venue_1":"Web Intelligence","year":"2011","title":"Detecting Intent of Web Queries Using Questions and Answers in CQA Corpus","authors":"Soungwoong Yoon, Adam Jatowt, Katsumi Tanaka","author_ids":"3279934, 1774986, 1750132","abstract":"Detecting intent in Web search activity is important task for finding relevant Web information. However extracting intents from users' queries is difficult as users express their intent by issuing short and often ambiguous queries, yet at the same time it is crucial factor for enhancing user satisfaction. Showing the variety of candidate intents behind a query could help users choose correct intent expressions and improve the Web search. In this paper, we propose the methodology for detecting intent of Web queries using Community Question-Answer (CQA)information. Our assumption is that questions and its answers in CQA corpus reflect intents of questioners. To detect these intents, we use the semantic connections between questions and its answers. We categorize questions to find the connections of features within a question and its answers, detect intent words in answers by calculating supports of concerned CQA contents, and cluster questions and their answers by these intent words. Experimental results show that the variety of Web query intents can be found with satisfactory performance.","cites":"1","conferencePercentile":"31.39534884"},{"venue":"Web Intelligence","id":"6d4229f81b19c36b27357b3351bbe7cd88d49db8","venue_1":"Web Intelligence","year":"2011","title":"\"Read\" More from Business Cards: Toward a Smart Social Contact Management System","authors":"Bin Guo, Daqing Zhang, Dingqi Yang","author_ids":"1836820, 4368063, 1787549","abstract":"The ability to leverage the power of a network of social contacts is important to get things done. However, as the number of contacts increases, people often find it difficult to maintain their contact network by using merely memory, and are frequently encompassed with questions like \"who is that person, I met him in Tokyo last year\". Existing contact tools make up for the shortage of unreliable human memory by storing contact information in the digital format, but laying much burden on users on manually inputting contact data. This paper, however, presents a social contact management system called SCM, which supports the auto-collection of rich contact data by exploring the aggregated power of pervasive sensing and Web intelligence techniques. Regarding that people often need to leverage several associated things (e.g., meeting location) to fetch other information about a contact (e.g., his name), we also develop an associative contact retrieval method. The effectiveness and runtime performance of our system is validated through a set of experiments.","cites":"4","conferencePercentile":"75.58139535"},{"venue":"Web Intelligence","id":"bdb0f345dda63ae859d62e0deb4090196f3e0427","venue_1":"Web Intelligence","year":"2013","title":"OnPerDis: Ontology-Based Personal Name Disambiguation on the Web","authors":"Zhao Lu, Zhixian Yan, Liang He","author_ids":"7721665, 7833657, 1765426","abstract":"With the growth of web documents, the ambiguity of personal name becomes more common and brings poor performance of web search. Identifying a correct personal entity from the a piece of or the whole document is still a very challenging problem, especially for Chinese websites. In this paper, we propose a novel Ontology-based approach for Personal Name Disambiguation (named \"OnPerDis\"). This approach has two main steps: first, we construct person ontology (PO) with rich conceptual modeling as well as a large set of supporting instances, second, for a given personal name on the web, we create a temporary instance and extract features from the web documents, calculate the similarity between this temporary instance and the instances in the PO. The one with the highest similarity score is chosen as the appropriate personal name. Our extensive evaluations with two rich real-life datasets (CIPS-SIGHAN 2012 NERD and Chinese web documents) shows OnPerDis' efficacy on personal name disambiguation on the Web.","cites":"2","conferencePercentile":"68.82352941"},{"venue":"Web Intelligence","id":"03f787cefb73e7036b8de99e226b51952d32bcff","venue_1":"Web Intelligence","year":"2009","title":"FaSet: A Set Theory Model for Faceted Search","authors":"Dario Bonino, Fulvio Corno, Laura Farinetti","author_ids":"1806604, 1712546, 3141797","abstract":"Faceted classification is a technique originated and refined in the library science field, that recently gained a lot of attention for creating efficient search interfaces for web databases. Faceted search requires the definition of a formal representation model, a search algorithm and a responsive user interface. This paper proposes FaSet, a representation model and search algorithm supporting the implementation of faceted search engines. FaSet relies on set theory, and strikes a good balance between expressive power and ease of implementation on web architectures. The paper presents the formal definition of the model, search and ranking algorithms, and a relational mapping of data structures and algorithms that enables its efficient implementation.","cites":"1","conferencePercentile":"29.48717949"},{"venue":"Web Intelligence","id":"00906ce8f3d422568c08b462a1a2dc79d867947e","venue_1":"Web Intelligence","year":"2009","title":"From \"Dango\" to \"Japanese Cakes\": Query Reformulation Models and Patterns","authors":"Paolo Boldi, Francesco Bonchi, Carlos Castillo, Sebastiano Vigna","author_ids":"1733343, 1705764, 3747087, 1737624","abstract":"Understanding query reformulation patterns is a key step towards next generation web search engines: it can help improving users' web-search experience by predicting their intent, and thus helping them to locate information more effectively. As a step in this direction, we build an accurate model for classifying user query reformulations into broad classes (generalization, specialization, error correction or parallel move), achieving 92\\% accuracy. We apply the model to automatically label two large query logs, creating annotated query-flow graphs. We study the resulting reformulation patterns, finding results consistent with previous studies done on smaller manually annotated datasets, and discovering new interesting patterns, including connections between reformulation types and topical categories. Finally, applying our findings to a third query log that is publicly available for research purposes, we demonstrate that our reformulation classifier leads to improved recommendations in a query recommendation system.","cites":"50","conferencePercentile":"100"},{"venue":"Web Intelligence","id":"ca99b12156d8e005220ed3d0f8e353400c95d105","venue_1":"Web Intelligence","year":"2012","title":"Semantic Labelling for Document Feature Patterns Using Ontological Subjects","authors":"Xiaohui Tao, Yuefeng Li, Bin Liu, Yan Shen","author_ids":"2676424, 7771192, 1702756, 2044879","abstract":"Finding and labelling semantic features patterns of documents in a large, spatial corpus is a challenging problem. Text documents have characteristics that make semantic labelling difficult, the rapidly increasing volume of online documents makes a bottleneck in finding meaningful textual patterns. Aiming to deal with these issues, we propose an unsupervised documnent labelling approach based on semantic content and feature patterns. A world ontology with extensive topic coverage is exploited to supply controlled, structured subjects for labelling. An algorithm is also introduced to reduce dimensionality based on the study of ontological structure. The proposed approach was promisingly evaluated by compared with typical machine learning methods including SVMs, Rocchio, and kNN.","cites":"0","conferencePercentile":"20.78651685"},{"venue":"Web Intelligence","id":"f7511bc90c42cb4f2574a57d484d532baf162221","venue_1":"Web Intelligence","year":"2012","title":"Inferring User Interest Using Familiarity and Topic Similarity with Social Neighbors in Facebook","authors":"Dabi Ahn, Taehun Kim, Soon J. Hyun, Dongman Lee","author_ids":"1896711, 2854768, 2928684, 1724024","abstract":"Uncovering user interest plays an important role to develop personalized systems in various fields including the Web and pervasive computing. In particular, online social networks (OSNs) are being spotlighted as the means to understand users' social behavior out of abundant online social information. In this paper, we explore a computational method of inferring user interest in Facebook by combining the degree of familiarity and topic similarity with social neighbors based on social correlation phenomenon. By conducting a question-naire survey, we demonstrate that our proposed method increases the accuracy of inference by 12.4% compared to existing methods which do not consider the latent topic structure implied in social contents.","cites":"2","conferencePercentile":"73.03370787"},{"venue":"Web Intelligence","id":"4a65485292becad479d534b8129e382468107a03","venue_1":"Web Intelligence","year":"2009","title":"In the Mood to Click? Towards Inferring Receptiveness to Search Advertising","authors":"Qi Guo, Eugene Agichtein, Charles L. A. Clarke, Azin Ashkan","author_ids":"5022607, 1685296, 1751287, 1715458","abstract":"We present a method for modeling, and automaticallyinferring, the current interest of a user in searchadvertising. Our task is complementary to that of predictingad relevance or commercial intent of a query in the aggregate, since the user intent may vary significantly for the same query. To achieve this goal, we develop a fine-grained user interaction model for inferring searcher receptiveness to advertising. We show that modeling the search context and behavior can significantly improve the accuracy of ad clickthrough prediction for the current user, compared to the existing state-of-the-artclassification methods that do not model this additional session level contextual and interaction information. In particular, our experiments over thousands of search sessions from hundreds of real users demonstrate that our model is more effective at predicting ad clickthrough within the same search session. Our work has other potential applications, such as improving searchinterface design (e.g., varying the number or type of ads) based on user interest, and behavioral targeting (e.g., identifying users interested in immediate purchase).","cites":"11","conferencePercentile":"88.46153846"},{"venue":"Web Intelligence","id":"154bc2c46228c2335eadfbf10fba64210223dde8","venue_1":"Web Intelligence","year":"2003","title":"Web Image Retrieval Re-Ranking with Relevance Model","authors":"Wei-Hao Lin, Rong Jin, Alexander G. Hauptmann","author_ids":"8131758, 1718400, 7661726","abstract":"Web image retrieval is a challenging task that requires efforts from image processing, link structure analysis, and web text retrieval. Since content-based image retrieval is still considered very difficult, most current large-scale web image search engines exploit text and link structure to \" understand \" the content of the web images. However, local text information, such as caption, filenames and adjacent text, is not always reliable and informative. Therefore, global information should be taken into account when a web image retrieval system makes relevance judgment. In this paper, we propose a re-ranking method to improve web image retrieval by reordering the images retrieved from an image search engine. The re-ranking process is based on a relevance model, which is a probabilistic model that evaluates the relevance of the HTML document linking to the image , and assigns a probability of relevance. The experiment results showed that the re-ranked image retrieval achieved better performance than original web image retrieval, suggesting the effectiveness of the re-ranking method. The relevance model is learned from the Internet without preparing any training data and independent of the underlying algorithm of the image search engines. The re-ranking process should be applicable to any image search engines with little effort.","cites":"40","conferencePercentile":"93.87755102"},{"venue":"Web Intelligence","id":"e2fd8c5a8bd941eb30398bd65a7db968c812158e","venue_1":"Web Intelligence","year":"2004","title":"Text Adaptation for Mobile Digital Teletext","authors":"Chengyuan Peng, Petri Vuorimaa","author_ids":"1713109, 1704368","abstract":"Small and varying screen sizes of mobile devices pose a big problem for digital Teletext service to display its content. It is difficult to display all the text information on a small screen, where page scroll or transparent page to live video is not practical. This paper presents an adaptive text extraction method which can automatically extract key information from original text and keep semantic meanings as close as possible. We combine both statistical methods and coarse coding algorithm from neural science to shorten long text sentences in terms of generalization. The experiment results show that the methods are efficient and effective.","cites":"0","conferencePercentile":"14.4654088"},{"venue":"Web Intelligence","id":"ce5cae998406c1b4224d45c6c8ad041846c0d2eb","venue_1":"Web Intelligence","year":"2007","title":"Question Answering over Implicitly Structured Web Content","authors":"Eugene Agichtein, Christopher J. C. Burges, Eric Brill","author_ids":"1685296, 3158445, 1747743","abstract":"PageRank is an algorithm used by several search engines to rank web documents according to their assumed relevance and popularity deduced from theWeb's link structure. PageRank determines a global ordering of candidate search results according to each page's popularity as determined by the number and importance of pages linking to these results. Personalized and topic-sensitive PageRank are variants of the algorithm that return a local ranking based on each user's preferences as biased by a set of pages they trust or topics they prefer. In this paper we compare personalized and topic-sensitive local PageRanks to the global PageRank showing experimentally how similar or dissimilar results of personalization can be to the original global rank results and to other personalizations. Our approach is to examine a snapshot of the Web and determine how advantageous personalization can be in the best and worst cases and how it performs at various values of the damping factor in the PageRank formula.","cites":"3","conferencePercentile":"50.74074074"},{"venue":"Web Intelligence","id":"0b4790420d319afaf7d47a4dca49881623f1a1a7","venue_1":"Web Intelligence","year":"2009","title":"A Query Substitution-Search Result Refinement Approach for Long Query Web Searches","authors":"Yan Chen, Yanqing Zhang","author_ids":"1700696, 1688104","abstract":"Long queries are widely used in current Web applications, such as literature searches, news searches, etc. However, since long queries are frequently expressed as natural language texts but not keywords, the current keywords-based search engines, like GOOGLE, perform worse with long queries than with short ones. This paper proposes a query substitution and search result refinement approach for long query Web searches. First, we retrieved several short queries related to a long query from the users&#8217; query history. Then, we constructed the short query clusters and selected the most representative queries to substitute the original long query. However, since searching relevant short queries may ignore contexts and terms in the original long query and thus obtain diverse results and neighboring information, we compared the contexts from search results with the contexts from original long query and filtered non-relevant results. The experiments show that our approach achieves high precision for long query Web searches.","cites":"8","conferencePercentile":"82.90598291"},{"venue":"Web Intelligence","id":"cfbfd4d9c50b2d5ece995160c7fc15f164800696","venue_1":"Web Intelligence","year":"2006","title":"Utilizing Rich Bluetooth Environments for Identity Prediction and Exploring Social Networks as Techniques for Ubiquitous Computing","authors":"Jukka Perkiö, Ville H. Tuulos, Marion Hermersdorf, Heli Nyholm, Jukka Salminen, Henry Tirri","author_ids":"2813281, 2756745, 1919271, 2976309, 2444313, 1834766","abstract":"Personal identification and using that information is in the heart of many ubiquitous systems. We present two complementary techniques, namely personal identification without directly observing the subject, and using that information for understanding the social relations between the subjects. We show that with certain presumptions it is possible to predict one's identity with reasonable certainty only by observing one's Bluetooth neighborhood without the need to directly observe the subject. We also show how this information can be used for exploring the social relations between the subjects.","cites":"5","conferencePercentile":"43.33333333"},{"venue":"Web Intelligence","id":"88e15335ad4a309d547caf135c20d8cc3e2d9149","venue_1":"Web Intelligence","year":"2005","title":"Multi-Faceted Information Retrieval System for Large Scale Email Archives","authors":"Jukka Perkiö, Ville H. Tuulos, Wray L. Buntine, Henry Tirri","author_ids":"2813281, 2756745, 1854608, 1834766","abstract":"We profile a system for search and analysis of large-scale email archives. The system builds around four facets: Content-based search engine, statistical topic model, automatically inferred social networks and time-series analysis. The facets correspond to the types of information available in email data. The presented system allows chaining or combining the facets flexibly. Results of one facet may be used as input to another, yielding remarkable combinatorial power. In information retrieval point of view, the system provides support for exploration, approximate textual searches and data visualization. We present some experimental results based on a large real-world email corpus.","cites":"8","conferencePercentile":"79.08496732"},{"venue":"Web Intelligence","id":"9a2c88e6092e9d8d1809fcfc7b3e74515e40eb2a","venue_1":"Web Intelligence","year":"2008","title":"TheHotMap.com: Enabling Flexible Interaction in Next-Generation Web Search Interfaces","authors":"Orland Hoeber, Michael Brooks, Daniel Schroeder, Xue Dong Yang","author_ids":"1679276, 4028815, 8085736, 1697422","abstract":"TheHotMap.com is an example of a next-generation Web search interface, wherein users are able to take an active role in the Web search process. Information that can assist searchers in their Web search tasks is presented in a visual manner. The system supports user interaction both during the query refinement process, as well as the search results exploration process. This paper describes the features of TheHotMap.com; usage log analysis illustrates the benefits of supporting flexible interaction within a single unified Web search interface.","cites":"1","conferencePercentile":"29.39393939"},{"venue":"Web Intelligence","id":"1a0c7b0011117917c53b49b88c05034db1b99021","venue_1":"Web Intelligence","year":"2004","title":"Exploring Independent Trends in a Topic-Based Search Engine","authors":"Jukka Perkiö, Wray L. Buntine, Sami Perttu","author_ids":"2813281, 1854608, 2088104","abstract":"Topic-based search engines are an alternative to simple keyword search engines that are common in today's intranets. The temporal behaviour of the topics in a topic model based search engine can be used for trend analysis, which is an important research goal on its own. We apply topic modelling to an online financial newspaper data and show that some of the trends in the topics are consistent with common understanding.","cites":"10","conferencePercentile":"87.42138365"},{"venue":"Web Intelligence","id":"2938be6435ff08a7f8f25b9e0c5c5630c2a63178","venue_1":"Web Intelligence","year":"2005","title":"IPR: Automated Interaction Process Reconciliation","authors":"Zongxia Du, Jinpeng Huai, Yunhao Liu, Chunming Hu, Lei Lei","author_ids":"1689227, 7392431, 1723433, 1767378, 1690879","abstract":"Inter-organizational business processes usually require complex and time-consuming interactions between partners than simple interactions supported by WSDL. Automated reconciliation is essential to enable dynamic inter-organizational business collaboration. To the best of our knowledge, however, there is not a practical automated reconciliation algorithm available. In this paper, we propose a practical automated reconciliation algorithm, called IPR (Interaction Process Reconciliation) based on Petri Net, which is able to effectively facilitate dynamic interactions among trading partners in a peer-to-peer fashion. We implement a prototype IPR server in our lab, and evaluate our design by comprehensive experiments. Results show that IPR significantly outperforms existing approaches in terms of matching success rate, response time, and matching efficiency.","cites":"7","conferencePercentile":"73.20261438"},{"venue":"Web Intelligence","id":"46db13ebe626b4c511cbef5317edafeb1277880b","venue_1":"Web Intelligence","year":"2010","title":"Integrating Provenance Information in Reservoir Engineering","authors":"Jing Zhao, Na Chen, Karthik Gomadam, Viktor K. Prasanna","author_ids":"5349795, 1765104, 2009665, 1728271","abstract":"Data management and analysis has become an integral component in the area of reservoir engineering. An important metric that determines the overall effectiveness of data analysis is data quality. Data provenance, the metadata that pertains to the derivation history of data objects, has emerged as an invaluable asset in evaluating data quality. The reservoir facilities and software systems that collect provenance information are often distributed, thus making it difficult to analyze provenance data. Our primary contribution in this paper is an approach for provenance information integration in reservoir engineering.","cites":"1","conferencePercentile":"34.3220339"},{"venue":"Web Intelligence","id":"ac4ff12438a7d90c29f82947734a4704cca95866","venue_1":"Web Intelligence","year":"2001","title":"Knowledge-Based Validation, Aggregation, and Visualization of Meta-data: Analyzing a Web-Based Information System","authors":"Heiner Stuckenschmidt, Frank van Harmelen","author_ids":"1698459, 1725286","abstract":"As meta-data become of ever more importance to the Web, we will need to start managing such meta-data. We argue that there is a strong need for meta-data validation and aggregation. We introduce the WebMaster Approach for verifying semi-structured information and show how it can be used to validate, aggregate and visualize the Meta-Data of an existing Information System. We conclude that the possibility to verify and aggregate meta-data is an added value with respect to content based access to information. The information society demands large-scale availability of data and information. With the advent of the World Wide Web huge amounts of information is available in principle, however size and the inherent heterogeneity of the Web makes it difficult to find and access useful information. A suitable information source must be located which contains the data needed for a given task. Once the information source has been found, access to the data therein has to be provided. A common approach to this problem is to provide so-called meta-data, i.e. data about the actual information. This data may cover very different aspects of information: technical data about storage facilities and access methods co-exist with content descriptions and information about intended uses, suitability and data quality. Concerning the problem of finding and accessing information, the role of meta-data is twofold: On the side of information providers it serves as a means of organizing, maintaining and cataloguing data, on the side of the information users meta-data helps to find, access and interpret information. Recently, standards have been proposed that cover different aspects of meta-data, especially the syntax for coding, the model structure and content of a meta-data model. Some of these standards are:","cites":"4","conferencePercentile":"38.63636364"},{"venue":"Web Intelligence","id":"de3fdaf8a683e03178c4605934f4c28796328ccb","venue_1":"Web Intelligence","year":"2004","title":"The Role of Technology in Interest-Based Communities: Interactivity, Immersion and Connectivity","authors":"Kaisa Still, Minna Isomursu, Johanna Still, Pekka Isomursu","author_ids":"2387087, 2682707, 3194030, 1865079","abstract":"This paper explores the creation and distribution of knowledge in communities that have emerged through a shared interest or goal. The focus is on the technology used for supporting knowledge creation and distribution. We examine the problem area through three case studies: birdwatchers, virtual stables and ice-hockey fans. As a result, we present an analysis of issues concerning knowledge creation and distribution from the viewpoints of interactivity, immersion, and connectivity.","cites":"2","conferencePercentile":"48.74213836"},{"venue":"Web Intelligence","id":"1b429bf35594bf5e4103d93ed0b415509b261246","venue_1":"Web Intelligence","year":"2005","title":"Predictive Algorithms for Browser Support of Habitual User Activities on the Web","authors":"Janez Brank, Natasa Milic-Frayling, Anthony Frayling, Gavin Smyth","author_ids":"1795846, 1780840, 2928874, 2161994","abstract":"Routine user activities on the Web result in the revisitation of Web sites and pages. Standard browser applications provide limited support for this type of habitual behaviour. They typically expose lists of visited URLs that are automatically recorded by the system or manually created by the user, such as bookmarks. Studies have shown that these approaches are not successful in supporting routine user activities. Informed by our user research we designed a browser feature that automatically exposes candidate URLs for revisitation by the user. In this paper we describe and evaluate the algorithms that we use to model the user&#253;s habitual behaviour. We demonstrate how a structured navigation history model facilitates the discovery of relevant usage patterns and supports predictive algorithms that are applicable to relatively short personal navigation histories.","cites":"2","conferencePercentile":"37.90849673"},{"venue":"Web Intelligence","id":"692d3fa73dcf671750001e6368d0b61d80bd2003","venue_1":"Web Intelligence","year":"2005","title":"Implementation and Evaluation of a Distributed RDF Storage and Retrieval System","authors":"Gergely Adamku, Heiner Stuckenschmidt","author_ids":"1762614, 1698459","abstract":"It is widely agreed that the Semantic Web will be build on RDF. Therefore the success of the Semantic Web also depends on the availability of a scalable and reliable infrastructure for storing and accessing RDF data. A number of storage and retrieval systems have been developed recently, but despite the inherently distributed nature of the Semantic Web most of these systems do not support distributed storage and retrieval of data. In this paper we report our experiences with implementing a distributed storage and query infrastructure on top of an existing RDF infrastructure. We present the system architecture and discuss performance issues based on a set of experiments with the infrastructure. We conclude with an identification of remaining performance bottlenecks and point to further improvements.","cites":"11","conferencePercentile":"86.2745098"},{"venue":"Web Intelligence","id":"6a123dedd0eb326063c6bc3842c636b10320d4e0","venue_1":"Web Intelligence","year":"2005","title":"Referential Context Mining: Discovering Viewpoints from the Web","authors":"Koji Zettsu, Katsumi Tanaka","author_ids":"1831975, 1750132","abstract":"The Web is a vast playground for the propagation of information by individuals. The capability of Web users to leverage the value of Web content, in terms of factors such as usefulness, reputation, or reliability, has emerged as a requirement. The most significant characteristics of the Web are hyperlinks, which enables an author to refer to Web content published by other people. As a result, Web content can refer to other content on the Web in various contexts. The references provide important clues to understanding the roles or reputations of various Web pages according to the viewpoints of third parties. In this paper we propose an approach to mining referential contexts on the Web.","cites":"0","conferencePercentile":"9.477124183"},{"venue":"Web Intelligence","id":"381c4dc6083e93882c0beec6a7a805d1f2162f45","venue_1":"Web Intelligence","year":"2007","title":"Semantic Tagging for Large-scale Content Management","authors":"Liming Chen, Craig Roberts","author_ids":"1699578, 8592446","abstract":"Knowledge incorporation is one challenge in e-Commerce automated negotiation. In this paper, we describe a model of B2B negotiation using knowledge. We classify the types of knowledge namely general knowledge and negotiation knowledge, in the negotiation process. A methodology that uses Knowledge Bead (KB) and meta-KB as knowledge representation that would be suitable for the design of automated negotiation systems is discussed. An experimental prototype demonstrates that by incorporating knowledge into automated negotiation yields improved results.","cites":"1","conferencePercentile":"23.7037037"},{"venue":"Web Intelligence","id":"53e3fe8cdada0ae3dd5695ca323263a329b546ea","venue_1":"Web Intelligence","year":"2004","title":"Empowering Resource Providers to Build the Semantic Grid","authors":"Liming Chen, Simon J. Cox, Feng Tao, Nigel Shadbolt, Colin Puleston, Carole A. Goble","author_ids":"1699578, 2048967, 1755581, 1705314, 1729174, 1701008","abstract":"The future success of Grid-enabled e-Science depends on the availability of semantic/knowledge-rich resources on the Grid, i.e., the so-called semantic Grid. This requires not only novel knowledge modelling and representation formalisms but also a shift of knowledge acquisition and population from a limited number of specialised knowledge engineers to resource providers. To this end we have developed a lightweight ontology-enabled tool, \"Function Annotator\", to support resource providers in capturing and publishing resource semantics and knowledge. Function Annotator takes a different line to most knowledge acquisition tools in that it is designed for use by resource providers, probably in the absence of a knowledge engineer. Its aim is to facilitate large scale knowledge population on the Grid. Function Annotator is built on the state-of-the-art of semantic web technologies, such as ontologies, OWL, instance store and DL-based reasoning, thus ensuring flexibility and scalability on the Grid. This paper describes the tool's role in a Grid-oriented resource lifecycle, its underlying technologies and implementation. It also illustrates the usage of the tool in the context of engineering design search and optimisation.","cites":"6","conferencePercentile":"74.21383648"},{"venue":"Web Intelligence","id":"c4b8607476657b95474fd58c728aa44c2dee14ea","venue_1":"Web Intelligence","year":"2004","title":"OBSA: Ontology-Based Semantic Information Processing Architecture","authors":"Jinguang Gu, Heping Chen, Lingxian Yang, Lin Zhang","author_ids":"1780982, 4784964, 3323032, 1708615","abstract":"Integrating with the respective advantages of XML Schema and Ontology, this paper puts forward a semantic information processing architecture-OBSA to solve the problem of heterogeneity of information sources and uncertainty of semantic. It introduces an F-Logic based semantic information presentation mechanism, presents a design of an ontology-based semantic representation language and a mapping algorithm converting Ontology to XML DTD/Schema, and an adapter architecture for accessing distributed and heterogeneous information.","cites":"4","conferencePercentile":"66.98113208"},{"venue":"Web Intelligence","id":"42e95b6466189333504292a529c0d71c5e91ebc5","venue_1":"Web Intelligence","year":"2010","title":"Coauthor Network Topic Models with Application to Expert Finding","authors":"Jia Zeng, William Kwok-Wai Cheung, Chun-hung Li, Jiming Liu","author_ids":"6611275, 1749915, 1682842, 1695157","abstract":"This paper presents the coauthor network topic (CNT) model constructed based on Markov random fields (MRFs) with higher-order cliques. Regularized by the complex coauthor network structures, the CNT can simultaneously learn topic distributions as well as expertise of authors from large document collections. Besides modeling the pairwise relations, we model also higher-order coauthor relations and investigate their effects on topic and expertise modeling. We derive efficient inference and learning algorithms from the Gibbs sampling procedure. To confirm the effectiveness, we apply the CNT to the expert finding problem on a DBLP corpus of titles from six different computer science conferences. Experiments show that the higher-order relations among coauthors can improve the topic and expertise modeling performance over the case with pairwise relations, and thus can find more relevant experts given a query topic or document.","cites":"5","conferencePercentile":"77.54237288"},{"venue":"Web Intelligence","id":"2e894d4f7b8b7008d5ab067de8a0ad3994661125","venue_1":"Web Intelligence","year":"2004","title":"A Scalable Topic-Based Open Source Search Engine","authors":"Wray L. Buntine, Jaakko Löfström, Jukka Perkiö, Sami Perttu, Vladimir Poroshin, Tomi Silander, Henry Tirri, Antti J. Tuominen, Ville H. Tuulos","author_ids":"1854608, 3126667, 2813281, 2088104, 2523793, 1759936, 1834766, 3122804, 2756745","abstract":"Site-based or topic-specific search engines work with mixed success because of the general difficulty of the information retrieval task, and the lack of good link information to allow authorities to be identified. We are advocating an open source approach to the problem due to its scope and need for software components. We have adopted a topic-based search engine because it represents the next generation of capability. This paper outlines our scalable system for site-based or topic-specific search, and demonstrates the developing system on a small 250,000 document collection of EU and UN web pages.","cites":"17","conferencePercentile":"94.96855346"},{"venue":"Web Intelligence","id":"15894e6bfe622cd845a6716212bf55ed9e02a594","venue_1":"Web Intelligence","year":"2009","title":"On Discovering Community Trends in Social Networks","authors":"Jian Li, William Kwok-Wai Cheung, Jiming Liu, Chun-hung Li","author_ids":"1701502, 1749915, 1695157, 1682842","abstract":"Real-world social networks (e.g., blogosphere) often evolve over time and thus poses challenges on conventional social network analysis techniques which model the underlying networks as static graphs. In this paper, we are interested in detecting dynamic communities and their trend of evolution in a social network by examining the structural and dynamic patterns of interactions. In doing so, we propose an iterative mining algorithm for computing the intensities and bursts of some hidden communities over time. Our method is probabilistic in nature and can be applied to both undirected graphs and directed graphs. Quantitative and qualitative performance comparisons between the proposed method and some representative methods for social network analysis are provided. Evaluation results based on three benchmark datasets, including Reuters terror news network, political blogosphere, and Enron emails, show that the proposed method is both effective and efficient.","cites":"1","conferencePercentile":"29.48717949"},{"venue":"Web Intelligence","id":"3a53054bedac0179c39bcadd36e691128770537a","venue_1":"Web Intelligence","year":"2009","title":"Estimating Ad Clickthrough Rate through Query Intent Analysis","authors":"Azin Ashkan, Charles L. A. Clarke, Eugene Agichtein, Qi Guo","author_ids":"1715458, 1751287, 1685296, 5022607","abstract":"Clickthrough rate, bid, and cost-per-click are known to be among the factors that impact the rank of an ad shown on a search result page. Search engines can benefit from estimating ad clickthrough in order to determine the quality of ads and maximize their revenue. In this paper, a methodology is developed to estimate ad clickthrough rate by exploring user queries and clickthrough logs. As we demonstrate, the average ad clickthrough rate depends to a substantial extent on the rank position of ads and on the total number of ads displayed on the page. This observation is utilized by a baseline model to calculate the expected clickthrough rate for various ads. We further study the impact of query intent on the clickthrough rate, where query intent is predicted using a combination of query features and the content of search engine result pages. The baseline model and the query intent model are compared for the purpose of calculating the expected ad clickthrough rate. Our findings suggest that such factors as the rank of an ad, the number of ads displayed on the result page, and query intent are effective in estimating ad clickthrough rate.","cites":"15","conferencePercentile":"94.87179487"},{"venue":"Web Intelligence","id":"26aef386676c2954a9621af76027ab8223a9dc5c","venue_1":"Web Intelligence","year":"2004","title":"Compound Critiques for Conversational Recommender Systems","authors":"Barry Smyth, Lorraine McGinty, James Reilly, Kevin McCarthy","author_ids":"1701131, 2610734, 2739272, 1748265","abstract":"Recommender systems bring together ideas from information retrieval and filtering, user profiling, adaptive interfaces and machine learning in an attempt to offer users more personalized and responsive search systems. Conversational recommenders guide a user through a sequence of iterations, suggesting specific items, and using feedback from users to refine their suggestions in subsequent iterations. Different recommender systems look for different types of feedback from users. In this paper we examine the role of critiquing, a form of feedback in which the user indicates a preference over a particular feature of a recommended item. For example, when shopping for a PC a user might indicate that they like the current suggestion but they are looking for something \"cheaper\"; \"cheaper\" is a critique over the price feature of the PC case. Sometimes it is useful to critique multiple features simultaneously (compound critiques). In this paper we describe how a recommender can automatically discover useful compound critiques during the recommendation session and how these critiques can be used to improve recommendation efficiency.","cites":"15","conferencePercentile":"94.02515723"},{"venue":"Web Intelligence","id":"b48475b89078f433c21bb9e4c0d94381d3f63760","venue_1":"Web Intelligence","year":"2007","title":"Online Search Scope Reconstruction by Connectivity Inference","authors":"Michael Chan, Stephen Chi-fai Chan, Cane Wing-ki Leung","author_ids":"5289464, 2508623, 2142726","abstract":"The paper develops a novel computational framework for predicting communication flow in social networks based on several contextual features. The problem is important because prediction of communication flow can impact timely sharing of specific information across a wide array of communities. We determine the intent to communicate and communication delay between users based on several contextual features in a social network corresponding to (a) neighborhood context, (b) topic context and (c) recipient context. The intent to communicate and communication delay are modeled as regression problems which are efficiently estimated using Support Vector Regression. We predict the intent and the delay, on an interval of time using past communication data. We have excellent prediction results on a real-world dataset from MySpace.com with an accuracy of 13-16%. We show that the intent to communicate is more significantly influenced by contextual factors compared to the delay.","cites":"0","conferencePercentile":"7.777777778"},{"venue":"Web Intelligence","id":"2cb5cfd66364f48db8e0bbf61876fb9e134e8629","venue_1":"Web Intelligence","year":"2013","title":"Exploring Computation Locality of Graph Mining Algorithms on MapReduce","authors":"Qiuhong Li, Ke Dai, Wei Wang, Peng Wang, Rongming He, Mingxiu Dong","author_ids":"8194282, 2628642, 1706612, 1722767, 1908862, 2720220","abstract":"Previous implementations of graph mining algorithms on MapReduce ignore the characteristic of locality in distributed systems. For distributed systems, locality means the operations take place in local computing nodes without the communication with remote computing nodes. In this paper we present LI-MR (Local Iteration MapReduce) framework to improve a class of graph operators which can be described by repeated matrix-vector multiplications. LI-MR considers locality of sub graphs and adopts coarse granularity of communication unit for MapReduce. In particular, for sub graphs, only partial operations need synchronization. We propose a method to implement random data access on Hadoop by outputting the results to HBase. With the support of range query provided by HBase, LI-MR allows sub graphs to fulfil computation task with enough information in main memory. Because the locality feature of sub graphs, the info for the computation is limited. In this way, LI-MR framework combines in-memory computation with MapReduce model for graph algorithms.","cites":"0","conferencePercentile":"19.41176471"},{"venue":"Web Intelligence","id":"69faa34387d053c265852c77a251723ca77a3a1d","venue_1":"Web Intelligence","year":"2007","title":"Using Improved FOAF to Enhance BPEL-extracted RBAC Capability","authors":"Wei Shi, Jian Wu, Ying Li, Zhaohui Wu, Bo Wang","author_ids":"3739876, 1734550, 4744617, 1687635, 1693029","abstract":"Recent years have seen a thriving development of the World Wide Web as the most visible social media which enables people to share opinions, experiences and expertise with each other across the world. People now get involved in many different social networks simultaneously, which are often large intricate web of connections among the massive entities they are made of. As a result, the challenge of collecting and analyzing large-scale data among social members has left most basic questions about the global composition and function of such networks largely unresolved: What is the essential organization of a social network? who are the influential individuals whose voice is echoed by others? To address these questions, this paper presents an algorithm called sketcher to discover and describe the overall backbone of a specific network. Experimental results on the American College Football, Scientific Collaboration, and Telecommunications Call networks show that sketcher can extract the essential composition of a social network both efficiently and intuitively.","cites":"0","conferencePercentile":"7.777777778"},{"venue":"Web Intelligence","id":"0151ff63ed36866f723b3269abcdfcb9ecf328ab","venue_1":"Web Intelligence","year":"2007","title":"Concordance-Based Entity-Oriented Search","authors":"Mikhail Bautin, Steven Skiena","author_ids":"2168395, 1721948","abstract":"Nonnegative Matrix Factorization (NMF) has been proven to be effective in text mining. However, since NMF is a well-known unsupervised components analysis technique, the existing NMF method can not deal with prior constraints, which are beneficial to clustering or classification tasks. In this paper, we address the text clustering problem via a novel strategy, called Pairwise Constraintsguided Non-negative Matrix Factorization (PCNMF for short). Differing from the traditional NMF method, the proposed method can capture the available abundance prior constraints in original space, which result in more effective for clustering or information retrieval. Therefore, PCNMF enforces the discriminative capability in the reduced space. Utilizing the appropriate transformation, PCNMF represents as a new optimization problem, which can be efficiently solved by an iterative approach. The cluster membership of each document can be easily determined as the standard NMF. Empirical studies based on Benchmark document corpus demonstrate appealing results.","cites":"9","conferencePercentile":"81.85185185"},{"venue":"Web Intelligence","id":"57f1c73fcac9e6fe405501a5706c2e683d0c6af4","venue_1":"Web Intelligence","year":"2009","title":"Improving Movie Gross Prediction through News Analysis","authors":"Wenbin Zhang, Steven Skiena","author_ids":"3149786, 1721948","abstract":"Traditional movie gross predictions are based on numerical and categorical movie data from The Internet Movie Database (IMDB). In this paper, we use the quantitative news data generated by Lydia, our system for large-scale news analysis, to help people to predict movie grosses. By analyzing two different models (regression and k-nearest neighbor models), we find models using only news data can achieve similar performance to those using IMDB data. Moreover, we can achieve better performance by using the combination of IMDB data and news data. Further, the improvement is statistically significant.","cites":"16","conferencePercentile":"95.72649573"},{"venue":"Web Intelligence","id":"5155773b8f1fa8ba6c61ef73ec90d9f45133354c","venue_1":"Web Intelligence","year":"2009","title":"Learning Deep Web Crawling with Diverse Features","authors":"Lu Jiang, Zhaohui Wu, Qinghua Zheng, Jun Liu","author_ids":"1697318, 1687635, 1719603, 1843598","abstract":"The key to Deep Web crawling is to submit promising keywords to query form and retrieve Deep Web content efficiently. To select keywords, existing methods make a decision based on keywords&#8217; statistic information deriving from TF and DF in local acquired records, thus work well only in textual databases providing full text search interfaces, whereas not well in structured databases of multi-attribute or field-restricted search interfaces. This paper proposes a novel Deep Web crawling method. Keywords are encoded as a tuple by its linguistic, statistic and HTML features so that a harvest rate evaluation model can be learned from the issued keywords for the un-issued in future. The method breaks through the assumption of plain-text search made by existing methods. Experimental results show that the method outperforms the state of the art methods.","cites":"13","conferencePercentile":"92.73504273"},{"venue":"Web Intelligence","id":"4d96dc28e5fc809aaecd56b8ff4fdc92f8f5aa96","venue_1":"Web Intelligence","year":"2013","title":"Participatory Service Design Based on User-Centered QoS","authors":"Donghui Lin, Toru Ishida","author_ids":"1727648, 1709883","abstract":"With the development of service-oriented computing environments, more and more Web services have become available. Service providers have to consider how to design composite services to meet requirements from various users. However, QoS of composite service is difficult to evaluate and predict due to the uncertainty and multiple metrics of QoS, which makes it necessary for user-centered design of composite services. Moreover, combining human services and Web services is becoming an important issue in service composition in cases that Web services cannot meet the requirements from users. Therefore, it is necessary to test the service composition environments for human-computer interaction and study human behaviors. In this paper, we address the above issues by proposing a participatory service design approach based on user-centered QoS considering a real-world case of field-based multi-language communication service design. To achieve this goal, we first describe the QoS model for service design considering users' requirements. Then, we propose the participatory service design process, consisting of service model refinement, participatory simulation, QoS evaluation and QoS data update. Finally, we use the field study of multi-language service design for Vietnamese agricultural knowledge communication to illustrate our proposed design methodology.","cites":"1","conferencePercentile":"48.23529412"},{"venue":"Web Intelligence","id":"60d1257da896ee7452c4578383850865e582226d","venue_1":"Web Intelligence","year":"2006","title":"Personalized Hierarchical Clustering","authors":"Korinna Bade, Andreas Nürnberger","author_ids":"1684471, 1759689","abstract":"A hierarchical structure can provide efficient access to information contained in a collection of documents. However , such a structure is not always available, e.g. for a set of documents a user has collected over time in a single folder or the results of a web search. We therefore investigate in this paper how we can obtain a hierarchical structure automatically, taking into account some background knowledge about the way a specific user would structure the collection. More specifically, we adapt a hierarchical ag-glomerative clustering algorithm to take into account user specific constraints on the clustering process. Such an algorithm could be applied, e.g., for user specific clustering of Web search results, where the user's constraints on the clustering process are given by a hierarchical folder or book-mark structure. Besides the discussion of the algorithm itself , we motivate application scenarios and present an evaluation of the proposed algorithm on benchmark data.","cites":"16","conferencePercentile":"80.83333333"},{"venue":"Web Intelligence","id":"6c9b6d1ba055e362c183b8d34c86cf7206f4c0e1","venue_1":"Web Intelligence","year":"2005","title":"Web Log Session Analyzer: Integrating Parsing and Logic Programming into a Data Mart Architecture","authors":"Michel C. Desmarais","author_ids":"1736097","abstract":"Navigation and interaction patterns of Web users can be relatively complex, especially for sites with interactive applications that support user sessions and profiles. We describe such a case for an interactive virtual garment dressing room. The application is distributed over many web sites, supports personnalization and user profiles, and the notion of a multi-site user session. It has its own data logging system that generates approximately 5GB of complex data per month. The analysis of those logs requires more sophisticated processing than is typically done using a relational language. Even the use of procedural languages and DBMS can prove tedious and inefficient. We show an approach to the analysis of complex log data based on a parallel stream processing architecture and the use of specialized languages, namely a grammatical parser and a logic programming module, that offers an efficient, flexible, and powerful solution.","cites":"2","conferencePercentile":"37.90849673"},{"venue":"Web Intelligence","id":"4ef7f58c7cb017005fb724d94f0ccbfa9110fb1b","venue_1":"Web Intelligence","year":"2013","title":"Incorporating Structural Diversity of Neighbors in a Diffusion Model for Social Networks","authors":"Qing Bao, William Kwok-Wai Cheung, Yu Zhang","author_ids":"2371443, 1749915, 1729700","abstract":"Diffusion is known to be an important process governing the behaviours observed in network environments like social networks, contact networks, etc. For modeling the diffusion process, the Independent Cascade Model (IC Model) is commonly adopted and algorithms have been proposed for recovering the hidden diffusion network based on observed cascades. However, the IC Model assumes the effects of multiple neighbors on a node to be independent and does not consider the structural diversity of nodes' neighbourhood. In this paper, we propose an extension of the IC Model with the community structure of node neighbours incorporated. We derive an expectation maximization (EM) algorithm to infer the model parameters. To evaluate the effectiveness and efficiency of the proposed method, we compared it with the IC model and its variants that do not consider the structural properties. Our empirical results based on the MemeTracker dataset, shows that after incorporating the structural diversity, there is a significant improvement in the modelling accuracy, with reasonable increase in run-time.","cites":"2","conferencePercentile":"68.82352941"},{"venue":"Web Intelligence","id":"428216bd6308ee14b729975550f70c9ec6d4793b","venue_1":"Web Intelligence","year":"2005","title":"A MAS Approach to Fusion of Heterogeneous Information","authors":"Gregor Pavlin, Patrick de Oude, Jan Nunnink","author_ids":"2051828, 2200049, 3277265","abstract":"Distributed Perception Networks (DPN) are a MAS approach to large scale fusion of heterogeneous and noisy information. DPN agents can establish meaningful information filtering channels between the relevant information sources and the decision makers. Through specification of high level concepts, DPN agent organizations generate distributed Bayesian Networks, which provide mappings between the observed symptoms and the hypotheses relevant to the decision making. In addition, DPNs support robust distributed inference as well as decentralized probabilistic resource allocation.","cites":"5","conferencePercentile":"61.11111111"},{"venue":"Web Intelligence","id":"48d093af6e703e8c98c15e174606a8f7be6b13b5","venue_1":"Web Intelligence","year":"2009","title":"Building Blocks: Layered Components Approach for Accumulating High-Demand Web Services","authors":"Satoshi Morimoto, Satoshi Sakai, Masaki Gotou, Heeryon Cho, Toru Ishida, Yohei Murakami","author_ids":"1804003, 8668362, 3333216, 3282583, 1709883, 8703425","abstract":"Customization of systems is costly, but it is necessary to better meet the needs of multi-various tasks and requirements in the fields such as medical care, education, and so on. A machine translation system, for example, can provide a certain level of multilingual communication support if a human translator is absent; the translation system may need to be customized, however, if it is applied to a new application area. To realize easy customization of multilingual communication systems, we have developed the Language Grid Playground, an online language Web service platform which enables easy customization of various multilingual communication tools. We have established a stepwise process of classifying language services into a layered architecture and developing and accumulating lightweight building blocks that constitute communication tool components. Through this stepwise process, we were able to identify useful components in multilingual communication tools which can be flexibly combined to create new Web services. By implementing several tools and actually accumulating building blocks, we identified useful language service components and developed these components as programs which can be deployed as Web services.","cites":"1","conferencePercentile":"29.48717949"},{"venue":"Web Intelligence","id":"e60afc4e2e54c5798d24b1ee73488a3697d95ce6","venue_1":"Web Intelligence","year":"2008","title":"Service-Oriented Collective Intelligence for Intercultural Collaboration","authors":"Toru Ishida","author_ids":"1709883","abstract":"To increase the accessibility and usability of online language services, this paper explains the Language Grid, a service oriented collective intelligence initiative. The Language Grid is an infrastructure that allows end-users to create new language services for their intercultural / multilingual collaboration activities. To this end, language resources including data and programs are wrapped as Web services so that users can easily share and combine these Web services to create Web service workflows that support their own collaboration tools.","cites":"2","conferencePercentile":"41.81818182"},{"venue":"Web Intelligence","id":"0631abe929a464f1517b581bb73c4d76c4b27f1b","venue_1":"Web Intelligence","year":"2012","title":"Towards Topic Trend Prediction on a Topic Evolution Model with Social Connection","authors":"Jiangfeng Chen, Jianjun Yu, Yi Shen","author_ids":"2607129, 2936762, 1746161","abstract":"Hot topics are usually those breaking news discussed most at online forums, especially microblogging systems, such as twitter, which helps to learn user concentration and public opinion. This paper focuses on the problem of predicting emerging hot topics. Previous prediction models usually focus on building the content profile to discover the hot topics, they may neglect the social network function or overlook the keyword feature of the post. In this paper, we address this problem by introducing a combined model using the content and the connection information. We define the concept of topic hotness, introduce the algorithm calculating the hotness with content based hotness and connection based hotness, and finally we predict those emerging hot topics by the hotness evolution model.","cites":"1","conferencePercentile":"53.93258427"},{"venue":"Web Intelligence","id":"4e94542c5d97b78fa7ade31e13e7f8f1efcf53f1","venue_1":"Web Intelligence","year":"2005","title":"Agreement Technologies","authors":"Nicholas R. Jennings","author_ids":"1786650","abstract":"Building smart software that operates effectively in environments that: – Have no centralised control – Are highly interconnected – Are in constant state of flux – Are highly unpredictable – Involve multiple, individually-motivated actors 3","cites":"2","conferencePercentile":"37.90849673"},{"venue":"Web Intelligence","id":"9f36231fb88944450502948ea884401b578a8164","venue_1":"Web Intelligence","year":"2005","title":"Developing Agent Web Service Agreements","authors":"Shamimabi Paurobally, Nicholas R. Jennings","author_ids":"2040299, 1786650","abstract":"Web services have emerged as a new paradigm that supports loosely-coupled distributed systems in service discovery and service execution. Next generation web services will evolve from performing static invocations to engaging in flexible interactions and negotiations for dynamic resource procurement. To this end, this paper applies an agent-oriented based approach over a recent web service language, WS-Agreement, in order to facilitate conversations of sufficient expressiveness between adaptive and autonomous services. We discuss how such agent web service agreements can be implemented over IBM&#253;s Emerging Technologies Toolkit (ETTK) that itself includes an implementation of the WS-Agreement specification.","cites":"4","conferencePercentile":"55.22875817"},{"venue":"Web Intelligence","id":"111a1b5b436fc531cc1d7581fdd94de5a4bfb00d","venue_1":"Web Intelligence","year":"2007","title":"Perseus - A Personalized Reputation System","authors":"Petteri Nurmi","author_ids":"2583077","abstract":"E-finance industry is rapidly transforming and evolving toward more dynamic, flexible and intelligent solutions. The proposed e-finance portal provides an integrated enterprise platform for retail banking services as well as for other financial services. In the meantime, the proposed multilevel solution will keep monitoring and analyzing the huge volume of dynamic information flowing through the portal. In this way, the portal is able to find the useful knowledge for refining business processes and providing personalized services, and detect hidden financial problems as well.","cites":"3","conferencePercentile":"50.74074074"},{"venue":"Web Intelligence","id":"0da8f7c7a8d291befbf0e3e2a6ec623925cc32e0","venue_1":"Web Intelligence","year":"2005","title":"Page-reRank: Using Trusted Links to Re-Rank Authority","authors":"Paolo Massa, Conor Hayes","author_ids":"3078391, 2653825","abstract":"Search engines like Google.com use the the link structure of the Web to determine whether web pages are authoritative sources of information. However, the linking mechanism provided by HTML does not allow the web author to express different types of links, such as positive or negative endorsements of page content. As a consequence, search engine algorithms cannot discriminate between sites that are highly linked and sites that are highly trusted. We demonstrate our claim by running PageRank on a real world data set containing positive and negative links. We conclude that simple semantic extensions to the link mechanism would provide a richer semantic network from which to mine more precise Web Intelligence.","cites":"27","conferencePercentile":"96.40522876"},{"venue":"Web Intelligence","id":"ddf98c9a558eb094b7fbea74789efd4b954d5017","venue_1":"Web Intelligence","year":"2004","title":"Query Mining for Community Based Web Search","authors":"Evelyn Balfe, Barry Smyth","author_ids":"2355371, 1701131","abstract":"We present an innovative approach to personalized Web search that exploits the search behaviour of a community of users to re-rank future result-lists according to the implied preferences of this group. Evaluation results demonstrate the precision and recall benefits of our collaborative search technique and we show how personalization can be achieved without the need for individual user profiling.","cites":"4","conferencePercentile":"66.98113208"},{"venue":"Web Intelligence","id":"0018d92d1b31799f328035c176536a6e7df39992","venue_1":"Web Intelligence","year":"2010","title":"Image Set Classification Using Multi-layer Multiple Instance Learning with Application to Cannabis Website Classification","authors":"Nianhua Xie, Haibin Ling, Weiming Hu","author_ids":"1875062, 1805398, 1696704","abstract":"We propose using multi-layer multiple instance learning (MMIL) for image set classification and applying it to the task of cannabis website classification. We treat each image as an instance in an image set, then each image is further viewed as containing instances of local image patches. This representation naturally extends traditional multiple instance learning (MIL) to multi-layers. We then show that, when using the set kernels for all layers, an MMIL problem can be flattened to a simple one-layer MIL. This flattening, when combined with quantized local image patch representation, drastically improves the computational efficiency by two orders. The flattened set kernel is further improved by weighted codewords and an exponential kernel. The proposed approach is applied to a cannabis website classification task, in which we collected a dataset containing more than 220,000 images from 600 websites. In the experiments our approach compares favorably with several state-of-the-art methods.","cites":"1","conferencePercentile":"34.3220339"},{"venue":"Web Intelligence","id":"92098963151d065aa7758d15588a79b39feaefa9","venue_1":"Web Intelligence","year":"2001","title":"Mining Web Logs to Improve Web Caching and Prefetching","authors":"Qiang Yang, Henry Haining Zhang, Ian Tian Yi Li, Ye Lu","author_ids":"1733090, 3314590, 3346716, 2362714","abstract":"Caching and prefetching are well known strategies for improving the performance of Internet systems. The heart of a caching system is its page replacement policy, which selects the pages to be replaced in a proxy cache when a request arrives. By the same token, the essence of a prefetching algorithm lies in its ability to accurately predict future request. In this paper, we present a method for caching variable-sized web objects using an n-gram based prediction of future web requests. Our method aims at mining a prediction model from the web logs for document access patterns and using the model to extend the well-known GDSF caching policy. In addition, we present a new method to integrate this caching algorithm with a prediction-based prefetching algorithm. We empirically show that the system performance is greatly improved using the integrated approach.","cites":"4","conferencePercentile":"38.63636364"},{"venue":"Web Intelligence","id":"c01f2122279a4ff9a1a606e6ca0e9695e8cf64e2","venue_1":"Web Intelligence","year":"2010","title":"Communication Structure Discovery via Information Asymmetry in an Organizational Social Network","authors":"Cheng-Te Li, Shou-De Lin","author_ids":"2169355, 1724206","abstract":"In an organization, based on the positions of employees there is usually an existing hierarchy among them. However, in real-life cases, people&#8217;s interactions tend to form a certain communication structure due to some external forces or personal factors. In this paper, we aim at discovering the potential communication structure, in which nodes are typed labels (e.g. job-titles) and edges stand for tight interactions between typed labels in an organizational social network. To tackle this problem, we propose to exploit the concept of information asymmetry to model the core-periphery property in the communication structure. The proximity asymmetry is defined to realize the information asymmetry. We also devise two random-walk methods to calculate the proximity asymmetry between typed labels. The experiments conducted on the Enron email dataset shows that the proposed method outperforms some heuristic ones.","cites":"0","conferencePercentile":"12.71186441"},{"venue":"Web Intelligence","id":"353d9217ae20b0c5b3a45b6139d2bcf9cee8e941","venue_1":"Web Intelligence","year":"2005","title":"A Semantic Classification Approach for Online Product Reviews","authors":"Chao Wang, Jie Lu, Guangquan Zhang","author_ids":"6250419, 1685235, 1715857","abstract":"With the fast growth of e-commerce, product reviews on the Web have become an important information source for customers&#253; decision making when they plan to buy products online. As the reviews are often too many for customers to go through, how to automatically classify them into different semantic orientations (i.e. recommend/not recommend) has become a research problem. Different from traditional approaches that treat a review as a whole, our approach performs semantic classifications at the sentence level by realizing reviews often contain mixed feelings or opinions. In this approach, a typical feature selection method based on sentence tagging is employed and a na&#239;ve bayes classifier is used to create a base classification model, which is then combined with certain heuristic rules for review sentence classification. Experiments show that this approach achieves better results than using general na&#239;ve bayes classifiers.","cites":"8","conferencePercentile":"79.08496732"},{"venue":"Web Intelligence","id":"64ee3eed84046e284bfd4386defc2ac041a1c476","venue_1":"Web Intelligence","year":"2007","title":"Formal Specification of OWL-S with Object-Z: the Static Aspect","authors":"Hai H. Wang, Ahmed Saleh, Terry R. Payne, Nicholas Gibbins","author_ids":"1710162, 1748229, 1740601, 1708456","abstract":"As the Web becomes the major information source of our daily activities, tools for finding various information on it are indispensable. This paper addresses theWeb retrieval of instance-attribute information, e.g., the contact addresses and research interests (attributes) of faculty and students (instances). This kind of information need is very common but cannot be directly supported by current keywordmatching-based search engines. People commonly use a two-phase search: First, locate the candidate pages, e.g., a faculty page, and then search within them for the desired information, e.g., contact information. Based on the stimulation of such human search behavior, we design a retrieval engine, upon general search engines, to help find the instance-attribute information from the Web. The experiment on several faculty members has shown the feasibility of the approach.","cites":"2","conferencePercentile":"38.14814815"},{"venue":"Web Intelligence","id":"5cbe8be4e20d90b2f6e4cd9bd29e3936cad99af5","venue_1":"Web Intelligence","year":"2009","title":"Community Detection in Large-Scale Bipartite Networks","authors":"Xin Liu, Tsuyoshi Murata","author_ids":"1749705, 1702484","abstract":"Community detection in networks receives much attention recently. Most of the previous works are for unipartite networks composed of only one type of nodes. In real world situations, however, there are many bipartite networks composed of two types of nodes. In this paper, we propose a fast algorithm called LP&amp;BRIM for community detection in large-scale bipartite networks. It is based on a joint strategy of two developed algorithms -- label propagation (LP), a very fast community detection algorithm, and BRIM, an algorithm for generating better community structure by recursively inducing divisions between the two types of nodes in bipartite networks. Through experiments, we demonstrate that this new algorithm successfully finds meaningful community structures in large-scale bipartite networks in reasonable time limit.","cites":"26","conferencePercentile":"99.14529915"},{"venue":"Web Intelligence","id":"0d2048914a13a8dce584eccbff10796f5599a2d7","venue_1":"Web Intelligence","year":"2012","title":"A Double-Ranking Strategy for Long-Tail Product Recommendation","authors":"Mi Zhang, Neil J. Hurley, Wei Li, Xiangyang Xue","author_ids":"1706594, 1725433, 1765368, 5507458","abstract":"In this paper we attempt to retrieve the items in the long-tail for top-N recommendation. That is, to recommend products that the end-user likes, but that are not generally popular, which has been getting more and more notice lately. By analysing the existing issue of current recommendation algorithms, a strategy is proposed that succeeds in maintaining recommendation accuracy while reducing the concentration of the recommendation on popular items in the system. Evaluating on the publicly available Movie lens and Yahoo! datasets, the results show the recommendation algorithm proposed in this work retrieves items in the users' relatively unpopular tastes without losing the performance in their popular tastes, which ultimately results in a better overall accuracy for the system.","cites":"0","conferencePercentile":"20.78651685"},{"venue":"Web Intelligence","id":"14c26c314105ab30f1700d7f23acda2b7ae68fe1","venue_1":"Web Intelligence","year":"2010","title":"Niche Product Retrieval in Top-N Recommendation","authors":"Mi Zhang, Neil J. Hurley","author_ids":"1706594, 1725433","abstract":"A challenge for personalised recommender systems is to target products in the long tail. That is, to recommend products that the end-user likes, but that are not generally popular. To achieve this goal, in this paper we propose two strategies to identify relevant but niche products. The first strategy computes an inverse item popularity and applies it during the steps of top-N recommendation. Given a prior probability distribution of relevance based on item popularity, and a user-specific relevance probability, the other strategy uses a number of scores based on distance measures between these two distributions. We emphasize that the problem is to recommend relevant items from the user's broader range of tastes. Hence, in evaluation a concentration index is calculated to measure the extent to which the recommendation is spread to the user's niche tastes in conjunction with the standard precision metric which measures the overall relevance of the recommended set. The methods are evaluated empirically using the Movielens dataset and show a strong performance in niche item retrieval at the cost of a small reduction in precision.","cites":"6","conferencePercentile":"81.77966102"},{"venue":"Web Intelligence","id":"cd0ac99c0d8b7731ada81f4fb89bee7a2bbb7968","venue_1":"Web Intelligence","year":"2009","title":"Novel Item Recommendation by User Profile Partitioning","authors":"Mi Zhang, Neil J. Hurley","author_ids":"1706594, 1725433","abstract":"Standard top-N collaborative recommendation algorithms are very poor at recommending relevant products to a user that are more novel than her average tastes. Our study shows that novel recommendation is difficult because standard similarity metrics measure the aggregate similarity to multiple items in the user profile and the influence of more novel items is lost in the aggregation. To better capture the user's range of tastes, we propose to partition the user profile into clusters of similar items and compose the recommendation list of items that match well with each cluster, rather than with the entire user profile. In this paper we evaluate a number of partitioning strategies in combination with a dimension reduction strategy. A new evaluation methodology is introduced to capture the system ability to diversify its recommendations across relevant items regardless of their novelty. By plotting concentration curves of novelty against accuracy, we show that this strategy succeeds in reducing the system bias towards similar items at a small cost to overall accuracy.","cites":"20","conferencePercentile":"96.58119658"},{"venue":"Web Intelligence","id":"7257b8799110c1025d6bea63efe0e4df1a344bf5","venue_1":"Web Intelligence","year":"2007","title":"An Ontology-Driven Approach To Reflective Middleware","authors":"Reto Krummenacher, Elena Paslaru Bontas Simperl, Dieter Fensel","author_ids":"2087636, 2927032, 1766239","abstract":"Mining search engine query log is a new method for evaluating web site link structure and information architecture. In this paper we propose a new query-URL co-clustering for a web site useful to evaluate information architecture and link structure. Firstly, all queries and clicked URLs corresponding to particular web site are collected from a query log as bipartite graph, one side for queries and the other side for URLs. Then a new content free clustering is applied to cluster queries and URLs concurrently. Afterwards, based on information entropy, clusters of URLs and queries will be used for evaluating link structure and information architecture respectively. Data sets of different web sites have been extracted from a huge query log to evaluate our method, and experiments show promising result.","cites":"1","conferencePercentile":"23.7037037"},{"venue":"Web Intelligence","id":"66368ba9b91889872d53639d3d77d7cf9825d734","venue_1":"Web Intelligence","year":"2005","title":"Tracking Information Epidemics in Blogspace","authors":"Eytan Adar, Lada A. Adamic","author_ids":"2630700, 1778398","abstract":"Beyond serving as online diaries, weblogs have evolved into a complex social structure, one which is in many ways ideal for the study of the propagation of information. As weblog authors discover and republish information, we are able to use the existing link structure of blogspace to track its flow. Where the path by which it spreads is ambiguous, we utilize a novel inference scheme that takes advantage of data describing historical, repeating patterns of \"infection.\" Our paper describes this technique as well as a visualization system that allows for the graphical tracking of information flow.","cites":"207","conferencePercentile":"100"},{"venue":"Web Intelligence","id":"59fd142e23aadec13b64dfe9b531d8f5e6ecfd99","venue_1":"Web Intelligence","year":"2011","title":"Approaches to Relating and Integrating Semantic Data from Heterogeneous Sources","authors":"John Keeney, Aidan Boran, Ivan Bedini, Christopher J. Matheus, Peter F. Patel-Schneider","author_ids":"1727917, 2174495, 1892586, 1688579, 1683553","abstract":"Integrating and relating heterogeneous data using inference is one of the cornerstones of semantic technologies and there are a variety of ways in which this may be achieved. Cross source relationships can be automatically translated or inferred using the axioms of RDFS/OWL, via user generated rules, or as the result of SPARQL query result transformations. For a given problem it is not always obvious which approach (or combination of approaches) will be the most effective and few guidelines exist for making this choice. This paper discusses these three approaches and demonstrates them using an \"acquaintance\" relationship drawn from data residing in common RDF information sources such as FOAF and DBLP data stores. The implementation of each approach is described along with practical considerations for their use. Quantitative and qualitative evaluation results of each approach are presented and the paper concludes with initial suggestions for guiding principles to help in selecting an appropriate approach for integrating heterogeneous semantic data sources.","cites":"4","conferencePercentile":"75.58139535"},{"venue":"Web Intelligence","id":"ecbe4f7e4507e1dd06abec0f3037e2ff2264b25a","venue_1":"Web Intelligence","year":"2009","title":"Statistical Modeling of Diversity in Top-N Recommender Systems","authors":"Mi Zhang, Neil J. Hurley","author_ids":"1706594, 1725433","abstract":"This paper provides the first statistical analysis of recommendation diversity. We propose a model that allows diversity to be evaluated analytically using the concentration index, a statistical measure of diversity. While this model abstracts the recommendation process, it provides good overall agreement with real recommendation algorithms. Using the model we are able to analytically demonstrate the trade-off between diversity and overall system performance. Moreover, the model makes explicit the various choices that are available to the algorithm designer to improve recommendation diversity. Our exploration of these choices provides good insight into what can be achieved in practice by algorithms that attempt to provide greater recommendation diversity without significant degradation of system precision.","cites":"5","conferencePercentile":"71.79487179"},{"venue":"Web Intelligence","id":"e9da0623bbb8d420952e44c957241f903eab0a3d","venue_1":"Web Intelligence","year":"2003","title":"Clustering for Web Information Hierarchy Mining","authors":"Hung-Yu Kao, Jan-Ming Ho, Ming-Syan Chen","author_ids":"1738550, 1786429, 1691171","abstract":"Benefiting from the growth of techniques of dynamic page generation, the amount and the complexity of Web pages increase explosively. The structures of Web pages which are dynamically generated by the same templates are thus similar to one another and are usually assembled by a set of fundamental information clusters These neighboring information clusters usually represent the similar semantics and form a larger cluster with the more generalized information. The hierarchical structure generated by information clusters in a bottom-up manner is called the information hierarchy of a page. In this paper, we study the problem of mining the information hierarchies of pages in Web sites to recognize the information distribution of pages within the multi-level, multi-granularity configurations. Explicitly, we propose an information clustering system that applies a top-down information centroid searching algorithm and a multi-granularity centroid converging process on the document object model (DOM) trees of pages to build the information hierarchies of pages. Experiments on several real news Web sites show the high precision and recall rates of the proposed method on determining information clusters of pages and also validate its practical applicability to real Web sites.","cites":"0","conferencePercentile":"5.102040816"},{"venue":"Web Intelligence","id":"3dab6d9c07dc39eec1700b9eec6db51b2a29228e","venue_1":"Web Intelligence","year":"2004","title":"A Driving Force for e-Transformation - The Centre for e-Transformation Research / WIC Hong Kong Centre","authors":"Jiming Liu, William Kwok-Wai Cheung","author_ids":"1695157, 1749915","abstract":"The Centre for e-Transformation Research (CTR), also an affiliated Centre of Web Intelligence Consortium (WIC), is established under the Science Faculty of Hong Kong Baptist University, currently funded by Hong Kong Research Grant Council Central Allocation and FRG Strategic Research Grant, Hong Kong Baptist University for developing an Area of Strength in e-transformation research, making high impact to various sectors of the society, from e-business, e-learning, to e-government, to name a few.","cites":"0","conferencePercentile":"14.4654088"},{"venue":"Web Intelligence","id":"549cc316fe72909bd854a551308e6b1bae735f32","venue_1":"Web Intelligence","year":"2004","title":"Dynamic Resource Selection For Service Composition in The Grid","authors":"William Kwok-Wai Cheung, Jiming Liu, Kevin H. Tsang, Raymond K. Wong","author_ids":"1749915, 1695157, 2185254, 1689359","abstract":"While numerous efforts have focused on service composition in the Grid environment, service selection among similar services from multiple providers has not been addressed. In particular, all service composition work done so far are based on a given selection of services under a well set environment. As a result, uncertainty (e.g., server load, network traffic, computation time of the services due to changing memory and other unexpected conditions) under a real, dynamic environment has never been considered. This paper prototypes the service selection under a Grid environment and proposes an uncertainty framework to address the issue. Experimental results show that our considerations are valid and our preliminary solution works well in our Globus Grid network.","cites":"10","conferencePercentile":"87.42138365"},{"venue":"Web Intelligence","id":"b74eb2c497c049f43a3c33a08804e6a0330d8f27","venue_1":"Web Intelligence","year":"2005","title":"A Service-Oriented Personalization Mechanism in Pervasive Environments","authors":"Yuping Yang, M. Howard Williams, Lachlan M. MacKinnon, Rob Pooley","author_ids":"3875162, 1804214, 3140068, 2886102","abstract":"An important aspect of a pervasive environment is that it needs to support mobile users ¿ i.e. users whose context changes frequently. In doing so it is important to take account of a user&#253;s context in adapting and personalizing services for the user. This paper describes a personalization mechanism that is exploited in the Daidalos project to provide users with value-added enhanced services. It personalizes services across layers including networking and service layers.","cites":"3","conferencePercentile":"47.05882353"},{"venue":"Web Intelligence","id":"27cf96682a3f8b2bf472599d7af516f1057ec2f9","venue_1":"Web Intelligence","year":"2011","title":"Revealing Associations between Events and Their Characteristic Items","authors":"Shin-ya Sato, Masami Takahashi, Tetsuya Nakamura, Masato Matsuo","author_ids":"2521219, 2845913, 7759067, 2523272","abstract":"We pose a new problem of discovering associations between events in our daily lives and their characteristic items, such as (Halloween, pumpkin) and (Christmas, chimney). To solve the problem, we dopted an approach similar to that of existing research on event detection, which tries to discover events by detecting bursts of occurrence frequency of a relevant term in a document stream, where the term (item) is associated with the discovered event. We extracted events from blog entries available on the Web, while the previous studies mostly used news articles as document streams. Blog entries are shown to have quite different characteristics to news articles. Considering this fact, we developed a method for discovering the associations by integrating existing techniques that can handle and take advantage of the characteristics of blog data. We verified through experiments using actual data that the proposed approach works quite well.","cites":"0","conferencePercentile":"11.62790698"},{"venue":"Web Intelligence","id":"2018c6f9e3f4a914c0298a8ec8a40d7909c80dbc","venue_1":"Web Intelligence","year":"2008","title":"Linking Privacy and User Preferences in the Identity Management for a Pervasive System","authors":"Elizabeth Papadopoulou, Sarah McBurney, Nick K. Taylor, M. Howard Williams","author_ids":"2202685, 1901643, 2809017, 1804214","abstract":"Two important concepts in developing ubiquitous or pervasive computing technologies that are acceptable to the end user are personalization and privacy. On the one hand it is essential to take account of user needs and preferences to personalize decision making within such a system, on the other hand it is equally important to protect user privacy. One approach to handling user privacy is through the use of virtual identities. This has the advantage that it can also benefit the handling of user preferences. In particular, virtual identities can be used as a substitute for roles. On the other hand user preferences can be used in identity management to assist in selecting a virtual identity to hide the real identity of the user, thereby improving user-friendliness of the system. This paper describes this symbiosis and how it is implemented in the Daidalos pervasive system.","cites":"0","conferencePercentile":"10.60606061"},{"venue":"Web Intelligence","id":"5eb206d30412fbcc5795f9db438b1ab1ffa2a1ec","venue_1":"Web Intelligence","year":"2004","title":"Mining Local Data Sources For Learning Global Cluster Models","authors":"Chak-Man Lam, Xiaofeng Zhang, William Kwok-Wai Cheung","author_ids":"1850594, 1697234, 1749915","abstract":"Distributed data mining has been a topic getting more important nowadays as there are many cases where physically sharing of data is probibited, e.g., due to huge data volume or data privacy. In this paper, we are interested in learning a global cluster model by exploring data in distributed sources. A methodology based on periodic model exchange and merge is proposed and applied to hyperlinked Web pages analysis. In addition, we have tested a number of variations of the basic idea, including putting more emphasis on the privacy concern and testing the effect of having different numbers of distributed sources. Experimental results show that the proposed distributed learning scheme is effective with accuracy close to the case with all the data physically shared for the learning.","cites":"6","conferencePercentile":"74.21383648"},{"venue":"Web Intelligence","id":"78474f2b8dd3d8870684a7247ed6e80a32bfd37f","venue_1":"Web Intelligence","year":"2011","title":"Wikipedia Sets: Context-Oriented Related Entity Acquisition from Multiple Words","authors":"Masumi Shirakawa, Kotaro Nakayama, Takahiro Hara, Shojiro Nishio","author_ids":"2657265, 3156934, 1697569, 1717916","abstract":"In this paper, we propose a method which acquires related words (entities) from multiple words by naturally disambiguating their meaning and considering their contexts. In addition, we introduce a bootstrapping method for improving the coverage of association relations. Experimental result shows that our method can acquire related words depending on the contexts of multiple words compared to the ESA-based method.","cites":"0","conferencePercentile":"11.62790698"},{"venue":"Web Intelligence","id":"0168c82617048e0423a7680573d45194791f1ca9","venue_1":"Web Intelligence","year":"2003","title":"Mining Web Site?s Clusters from Link Topology and Site Hierarchy","authors":"William Kwok-Wai Cheung, Yuxiang Sun","author_ids":"1749915, 2975290","abstract":"Foraging information in large and complex web sites simply using keyword search usually results in unpleasant experience due to the relatively low precision of existing search engines. To support more precise information search, some abstractions of the web sites, like sitemaps, are needed. However, their creation normally requires manual effort. In this paper, we extend the HITS algorithm and integrate hyperlink topology and web site hierarchy to identify a hierarchy of web page clusters as web site abstractions. As the algorithm is based on HITS, each cluster follows the bipartite graph structure and is computed with an authority and hub pair as the cluster summary. The effectiveness of the algorithm has been evaluated using three different web sites (containing ~ 6000-14000 web pages) with promising results. Detailed interpretation of the experimental results as well as qualitative comparison with other related works are also included. Abstract Foraging information in large and complex web sites simply using keyword search usually results in unpleasant experience due to the relatively low precision of existing search engines. To support more precise information search, some abstractions of the web sites, like sitemaps, are needed. However, their creation normally requires manual effort. In this paper, we extend the HITS algorithm and integrate hyperlink topology and web site hierarchy to identify a hierarchy of web page clusters as web site abstractions. As the algorithm is based on HITS, each cluster follows the bipartite graph structure and is computed with an authority and hub pair as the cluster summary. The effectiveness of the algorithm has been evaluated using three different web sites (containing ¢ 6000-14000 web pages) with promising results. Detailed interpretation of the experimental results as well as qualitative comparison with other related works are also included.","cites":"3","conferencePercentile":"39.79591837"},{"venue":"Web Intelligence","id":"8a6fec3a58d07c7a8e1b7c61bd74a7c980277e70","venue_1":"Web Intelligence","year":"2005","title":"A Formal Language for Access Control Policies in Distributed Environment","authors":"Peng Liu, Jian-bin Hu, Zhong Chen","author_ids":"1712572, 2815578, 4916991","abstract":"Although several access control policies have been proposed for securing access to resources, they focused on security of distributed environments that were rather static. Nowadays distributed environment becomes open and dynamic. In this paper, we propose a formal language for access control policies in open and dynamic environment. The language is based on description logic program and generalized courteous logic program supporting classical negation, prioritized conflict handling and mutual exclusion constraints. The language allows the specification of positive and negative authorization, privilege delegation and revocation, prioritized conflict resolution and mutual authorization exclusions.","cites":"3","conferencePercentile":"47.05882353"},{"venue":"Web Intelligence","id":"f8cefd1b1fed6b0123c43595f47283e64f71d3aa","venue_1":"Web Intelligence","year":"2012","title":"Cognitive Resource-Aware Adaptive Web Service Binding and Scheduling","authors":"Angel Jiménez Molina, Jang-Ho Choi, Jorge Gaete-Villegas, In-Young Ko","author_ids":"1954443, 1926714, 2581673, 2532033","abstract":"The proactive and spontaneous delivery of Web services for users on the move can lead to the depletion of their cognitive resources, affecting the normal processes of their physical activities. This is due to the competition for limited cognitive resources between the human-computer interactions required by Web services and the users' physical activities. This paper introduces a mechanism for binding and scheduling Web services based on an assessment of this competition for users on the move. The proposed approach is built on two theories from cognitive psychology. This mechanism is realized by a descriptive model of activities and Web services which is enriched with a cognitive layer. A computational model uses this description to assess the degree of the demand for cognitive resources by both the physical activities and the Web services. Additionally, a Web services coordination mechanism based on this level of demand, the principle of progressive disclosure, and the temporal concurrency of Web services ensures less cognitively taxing Web service compositions.","cites":"0","conferencePercentile":"20.78651685"},{"venue":"Web Intelligence","id":"24a1eddef73c2f207ed5f51230e3d413188b188e","venue_1":"Web Intelligence","year":"2004","title":"An Access Control Model for Web Services in Business Process","authors":"Peng Liu, Zhong Chen","author_ids":"1712572, 4916991","abstract":"Business process describes a set of services that span enterprise boundaries and are provided by enterprises that see each other as partners. Web services is widely accepted and adopted to construct business process. Web services are built in exposed environment and open to security threats. When a web service contained in a business process is authorized to illegal users, it will cause economic loss of the service provider. Although there exist some standards for security of Web services and access control for services in distributed systems are well studied, there is a lack of comprehensive approach in access control for web services, especially in business process. In this paper, an extended RBAC model, called WS-RBAC, is proposed to secure web services in business process. The model takes web services in business process as protected objects and extends the classical RBAC model. Next, The software architecture of WS-RABC is presented. This paper also presents how to specify business process in the model and the authorization constraints of WS-RBAC based on WS-Policy.","cites":"7","conferencePercentile":"77.98742138"},{"venue":"Web Intelligence","id":"045e238fbd6607353f51ad26e09c581fe242a7be","venue_1":"Web Intelligence","year":"2004","title":"Mining the Web to Create a Language Model for Mapping between English Names and Phrases and Japanese","authors":"Gregory Grefenstette, Yan Qu, David A. Evans","author_ids":"1746017, 3108612, 1778403","abstract":"The Web provides the largest, exploitable collection of language use. If we can mine the Web to build abstract models of language use, these models may have many applications. Here we present one example of using the implicit intelligence of language use to solve an important problem for machine translation programs and cross-lingual applications. This problem involves the translation of words written in katakana characters in Japanese. In this paper, we describe techniques of discovering katakana transliteration of English names and of finding English translations of multiword katakana sequences using implicit language models of English and Japanese found on the Web. These techniques were evaluated against human-constructed English-katakana glosses.","cites":"5","conferencePercentile":"71.06918239"},{"venue":"Web Intelligence","id":"d69f9935691fb331500638c3cf50235443204df5","venue_1":"Web Intelligence","year":"2012","title":"Biological Mutualistic Models Applied to Study Open Source Software Development","authors":"Pablo Loyola, In-Young Ko","author_ids":"2915459, 2532033","abstract":"The evolution of the Web has allowed the generation of several platforms for collaborative work. One of the main contributors to these advances is the Open Source initiative, in which projects are boosted to a new level of interaction and cooperation that improves their software quality and reliability. In order to understand how the group of contributors interacts with the software under development, we propose a novel methodology that adapts Lotka-Volterra-based biological models used for host-parasite interaction. In that sense, we used the concept mutualism from social parasites. Preliminary results based on experiments on the Github collaborative platform showed that Open Source phenomena can be modeled as a mutualistic system, in terms of the evolution of the population of developers and repositories.","cites":"1","conferencePercentile":"53.93258427"},{"venue":"Web Intelligence","id":"8933a13589f032ffff0039b5fceee5df3ab83718","venue_1":"Web Intelligence","year":"2003","title":"Functionality Adaptation: A Context-Aware Service Code Adaptation for Pervasive Computing Environments","authors":"VivienWai-Man Kwan, Francis Chi-Moon Lau, Cho-Li Wang","author_ids":"2052946, 1708000, 1700250","abstract":"Pervasive computing has attracted a lot of attention in recent years. Proxy servers that are suitable for pervasive computing have also been designed. They use different kinds of content adaptation techniques (such as distillation and transcoding) to adapt web contents in the content-rich servers to the resource-constrained devices. Although the adaptation of web contents have been widely discussed, less attention is put on the adaptation of services (or service codes), which is also important to enable computing anytime, anywhere, and on any device. In this paper, we present a proxy-based context-aware adaptation of service codes, known as functionality adaptation. The main difficulty of such an adaptation is to estimate the resource usage required for the execution, which varies with the input size and is available only at run-time. We propose a conservative solution for the adaptation. A simple prototype has been implemented to evaluate the quality of the adaptation.","cites":"8","conferencePercentile":"59.18367347"},{"venue":"Web Intelligence","id":"a4d647ca9530f136657c5c5702e623dc53180928","venue_1":"Web Intelligence","year":"2004","title":"Offer Group Generation and Delayed Processing in Multi-Issue Negotiation","authors":"Ning Zhang, Song Zhang, Lei Wang, Jie Yang, Zhuoqun Xu","author_ids":"2561582, 1682132, 1743559, 2081112, 1795885","abstract":"In this paper we describe a mechanism for automated negotiation in which artificial agents can deal with a multi-issue negotiation in a one-to-many way based on some strategies. The negotiation process are governed dynamically by some strategies that emphasize on the diverse processing methods under the considering of different commodity attributes, including dynamic delayed evaluation and response to the received offers, generation of offer groupwith the same utility. Our analysis shows that the mechanism ensures that bargaining agents could reach a better agreement automatically. We also implement a prototype system to verify the advantages of our mechanism.","cites":"1","conferencePercentile":"35.22012579"},{"venue":"Web Intelligence","id":"9414d66e7a07da3195ec0da0f48c002506907c0f","venue_1":"Web Intelligence","year":"2004","title":"Building Domain Ontology Based on Web Data and Generic Ontology","authors":"Jie Yang, Lei Wang, Song Zhang, Xin Sui, Ning Zhang, Zhuoqun Xu","author_ids":"2081112, 1743559, 1682132, 1801190, 2561582, 1795885","abstract":"The automatic or semi-automatic construction of ontology has become a research topic of interest in recent years. This paper describes a mechanism for constructing domain specific ontologies automatically based on web data and generic ontology.Firstly, we employ the hierarchical agglomerative clustering(HAC) algorithm, clustering web pages hierarchically and resulting in a binary tree.Then an algorithm is proposed, which selectd from the binary tree the significative nodes as topics implying concepts of domain interests.Lastly, the Chinese generic ontology, HowNet, is introduced to evolve the topics (together with their hierarchical structures) into domain ontology.We experiment our method in the field of computer hardware based on web pages collected from Chinese BtoC web sites.An in-depth discussion on the experiment results is also given.","cites":"3","conferencePercentile":"59.74842767"},{"venue":"Web Intelligence","id":"99dff00f9cd24210579c8e7c4389d83048252c7e","venue_1":"Web Intelligence","year":"2010","title":"Improving Collaborative Filtering in Social Tagging Systems for the Recommendation of Scientific Articles","authors":"Denis Parra, Peter Brusilovsky","author_ids":"1796809, 1804693","abstract":"Social tagging systems pose new challenges to developers of recommender systems. As observed by recent research, traditional implementations of classic recommender approaches, such as collaborative filtering, are not working well in this new context. To address these challenges, a number of research groups worldwide work on adapting these approaches to the specific nature of social tagging systems. In joining this stream of research, we have developed and evaluated two enhancements of user-based collaborative filtering algorithms to provide recommendations of articles on Cite ULike, a social tagging service for scientific articles. The result obtained after two phases of evaluation suggests that both enhancements are beneficial. Incorporating the number of raters into the algorithms, as we do in our NwCF approach, leads to an improvement of precision, while tag-based BM25 similarity measure, an alternative to Pearson correlation for calculating the similarity between users and their neighbors, increases the coverage of the recommendation process.","cites":"14","conferencePercentile":"95.76271186"},{"venue":"Web Intelligence","id":"c0a6f7d8438567c5a67252091571d5bd29afb316","venue_1":"Web Intelligence","year":"2007","title":"From User Query to User Model and Back: Adaptive Relevance-Based Visualization for Information Foraging","authors":"Jae-wook Ahn, Peter Brusilovsky","author_ids":"1924998, 1804693","abstract":"In this paper, YourEye, the real-time phrase recommender is introduced that suggests the related frequent phrases to the incomplete user query. The frequent phrases are extracted from within previous queries based on a new frequency rate metric suitable for query stream mining. The advantages of YourEye compared to Google Suggest, a service powered by Google for phrase suggestion, is described. The experimental results also confirm the significant benefit of monitoring phrases instead of queries. The number of the monitored elements significantly reduces that results in smaller memory consumption as well as better performance.","cites":"2","conferencePercentile":"38.14814815"},{"venue":"Web Intelligence","id":"d4ad8d127a6348634fe48c323355482003f9b2ce","venue_1":"Web Intelligence","year":"2010","title":"Chem2Bio2RDF: A Linked Open Data Portal for Systems Chemical Biology","authors":"Bin Chen, Ying Ding, Huijun Wang, David J. Wild, Xiao Dong, Yuyin Sun, Qian Zhu, Madhuvanthi Sankaranarayanan","author_ids":"3671409, 1743781, 2237546, 1723239, 1765847, 1686318, 7702832, 2241021","abstract":"The Chem2Bio2RDF portal is a Linked Open Data (LOD) portal for systems chemical biology aiming for facilitating drug discovery. It converts around 25 different datasets on genes, compounds, drugs, pathways, side effects, diseases, and MEDLINE/PubMed documents into RDF triples and links them to other LOD bubbles, such as Bio2RDF, LODD and DBPedia. The portal is based on D2R server and provides a SPARQL endpoint, but adds on several unique features such as RDF faceted browser, user-friendly SPARQL query generator, MEDLINE/PubMed cross validation service, and Cytoscape visualization plugin. Three use cases demonstrate the functionality and usability of this portal. The portal is available at http://chem2bio2rdf.org.","cites":"5","conferencePercentile":"77.54237288"},{"venue":"Web Intelligence","id":"349c10dc798596bf72b2d411ed4baeed7159355b","venue_1":"Web Intelligence","year":"2007","title":"How Up-to-date should it be? the Value of Instant Profiling and Adaptation in Information Filtering","authors":"Daqing He, Peter Brusilovsky, Jonathan Grady, Qi Li, Jae-wook Ahn","author_ids":"1725184, 1804693, 1780018, 1682467, 1924998","abstract":"In this research, we proposed and validated an approach to using information visualization to augment search engines in supporting the analysis of business stakeholder information on the Web. We report in this paper findings from a preliminary evaluation comparing a visualization prototype with a traditional method of stakeholder analysis (Web browsing and searching). We found that the prototype achieved a higher perceived usefulness and perceived analysis effectiveness and was perceived favorably in expediting the subjects' decision making and in helping them understand the analysis results. Overall, the proposed approach was found to augment traditional methods of analyzing business stakeholders. We discuss implications to researchers and practitioners and future directions.","cites":"8","conferencePercentile":"78.88888889"},{"venue":"Web Intelligence","id":"610326818d633e7c4980f21a3c371793e6adc23c","venue_1":"Web Intelligence","year":"2012","title":"User Interest and Topic Detection for Personalized Recommendation","authors":"Xuning Tang, Mi Zhang, Christopher C. Yang","author_ids":"3338831, 1706594, 1734151","abstract":"Recommender system provides users with personalized suggestions of product or information. Typically, recommender systems rely on a bipartite graph model to capture user interest. As an extension, some boosted methods analyze content information to further improve the quality of personalized recommendation. However, due to the prevalence of short and sparse messages in online social media, traditional content-boosted methods do not guarantee to capture user preference accurately especially for web contents. In this paper, we propose a novel graphical model to extract hidden topics from web contents, cluster web contents, and detect users' interests on each cluster. In addition, we introduce two reranking models which utilize the detected user interest to further boost the quality of personalized recommendation. Experiment results on a public dataset demonstrated the limitation of a traditional content-boosted approach, and also showed the validity of our proposed techniques.","cites":"4","conferencePercentile":"86.51685393"},{"venue":"Web Intelligence","id":"e25aa7b20c7e80230ffd0481c647ce377aa96935","venue_1":"Web Intelligence","year":"2010","title":"Linked Open Social Signals","authors":"Pablo N. Mendes, Alexandre Passant, Pavan Kapanipathi, Amit P. Sheth","author_ids":"1692493, 1733056, 2223082, 1709950","abstract":"In this paper we discuss the collection, semantic annotation and analysis of real-time social signals from micro blogging data. We focus on users interested in analyzing social signals collectively for sense making. Our proposal enables flexibility in selecting subsets for analysis, alleviating information overload. We define an architecture that is based on state-of-the-art Semantic Web technologies and a distributed publish-subscribe protocol for real time communication. In addition, we discuss our method and application in a scenario related to the health care reform in the United States.","cites":"22","conferencePercentile":"97.45762712"},{"venue":"Web Intelligence","id":"ac1df669e1a21dfacf35d4d10f3fe420b8ecf9d4","venue_1":"Web Intelligence","year":"2011","title":"Improving PGP Web of Trust through the Expansion of Trusted Neighborhood","authors":"Guibing Guo, Jie Zhang, Julita Vassileva","author_ids":"3228473, 2710322, 1681161","abstract":"PGP Web of Trust where users can sign digital signatures on public key certificates of other users has been successfully applied in securing emails and files transmitted over the Internet. However, its rigorous restrictions on utilizable trust relationships and acceptable signatures limit its performance. In this paper, we first make some modification and extension to PGP Web of Trust by relaxing those constraints. In addition, we propose a novel method to further expand trusted neighborhood of users by merging the signatures of the trusted neighbors and finding the similar users based on the merged signature set. Confirmed by the experiments carried out in different simulated real-life scenarios, our method applied to both the modified and extended PGP methods can improve their performance. With the expansion of trusted neighborhood, the performance of the original PGP Web of Trust is also improved considerably.","cites":"2","conferencePercentile":"50"},{"venue":"Web Intelligence","id":"7ced04387da05f39d86a27a40fd42af072df29c8","venue_1":"Web Intelligence","year":"2008","title":"From Web to Map: Exploring the World of Music","authors":"Olga Goussevskaia, Michael Kuhn, Michael Lorenzi, Roger Wattenhofer","author_ids":"1785331, 1772075, 1768904, 1716440","abstract":"Ever growing music collections ask for novel ways of organization. The traditional browsing of folder hierarchies or search by title and album tends to be insufficient to maintain an overview of a collection of orders of thousands of tracks. Methods based on song similarity offer an alternative to keyword-based search. In this work we propose to use a high-dimensional map of the \"world of music\" as a data structure for music retrieval and exploration of personal collections. Our approach does not require expensive analysis of audio signals and scales to hundreds of thousands of tracks. The techniques presented in this work can be used in a variety of applications, ranging from automatic DJs to file sharing on mobile devices. As a concrete example, we have developed a web-application that allows users to visualize and navigate through their music collections and create playlists by specifying trajectories.","cites":"10","conferencePercentile":"86.66666667"},{"venue":"Web Intelligence","id":"0b5728f0def10192ea955a89bd8763174a311071","venue_1":"Web Intelligence","year":"2004","title":"Type-Based Composition of Information Services in Large Scale Environments","authors":"Ion Constantinescu, Boi Faltings, Walter Binder","author_ids":"1685108, 1735128, 4303222","abstract":"Service matchmaking and composition has recently drawn increasing attention in the research community. Most existing algorithms construct chains of services based on exact matches of input/output types. However, this does not work when the available services only cover a part of the range of the input type. We present an algorithm that also allows partial matches and composes them using switches that decide on the required service at runtime based on the actual data type. We report experiments on randomly generated composition problems that show that using partial matches can decrease the failure rate of the integration algorithm using only complete matches by up to 7 times with no increase in the number of directory accesses required. This shows that composition with partial matches is an essential and useful element of web service composition.","cites":"6","conferencePercentile":"74.21383648"},{"venue":"Web Intelligence","id":"186774d6aa12fd39a1d057e42c2513c26aa18f0e","venue_1":"Web Intelligence","year":"2006","title":"Efficient Service Composition Using Zero-Suppressed Reduced Ordered Binary Decision Diagrams","authors":"Walter Binder, Ion Constantinescu, Boi Faltings","author_ids":"4303222, 1685108, 1735128","abstract":"— Recent algorithms for automated service composition issue many complex queries to service directories. As service directories are shared resources, they may become performance bottlenecks. In order to increase scalability, we introduce a compact directory digest, which is distributed to clients and includes all information needed for automated service composition. Therefore , complex directory queries during service composition can be avoided. We encode a directory digest as a Zero-Suppressed Reduced Ordered Binary Decision Diagram (ZDD). In several steps, we refine a simple service composition algorithm in order to leverage the ZDD representation. Introducing specialized ZDD operations, we achieve a service composition algorithm that scales very well with an increasing size of the directory digest.","cites":"0","conferencePercentile":"3.333333333"},{"venue":"Web Intelligence","id":"475a1bb1b86d2559390fb6a951a3ef2444c992ed","venue_1":"Web Intelligence","year":"2012","title":"Sentiment Analysis of Turkish Political News","authors":"Mesut Kaya, Guven Fidan, Ismail Hakki Toroslu","author_ids":"1881935, 2057627, 2820623","abstract":"In this paper, sentiment classification techniques are incorporated into the domain of political news from columns in different Turkish news sites. We compared four supervised machine learning algorithms of Na&#239;ve Bayes, Maximum Entropy, SVM and the character based N-Gram Language Model for sentiment classification of Turkish political columns. We also discussed in detail the problem of sentiment classification in the political news domain. We observe from empirical findings that the Maximum Entropy and N-Gram Language Model outperformed the SVM and Na&#239;ve Bayes. Using different features, all the approaches reached accuracies of 65% to 77%.","cites":"5","conferencePercentile":"91.01123596"},{"venue":"Web Intelligence","id":"140e41c31949aedb36b22a15ffb4a3f225a65ae2","venue_1":"Web Intelligence","year":"2012","title":"Personalized News Recommendation Based on Collaborative Filtering","authors":"Florent Garcin, Kai Zhou, Boi Faltings, Vincent Schickel","author_ids":"2395924, 1741943, 1735128, 2241143","abstract":"Because of the abundance of news on the web, news recommendation is an important problem. We compare three approaches for personalized news recommendation: collaborative filtering at the level of news items, content-based system recommending items with similar topics, and a hybrid technique. We observe that recommending items according to the topic profile of the current browsing session seems to give poor results. Although news articles change frequently and thus data about their popularity is sparse, collaborative filtering applied to individual articles provides the best results.","cites":"3","conferencePercentile":"81.46067416"},{"venue":"Web Intelligence","id":"09e162c7786cdc24409ba5550cfc76edd5aa95e3","venue_1":"Web Intelligence","year":"2013","title":"Automatic Domain Identification for Linked Open Data","authors":"Sarasi Lalithsena, Pascal Hitzler, Amit P. Sheth, Prateek Jain","author_ids":"2973556, 1699771, 1709950, 3164102","abstract":"Linked Open Data (LOD) has emerged as one of the largest collections of interlinked structured datasets on the Web. Although the adoption of such datasets for applications is increasing, identifying relevant datasets for a specific task or topic is still challenging. As an initial step to make such identification easier, we provide an approach to automatically identify the topic domains of given datasets. Our method utilizes existing knowledge sources, more specifically Freebase, and we present an evaluation which validates the topic domains we can identify with our system. Furthermore, we evaluate the effectiveness of identified topic domains for the purpose of finding relevant datasets, thus showing that our approach improves reusability of LOD datasets.","cites":"6","conferencePercentile":"95.29411765"},{"venue":"Web Intelligence","id":"3653d7c4ee7803236a8b6d5462cf68728f836afa","venue_1":"Web Intelligence","year":"2009","title":"Monetizing User Activity on Social Networks - Challenges and Experiences","authors":"Meena Nagarajan, Kamal Baid, Amit P. Sheth, Shaojun Wang","author_ids":"3041479, 3218985, 1709950, 1721114","abstract":"This work summarizes challenges and experiences in monetizing user activity on public forums on social network sites. We present a approach that identifies the monetization potential of user posts and eliminates off-topic content to identify the most relevant and monetizable keywords for advertising. Preliminary studies using data from MySpace and Facebook show that 52% of ad impressions generated using keywords from our system were more targeted compared to the 30% relevant impressions generated without using our system.","cites":"5","conferencePercentile":"71.79487179"},{"venue":"Web Intelligence","id":"98d10aa8dc70d683b0937971e8f4c41ccf0aff6b","venue_1":"Web Intelligence","year":"2004","title":"Effective Interaction Principles for Online Product Search Environments","authors":"Pearl Pu, Boi Faltings, Marc Torrens","author_ids":"1781996, 1735128, 3274182","abstract":"To find products in online environments, people increasingly rely on computerized search tools.The performance of such tools depends crucially on an accurate model of their users' preferences.Obtaining such models requires an adequate interaction model and system guidance.","cites":"15","conferencePercentile":"94.02515723"},{"venue":"Web Intelligence","id":"06d21e19b59a8392e39dcf9e2b4a07316bab1f50","venue_1":"Web Intelligence","year":"2004","title":"Eliciting Truthful Feedback for Binary Reputation Mechanisms","authors":"Radu Jurca, Boi Faltings","author_ids":"2565197, 1735128","abstract":"Reputation mechanisms offer an efficient way of building the necessary level of trust in electronic markets. Feedback about an agent's past behavior can be aggregated into a measure of reputation, and used by other agents for taking trust decisions. Unfortunately, true feedback cannot be automatically assumed. In the absence of Trusted Third Parties, the mechanism has to make it rational for agents to truthfully share reputation information. In this paper we describe two mechanisms that can be used in decentralized environments for eliciting true feedback. The mechanisms are accompanied by examples inspired by real scenarios.","cites":"10","conferencePercentile":"87.42138365"},{"venue":"Web Intelligence","id":"079146123dfc0b9cb2d33be01451b49bdbe07009","venue_1":"Web Intelligence","year":"2004","title":"Incentive-Compatible Social Choice","authors":"Boi Faltings","author_ids":"1735128","abstract":"Many situations present a social choice problem where different self-interested agents have to agree on joint, co-ordinated decisions.For example, power companies have to agree on how to use the power grid, and airlines have to agree on how to schedule takeoffs and landings. Mechanisms for social choice are called incentive-compatible when cooperative behavior is optimal for all parties.The most well-known examples of incentive-compatible mechanisms are auctions.However, the party that receives the auction revenue has an incentive to manipulate the outcome to increase the revenue.For example, a power gird operator has an interest to reduce capacity and drive up prices.Conversely, if it provides sufficient capacity to every user it derives no revenue to cover its costs. We present a novel mechanism for social choice that is incentive-compatible without generating a payment surplus. We give several examples of applications where it solves the social choice problem without unwanted incentives, and provides significantly better overall utility than any other known mechanism.","cites":"3","conferencePercentile":"59.74842767"},{"venue":"Web Intelligence","id":"b74065ba2184ad757273793336570ab922fecf18","venue_1":"Web Intelligence","year":"2003","title":"Efficient Matchmaking and Directory Services","authors":"Ion Constantinescu, Boi Faltings","author_ids":"1685108, 1735128","abstract":"It has been widely recognised that matchmaking is an important component for environments populated with heterogeneous services. Several researchers have developed powerful techniques for the matchmaking problem in general. There are also specific representation of service capabilities such as DAML-S which provide a more specific framework for matchmaking. Most approaches to matchmaking have assumed a sequential search for a service with matching capabilities. This may become intractable when the number of available services gets large. In this paper, we consider how match-making can be developed into service directories that can be searched and maintained efficiently. Our main contribution is to show how matchmaking with DAML-S specifications can be integrated with efficient methods for searching and maintaining balanced directory trees. We also report on experimental results using an implementation based on generalised search trees.","cites":"47","conferencePercentile":"97.95918367"},{"venue":"Web Intelligence","id":"52cac870b4d8ea8a13a0d97639004f2dcf439a11","venue_1":"Web Intelligence","year":"2013","title":"Network Analysis of Third Party Tracking: User Exposure to Tracking Cookies through Search","authors":"Richard Gomer, Eduarda Mendes Rodrigues, Natasa Milic-Frayling, Monica M. C. Schraefel","author_ids":"2139882, 1704549, 1780840, 2284695","abstract":"Internet advertisers reach millions of customers through practices that real time tracking of users' online activities. The tracking is conducted by third party ad services engaged by the Web sites to facilitate marketing campaigns. Previous research has investigated tracking practices and tracking agencies associated with popular Web sites. Here we investigate the network properties of the third party referral structures that facilitate gathering of user information for the delivery of personalized ads. By considering third party domains associated with the top ten search results for a diverse set of queries, we arrived at the networks of third party domains in four search markets. We show a consistent network structure across markets, with a dominant connected component that, on average, includes 92.8% of network vertices and 99.8% of the connecting edges. There is 99.5% chance that a user will become tracked by all top 10 trackers within 30 clicks on search results. Finally, the third party networks exhibit properties of the small world networks. This implies a high-level global and local efficiency in spreading the user information and delivering targeted ads.","cites":"13","conferencePercentile":"100"},{"venue":"Web Intelligence","id":"ed1bb136098a135daba4d4ed8cd7d3d41b4f992b","venue_1":"Web Intelligence","year":"2008","title":"Social Tagging Behaviour in Community-Driven Question Answering","authors":"Eduarda Mendes Rodrigues, Natasa Milic-Frayling, Blaz Fortuna","author_ids":"1704549, 1780840, 1800870","abstract":"On-line community services such as Live QnA and Yahoo! Answers enable their members to ask questions and have them answered by the community. The questions are labelled by the users to facilitate search, navigation, and recommendations. In this paper we provide an in-depth analysis of the question labelling practices by contrasting the use of community generated tags in the Live QnA service with the use of topic categories from a fixed taxonomy in the Yahoo! Answers service. We found that community tagging is related to higher levels of social interactions amongst users. Analysis of the most frequently used community tags reveals that active users may establish strong social ties around specific tags. Furthermore, the discriminative value of individual community tags can be low since the corresponding questions may cover a variety of topics. Thus, appropriate care needs to be taken when designing search, browsing, and recommender features for question discovery.","cites":"10","conferencePercentile":"86.66666667"},{"venue":"Web Intelligence","id":"34567865f6934806b272f096b2d951575568278f","venue_1":"Web Intelligence","year":"2007","title":"Detection of Web Subsites: Concepts, Algorithms, and Evaluation Issues","authors":"Eduarda Mendes Rodrigues, Natasa Milic-Frayling, Blaz Fortuna","author_ids":"1704549, 1780840, 1800870","abstract":"The Internet is a vast resource of information. Unfortunately, finding and accessing this information is often a very cumbersome task even with existing information platforms. Searching on the WWW suffers from the fact that almost every word is ambiguous to a certain degree in the information-rich environment of the Internet. Clustering search results is a way to solve this problem. This paper demonstrates how to employ novel Information Retrieval measures to derive optimal parametrizations for a cluster algorithm.","cites":"3","conferencePercentile":"50.74074074"},{"venue":"Web Intelligence","id":"22f1b050cfe0b9a0bd1acbb0e8c02f845ec4b8dc","venue_1":"Web Intelligence","year":"2008","title":"Co-occurrence Analysis Focused on Blogger Communities","authors":"Shin-ya Sato, Kensuke Fukuda, Toshio Hirotsu, Satoshi Kurihara, Toshiharu Sugawara","author_ids":"2521219, 4371456, 1787777, 1717740, 1756020","abstract":"We studied the problem of finding a subspace of Web pages that is contextually consistent for co-occurrence analysis. We looked at blogs and proposed blogger-based co-occurrence analysis, which assumes that two items are relevant to each other if they appear in any of the blog entries posted by the same blogger. We show that (1) blogger-based analysis outperforms conventional page-based analysis in solving context-sensitive problems and that (2) analysis focused on bloggers forming a community yields better performance compared with that focused on isolated bloggers.","cites":"1","conferencePercentile":"29.39393939"},{"venue":"Web Intelligence","id":"3b6857fe3ced6e64ecb8d06750b025ca12dbe2c0","venue_1":"Web Intelligence","year":"2009","title":"Estimating Relevance of Items on Basis of Proximity of User Groups on Blogspace","authors":"Shin-ya Sato, Kensuke Fukuda, Toshio Hirotsu, Satoshi Kurihara, Toshiharu Sugawara","author_ids":"2521219, 4371456, 1787777, 1717740, 1756020","abstract":"We describe a new method to estimate the relevance of two items (such as products and works of art) on the basis of the relationship between the corresponding user (blogger) groups on a blogspace, where a user group refers to a collection of users interested in an item. We estimated the strength of the relationship between user groups on the basis of their proximity on the blogspace. We validated our approach through experimental studies using actual data. In developing the method for estimating relevance among items, we introduced a new technique for measuring the proximity of two groups of vertices on a network, which can be thought of as an extension of conventional co-occurrence analysis.","cites":"0","conferencePercentile":"8.974358974"},{"venue":"Web Intelligence","id":"143059c5ff08e70e866ece9739933933cb18a860","venue_1":"Web Intelligence","year":"2009","title":"Rigorous Probabilistic Trust-Inference with Applications to Clustering","authors":"Thomas DuBois, Jennifer Golbeck, Aravind Srinivasan","author_ids":"1742176, 1713898, 6003945","abstract":"The World Wide Web has transformed into an environment where users both produce and consume information. In order to judge the validity of information, it is important to know how trustworthy its creator is. Since no individual can have direct knowledge of more than a small fraction of information authors, methods for inferring trust are needed. We propose a new trust inference scheme based on the idea that a trust network can be viewed as a random graph, and a chain of trust as a path in that graph. In addition to having an intuitive interpretation, our algorithm has several advantages, noteworthy among which is the creation of an inferred trust-metric space where the shorter the distance between two people, the higher their trust. Metric spaces have rigorous algorithms for clustering, visualization, and related problems, any of which is directly applicable to our results.","cites":"12","conferencePercentile":"90.17094017"},{"venue":"Web Intelligence","id":"378adfafbca73a9a28e0aef1b1540b5ce812f0ef","venue_1":"Web Intelligence","year":"2004","title":"Web Intelligence in Mexico","authors":"Jesús Favela, Manuel Montes-y-Gómez, Edgar Chávez","author_ids":"1704175, 1715829, 1793108","abstract":"The Mexico Research Centre of the Web Intelligence Consortium was established in 2003 motivated by Mexico being selected as the host of the 2nd Atlantic Web Intelligence Conference. It currently has 18 members including faculty and doctoral students from 7 different institutions. The WIC-Mexico includes groups working in the areas of Intelligent Web Information Retrieval, Web Mining and Farming, Knowledge Management, and Agents in Ubiquitous Computing.","cites":"0","conferencePercentile":"14.4654088"},{"venue":"Web Intelligence","id":"2f159855cfacbcd0f28f38e5d95d807836ed0e94","venue_1":"Web Intelligence","year":"2006","title":"Web Service Discovery via Semantic Association Ranking and Hyperclique Pattern Discovery","authors":"Aabhas V. Paliwal, Nabil R. Adam, Hui Xiong, Christof Bornhövd","author_ids":"2655467, 1798962, 1707713, 1698512","abstract":"Semantic Web technology is a promising first step for automated web service discovery. Most current approaches for web service discovery cater to semantic web services, i.e., web services that have associated semantic descriptions. It is unrealistic, however, to expect all new services to have associated semantic descriptions. Furthermore, the descriptions of the vast majority of already existing services do not have explicitly associated semantics. In this paper we present a novel approach for web service discovery that combines semantic and statistical association metrics. Semantic metrics are based on the semantic aspects of relevant ontology. Statistical association metrics are based on the association aspects of web services instances (their inputs and outputs). Specifically, our approach exploits semantic relationship ranking for establishing semantic relevance, and a hyperclique pattern discovery method for grouping web service parameters into meaningful associations. These associations combined by the semantic relevance are then leveraged to discover and rank web services.","cites":"13","conferencePercentile":"73.33333333"},{"venue":"Web Intelligence","id":"0e00bf88fdc99681f18a62ee13ae07aec3e29f07","venue_1":"Web Intelligence","year":"2007","title":"A New Approach to Describe Web Services","authors":"Hongbing Wang, Hui Liu, Chen Wang, Patrick C. K. Hung","author_ids":"1748018, 1749569, 1710899, 1707003","abstract":"In this paper, we investigate the emotion classification of web blog corpora using support vector machine (SVM) and conditional random field (CRF) machine learning techniques. The emotion classifiers are trained at the sentence level and applied to the document level. Our methods also determine an emotion category by taking the context of a sentence into account. Experiments show that CRF classifiers outperform SVM classifiers. When applying emotion classification to a blog at the document level, the emotion of the last sentence in a document plays an important role in determining the overall emotion.","cites":"0","conferencePercentile":"7.777777778"},{"venue":"Web Intelligence","id":"38b596e7c2ec5926f8c9e7af79fe3b5503e5f91b","venue_1":"Web Intelligence","year":"2005","title":"Applying the HYRIWYG Incentive Mechanism in a Recommender System","authors":"Ana Cristina Bicharra Garcia, Leandro Neumann Ciuffo","author_ids":"1715457, 2405221","abstract":"The use of Recommender Systems (RS) has become common in several e-commerce websites. Collaborative Filtering is one of the most popular RS techniques. It infers an user's predilections based on similarity with other users. However, to work correctly, the RS depends on the evaluator's participation with truly opinions. The HYRIWYG mechanism proposes an incentive model to motivate users to contribute with a high number of opinions and, more important, guaranteeing the truthfulness of the information. In this paper, we present HYRIWYG mechanism and discuss it using an empirical study in the movie evaluation domain. Initial results highlight the great potential benefits of using this kind of incentive mechanism.","cites":"0","conferencePercentile":"9.477124183"},{"venue":"Web Intelligence","id":"24b3a2f2539b9a43918924c25896b5808048c62d","venue_1":"Web Intelligence","year":"2008","title":"Joint Extraction of Compound Entities and Relationships from Biomedical Literature","authors":"Cartic Ramakrishnan, Pablo N. Mendes, Rodrigo A. T. S. da Gama, Guilherme C. N. Ferreira, Amit P. Sheth","author_ids":"1710172, 1692493, 3284183, 1813238, 1709950","abstract":"In this paper we identify some limitations of contemporary information extraction mechanisms in the context of biomedical literature. We present an extraction mechanism that generates structured representations of textual content. Our extraction mechanism achieves this by extracting compound entities, and relationships between them, occuring in text. A detailed evaluation of the relationship and compound entities extracted is presented. Our results show over 62% average precision across 8 relationship types tested with over 82% average precision for compound entity identification.","cites":"5","conferencePercentile":"68.48484848"},{"venue":"Web Intelligence","id":"3412e1bc5de9eedfc8db3803f1802e19f454b219","venue_1":"Web Intelligence","year":"2008","title":"Growing Fields of Interest - Using an Expand and Reduce Strategy for Domain Model Extraction","authors":"Christopher Thomas, Pankaj Mehra, Roger Brooks, Amit P. Sheth","author_ids":"3137453, 1740961, 8044388, 1709950","abstract":"Domain hierarchies are widely used as models underlying information retrieval tasks. Formal ontologies and taxonomies enrich such hierarchies further with properties and relationships but require manual effort; therefore they are costly to maintain, and often stale. Folksonomies and vocabularies lack rich category structure. Classification and extraction require the coverage of vocabularies and the alterability of folksonomies and can largely benefit from category relationships and other properties. With Doozer, a program for building conceptual models of information domains, we want to bridge the gap between the vocabularies and Folksonomies on the one side and the rich, expert-designed ontologies and taxonomies on the other. Doozer mines Wikipedia to produce tight domain hierarchies, starting with simple domain descriptions. It also adds relevancy scores for use in automated classification of information. The output model is described as a hierarchy of domain terms that can be used immediately for classifiers and IR systems or as a basis for manual or semi-automatic creation of formal ontologies.","cites":"11","conferencePercentile":"89.6969697"},{"venue":"Web Intelligence","id":"2f4abdc400e1b262e829af857a317f2dba9b9dfd","venue_1":"Web Intelligence","year":"2007","title":"Semantic Convergence of Wikipedia Articles","authors":"Christopher Thomas, Amit P. Sheth","author_ids":"3137453, 1709950","abstract":"A large part of the modern web is characterized by usergenerated content categorized using collaborative tagging or folksonomy. It becomes difficult to search for relevant content because of ambiguity in lexical representation of concepts and variances in preferences of users. With more and more services relying on tags for content categorization, it is important that search techniques evolve to better suit the scenario. A promising approach towards solving these problems is to use machine common sense in conjunction with folksonomy. A past attempt to use this approach has shown positive results in finding relevant content but it does not address the issue of noise in search results. In this paper, we use the personalized web search technique of traditional web search systems to address the issue of irrelevant search results in common sense and folksonomy based search systems. In personalized web search, results are reflective of user's preferences, which are decided by search history and categories of interest. We propose modifications to personalized web search technique. Using this modified approach, we extend the basic common sense and folksonomy based search systems to address the issue of noise in search results.","cites":"16","conferencePercentile":"94.07407407"},{"venue":"Web Intelligence","id":"5d0ee59ee916d257445165ad0c4365c1b5577fed","venue_1":"Web Intelligence","year":"2007","title":"Blogosonomy : Autotagging Any Text Using Bloggers' Knowledge","authors":"Shigeru Fujimura, Ko Fujimura, Hidenori Okuda","author_ids":"2838520, 3053549, 2524469","abstract":"Finding and keeping track of other researchers' publication lists is an essential activity for every researcher, because they often contain citations not found elsewhere and may provide access to information, such as slides and talks, which can help other researchers keep abreast of state-ofthe-art knowledge and technology. There are many different ways to generate publication list web pages, and a researcher may have several different versions of a publication list on the Web because he holds different positions. So it is difficult to find the correct publication list web page from the top results retrieved from search engines, especially when we only know the name of the researcher. Very few works have addressed the problem. In this paper, we propose a system called the \"Publication List Web Page Finder\" (PLF), which can automatically find the publication list web pages for a given researcher's name. The PLF system is an automatic and language-independent system, and its main idea is that publication list web pages often contain many citations about a specific researcher, so the system uses those citations as clues to find out publication list web pages. Our experimental results show that the PLF system outperforms other approaches, especially when a researcher has multiple publication list web pages.","cites":"12","conferencePercentile":"91.11111111"},{"venue":"Web Intelligence","id":"ffe340b04c108c2f1834514c340a06866b65559d","venue_1":"Web Intelligence","year":"2009","title":"Zero-Sum Reward and Punishment Collaborative Filtering Recommendation Algorithm","authors":"Nan Li, Chunping Li","author_ids":"1736069, 1692180","abstract":"In this paper, we propose a novel memory-based collaborative filtering recommendation algorithm. Our algorithm use a new metric named influence weight, which is adjusted with zero-sum reward and punishment mechanism whenever the active user provides a new rating, to select neighbors and weight their opinions. Since the weight of personalized ratings, which contain more value for searching similar neighbors, is magnified appropriately in the formation of influence weight, our algorithm can find similar neighbors more effectively and filter the fake users introduced by shilling attacks automatically. When predicting for the active user, our algorithm select neighbors with the Top-N largest positive influence weights and predict their missing ratings. This rating smoothing method can alleviate data sparsity more efficiently. Then it computes the weighted average of all the selected neighbors' opinions and generates recommendations. Empirical results confirm that our algorithm achieves significant progress in all aspects of accuracy, scalability, robustness against data sparsity and shilling attacks simultaneously.","cites":"1","conferencePercentile":"29.48717949"},{"venue":"Web Intelligence","id":"8a3397de442af1ea5c234749856c4c4405b11680","venue_1":"Web Intelligence","year":"2003","title":"Bayesian Network-Based Trust Model","authors":"Yao Wang, Julita Vassileva","author_ids":"1711589, 1681161","abstract":"In this paper, we propose a Bayesian network-based trust model. Since trust is multi-faceted, even in the same context, agents still need to develop differentiated trust in different aspects of other agents' behaviors. The agent's needs are different in different situations. Depending on the situation, an agent may need to consider its trust in a specific aspect of another agent's capability or in a combination of multiple aspects. Bayesian networks provide a flexible method to present differentiated trust and combine different aspects of trust. A Bayesian network-based trust model is presented for a file sharing peer-to-peer application .","cites":"96","conferencePercentile":"100"},{"venue":"Web Intelligence","id":"5f7678f7ba3cf502cc7e0f65dbe71d3bc73e84f8","venue_1":"Web Intelligence","year":"2004","title":"Trust-Based Community Formation in Peer-to-Peer File Sharing Networks","authors":"Yao Wang, Julita Vassileva","author_ids":"1711589, 1681161","abstract":"Decentralized peer-to-peer (P2P) networks can benefit from forming interest-based communities that can provide peers with information about the resources shared in the community and collectively computed rating of their quality as well as about the agents in the community and their reputation. We propose a mechanism for forming communities in a P2P system for sharing academic papers. The mechanism requires each agent to compute its trust in the agents with whom it interacts. A simulation shows that such communities can benefit peers.","cites":"26","conferencePercentile":"96.5408805"},{"venue":"Web Intelligence","id":"12949dd45d05ba5ad0eab34aefece4740e7f9865","venue_1":"Web Intelligence","year":"2012","title":"Analysis of Discussion Page in Wikipedia Based on User's Discussion Capability","authors":"Sungmin Joo, Hideaki Takeda","author_ids":"8175834, 1696371","abstract":"Wikipedia is the user contributed encyclopedia edited collaboratively by a wide-range of people. Wikipedia usually determines contents of article and editorial policies through discussion among participants. It requires a lot of effort in deducing its conclusion often due to protracted discussion. We need some measurement to examine how discussion is valuable to reach conclusion. So, we call it discussion validity and define it with the model with discussion capability of participants. Discussion capability of participants consists of three features each of which represents characteristic aspect of users' behavior in discussion, and approximated from the corresponding three features of their utterances. We conducted the experiments with the subjects to verify the model and found that our model resulted better than the conventional model and proposed the automatic prediction of discussion validity using the text analysis. Then we estimated discussion validity through the model with the estimated values. It turned out that the estimation was well fitted with the values by the subjects.","cites":"0","conferencePercentile":"20.78651685"},{"venue":"Web Intelligence","id":"66c28b16f8aa6a8c1d48f2f92323af71cd6c7c61","venue_1":"Web Intelligence","year":"2007","title":"Layers and Hierarchies in Real Virtual Networks","authors":"Olga Goussevskaia, Michael Kuhn, Roger Wattenhofer","author_ids":"1785331, 1772075, 1716440","abstract":"This talk will trace the growing influence of fundamental ideas from computer science on the nature of research in a number of scientific fields. There is a growing awareness that information processing lies at the heart of the processes studied in fields as diverse as quantum mechanics, statistical physics, nanotechnology, neuroscience, linguistics, economics and sociology. Increasingly, mathematical models in these fields are expressed in algorithmic languages and describe algorithmic processes. The speaker will briefly describe connections between quantum computing and the foundations of quantum mechanics, and between statistical mechanics and phase transitions in computation. He will indicate how the growth of the Web has created new phenomena to be investigated by sociologists and economists. He will then focus in greater detail on computational molecular biology, where the view of living cells as complex information processing systems has become the dominant paradigm, and will discuss specific algorithmic problems arising in the sequencing of genomes, the comparative analysis of the resulting genomic sequences,the modeling of networks of interacting proteins, and the associations between genetic variation and disease.","cites":"4","conferencePercentile":"60.37037037"},{"venue":"Web Intelligence","id":"c42407de1086d39e6e0a774c744e63ac4ea3dbfa","venue_1":"Web Intelligence","year":"2010","title":"Effective Web Service Selection via Communities Formed by Super-Agents","authors":"Yao Wang, Jie Zhang, Julita Vassileva","author_ids":"1711589, 2710322, 1681161","abstract":"In this paper, we propose a novel community-based approach for web service selection where super-agents with more capabilities serve as community managers. They maintain communities and build community-based reputation for a service based on the opinions from all community members that have similar interests and judgement criteria. The community-based reputation is useful for consumer agents in selecting satisfactory services when they do not have much personal experience with the services. Experimental results show that our approach results in more effective service selection. A practical reward mechanism is also introduced to create incentives for super-agents to contribute their resources and provide truthful community-based reputation information, as strong support for our approach.","cites":"6","conferencePercentile":"81.77966102"},{"venue":"Web Intelligence","id":"59e4475c84e6313a576627fb0fdd3463b2888e48","venue_1":"Web Intelligence","year":"2013","title":"Characterising Concepts of Interest Leveraging Linked Data and the Social Web","authors":"Fabrizio Orlandi, Pavan Kapanipathi, Amit P. Sheth, Alexandre Passant","author_ids":"1732632, 2223082, 1709950, 1733056","abstract":"Extracting and representing user interests on the Social Web is becoming an essential part of the Web for personalisation and recommendations. Such personalisation is required in order to provide an adaptive Web to users, where content fits their preferences, background and current interests, making the Web more social and relevant. Current techniques analyse user activities on social media systems and collect structured or unstructured sets of entities representing users' interests. These sets of entities, or user profiles of interest, are often missing the semantics of the entities in terms of: (i) popularity and temporal dynamics of the interests on the Social Web and (ii) abstractness of the entities in the real world. State of the art techniques to compute these values are using specific knowledge bases or taxonomies and need to analyse the dynamics of the entities over a period of time. Hence, we propose a real-time, computationally inexpensive, domain independent model for concepts of interest composed of: popularity, temporal dynamics and specificity. We describe and evaluate a novel algorithm for computing specificity leveraging the semantics of Linked Data and evaluate the impact of our model on user profiles of interests.","cites":"0","conferencePercentile":"19.41176471"},{"venue":"Web Intelligence","id":"2a93f7449a08a412664a6cd7360c3dbff8486fc4","venue_1":"Web Intelligence","year":"2012","title":"An Empirical Analysis of Semantic Techniques Applied to a Network Management Classification Problem","authors":"Aidan Boran, Ivan Bedini, Christopher J. Matheus, Peter F. Patel-Schneider, Stefan Bischof","author_ids":"2174495, 1892586, 1688579, 1683553, 1957042","abstract":"Semantic technologies are increasingly being employed to integrate, relate and classify heterogeneous data from various problem domains. To date, however, little empirical analysis has been carried out to help identify the benefits and limitations of different semantic approaches on specific data integration and classification problems. This paper evaluates three alternative semantic techniques for performing classification over data derived from the telecommunications domain. The problem of interest involves inferring the \"health\" status of network nodes (femtocells) from synthesized performance management (PM) instance data based on the operational PM schema. The semantic approaches used in the comparison include OWL2 axioms, SPARQL queries and SWRL rules. Empirical tests were performed across a range of data set sizes, using Pellet for axioms and rules and ARQ for queries. The experimental results provide (mostly) quantitative and (some) qualitative indication of the relative merits of each approach. Key among these findings is confirmation of the clear superiority of queries over rules and axioms in terms of raw performance and scalability.","cites":"0","conferencePercentile":"20.78651685"},{"venue":"Web Intelligence","id":"6853dfcfcd5e0aa7cf697cf860a4d25f25070f15","venue_1":"Web Intelligence","year":"2007","title":"Why HTTPS Is Not Enough - A Signature-Based Architecture for Trusted Content on the Social Web","authors":"Matthias Quasthoff, Harald Sack, Christoph Meinel","author_ids":"3136518, 2907174, 1708312","abstract":"Non-native English speakers often have problems determining the exact form of an idiomatic expression while they have some vague idea about the key words in them. In this paper, we describe a system called Webtionary that allows users to consult idiomatic usage by entering a questionable expression. Webtionary uses web search to find candidate corrections and suggests expressions that are commonly used in writing and semantically-related to the user query. Evaluation results show that Webtionary significantly outperforms direct web search in providing useful suggestions.","cites":"4","conferencePercentile":"60.37037037"},{"venue":"Web Intelligence","id":"6dea168b170cf9cd803dced45ff2a805dba98fd8","venue_1":"Web Intelligence","year":"2013","title":"Identifying Domain Experts in the Blogosphere - Ranking Blogs Based on Topic Consistency","authors":"Philipp Berger, Patrick Hennig, Christoph Meinel","author_ids":"1764842, 1760108, 1708312","abstract":"Current ranking algorithms, such as Page Rank, Technorati authority, and BI-Impact, favor blogs that report on a diversity of topics since those attract a large audience and thus more visitors, links, and comments. On the other side, niche blogs with a very specific topic only attract a small audience and thus have only a small reach. This results in a low ranking from today's blog retrieval systems. We argue that the consistency of a blog, i.e. how focused an author reports on a single topic, is a sign for expert knowledge. To find these blogs is particular important for other domain experts to identify blogs that they would like to follow and stay in active contact. To ease the retrieval of expert blogs, i.e. to separate them from the mass of blogs that report on random topics, we introduce a metric for blogs based on topic consistency. We divide the consistency ranking in four different aspects: (1) intra-post, (2) inter-post, (3) intra-blog, and (4) inter-blog consistency. By evaluating the metric with a test data set of 12,000 crawled blogs, we demonstrate the plausibility of our approach.","cites":"0","conferencePercentile":"19.41176471"},{"venue":"Web Intelligence","id":"216e6e472025383b49f184b12fd817bc53b64aac","venue_1":"Web Intelligence","year":"2010","title":"Visualizing Blog Archives to Explore Content- and Context-Related Interdependencies","authors":"Justus Bross, Patrick Schilf, Christoph Meinel","author_ids":"2696297, 3130566, 1708312","abstract":"There has been virtually little in the way of user interfaces designed for the exploration and information gathering from large weblog datasets to allow for an integrated and aggregated knowledge collection and information analysis tool. Users have to rely on their own capability to find, select or filter entries and navigate through a blog archive. For weblogs with a large collection of entries this task easily becomes tedious, since current blog interfaces lack fundamental support for facilitating the exploration of their archives. A solution to this problem could be POSTCONNECT, a mature blog-archive visualization tool presented in this paper.","cites":"4","conferencePercentile":"70.33898305"},{"venue":"Web Intelligence","id":"4fb0968d988093e5b6918936a33803f9b462b65b","venue_1":"Web Intelligence","year":"2007","title":"Detecting the Changes ofWeb Students' Learning Interest","authors":"Long Wang, Christoph Meinel","author_ids":"3226127, 1708312","abstract":"Many semantic web applications require selective sharing of ontologies between autonomous entities due to copyright, privacy or security concerns. In such cases, an agent might want to hide a part of its ontology while sharing the rest. However, prohibiting any use of the hidden part of the ontology in answering queries from other agents may be overly restrictive. We provide a framework for privacypreserving reasoning in which an agent can safely answer queries against its knowledge base using inferences based on both the hidden and visible part of the knowledge base, without revealing the hidden knowledge. We show an application of this framework in the widely used special case of hierarchical ontologies.","cites":"1","conferencePercentile":"23.7037037"},{"venue":"Web Intelligence","id":"f5a337620a98e1a2b145c3140d2c35cc3c2d52b8","venue_1":"Web Intelligence","year":"2008","title":"Thinking Big - AI at Web Scale","authors":"Michael J. Witbrock","author_ids":"2819135","abstract":"The true promise of the Web can&#8217;t be realised by the lone programmers and simple applications of Web 1.0; it can&#8217;t even be realised by the advanced interfaces and hordes of contributing users of Web 2.0 - it can be realised by individuals and groups of humans collaborating with individual and cloud connected computers. That&#8217;s Web 3.0. What will it take to make computers into effective collaborators? It will take heterogeneous, ubiquitous reasoning at massive scale - the aim of the EU funded LarKC project; It will take semantically rich shared representations - the aim of OpenCyc (and other, linked projects); it will take more sophisticated reasoning, including probabilistic and contextual reasoning, and it will take sophisticated, social, human-computer and computer-interfaces. In this talk, I&#8217;ll focus on Cycorp Europe and our effort in the LarKC project, and describe how we hope it will start to tie our work, and the work of others, together to produce a truly knowledgeable, collaborative, intelligent Web","cites":"0","conferencePercentile":"10.60606061"},{"venue":"Web Intelligence","id":"d83770db6ddc17ff635ae2c376e254946c610240","venue_1":"Web Intelligence","year":"2006","title":"Effective Page Segmentation Combining Pattern Analysis and Visual Separators for Browsing on Small Screens","authors":"Peifeng Xiang, Xin Yang, Yuanchun Shi","author_ids":"1707918, 6826800, 1732440","abstract":"Page segmentation plays a key role in browsing on small screens. It breaks a large page into smaller segments according to their semantic relationships. Then, various approaches such as single column adaptation and thumbnail view with zooming links can be implemented based on these page segments. However, for current flexible web pages, segmentation remains a challenging task. This paper proposes an effective automatic segmentation method which combining pattern analysis and visual separators. The basic idea is that a page's semantic structure is largely reflected by repeated continuous patterns and visual separators, which coincides with human's visual perception. The proposed method works in three steps: generating a refined tag tree from the DOM tree, recognizing and merging inexact patterns recursively, and segmenting the others by visual separators. Our experimental results show that the proposed method outperforms existing methods, especially for pages automatically generated from templates.","cites":"8","conferencePercentile":"55.83333333"},{"venue":"Web Intelligence","id":"0f560301ac19cc3008e59522733641dbb57944b5","venue_1":"Web Intelligence","year":"2005","title":"Measuring the Relative Performance of Schema Matchers","authors":"Shlomo Berkovsky, Yaniv Eytani, Avigdor Gal","author_ids":"1696183, 3253335, 1782519","abstract":"Schema matching is a complex process focusing on matching between concepts describing the data in heterogeneous data sources. There is a shift from manual schema matching, done by human experts, to automatic matching, using various heuristics (schema matchers). In this work, we consider the problem of linearly combining the results of a set of schema matchers. We propose the use of machine learning algorithms to learn the optimal weight assignments, given a set of schema matchers. We also suggest the use of genetic algorithms to improve the process efficiency.","cites":"3","conferencePercentile":"47.05882353"},{"venue":"Web Intelligence","id":"cc9b075c6cacc2ab4ff15f29447f634137f5b902","venue_1":"Web Intelligence","year":"2013","title":"Service Discovery Method Based on User Intent","authors":"Yasuyuki Kataoka, Tomoki Watanabe, Kiyoshi Tanaka, Suguru Higashino","author_ids":"1742399, 1686577, 1704974, 1713187","abstract":"This paper introduces a method that supports a user who has only a vague idea of service use in discovering suitable mobile applications. The proposal allows the user to add application functions after selecting the purpose of service use from a list of novel application functions. The proposal is based on our concept of ISHI (Intent of Service and Human Interface) which works as an interface between service and user. ISHI can automatically determine the importance level and the novelty level of an application from various data. The proposed method is based on not only natural language but also the structured data of mobile applications. User experiments show that the proposed method yields, compared to the conventional method, better performance with respect to the time duration of application search and the frequency of recourse to new service functions.","cites":"0","conferencePercentile":"19.41176471"},{"venue":"Web Intelligence","id":"770bb2ff6336fc4d7f5235b17d8d8b61ab6bcaf8","venue_1":"Web Intelligence","year":"2011","title":"ImpactWheel: Visual Analysis of the Impact of Online News","authors":"Wei Wei, Nan Cao, Jon Atle Gulla, Huamin Qu","author_ids":"1725923, 8476684, 1755274, 1782565","abstract":"Online news usually describes various events over multiple topics. Some of them may generate great impact and affection on other events, organizations or people. For example, a bankruptcy news about a big company may generate a great impact on other companies. Detecting this kind of impact helps users better to understand the affection of a specified event and its epidemic. Powerful text mining techniques have been developed to help users to detect topic trends of news articles. However, there is a lack of effective analysis tools that analyze and reveal the news impact in an intuitive approach. In this paper, we introduce Impact Wheel, an explorative visual analysis system for topic driven news impact detection. We describe two unique aspects of Impact Wheel, including 1) topic driven impact analysis and 2) interactive rich context visualization. Experiments on performance evaluation show that our proposed approach outperforms the two baseline methods on topic driven impact analysis. In addition, we demonstrate the power of the Impact Wheel system through a case study, which shows the benefits of this work, especially in support of rich topic data analysis.","cites":"1","conferencePercentile":"31.39534884"},{"venue":"Web Intelligence","id":"6a72a0831b9601939b32f3c8db99205ec48e8820","venue_1":"Web Intelligence","year":"2005","title":"The WebCAT Framework - Automatic Generation of Meta-Data for Web Resources","authors":"Bruno Martins, Mário J. Silva","author_ids":"1699763, 2564666","abstract":"Automated methods for resource annotation are a clear necessity, as the success of the SemanticWeb depends on the availability of Web resources with meta-data conforming to known standards and ontologies. This paper describes the WebCAT framework for automatically generating RDF descriptions of Web pages. We present a general view of the system and the algorithms involved, giving an emphasis to typical issues in processing Web data.","cites":"4","conferencePercentile":"55.22875817"},{"venue":"Web Intelligence","id":"43c8766a13db81ed71d48ee6243e04ae734e8521","venue_1":"Web Intelligence","year":"2008","title":"The Metadata Triumvirate: Social Annotations, Anchor Texts and Search Queries","authors":"Michael G. Noll, Christoph Meinel","author_ids":"2248606, 1708312","abstract":"In this paper, we study and compare three different but related types of metadata about web documents: social annotations provided by readers of web documents, hyperlink anchor text provided by authors of web documents, and search queries of users trying to find web documents. We introduce a large research data set called CABS120k08 which we have created for this study from a variety of information sources such as AOL500k, the Open Directory Project, del.icio.us/Yahoo!, Google and the WWW in general. We use this data set to investigate several characteristics of said metadata including length, novelty, diversity, and similarity and discuss theoretical and practical implications.","cites":"22","conferencePercentile":"98.48484848"},{"venue":"Web Intelligence","id":"8e3246116953755d99ec9b575a76c4160eaaa465","venue_1":"Web Intelligence","year":"2010","title":"Modeling Users' Information Goal Transitions and Satisfaction Judgment: Understanding the Full Search Process","authors":"Shandian Zhe, Tian Xia, Xueqi Cheng","author_ids":"2390798, 1737585, 1978584","abstract":"To improve web search effectiveness and help personalized search applications, it is important to understand users' search process, especially the underlying information goal transitions and satisfaction judgment on result pages. Unlike previous work modeling the two types of hidden information separately, the paper proposes to simultaneously model them based on users' full search process, including both queries and clicks. Thus, a full model can be built up and the dependences between them can be leveraged. Specially, we employ a hierarchical conditional random field (HCRF) for learning and prediction, with fruitful search activity features proposed and leveraged. Experimental results show that our approach reaches a high overall precision(87%) and significantly outperforms the baseline methods. Moreover, our model is applied in a re-ranking application and shows that it can benefit personalized web search.","cites":"2","conferencePercentile":"51.27118644"}]}