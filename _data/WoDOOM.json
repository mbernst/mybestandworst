{"WoDOOM.csv":[{"venue":"WoDOOM","id":"3915e76998ccc2ad305ed16219047758761b497c","venue_1":"WoDOOM","year":"2013","title":"Finding fault: detecting issues in a versioned ontology","authors":"Maria Copeland, Rafael S. Gonçalves, Bijan Parsia, Ulrike Sattler, Robert Stevens","author_ids":"8354499, 2310943, 1720331, 1695737, 1702360","abstract":"Understanding ontology evolution is becoming an active topic of interest to ontology engineers, e.g., we have large collaborative developed ontolo-gies but, unlike software engineering, comparatively little is understood about the dynamics of historical changes, especially at a fine level of granularity. Only recently has there been a systematic analysis of changes across ontology versions, but still at a coarse-grained level. The National Cancer Institute (NCI) Thesaurus (NCIt) is a large, collaboratively-developed ontology, used for various Web and research-related purposes, e.g., as a medical research controlled vocabulary. The NCI has published ten years worth of monthly versions of the NCIt as Web Ontol-ogy Language (OWL) documents, and has also published reports on the content of, development methodology for, and applications of the NCIt. In this paper, we carry out a fine-grained analysis of the asserted axiom dynamics throughout the evolution of the NCIt from 2003 to 2012. From this, we are able to identify ax-iomatic editing patterns that suggest significant regression editing events in the development history of the NCIt.","cites":"4","conferencePercentile":"71.42857143"},{"venue":"WoDOOM","id":"fa5fb7fccc3448a720831f76000bca4be75b5284","venue_1":"WoDOOM","year":"2013","title":"Debugging weighted ontologies","authors":"Heiner Stuckenschmidt","author_ids":"1698459","abstract":"We present our work on debugging weighted ontologies. We define this problem as computing a consistent subontology with a maximal sum of axiom weights. We present a reformulation of the problem as finding the most probable consistent ontology according to a log-linear model and show how existing methods from probabilistic reasoning can be adapted to our problem. We close with a discussion of the possible application of weighted ontology debugging to web scale information extraction. Probably the most often quoted advantage of logic-based ontologies are the possibility to check the model for different kinds of logical inconsistencies as possible symptoms of modeling errors. Since the work of Schlohbach and Cornet [19] many researchers have investigated the task of debugging description-logic ontologies, which dies not only include the detection of logical inconsistency, but also the identifying minimal sets of axioms causing it and removing axioms from the ontology to make it consistent again (e.g. [18, 16, 6, 8]). While computing the cause of an inconsistency is relatively well understood and established techniques from diagnostic reasoning like the hitting set algorithm have been successfully applied and adapted to the problem of debugging ontologies, the decision which axioms to discard to retain consistency is still a largely unsolved problem. The classical solution used for instance in the field of believe revision is principle of minimal change that prefers solutions that remove the least number of axioms (compare e.g. [21]. While this approach has theoretical merits, it is not adequate for practical applications. For certain special cases such as debugging ontology mappings we can even observe that the principle of minimal change will remove correct axioms in most cases leaving incorrect ones in. As a consequence, researchers have focused on interactive debugging methods where a human user decides which axioms to remove while being supported by the debugging system [8, 10]. While interactive repair of ontologies is feasible when ontologies are rather small, more recently researchers get interested in debugging ontologies that have been automatically created from text or data sources. The resulting models are typically quite big and contain a high number of inconsistencies. While many classical debugging tools already have trouble in more classical settings as we have shown in our study on the practical applicability of debugging [20], using these tools on sets of automatically generated axioms turns out to be a hopeless endeavor. In this paper, we summarize work on …","cites":"1","conferencePercentile":"28.57142857"}]}