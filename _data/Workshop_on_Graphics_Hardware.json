{"Workshop_on_Graphics_Hardware.c":[{"venue":"Workshop on Graphics Hardware","id":"ff442de770350e738017c8909957088411817d06","venue_1":"Workshop on Graphics Hardware","year":"1998","title":"Simple Models of the Impact of Overlap in Bucket Rendering","authors":"Milton Chen, Gordon Stoll, Homan Igehy, Kekoa Proudfoot, Pat Hanrahan","author_ids":"1713071, 2753832, 2204933, 2519393, 4982303","abstract":"Bucket rendering is a technique in which the framebuffer is subdivided into coherent regions that are rendered independently. The primary benefits of this technique are the decrease in the size of the working set of framebuffer memory required during rendering and the possibility of processing multiple regions in parallel. The drawbacks of this technique are the cost of computing the regions overlapped by each triangle and the redundant work required in processing triangles multiple times when they overlap multiple regions. Tile size is a critical parameter in bucket rendering systems: smaller tile sizes allow smaller memory footprints and better parallel load balancing but exacerbate the problem of redundant computation. In this paper, we use mathematical models, instrumentation, and trace-driven simulation to evaluate the impact of overlap and conclude that the problem of overlap is limited in scope. If triangles are small, the overlap factor itself is also small. If triangles are large, overlap is high but pixel work dominates the rendering time. In pipelined rendering systems, the worst-case impact of overlap occurs when the area of an input triangle is equal to the area for which the pipeline is balanced—that is, the triangle-related computation time is equal to the pixel-related computation time. Thus, as the current trends of exponentially increasing triangle rate, slowly increasing screen resolution, and increasing per-pixel computation continue to push this balance point toward triangles with smaller area, bucket rendering systems will be able to utilize smaller tiles efficiently.","cites":"15","conferencePercentile":"40.90909091"},{"venue":"Workshop on Graphics Hardware","id":"79acae8e206078c57efe4d2b9db6c4c9673ade95","venue_1":"Workshop on Graphics Hardware","year":"2000","title":"Towards Interactive Bump Mapping with Anisotropic Shift-Variant BRDFs","authors":"Jan Kautz, Hans-Peter Seidel","author_ids":"1690538, 1746884","abstract":"In this paper a technique is presented that combines interactive hardware accelerated bump mapping with shift-variant anisotropic reflectance models. An evolutionary path is shown how some simpler reflectance models can be rendered at interactive rates on current low-end graphics hardware, and how features from future graphics hardware can be exploited for more complex models.\nWe show how our method can be applied to some well known reflectance models, namely the Banks model, Ward's model, and an anisotropic version of the Blinn-Phong model, but it is not limited to these models.\nFurthermore, we take a close look at the necessary capabilities of the graphics hardware, identifiy problems with current hardware, and discuss possible enhancements.","cites":"62","conferencePercentile":"85.71428571"},{"venue":"Workshop on Graphics Hardware","id":"19b575dea180445b9a8ec8a349f50d1613c61693","venue_1":"Workshop on Graphics Hardware","year":"1998","title":"Performance Issues of a Distributed Frame Buffer on a Multicomputer","authors":"Bin Wei, Douglas W. Clark, Edward W. Felten, Kai Li","author_ids":"2434653, 3064926, 1752733, 2359779","abstract":"A multiple-port, distributed frame buffer has been recently proposed to support parallel rendering on multicomputers. This paper describes an implementation of such a distributed frame buffer for the Intel Paragon routing network, and reports its performance results. We have conducted several experiments with the system we have developed. Our results indicate that placing a multiple-port, distributed frame buffer directly on the host internal routing network can provide high throughput to eliminate the bottleneck of merging a final image from multiple processors to a frame buffer. This architectural approach can also effectively support image composition for sort-last. The synchronization algorithm we have developed requires only one-way communication and minimizes receive overhead for message passing to the frame buffer.","cites":"7","conferencePercentile":"22.72727273"},{"venue":"Workshop on Graphics Hardware","id":"4fa0c0f39bbd8b5c186c3e895efb315e92a94669","venue_1":"Workshop on Graphics Hardware","year":"2000","title":"Tracking Graphics State For Networked Rendering","authors":"Ian Buck, Greg Humphreys, Pat Hanrahan","author_ids":"2999741, 1734552, 4982303","abstract":"As networks get faster, it becomes more feasible to render large data sets remotely. For example, it is useful to run large scientific simulations on remote compute servers but visualize the results of those simulations on one or more local displays. The WireGL project at Stanford is researching new techniques for rendering over a network. For many applications, we can render remotely over a gigabit network to a tiled display with little or no performance loss over running locally. One of the elements of WireGL that makes this performance possible is our ability to track the graphics state of a running application.\nIn this paper, we will describe our techniques for tracking state, as well as efficient algorithms for computing the difference between two graphics contexts. This fast differencing operation allows WireGL to transmit less state data over the network by updating server state lazily. It also allows our system to context switch between multiple graphics applications several million times per second without flushing the hardware accelerator. This results in substantial performance gains when sharing a remote display between multiple clients.\n network to a tiled display with little or no performance loss over running locally. One of the elements of WireGL that makes this performance possible is our ability to track the graphics state of a running application.\nIn this paper, we will describe our techniques for tracking state, as well as efficient algorithms for computing thi","cites":"53","conferencePercentile":"78.57142857"},{"venue":"Workshop on Graphics Hardware","id":"d1181fbd7864cc9eda86f31fce678d5a70b4ab2b","venue_1":"Workshop on Graphics Hardware","year":"1999","title":"Parallel Texture Caching","authors":"Homan Igehy, Matthew Eldridge, Pat Hanrahan","author_ids":"2204933, 2446549, 4982303","abstract":"The creation of high-quality images requires new functionality and higher performance in real-time graphics architectures. In terms of functionality, texture mapping has become an integral component of graphics systems, and in terms of performance, parallel techniques are used at all stages of the graphics pipeline. In rasterization, texture caching has become prevalent for reducing texture bandwidth requirements. However, parallel rasteriza-tion architectures divide work across multiple functional units, thus potentially decreasing the locality of texture references. For such architectures to scale well, it is necessary to develop efficient parallel texture caching subsystems. We quantify the effects of parallel rasterization on texture locality for a number of rasterization architectures, representing both current commercial products and proposed future architec-tures. A cycle-accurate simulation of the rasterization system demonstrates the parallel speedup obtained by these systems and quantifies inefficiencies due to redundant work, inherent parallel load imbalance, insufficient memory bandwidth, and resource contention. We find that parallel texture caching works well, and is general enough to work with a wide variety of rasterization architectures.","cites":"20","conferencePercentile":"66.66666667"},{"venue":"Workshop on Graphics Hardware","id":"04009e047e998d6695f7be12afa5f1ebc617fef3","venue_1":"Workshop on Graphics Hardware","year":"1993","title":"Real-Time Architecture for High Resolution Volume Visualization","authors":"Hanspeter Pfister, Arie E. Kaufman","author_ids":"1701371, 1716343","abstract":"This paper describes a high-performance &pecial-purpose system, the Cube-3 machine, for displaying and manipulating high-resolution volumetric datasets in real-time. Cube-3 will allow scientists, engineers, and biomedical researchers to interactively visualize and investigate their static high-resolution sampled, simulated, or computed volumetric dataset. Furthermore, once acquisition devices or mechanisms are capable of acquiring a complete high-resolution dynamic dataset in real-time, CubeS , tightly coupled with them, will be capable of delivering real-time 4D (spatial-temporal) volume visualization, a task currently not possible with present technologie&.","cites":"12","conferencePercentile":"100"},{"venue":"Workshop on Graphics Hardware","id":"832233e9beed6d1c33571dab2a2b9c84b8de163b","venue_1":"Workshop on Graphics Hardware","year":"2000","title":"Prefiltered Antialiased Lines Using Half-Plane Distance Functions","authors":"Bob McNamara, Joel McCormack, Norman P. Jouppi","author_ids":"1919773, 2230633, 1715454","abstract":"We describe a method to compute high-quality antialiased lines by adding a modest amount of hardware to a fragment generator based upon half-plane edge functions. (A fragment contains the information needed to paint one pixel of a line or a polygon.) We surround an antialiased line with four edge functions to create a long, thin, rectangle. We scale the edge functions so that they compute signed distances from the four edges. At each fragment within the antialiased line, the four distances to the fragment are combined and the result indexes an intensity table. The table is computed by convolving a filter kernel with a prototypical line at various distances from the line's edge. Because the convolutions aren't performed in hardware, we can use wider, more complex filters with better high-frequency rejection than the narrow box filter common to supersampling antialiasing hardware. The result is smoother antialiased lines.\nOur algorithm is parameterized by the line width and filter radius. These parameters do not affect the rendering algorithm, but only the setup of the edge functions. Our algorithm antialiases line endpoints without special handling. We exploit this to paint small blurry squares as approximations to small antialiased round points. We do not need a different fragment generator for antialiased lines, and so can take advantage of all optimizations introduced in the existing fragment generator.","cites":"6","conferencePercentile":"17.85714286"},{"venue":"Workshop on Graphics Hardware","id":"07d887d6e2b8e893d1a7d88482664d395ae18ca6","venue_1":"Workshop on Graphics Hardware","year":"1994","title":"Sheared Interpolation and Gradient Estimation for Real-Time Volume Rendering","authors":"Hanspeter Pfister, Frank Wessels, Arie E. Kaufman","author_ids":"1701371, 2090599, 1716343","abstract":"In this paper we present a technique for the interactive control and display of static and dynamic 3D datasets. We describe novel ways of tri-linear interpolation and gradient estimation for a real-time volume rendering system, using coherency between rays. We show simulation results that compare the proposed methods to traditional algorithms and present them in the context of Cube-3, a special-purpose architecture c apable of rendering 512 3 16-bit per voxel datasets at over 20 frames per second.","cites":"15","conferencePercentile":"100"},{"venue":"Workshop on Graphics Hardware","id":"323690769a56e8654726e65d58a7663f974b5a65","venue_1":"Workshop on Graphics Hardware","year":"1995","title":"Towards a Scalable Architecture for Real-Time Volume Rendering","authors":"Hanspeter Pfister, Arie E. Kaufman, Frank Wessels","author_ids":"1701371, 1716343, 2090599","abstract":"In this paper we present our research eorts towards a scalable volume rendering architecture for the real-time visualization of dynamically changing high-resolution datasets. Using a linearly skewed memory interleav-ing we were able to develop a parallel data BLOCKINow model that leads to local, xed-bandwidth interconnections between processing elements. This parallel data BLOCKINow model diers from previous work in that it requires no global communication of data except at the pixel level. Using this data BLOCKINow model we are developing Cube-4, an architecture that is scalable to very high performances and allows for modular and extensible hardware implementations .","cites":"20","conferencePercentile":"77.77777778"},{"venue":"Workshop on Graphics Hardware","id":"42f3ecf8a66fd97066ea04d86f3ee0300c3abbc5","venue_1":"Workshop on Graphics Hardware","year":"1999","title":"Z3: An Economical Hardware Technique for High-Quality Antialiasing and Transparency","authors":"Norman P. Jouppi, Chun-Fa Chang","author_ids":"1715454, 2305933","abstract":"In this paper we present an algorithm for low-cost hardware antialiasing and transparency. This technique keeps a central Z value along with 8-bit floating-point Z gradients in the X and Y dimensions for each fragment within a pixel (hence the name Z 3). It uses a small fixed amount of storage per pixel. If there are more fragments generated for a pixel than the space available, it merges only as many fragments as necessary in order to fit in the available per-pixel memory. The merging occurs on those fragments having the closest Z values. This combines different fragments from the same surface, resulting in both storage and processing efficiency. When operating with opaque surfaces, Z 3 can provide superior image quality over sparse supersampling methods that use eight samples per pixel while using storage for only three fragments. Z 3 also makes the use of large numbers of samples (e.g., 16) feasible in inexpensive hardware, enabling higher quality images. It is simple to implement because it uses a small fixed number of fragments per pixel. Z 3 can also provide order-independent transparency even if many transparent surfaces are present. Moreover, unlike the original A-buffer algorithm it correctly antialiases interpenetrating transparent surfaces because it has three-dimensional Z information within each pixel.","cites":"38","conferencePercentile":"91.66666667"},{"venue":"Workshop on Graphics Hardware","id":"8811be84f3cc938ddfe57869ba6ba302eec4a270","venue_1":"Workshop on Graphics Hardware","year":"1996","title":"Cube-4 Implementations on the Teramac Custom Computing Machine","authors":"Urs Kanus, Michael Meißner, Wolfgang Straßer, Hanspeter Pfister, Arie E. Kaufman, Rick Amerson, Richard J. Carter, W. Bruce Culbertson, Philip Kuekes, Greg Snider","author_ids":"2145311, 1692799, 1697038, 1701371, 1716343, 1779166, 1789104, 1774215, 1769898, 1781374","abstract":"We present two implementations of the Cube-4 volume rendering architecture on the Teramac cus­ tom computing machine. Cube-4 uses a slice­ parallel ray-casting alg01'ithm that allows for a paral­ lel and pipelined implementation of ray-casting with tri-linear interpolation and su'rface normal estima­ tion from interpolated samples. Shading, classifica­ tion and compositing are part of rendering pipeline. Wzth the partitioning schemes introduced in this pa­ per, Cube-4 is capable of 1'endering lmye datasets with a limited number of pipelines. The Teramac hardwm'e simulat01' at the Hewlett-Packard research laboratories, Palo Alto, CA, on which Cube-4 was implemented, belongs to the new class of custom computing machines. Teramac combines the speed of special-purpose hardware with the flexibility of general-purpose computel's. With Teramac as a de­ velopment tool we were able to implement in just five weeks working Cube-4 prototypes, capable of rendering for example datasets of 128 3 voxels in 0.65 seconds at 0,96 MHz processing frequency. The performance results from these implementations indicate real-time performance for high-resolution data-sets.","cites":"1","conferencePercentile":"57.14285714"},{"venue":"Workshop on Graphics Hardware","id":"19ce994ba111f2ca533625b0e175a68fcf7f1fe3","venue_1":"Workshop on Graphics Hardware","year":"1997","title":"EM-Cube: An Architecture for Low-Cost Real-Time Volume Rendering","authors":"Randy Osborne, Hanspeter Pfister, Hugh C. Lauer, Neil McKenzie, Sarah F. Frisken, Wally Hiatt, TakaHide Ohkarni","author_ids":"2330370, 1701371, 1830906, 2860945, 3040589, 3201997, 2993948","abstract":"EM-Cube is a VLSI architecture for low-cost, high quality volume rendering at full video frame rates. Derived from the Cube4 architecture developed at SUNY at Stony Brook, EM-Cube computes sample points and gradients on-the-fly to project 3-dimensional volume dnta onto 2-dimensional images with realistic lighting and shading. A modest rendering system based on EM-Cube consists of a PC1 card with four rendering chips (ASICs), four 64Mbit SDRAMs to hold the volume data, and four SRAMs to capture the rendered image. The performance target for this configuration is to render images from a 25G3 x 16 bit data set at 30 fmmes/sec. The EM-Cube architecture can be scaled to larger volume data-sets and/or higher frame rates by adding additional ASKS, SDRAMs, and SRAMs. This paper addresses three major challenges encountered developing EM-Cube into a pm&al product: exploiting the bandwidth inherent in the SDRAMs containing the volume data, keeping the pin-count between adjacent ASICs at a tractable level, and reducing the on-chip stomge required to hold the intermediate results of rendering.","cites":"50","conferencePercentile":"93.33333333"},{"venue":"Workshop on Graphics Hardware","id":"a37c6b965f49eef669dfe440540a0f648ab292b2","venue_1":"Workshop on Graphics Hardware","year":"1998","title":"Neon: A Single-Chip 3D Workstation Graphics Accelerator","authors":"Joel McCormack, Bob McNamara, Chris Gianos, Larry Seiler, Norman P. Jouppi, Kenneth W. Correll","author_ids":"2230633, 1919773, 2857276, 3355726, 1715454, 2217404","abstract":"High-performance 3D graphics accelerators traditionally require multiple chips on multiple boards, including geometry, rasterizing, pixel processing, and texture mapping chips. These designs are often scalable: they can increase performance by using more chips. Scalability has obvious costs: a minimal configuration needs several chips, and some configurations must replicate texture maps. A less obvious cost is the almost irresistible temptation to replicate chips to increase performance, rather than to design individual chips for higher performance in the first place.\n      In contrast, Neon is a single chip that performs like a multichip design. Neon accelerates OpenGL [19] 3D rendering, as well as X11 [20] and Windows/NT 2D rendering. Since our pin budget limited peak memory bandwidth, we designed Neon from the memory system upward in order to reduce bandwidth requirements. Neon has no special-purpose memories; its eight independent 32-bit memory controllers can access color buffers, Z depth buffers, stencil buffers, and texture data. To fit our gate budget, we shared logic among different operations with similar implementation requirements, and left floating point calculations to Digital s Alpha CPUs. Neon s performance is between HP s Visualize fx4 and fx6, and is well above SGI' s MXE for most operations. Neon-based boards cost much less than these competitors, due to a small part count and use of commodity SDRAMs.","cites":"21","conferencePercentile":"54.54545455"},{"venue":"Workshop on Graphics Hardware","id":"79631a3f1b42296675b65e85799605ddb235c488","venue_1":"Workshop on Graphics Hardware","year":"2001","title":"Hardware Support for Non-photorealistic Rendering","authors":"Ramesh Raskar","author_ids":"1717566","abstract":"Special features such as ridges, valleys and silhouettes, of a polygonal scene are usually displayed by explicitly identifying and then rendering `edges' for the corresponding geometry. The candidate edges are identified using the connectivity information, which requires preprocessing of the data. We present a non-obvious but surprisingly simple to implement technique to render such features without connectivity information or preprocessing. At the hardware level, based only on the vertices of a given flat polygon, we introduce new polygons, with appropriate color, shape and orientation, so that they eventually appear as special features.","cites":"49","conferencePercentile":"100"},{"venue":"Workshop on Graphics Hardware","id":"0c49040a5111974dd1caa6d9c9848d00dfef7701","venue_1":"Workshop on Graphics Hardware","year":"1999","title":"Load Balancing for Multi-Projector Rendering Systems","authors":"Rudrajit Samanta, Jiannan Zheng, Thomas A. Funkhouser, Kai Li, Jaswinder Pal Singh","author_ids":"3355598, 2616147, 1807080, 2359779, 1685479","abstract":"Multi-projector systems are increasingly being used to provide large-scale and high-resolution displays for next-generation interactive 3D graphics applications, including large-scale data visual-ization, immersive virtual environments, and collaborative design. These systems must include a very high-performance and scalable 3D rendering subsystem in order to generate high-resolution images at real time frame rates. This paper describes a sort-first based parallel rendering system for a scalable display wall system built with a network of PCs, graphics accelerators, and portable projectors. The main challenge is to develop scalable algorithms to partition and assign rendering tasks effectively under the performance and func-tionality constrains of system area networks, PCs, and commodity 3-D graphics accelerators. We have developed three coarse-grained partitioning algorithms and incorporated them into a working prototype system. This paper describes these algorithms and reports our initial experimental results aimed at investigating the feasibility of constructing a sort-first rendering system using a network of PCs and evaluating algorithmic trade-offs and performance bottlenecks within such a system. Our results indicate that the coarse-grained characteristics of the sort-first architecture are well suited for constructing a parallel rendering system running on a PC cluster.","cites":"90","conferencePercentile":"100"},{"venue":"Workshop on Graphics Hardware","id":"1dbfd8c7e6145c4f128140a3a06315d5232ed558","venue_1":"Workshop on Graphics Hardware","year":"2000","title":"Hybrid Sort-First and Sort-Last Parallel Rendering with a Cluster of PCs","authors":"Rudrajit Samanta, Thomas A. Funkhouser, Kai Li, Jaswinder Pal Singh","author_ids":"3355598, 1807080, 2359779, 1685479","abstract":"We investigate a new hybrid of sort-first and sort-last approach for parallel polygon rendering, using as a target platform a cluster of PCs. Unlike previous methods that statically partition the 3D model and/or the 2D image, our approach performs dynamic, view-dependent and coordinated partitioning of both the 3D model and the 2D image. Using a specific algorithm that follows this approach, we show that it performs better than previous approaches and scales better with both processor count and screen resolution. Overall, our algorithm is able to achieve interactive frame rates with efficiencies of 55.0% to 70.5% during simulations of a system with 64 PCs. While it does have potential disadvantages in client-side processing and in dynamic data management&#8212;which also stem from its dynamic, view-dependent nature&#8212;these problems are likely to diminish with technology trends in the future.","cites":"71","conferencePercentile":"92.85714286"},{"venue":"Workshop on Graphics Hardware","id":"053b84ad70396491e231b053a8e75abfa900d62d","venue_1":"Workshop on Graphics Hardware","year":"1997","title":"Triangle Scan Conversion using 2D Homogeneous Coordinates","authors":"Marc Olano, Trey Greer","author_ids":"2513270, 3345691","abstract":"We present a new triangle scan conversion algorithm that works entirely in homogeneous coordinates. By using homogeneous coordinates, the algorithm avoids costly clipping tests which make pipelining or hardware implementations of previous scan conversion algorithms difficult. The algorithm handles clipping by the addition of clip edges, without the need to actually split the clipped triangle. Furthermore, the algorithm can render true homogeneous triangles, including external triangles that should pass through infinity with two visible sections. An implementation of the algorithm on Pixel-Planes 5 runs about 33% faster than a similar implementation of the previous algorithm.","cites":"40","conferencePercentile":"86.66666667"},{"venue":"Workshop on Graphics Hardware","id":"4576fcc029d04248647f456bc17aaee9c9a0fe73","venue_1":"Workshop on Graphics Hardware","year":"1993","title":"Direct Visualization of Quadrics","authors":"H. Laporte, Eric Nyiri, Max Froumentin, Christophe Chaillou","author_ids":"2967678, 1791145, 3205546, 1774410","abstract":"Today, most of the powerful graphic systems are based on 3D-triangle display methods. However, this approach generates well-known problems, like the low quality of contours and shading, and the necessity to have large amounts of primitives to display complex scenes. A way to solve these problems is to use higher level primitives, among which a very interesting one is the quadric surface. We study here direct visualization of quadric surfaces (quadrics for short). Although we study all the rendering process, we focus on the scan conversion stage. First, we present mathematical and modeling backgrounds where we show that a quadric surface can easily be rendered in scan-line. Then we give the general algorithm and details about the difficult part, i.e. the bounding plane algorithm. A functional description of a scan converting processor is proposed, using a modular approach. In the last part, we give a hardware implementation of each module and the whole processor. We also do an estimation of the silicon cost. The conclusion is that our quadric patch scan converter can actually be realized. 1.1 Introduction Today, machines dedicated to image synthesis use polygons as display primitives. There are several reasons to this. First polygons (and more particularly triangles) are very simple shapes so complexity is low and few calculations are required to render them (i.e. bilinear interpolation). Furthermore there are lots of optimized algorithms and special purpose components for scan conversion. Today the most efficient machines are able to compute more than one million Gouraud shaded triangles per second [5J. Nevertheless drawbacks exist. We can point out the problems of approximated contours (because of the tessellation of modeling primitives such as B-spline or Bezier patches) and the fact that a huge number of triangles is necessary to r~present a scene. To avoid these drawbacks, using higher level primitives is promising. A few attempts have been made especially in the Pixel-Plane 5 machine [4J. Our goal is to go further in this way. Using quadric surfaces seems interesting as they are defined by a quadratic implicit equation, depths and normal vectors are easily computed for scan-line Z-buffer algorithms. However this alternative to the facet involves important modifications. The complete study is devided into two parts. The first part deals with modeling problems. The second one considers the rendering pipeline, mainly including host requirements, anti-aliasing, texture mapping and of course direct visualization. This paper only discusses direct visu-alization issues. …","cites":"0","conferencePercentile":"28.57142857"},{"venue":"Workshop on Graphics Hardware","id":"b6056523c9a10516e5156e144f592c7c2a380c69","venue_1":"Workshop on Graphics Hardware","year":"1997","title":"Codesign Of Graphics Hardware Accelerators","authors":"Jon P. Ewins, Phil L. Watten, Martin White, Michael McNeill, Paul F. Lister","author_ids":"2340069, 1707017, 3809263, 2808997, 1733974","abstract":"The design of a hardware architecture for a computer graphics pipeline requires a thorough understanding of the algorithms involved at each stage, and the implications these algorithms have on the organisation of the pipeline architecture. The choice of algorithm, the flow of pixel data through the pipeline, and bit width precision issues are crucial decisions in the design of new hardware accelerators. Making these decisions correctly requires intensive investigation and experimentation. The use of hardware description languages such as VHDL, allow for sound top down design methodologies, but their effectiveness in such experimental work is limited. This paper discusses the use of software tools as an aid to hardware development and presents applications that demonstrate the possibilities of this approach and the benefits that can be attained from an integrated codesign design environment.","cites":"9","conferencePercentile":"30"},{"venue":"Workshop on Graphics Hardware","id":"1132321504a4cb28d85d5c1b02c78b554007d792","venue_1":"Workshop on Graphics Hardware","year":"2000","title":"Towards Hardware Implementation Of Loop Subdivision","authors":"Stephan Bischoff, Leif Kobbelt, Hans-Peter Seidel","author_ids":"7273435, 1763010, 1746884","abstract":"We present a novel algorithm to evaluate and render Loop subdivision surfaces. The algorithm exploits the fact that Loop subdivision surfaces are piecewise polynomial and uses the forward difference technique for efficiently computing uniform samples on the limit surface. The main advantage of our algorithm is that it only requires a small and constant amount of memory that does not depend on the subdivision depth. The simple structure of the algorithm enables a scalable degree of hardware implementation. By low-level parallelization of the computations, we can reduce the critical computations costs to a theoretical minimum of about one float [3]-operation per triangle.","cites":"29","conferencePercentile":"57.14285714"},{"venue":"Workshop on Graphics Hardware","id":"8038cbbc866ec927ad95d0801d7bd6d396135e91","venue_1":"Workshop on Graphics Hardware","year":"2001","title":"Real-Time Bump Map Synthesis","authors":"Jan Kautz, Wolfgang Heidrich, Hans-Peter Seidel","author_ids":"1690538, 1752192, 1746884","abstract":"In this paper we present a method that automatically synthesizes bump maps at arbitrary levels of detail in real-time. The only input data we require is a normal density function; the bump map is generated according to that function. It is also used to shade the generated bump map.\nThe technique allows to infinitely zoom into the surface, because more (consistent) detail can be created on the fly. The shading of such a surface is consistent when displayed at different distances to the viewer (assuming that the surface structure is self-similar).\nThe bump map generation and the shading algorithm can also be used separately.","cites":"15","conferencePercentile":"35.71428571"},{"venue":"Workshop on Graphics Hardware","id":"9cde75e4eb376658ce7b86b551536d5d469e1e4f","venue_1":"Workshop on Graphics Hardware","year":"2001","title":"Vertex-based Anisotropic Texturing","authors":"Marc Olano, Shrijeet Mukherjee, Angus Dorbie","author_ids":"2513270, 3076940, 2987320","abstract":"MIP mapping is a common method used by graphics hardware to avoid texture aliasing. In many situations, MIP mapping over-blurs in one direction to prevent aliasing in another. Anisotropic texturing reduces this blurring by allowing differing degrees of filtering in different directions, but is not as common in hardware due to the implementation complexity of current techniques. We present a new algorithm that enables anisotropic texturing on any current MIP map graphics hardware supporting MIP level biasing, available in OpenGL 1.2 or through the <i>GL_EXT_texture_lod_bias</i> or <i>GL_SGIX_texture_lod_bias</i> OpenGL extensions. The new algorithm computes anisotropic filter footprint parameters per vertex. It constructs the anisotropic filter out of several MIP map texturing passes or multi-texture lookups. Each lookup uses MIP level bias and perturbed texture coordinates to place one probe used to construct the more complex filter profile.","cites":"4","conferencePercentile":"17.85714286"}]}