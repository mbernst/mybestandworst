{"Workshop_on_Vision_Algorithms.c":[{"venue":"Workshop on Vision Algorithms","id":"98390817bbdbbcd43181fff6c499cf1a7e390efd","venue_1":"Workshop on Vision Algorithms","year":"1999","title":"Uncertainty Modeling for Optimal Structure from Motion","authors":"Daniel D. Morris, Kenichi Kanatani, Takeo Kanade","author_ids":"2681745, 1682208, 7642093","abstract":"The parameters estimated by Structure from Motion (SFM) contain inherent indeterminacies which we call gauge freedoms. Under a perspective camera, shape and motion parameters are only recovered up to an unknown similarity transformation. In this paper we investigate how covariance-based uncertainty can be represented under these gauge freedoms. Past work on uncertainty modeling has implicitly imposed gauge constraints on the solution before considering covariance estimation. Here we examine the eeect of selecting a particular gauge on the uncertainty of parameters. We show potentially dramatic eeects of gauge choice on parameter uncertainties. However the inherent geometric uncertainty remains the same irrespective of gauge choice. We derive a Geometric Equivalence Relationship with which covariances under different parametrizations and gauges can be compared, based on their true geometric uncertainty. We show that the uncertainty of gauge invariants exactly captures the geometric uncertainty of the solution, and hence provides useful measures for evaluating the uncertainty of the solution. Finally we propose a fast method for covariance estimation and show its correctness using the Geometric Equivalence Relationship.","cites":"30","conferencePercentile":"58.33333333"},{"venue":"Workshop on Vision Algorithms","id":"1f2ee7714c3018c1687f9b17f2bc889c5c017439","venue_1":"Workshop on Vision Algorithms","year":"1999","title":"Bundle Adjustment - A Modern Synthesis","authors":"Bill Triggs, Philip F. McLauchlan, Richard I. Hartley, Andrew W. Fitzgibbon","author_ids":"1756114, 1760976, 1734629, 1708974","abstract":"This paper is a survey of the theory and methods of photogrammetric bundle adjustment, aimed at potential implementors in the computer vision community. Bundle adjustment is the problem of refining a visual reconstruction to produce jointly optimal structure and viewing parameter estimates. Topics covered include: the choice of cost function and robustness; numerical optimization including sparse Newton methods, linearly convergent approximations, updating and recursive methods; gauge (datum) invariance; and quality control. The theory is developed for general robust cost functions rather than restricting attention to traditional nonlinear least squares.","cites":"1198","conferencePercentile":"100"},{"venue":"Workshop on Vision Algorithms","id":"a6fbefbee8b814dc3183e26ef37a44fc5015600d","venue_1":"Workshop on Vision Algorithms","year":"1999","title":"An Experimental Comparison of Stereo Algorithms","authors":"Richard Szeliski, Ramin Zabih","author_ids":"1717841, 2984143","abstract":"While many algorithms for computing stereo correspondence have been proposed, there has been very little work on experimentally evaluating algorithm performance, especially using real (rather than synthetic) imagery. In this paper we propose an experimental comparison of several different stereo algorithms. We use real imagery, and explore two different methodologies, with different strengths and weaknesses. Our first methodology is based upon manual computation of dense ground truth. Here we make use of a two stereo pairs: one of these, from the University of Tsukuba, contains mostly fronto-parallel surfaces; while the other, which we built, is a simple scene with a slanted surface. Our second methodology uses the notion of prediction error, which is the ability of a disparity map to predict an (unseen) third image, taken from a known camera position with respect to the input pair. We present results for both correlation-style stereo algorithms and techniques based on global methods such as energy minimization. Our experiments suggest that the two methodologies give qualitatively consistent results. Source images and additional materials, such as the implementations of various algorithms, are available on the web from","cites":"74","conferencePercentile":"75"}]}