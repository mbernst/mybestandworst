{"World_Haptics.csv":[{"venue":"World Haptics","id":"70c9dc7acf5dbb45340b7a9c2e53db4deea114fa","venue_1":"World Haptics","year":"2011","title":"Noise-free haptic interaction with a bowed-string acoustic model","authors":"Stephen Sinclair, Marcelo M. Wanderley, Vincent Hayward, Gary P. Scavone","author_ids":"2871871, 1757247, 8113012, 1993484","abstract":"Force-feedback interaction with a bowed string model can suffer critically from noise in the velocity signal derived from differentiating position measurements. To address this problem, we present a model for bowed string interaction based on a position-constraint friction. We validate the proposed model by comparing to previous work using off-line simulations, and show measurements of interaction on haptic hardware. This noise-free excitation signal leads to cleaner string motion than previous models, thereby improving the quality of force and audio synthesis.","cites":"5","conferencePercentile":"70"},{"venue":"World Haptics","id":"b1b6c0b1c87fda1d97ffe2075f46f4fbe9c25bee","venue_1":"World Haptics","year":"2013","title":"Visio-Acoustic screen for contactless touch interface with tactile sensation","authors":"Kazuma Yoshino, Hiroyuki Shinoda","author_ids":"1819657, 1715925","abstract":"This paper proposes a contactless touch screen that produces tactile sensation just 1-3cm before the actual touch on the screen. The system has a screen, visual projectors, and sensors for finger motion detection, which composes a non-contact touch screen by gesture sensing. In this paper we add a non-contact tactile display using an airborne ultrasound phased array. The key device of the system is a screen that is a scattering plane for visual projectors and transparent for ultrasound. We show the design of the screen and examine the effectiveness through numerical simulations and experiments. The screen has an additional property that stops the air flow going through the screen maintaining the transparency for the ultrasound. We constructed the contactless touch screen system and examined the position sensing accuracy under the tactile support. 1 INTRODUCTION In this paper, we propose a contactless touch screen with tactile feedback. This system is similar to a usual touch screen but users can feel tactile sensation just 1-3cm before the screen surface. Users can find buttons with tactile stimulation and get tactile feedback for interaction. One of the suitable application scenes of this system in public spaces is shown in Figure 1. The screen displays an interactive guide map in a department store. Such an interaction system as shown in Fig. 1 but without tactile feedback is one of typical near-future applications of non-contact interactive display using gesture-sensing [1-6]. The visual information is displayed at free location on the screen with the projectors, and the information changes in response to the user's gestures. Since the screen is only a passive scattering plane, there is a rich design freedom in shape and alignment of the display. As the gesture is sensed with remote sensors, physical contacts with the screen are not always necessary for interaction. Non-contact nature of interface device is preferable for avoiding hygienic problems as well as enabling 3D interaction. Especially in hospitals, non-contact interfaces are desired [4]. But the problem of such non-contact interfaces is they lack tactile feedback. In this paper, we propose adding tactile feedback to these devices. We stimulate the user's finger with the radiation pressure of airborne ultrasound [7] propagating through the screen. Stimulating the finger just before the real touch enables the user to push the virtual buttons more surely and easily without actual contact to the screen. The system requires no prepared devices of the users for …","cites":"4","conferencePercentile":"77.35849057"},{"venue":"World Haptics","id":"87162ffd6d2eef28f5267478afd64f0361475ca8","venue_1":"World Haptics","year":"2013","title":"Sharp tactile sensation using superposition of vibrotactile stimuli in different phases","authors":"Tatsuma Sakurai, Hiroyuki Shinoda, Masashi Konyo","author_ids":"1996930, 1715925, 1737580","abstract":"The overlapping of vibrations that are in different phases and in close proximity to each other produces a tactile image that is more localized than one produced by pin vibrators. The mechanism behind the former is still unclear; it may be attributed to the fact that the resultant vibration is highly localized and of a high frequency, making the tactile sensations more perceptible by the human hand. In this study, a finite element (FE) model of a human finger is analyzed to investigate the reason for the difference in the sizes of tactile images produced under different mechanical conditions. In the dynamic analysis, we observed the spatial distribution of the strain energy density (SED) in the model and estimated the perceptual area of the mechanical stimuli. To determine the perceptual area, the threshold SED for perceiving the vibratory stimuli was determined by analyzing the FE finger model on a flat vibratory surface. In the deformation analysis results, we observed that the spatial distribution of SED was more localized by the overlapped vibrations than in a pin vibrator. Moreover, spectral analysis revealed that a higher-frequency vibration was generated locally between the two vibrations. A psychophysical experiment was conducted to determine the effect of the high frequency component on detection thresholds. 1 INTRODUCTION Surface shape production techniques that utilize haptic feedback have been in great demand owing to the proliferation of touch panels and other touch-controlled electronic devices. Haptic perception of surface shapes provides important cues for detecting edges, lines, and other geometric information such as a letter or symbol. Moreover, it facilitates intuitive handling in virtual interactions. Since humans are highly sensitive to vibrations, haptic perception is generally exploited by supplying vibratory stimuli to the skin. This method is known as vibrotactile stimulation and the stimuli are generated by vibrators or electrodes. Haptic displays are generally equipped with a large array of vibrators, which vibrate independently and combine all the many dot-shaped sensations that they individually generate into a single tactile shape. To transmit more tactile information, higher spatial resolution stimuli are used. Recently, many haptic displays have been developed for the transmission of high-spatial-resolution tactile information. For example, the optical-to-tactile converter (Optacon) is a Braille display that produces tactile images by combining several dot patterns [1], with each vibrotactile dot sensation produced by pin-shaped vibrators. Not only Braille dots but also surface shapes can be produced from the information obtained …","cites":"0","conferencePercentile":"14.1509434"},{"venue":"World Haptics","id":"4cf44111d93eefb79fd91361b7d3b676a50dc7fc","venue_1":"World Haptics","year":"2015","title":"Perception of distance-to-obstacle through time-delayed tactile feedback","authors":"Jess Hartcher-O'Brien, Malika Auvray, Vincent Hayward","author_ids":"1966401, 3052257, 8113012","abstract":"— In previous vision-to-touch sensory substitution approaches, including most 'electronic white canes', typical approaches include mapping space-to-space, space-to-intensity, or space-to-frequency. To our knowledge, however, mapping space to time-delay has not been considered. Yet, because organisms must anticipate impending collisions with obstacles or anticipate being contacted by approaching objects, many organisms have developed computational shortcuts where distance-to-target is assumed to be proportional to a time-span. This shortcut often manifests itself in low-level sensorimotor behaviours and perceptual mechanisms. We studied whether untrained humans would spontaneously employ such a shortcut to estimate distance-to-obstacle in the absence of vision. The observers pressed a push button and a tactile pulse was delivered to the hand with a delay proportional to the distance to an obstacle detected by an optical range finder that they wore. The observers were not informed of the nature of the coding but could freely probe the obstacle while walking toward the target. Upon randomized presentation of obstacle distances, the observers quickly calibrated their judgement of distance-to-obstacle and were able to estimate this distance within a range of four meters for a proportionality factor corresponding to a velocity of one m/s.","cites":"2","conferencePercentile":"76.92307692"},{"venue":"World Haptics","id":"0e0f8862f8fb77d9a05038619092a8e94651536e","venue_1":"World Haptics","year":"2015","title":"Inside vs. outside: Haptic perception of object size","authors":"Wouter M. Bergmann Tiest, Vincent Hayward","author_ids":"8200974, 8113012","abstract":"— We have performed a psychophysical experiment to investigate differences in perceived object size when exploring the inside or outside of objects. The experiment consisted of five conditions, in which ten blindfolded subjects compared the size of circular disks and holes using either the index finger, two different probes, the finger-span method, or an infinitesimal virtual probe. The result showed significant negative biases for the conditions with the large probe and the finger-span method, meaning that an object felt on the inside should be larger than an object felt on the outside in order to be perceived as the same size. This indicates that subjects are unable to sufficiently correct for the diameter of the probe when exploring objects. At the same time, a general tendency was observed in all conditions that involved movement to feel the inside of objects as larger than the outside. This suggests that, in order to obtain a neutral estimate of object size in a virtual environment, one should use a virtual probe diameter of about 4 % of the size of the object to be explored.","cites":"2","conferencePercentile":"76.92307692"},{"venue":"World Haptics","id":"ff1213717bd7f27e73ab30420d1e480a68b17bea","venue_1":"World Haptics","year":"2013","title":"Localized tactile stimulation by time-reversal of flexural waves: Case study with a thin sheet of glass","authors":"Charles Hudin, José Lozada, Vincent Hayward","author_ids":"3174635, 2145232, 8113012","abstract":"This paper addresses the issue of producing localized tactile stimuli on a transparent surface. An approach based on time reversal of acoustic waves is presented and implemented on a thin glass surface actuated by piezoelectric transducers located at the periphery. The physical performance measurement, completed by a user study demonstrates the ability to provide localised and perceivable tactile stimulation.","cites":"3","conferencePercentile":"66.03773585"},{"venue":"World Haptics","id":"b7182749fb30f962e4546da27966431aa670e00c","venue_1":"World Haptics","year":"2011","title":"Weak spatial constancy in touch","authors":"Mark Wexler, Vincent Hayward","author_ids":"1815487, 8113012","abstract":"We propose extending the concept of spatial constancy to haptic perception. In vision, spatial constancy refers to the conversion of retinotopic signals into spatiotopic representations, allowing the observer to perceive space independently of his or her own eye movements , or at least partly so. The problem would seem at least as important in haptic perception, where sensory surfaces undergo even more complex movements in space. Here we develop a methodology for studying haptic spatial constancy, which involves a tac-tile display mounted on a mobile platform, and which allows us to decouple movements of the sensory surface—in this case the fingertip—from movements of objects on the fingertip. Using this apparatus, we find evidence for only weak haptic spatial constancy.","cites":"3","conferencePercentile":"52.22222222"},{"venue":"World Haptics","id":"10f248284008a214e6b5ee70ce25590ae9ef6ab7","venue_1":"World Haptics","year":"2011","title":"Tactile data entry for extravehicular activity","authors":"Richard J. Adams, Aaron B. Olowin, Blake Hannaford, O. Scott Sands","author_ids":"2960004, 3202160, 2036485, 2209288","abstract":"In the task-saturated environment of extravehicular activity (EVA), an astronaut's ability to leverage suit-integrated information systems is limited by a lack of options for data entry. In particular, bulky gloves inhibit the ability to interact with standard computing interfaces such as a mouse or keyboard. This paper presents the results of a preliminary investigation into a system that permits the space suit gloves themselves to be used as data entry devices. Hand motion tracking is combined with simple finger gesture recognition to enable use of a virtual keyboard, while tactile feedback provides touch-based context to the graphical user interface (GUI) and positive confirmation of keystroke events. In human subject trials, conducted with twenty participants using a prototype system, participants entered text significantly faster with tactile feedback than without (p = 0.02). The results support incorporation of vibrotactile information in a future system that will enable full touch typing and general mouse interactions using instrumented EVA gloves. 1 INTRODUCTION The constraints of an EVA suit make conventional modes of human-computer interaction difficult. The environment is inherently mobile, so desktop standards such as a keyboard, mouse, and large liquid crystal displays (LCDs) are unavailable. While adaptations of smaller LCDs and keyboards used in state-of-the-art smartphones are possible, they have not proven to be practical. A small forearm-mounted LCD touch screen was previously evaluated in the Electronic Cuff Checklist and flown on several space shuttle missions [1]. Unfortunately, challenges of glare, small display size, user fatigue, and mobility constraints limited its effectiveness. Restrictions imposed by the space suit glove make interacting with a small keyboard, either real or virtual (touch screen), impractical. These considerations motivate continuing research into modes of human-computer interaction that are better adapted to the constraints and opportunities created by the EVA suit. To provide crewmembers the same advantages enjoyed by an average smartphone user, future EVA systems may leverage visual, aural, and tactile modes of information exchange. Humans are visually dominant animals, with the ability to process information through the optical channel at an extremely high rate. Graphical display is thus an essential element in an effective human-computer interaction system. The most likely candidate for future EVA systems is the helmet mounted display, studied previously by NASA in a number of settings including simulated Mars environments [2]. Related work continues today at multiple NASA centers. Closing the loop on this visual element requires the ability to point, select, and …","cites":"2","conferencePercentile":"37.77777778"},{"venue":"World Haptics","id":"66128d5ef91c564a40ad4720b9bce33fb82bd7bd","venue_1":"World Haptics","year":"2015","title":"Delivering directional haptic cues through eyeglasses and a seat","authors":"Tomi Nukarinen, Jussi Rantala, Ahmed Farooq, Roope Raisamo","author_ids":"2481933, 2182905, 7950260, 1749337","abstract":"—Navigation systems usually require visual or auditory attention. Providing the user with haptic cues could potentially decrease cognitive demand in navigation. This study is investigating the use of haptic eyeglasses in navigation. We conducted an experiment comparing directional haptic cues to visual cueing in a car navigation task. Participants (N=12) drove the Lane Change Test simulator with visual text cues, haptic cues given by the eyeglasses and haptic cues given by a car seat. The participants were asked to confirm the recognition of a directional cue (left or right) by pressing an arrow on a tablet screen and by navigating to the corresponding lane. Reaction times and errors were measured. The participants filled in the NASA-TLX questionnaire and were also interviewed about the different cues. The results showed that in comparison to the visual text cues the haptic cues were reacted to significantly faster. Haptic cueing was also evaluated as less frustrating than visual cueing. The haptic eyeglasses fared slightly, although not significantly, better than the haptic seat in subjective and objective evaluations. The paper suggests that haptic eyeglasses can decrease cognitive demand in navigation and have many possible applications.","cites":"1","conferencePercentile":"59.61538462"},{"venue":"World Haptics","id":"6e976b85f23206c86ca0920b7c5bf5e46155ce7f","venue_1":"World Haptics","year":"2013","title":"Perceptual collapse: The fusion of spatially distinct tactile cues into a single percept","authors":"Steven G. Manuel, J. Edward Colgate, Michael A. Peshkin, Roberta L. Klatzky","author_ids":"2969321, 1700106, 1789986, 1735008","abstract":"This work investigates how haptic percepts are combined across two fingertips. Two single-degree-of-freedom haptic interfaces were used to present virtual bumps to the thumb and index finger of subjects' right hand. As subjects slid the two interfaces from left to right while maintaining a fixed finger separation, they would encounter one bump with the index finger and one with the thumb. The objective bump locations were varied randomly, from spatially coincident to separated by slightly more than the fingertips. Subjects were asked to report the number of bumps in the objective world and the number of times they encountered each bump, and also to point to the locations of the bumps. We found that subjects exhibited a strong bias toward reporting a single objective bump in the virtual world. However, the percept varied from one bump encountered twice, when the two virtual bumps were nearly spatially coincident, to one bump encountered once, which occurred when the two virtual bumps were close to finger separation and therefore encountered nearly simultaneously. The latter result is evidence for a kinesthetic grouping phenomenon: temporally synchronized sensations at multiple fingers can be perceptually collapsed into a single percept in both time and space. 1 INTRODUCTION It is well known that kinesthetic cues are sufficient for individuals to perceive illusory protrusions (\"virtual bumps\") on an otherwise flat surface [1]. In this paper we examine the situation in which two fingers on the same hand encounter virtual bumps and we show that, depending on bump separation and finger separation, either one or two bumps may be perceived. Thus, we provide evidence for grouping of percepts in a kinesthetic task. To the best of our knowledge, this is the first explicit demonstration of a Gestalt-like grouping principle in the kinesthetic domain. Our interest in this problem stems from recent advances in surface haptic devices capable of providing force feedback to individual fingertips [2, 3]. It is not a great stretch to imagine touch screens capable of applying forces (direction and magnitude) independently to each of multiple fingertips, and to ask the question: what new experiences will be enabled beyond those available to single fingertips? We have already shown that two points of contact on opposing surfaces can actually mitigate a single-finger illusory percept [4], but our experience also suggests that when the forces on individual fingers are properly designed and coordinated, novel percepts may emerge. The most basic …","cites":"3","conferencePercentile":"66.03773585"},{"venue":"World Haptics","id":"8b2c14d0e727b49d7ec1d00ab4dc24957e6f6c2a","venue_1":"World Haptics","year":"2013","title":"Fingertip friction modulation due to electrostatic attraction","authors":"David J. Meyer, Michael A. Peshkin, J. Edward Colgate","author_ids":"1803101, 1789986, 1700106","abstract":"The human fingertip is extremely sensitive to lateral (shear) forces that arise in surface exploration. We and others have developed haptic displays that work by modulating surface friction via electro-static attraction. Despite the demonstrated ability of these displays to render haptic environments, an understanding of the fingertip-surface interface is lacking. We have developed a tribometer for measuring the lateral frictional forces on a fingertip under well-controlled conditions. We show an expected square law dependence of frictional force (and inferred electrostatic normal force) on actuation voltage, although we observe a large person to person variability. We model an expected dependence of the frictional force on the frequency of the actuation voltage, predicting a first order cut off below about 500Hz. However, our measurements are unambiguously at odds with the model's predictions.","cites":"4","conferencePercentile":"77.35849057"},{"venue":"World Haptics","id":"97c415d49da8a5a3ff440817dce1455e5b4124be","venue_1":"World Haptics","year":"2015","title":"Bioinspired artificial fingertips that exhibit friction reduction when subjected to transverse ultrasonic vibrations","authors":"Rebecca Fenton Friesen, Michael Wiertlewski, Michael A. Peshkin, J. Edward Colgate","author_ids":"2147032, 3265090, 1789986, 1700106","abstract":"— This paper presents the design of a bioinspired artificial fingertip that resembles the mechanical behavior of a human fingertip under conditions of both static deformation and high frequency excitation. The artificial fingertip is constructed around a deformable spherical membrane filled with a cellulose sponge, itself connected to a rigid structure that acts as a bone. Force-deformation characteristics and response to a transient mechanical perturbation are both shown to be in good qualitative agreement with those of a real finger. More importantly, the fingertip exhibits friction reduction when interacting with TPads (variable friction tactile displays based on transverse ultrasonic vibrations). Comparison with artificial fingertips that do not exhibit friction reduction suggests that mechanical damping characteristics play a key role in the amount of friction reduction achieved. I. INTRODUCTION Ultrasonic vibration of a flat touch panel, such as the TPad [1], [2], [3], creates a sizable reduction of the friction that a finger experiences while sliding across the surface. This phenomenon can be modulated as a function of finger position and velocity to create a wide variety of artificial sensations, such as rough and smooth textures or even 3-dimensional perceptions of gratings and bumps. However, the mechanisms behind this method of friction reduction are not well understood, and several competing theories exist. The prevailing theory relies on the squeeze-film effect: at sufficiently high frequency and amplitude air is pumped and captured between the finger and oscillating plate. This cushion of air acts like a spring, supporting part of the normal load [1], [4]. However, an alternative theory suggests that friction reduction could be due to the finger bouncing off the plate and undergoing intermittent contact [5], [6]. As the time of contact becomes shorter, the friction force is decreased. A deeper understanding of this phenomenon, in terms of the role of played by the air, the influence of the panel dynamics, as well as the contributions of the underlying fingertip structure, is crucial to better designing surface-haptic interfaces. Towards this goal, we created a series of artificial fingers whose mechanical structure mimics the arrangement of tissues found in human fingertips. The frictional properties of each artificial fingertip were measured and compared against both a commercially available artificial finger and a human fingertip. An artificial finger that mimics the frictional properties of human fingers would be a useful proxy in future experiments, and behavioral differences","cites":"1","conferencePercentile":"59.61538462"},{"venue":"World Haptics","id":"f3b7725d7d43cf1eeb28ecaeb662fc1de0705233","venue_1":"World Haptics","year":"2013","title":"Improving tactile feedback with an impedance adapter","authors":"Jack Lindsay, Richard J. Adams, Blake Hannaford","author_ids":"3157184, 2960004, 2036485","abstract":"—Vibration motors are often used to generate tactile effects by exciting a mass at a given frequency and amplitude. The characteristic impedance of this vibrotactile device is not always in harmony with the impedance of the human skin. This impedance mismatch can result in poor energy transfer, necessitating larger motors and greater power consumption than otherwise required. Herein, we investigate the feasibility of improving the energy transfer by placing a medium between the skin and the motor, which we dub an impedance adapter. We simulate the effects of this impedance adapter using a mathematical model, and evaluate its effect on skin displacement and a parameter we call skin stimulus. Skin stimulus is introduced as a measure of the perceptive effects of a haptic system, and is used to compare results between systems with an impedance adapter and those without. Our findings suggest a factor of four improvement in skin displacement and a twofold increase in skin stimulus are possible by introducing an optimized impedance adapter.","cites":"2","conferencePercentile":"51.88679245"},{"venue":"World Haptics","id":"b7cc8ad52045144c92d70ff47f6232a77dff24ad","venue_1":"World Haptics","year":"2015","title":"Surface haptics via electroadhesion: Expanding electrovibration with Johnsen and Rahbek","authors":"Craig D. Shultz, Michael A. Peshkin, J. Edward Colgate","author_ids":"1922059, 1789986, 1700106","abstract":" Abstract—This work aims to demonstrate and explain a nearly century old electrostatic haptic effect in human fingertips, which has since gone unreported. This effect, based on the original work of Johnsen and Rahbek [1], as well as research on electrostatic chucking devices [2], is capable of producing electrostatic forces on the finger an order of magnitude greater than those previously reported in literature. It is also capable of working with DC excitation, an aspect which stands out against previous reports which utilize purely AC excitation. This work also proposes a unified force model for this effect, drawn from electrostatic chuck research, and resolves this model with those in previous reports. We briefly discuss the background and specifics of the Johnsen-Rahbek effect, and include measurements made with our own electroadhesive surface and experimental apparatus. Finally, we discuss how this model fits in with previous observations, and its implications going forward.","cites":"2","conferencePercentile":"76.92307692"},{"venue":"World Haptics","id":"f367892440bbcf0a1c417a1626cd34b95dcee94c","venue_1":"World Haptics","year":"2015","title":"Modeling and synthesis of tactile texture with spatial spectrograms for display on variable friction surfaces","authors":"David J. Meyer, Michael A. Peshkin, J. Edward Colgate","author_ids":"1803101, 1789986, 1700106","abstract":"— Texture modeling strives to encapsulate the important properties of texture in a concise representation for interpretation, storage, and rendering. Models for tactile texture have yet to describe a representation that is both perceptually complete and sufficiently compact. In this work, we take inspiration from models of visual and auditory texture and propose a spatial spectrogram representation of tactile texture that separates localized features from textural aspects using a windowed Fourier decomposition. We investigate the length scales at which humans can perceive localized features, and represent textures as spectrograms that capture those local features. Additionally, we demonstrate a reconstruction algorithm capable of recreating texture from a spectrogram representation with no perceptual consequence.","cites":"2","conferencePercentile":"76.92307692"},{"venue":"World Haptics","id":"08206ff7a0eccdab365c959f065de00e84d55c33","venue_1":"World Haptics","year":"2013","title":"Anticipatory vibrotactile cueing facilitates grip force adjustment","authors":"Shogo Okamoto, Michael Wiertlewski, Vincent Hayward","author_ids":"1943489, 3265090, 8113012","abstract":"Human grip forces are automatically adjusted upon occurrence of an external disturbance experienced by an object that is held by a thumb and index finger. We investigated some of the cues that may be used by the brain to perform rapid grip restabilization. To this end we ask subjects to grip and hold an instrumented and actu-ated parallelepiped-shaped handle between the index finger and the thumb. Under computer control, the handle could be jerked from the still grip and could independently provided vibration of 250 or 100 Hz to the gripping fingers. We found that the latency of the motor corrective action was 139 ms on average, but when a vibro-tactile stimulation was applied 50 ms before the application of the pulling force, the latency was reduced on average to 117 ms. The average latency of the conscious response to the vibrotactile stimuli was 230 ms, suggesting that vibrotactile stimulation was capable of influencing the reflex action.","cites":"8","conferencePercentile":"94.33962264"},{"venue":"World Haptics","id":"7d39f4032873fc21cdcaae20e0e1f27745954485","venue_1":"World Haptics","year":"2013","title":"Vibrotactile inputs to the feet can modulate vection","authors":"Ildar Farkhatdinov, Nizar Ouarti, Vincent Hayward","author_ids":"3033486, 2732912, 8113012","abstract":"Vection refers to the illusion of self-motion when a significant portion of the visual field is stimulated by visual flow, while body is still. Vection is known to be strong for peripheral vision stimulation and relatively weak for central vision. In this paper, the results of an experimental study of central linear vection with and without vibrotactile feet stimulation are presented. Three types of vibratory stimuli were used: a sinusoidal signal, pink noise, and a chirp signal. Six subjects faced a screen looking at a looming visual flow that suggested virtual forward motion. The results showed that the sensation of self-motion happened faster and its intensity was the strongest for sinusoidal vibrations at constant frequency. For some subjects, a vibrotactile stimulus with an increasing frequency (a chirp) elicited as well a stronger vection. The strength of sensation of self-motion was the lowest in the cases when pink noise vibrations and no vibrotactile stimulation accompanied the visual flow stimulation. Possible application areas are mentioned.","cites":"1","conferencePercentile":"35.8490566"},{"venue":"World Haptics","id":"90430f7efb1da75a20788b789cd133ac9a853eaf","venue_1":"World Haptics","year":"2013","title":"Slip-induced vibration influences the grip reflex: a pilot study","authors":"Michael Wiertlewski, Satoshi Endo, Alan Wing, Vincent Hayward","author_ids":"3265090, 1682867, 8543280, 8113012","abstract":"Grasping is one of the most common forms of dexterity. So far, most research has focused on slow-varying loads which can be resisted by anticipatory grip adjustments. There are common cases, however, when a rapid, unexpected increase in the load occurs and where the central nervous system must readjust the grip dynamically to prevent slippage. During such events, the central nervous system reactively updates the grip force to minimize further escape of an object. While existing theories postulates that the shear strain of the finger pads caused by the load force is a primary source of information for detecting a new load condition, vibrations induced by even minute object slip in the hand might more effectively signal the occurrence of unwanted movement of the object relatively to the hand. With the help of a high-sensitivity force sensor interposed in the load-path of a fast traction-creating device, we recorded the fluctuations of the force projected onto the fingertip when a rapid perturbation was applied to a grasped object. These fluctuations are indicative of slip. The results highlight the existence of a correlation between the amplitude of the vibrations and the grip force modulation, when textural features are present. The study provides promising evidence that the central nervous system exploits vibrations to detect the onset of unwanted movement of an object relatively to the hand to optimally scale the grip force in response to unexpected, rapid load variations.","cites":"6","conferencePercentile":"87.73584906"},{"venue":"World Haptics","id":"1914b5e167b0342fe89772bcbb76acf2c66b1faa","venue_1":"World Haptics","year":"2011","title":"Tutorial: Psychophysical methods in haptic research","authors":"Lynette A. Jones, Hong Z. Tan","author_ids":"2994331, 1698913","abstract":"Haptics research is by definition a very interdisciplinary field, with scientists and engineers building and evaluating tactile and haptic displays and exploring the domains in which the technology developed can be most optimally used. Central to this process are human user studies in which the displays are evaluated in terms of their capacity to present information to users and the sensitivity of the user to changes in display parameters. A variety of psychophysical procedures are employed for this purpose, most of which have been adapted from research on the visual and auditory systems. The sensory systems involved in processing haptic information present unique challenges due to the active nature of sensory exploration and these need to be taken into account in designing psychophysical experiments with tactile and haptic displays. In this half-day tutorial we will give an overview of psychophysical methods that can be used to analyze haptic perception, including those associated with measuring thresholds, information transfer and multi-dimensional scaling. We will also consider how these methods should be employed in the context of studying novel tactile and haptic illusions. 3. LIST OF TOPICS a. Theoretical approaches (i.e. classical psychophysical theory and the theory of signal detection) and methods used to measure absolute and differential thresholds b. Supra-threshold stimuli and psychophysical ratio scaling c. Estimating information transfer rates d. Multidimensional stimuli and scaling e. Employing psychophysical techniques to quantify the strength and robustness of tactile and haptic illusions","cites":"0","conferencePercentile":"8.888888889"},{"venue":"World Haptics","id":"308bc6085bb9f76d236955e67575a8fa96d92c24","venue_1":"World Haptics","year":"2011","title":"Remote measurement of surface compliance distribution using ultrasound radiation pressure","authors":"Masahiro Fujiwara, Kei Nakatsuma, Masafumi Takahashi, Hiroyuki Shinoda","author_ids":"2382476, 2154094, 2504031, 1715925","abstract":"In this paper, we propose a remote measurement system of surface compliance distributions for haptic broadcasting. Our system is composed of an ultrasound phased array generating acoustic radiation pressure on the remote object surface and a laser displacement sensor. The compliance is evaluated by the ratio of the surface displacement to the applied force. We set up a system to examine the feasibility of the method. In the experiments, the distribution of the surface compliance comparable to the human skin was successfully measured for a flat object surface. 1 INTRODUCTION Sharing haptic information of real objects among people should be called Haptic Broadcasting, as shown in Figure 1, and is an attractive challenge in haptics. Conventional haptic tele-existence systems have assumed one-to-one communication between a slave hand and a haptic display, where the slave's motion is faithful to the user's motion and the haptic display duplicates the haptic interaction between the slave and the object. In the system, it is unnecessary to know the whole elasticity model of the object in advance. On the other hand, if millions of people want to touch an object at the same time, the above mentioned master-slave model fails since millions of slave hands cannot touch the object simultaneously. Thus, producing the whole physical model including elasticity, texture, and other haptic properties of an object is necessary when multiple users share haptic reactions. Our goal is to provide a method to obtain the haptic model of an unknown object instantaneously, for realizing haptic broadcasting of real objects. MacLean has also proposed the model-based approach in [1]. In this paper, we consider required specifications for the haptic broadcasting system and propose a method for sensing haptic properties of an object, especially a surface compliance distribution. In this paper, we propose a remote measurement system of a surface compliance (elasticity) distribution. This is one of the essential haptic properties. We optically measures the surface vibration induced by airborne ultrasound radiation pressure produced by an ultrasound phased array. The phased array device used in this paper is identical to the tactile display device used in [2]. We estimate the compliance by using the ratio of the surface displacement to the applied spot force of the radiation pressure, assuming the linearity of the elasticity. Since the measurement point can be scanned quickly without any mechanical contact to the object, we can obtain surface compliance at a high frame …","cites":"2","conferencePercentile":"37.77777778"},{"venue":"World Haptics","id":"2e91153b1b6db551048799d9369315945e71265c","venue_1":"World Haptics","year":"2013","title":"Judged Consonance of Tactile and Auditory Frequencies","authors":"Ryuta Okazaki, Taku Hachisu, Michi Sato, Shogo Fukushima, Vincent Hayward, Hiroyuki Kajimoto","author_ids":"2812591, 3242743, 2494645, 1844978, 8113012, 1776927","abstract":"With the aim of augmenting auditory sensation by tactile stimuli, we investigated cross-modal relationships between the two modalities, focusing on frequency. The results showed that frequency consonance between tactile and audio stimuli depends on the relationship between harmonics, in a manner similar to auditory waves, but with broader peaks. 1 INTRODUCTION Today, mobile devices come embedded with high-definition visual displays such as the \"retina\" display in iPhones (Apple Inc.). In contrast, high-definition sound is not always available in mobile devices. For example, low frequency components are absent because a bass speaker required for low frequency generation occupies a large space and activities such as walking may not be suited to wearing headphones. Low frequency components moreover can be hard to hear in noisy environments. These circumstances suggest the need to enhance audio on mobile devices in a different way. The purpose of this research is to augment auditory sensation by vibrotactile stimuli and ultimately achieve \" not physically audible but subjectively hearable tactile \" vibration. The tactile-auditory conversion had been proposed for the hearing-impaired [1][2], but our purpose is to develop this cross-modal interaction between tactile and auditory sensing for use by the general public. Although constrained in size, mobile devices have certain advantages in tactile stimulation because these are always held when in use. There are several studies suggesting tactile-audio cross-modal interactions. Suzuki et al. reported that tactile roughness perception is modified by adding task-irrelevant sound [3]. Yau et al. clarified that the subjective auditory intensity is affected by simultaneously presenting tactile stimuli [4]. Each factor of the tactile-audio interaction such as phase, synchrony, and frequency were also studied [5][6][7][8]. Physiological studies reported that tactile and auditory sensations share a common neural mechanism [9]. In our previous paper, we reported that the subjective auditory intensity, which is one of the basic perceptual attributes, becomes louder by adding tactile vibration using the same source as the sound [10]. However, for tactile stimuli, many investigations used white noise or signals using the same source as sound, as their primary interest was eliciting a subjective loudness. In contrast, another important attribute, frequency, is commonly perceivable by auditory and tactile modality. Naturally, the question arises whether we find a tactile-auditory relationship in the frequency region. This paper tries to answer this question. 2 EXPERIMENT 1 In the first experiment, we investigated whether the notion of \" same frequency \" exists between tactile and …","cites":"0","conferencePercentile":"14.1509434"},{"venue":"World Haptics","id":"e2d0a002227dab34a2df6d353214d8f61a051135","venue_1":"World Haptics","year":"2015","title":"Looking for physical invariants in the mechanical response of a tactually scanned Braille dot","authors":"Séréna Bochereau, Stephen Sinclair, Vincent Hayward","author_ids":"3223275, 2871871, 8113012","abstract":"— One human finger explored plastic Braille dots using a variety of velocity and force profiles. The fingertip friction forces were measured. Characteristics of the interaction were studied to explore the manifestation of the amplitude/duration interdependence of signals across velocity, normal force and dot height. Both amplitude, defined here as maximum tangential force, and duration, were seen to vary with velocity and normal force, however the integral of the tangential force over time was found to not have a strong dependence on either variable. When three consecutive dots of varying height were examined, the tangential force integral was not constant, but increased in proportion to height. We propose that the nervous system may use the tangential force integral as an invariant to recognise the same spatial asperity explored under different velocity and force conditions.","cites":"0","conferencePercentile":"26.92307692"},{"venue":"World Haptics","id":"780ce3cb6a87718849e02e9d653c67c84b62cda7","venue_1":"World Haptics","year":"2013","title":"Periodic tactile feedback for accelerator pedal control","authors":"Yosuke Kurihara, Taku Hachisu, Michi Sato, Shogo Fukushima, Hiroyuki Kajimoto","author_ids":"2909525, 3242743, 2494645, 1844978, 1776927","abstract":"Sensing the position and movement of the accelerator pedal in a vehicle is important for acceleration control and safety while driving. The accelerator pedal is controlled by the foot, but precise adjustment requires much training because the driver must rely on somatosensory cues, which provide limited feedback. In this study, we propose periodic tactile feedback for the accelerator pedal to provide an additional tactile cue. We conducted an experiment using a driving simulator to compare the lap time, the rate of off-track incidents and the subjective evaluation of controllability recorded in questionnaires. The experiment confirmed that the feedback makes the control of acceleration easier and facilitates safer driving. INTRODUCTION 1 The control of vehicle acceleration is important for safety. Cues with which to grasp the position of the accelerator pedal include the tachometer, speedometer, engine sound and proprioception of the foot. However, drivers cannot view the tachometer or listen to the engine sound continuously while driving since they need to pay attention to other visual and auditory cues while driving (e.g., they must look out for pedestrians and listen for the approach of other cars). Therefore, the proprioceptive cues of the foot are considered to be especially important for the control of the accelerator pedal by the foot. Compared with the case for general body movement, which is grasped by integrating multisensory cues such as visual, acoustic and haptic cues (especially visual cues in the case of for fine motion [1]), the lack of visual and auditory cues makes pedal control difficult. Drivers must acquire the skill of pedal control to some level at driving school, but good control takes a long time to learn. In our previous study, we proposed the augmentation of human proprioception by adding periodic tactile feedback as a new tactile cue that is synchronized with body movement. A kinesthetic sense at the elbow joint, for instance, can be emphasized by a simple mechanical device that mimics a rotary switch presenting a ―tick-tack feeling‖ [2]. Periodic feedback is often used for a dial on the dashboard of an automobile, which allows the driver to adjust the dial without looking [3]. Although the system is quite simple, we can regard it as a type of haptic augmented reality system. In this paper, we propose a periodic tactile feedback for a vehicle accelerator pedal that is synchronized with the position of the pedal.","cites":"0","conferencePercentile":"14.1509434"},{"venue":"World Haptics","id":"610ffc7188bf97eefa7c5d18f5d1078dadba1ed7","venue_1":"World Haptics","year":"2013","title":"Dynamic model displacement for model-mediated teleoperation","authors":"Xiao Xu, Giulia Paggetti, Eckehard G. Steinbach","author_ids":"1993318, 2562936, 7252930","abstract":"In this paper, we study and extend the concept of model-mediated teleoperation (MMT) for teleaction systems which provide live video feedback from the remote side with a time delay. In MMT, the haptic feedback is rendered locally on the operator side using a simple object surface model in order to keep the haptic control loop stable in the presence of communication delays. Because the live video from the remote side is received with delay, this results in a visual-haptic asynchrony for the displayed interaction events. In addition , sudden model parameter updates can lead to \" model-jump \" effects for the displayed haptic feedback. Both effects degrade the user experience and system performance. To address these issues, we propose an extension of MMT which we call model-displaced teleoperation (MDT) in this paper. In MDT, we adaptively shift the position of the local surface model to delay the haptic contact with the environment, thus compensating the visual-haptic asyn-chrony and avoiding the model-jump effect. As the haptic feedback is still rendered locally, the advantages of the MMT approach are retained and instabilities in the haptic interaction are avoided. In our experiments, we determine the optimal displacement compromise between visual-haptic asynchrony, the model-jump effect and perceived distance errors. Moreover, the subjective experience and objective task performance of the proposed MDT and the original MMT for a teleoperation setup with soft objects are evaluated. Our results show that the users prefer the MDT method compared to MMT once the communication delay between the teleoperator and the operator exceeds 50ms. In addition, the task error rate is reduced by about 50% and the subjects are better able to control their contact force for system delays larger than 50ms if the MDT method is employed.","cites":"1","conferencePercentile":"35.8490566"},{"venue":"World Haptics","id":"ef77ccc130c7d4eea3daaa94b7d7c0e28c98f9be","venue_1":"World Haptics","year":"2015","title":"Surface classification using acceleration signals recorded during human freehand movement","authors":"Matti Strese, Clemens Schuwerk, Eckehard G. Steinbach","author_ids":"1844844, 2577201, 7252930","abstract":"— When a tool is used to tap onto an object or the tool is dragged over its surface, vibrations are induced in the tool that can be captured using acceleration sensors. Based on these signals, this paper presents an approach for tool-mediated surface texture classification which is robust against varying scan-time parameters. We examine freehand recordings of 69 textures and propose a classification system that uses perception-related features such as hardness, roughness and friction as well as selected features adapted from speech recognition such as modified cepstral coefficients. We focus on mitigating the effect of varying contact force and hand speed conditions on these features as a prerequisite for a robust machine-learning-based approach for surface texture classification. Our system works without explicit scan force and velocity measurements. Experimental results show that our proposed approach allows for successful classification of surface textures under varying freehand movement conditions. The proposed features lead to a classification accuracy of 95% when combined with a Naive Bayes Classifier.","cites":"3","conferencePercentile":"94.23076923"},{"venue":"World Haptics","id":"4e3c7919e4c2e5806f6c8c0da52a4e3fec929e64","venue_1":"World Haptics","year":"2015","title":"Transparency analysis of client-server-based multi-rate haptic interaction with deformable objects","authors":"Clemens Schuwerk, Xiao Xu, Wolfgang Freund, Eckehard G. Steinbach","author_ids":"2577201, 1993318, 2331847, 7252930","abstract":"c 2015 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works. Abstract— In this paper we describe a client-server architecture for haptic interaction with simulated deformable objects. The computationally expensive object deformation is computed on the server at a low temporal update rate and transmitted to the clients. There, an intermediate representation of the deformable object is used to locally render haptic force feedback displayed to the user at the required rate of 1 kHz. Based on a one-dimensional deformable object, we analyze the transparency of this multi-rate architecture for a single client interaction. The delay introduced by the deformation simulation and the client-server communication leads to increased rendered forces at the clients compared to a reference scenario without delay. We propose a method that adaptively adjusts the stiffness used in the local force rendering at the client to compensate for this. The evaluation shows that the proposed method successfully compensates the effect of delay in the tested delay range of up to 100 ms. I. INTRODUCTION Applications for haptic virtual environments (VEs) can be found for example in the area of medical training, surgery simulation or gaming [1]. In this context, the haptic simulation of interactions with deformable objects is particularly important. Physics-based deformation simulations like the Finite Element Method (FEM) can become computationally very expensive. For example, only rates between 30 Hz and 60 Hz are achieved in [2]. On the other hand, the coupling between the human user, the haptic device and the VE necessitates high update rates of up to 1 kHz [3]. A multi-rate simulation (e.g. used in [2], [4], [5], [6]), where the force rendering and the deformable object simulation are decoupled, can be used to achieve a stable haptic interaction. Several users can collaborate in a so-called Shared Haptic Virtual Environment (SHVE), enabling for example collab-orative surgical training. Different communication architec-tures based on either the client-server (CS) or the peer-to-peer (P2P) communication paradigms can be conceived [7]. The CS architecture ensures a consistent object state, as the deformable object simulation is performed only on the centralized (and possibly very powerful) server. The deformed polygon mesh …","cites":"0","conferencePercentile":"26.92307692"},{"venue":"World Haptics","id":"081640e8604cd785b0eb43147ed708ea1320efad","venue_1":"World Haptics","year":"2011","title":"Enlarged electro-tactile display with repeated structure","authors":"Hiroyuki Kajimoto","author_ids":"1776927","abstract":"An electro-tactile display is a possible candidate for a tangible touch panel, because it only requires an electrode substrate that can be made transparent. However, although it needs relatively few components, it does still require several transistors per electrode, and wiring each electrode thus poses practical problems. This study therefore proposes the use of a repeated electrode structure to enlarge the display area of the electro-tactile display, without the need for additional electrical components. Skin impedance measurement, which was previously used for the stabilization of skin sensation, was utilized for sensing finger position, and the tactile pattern was presented only around the finger, enabling a larger presentation area. 1 INTRODUCTION A touch panel able to present tactile sensations is a promising application for tactile displays. In order to present visual as well as tactile information, the tactile display should be transparent and thin, to allow visual information to pass through the device. However, few types of tactile displays currently possess the potential to be both transparent and thin. One type of thin tactile display vibrates the whole surface. Fukumoto and Sugimura [1] and Poupyrev and Maruyama [2] achieved a clicking sensation by simply vibrating the display surface where it was in contact with the finger. Tangible touch panels utilizing this principle are already available in the market [3]. Nara et al. [4], Takasaki et al. [5] and Winfield et al. [6] proposed using the \"squeeze effect\", in which the friction coefficient of the plate surface is minimized by vibration in the ultrasonic range. Rapidly turning the vibration on and off allow arbitrary friction to be presented. This type of display can be manufactured relatively easily using a small number of actuators, but the spatial resolution is limited, in principle, by the size of the finger. Another type of display uses an electro-static effect [7][8]. The electrodes are located under an insulator layer, with which the finger makes contact. When a high voltage is applied to the electrodes, the skin connects to the electrodes by electro-static force. This is a relatively simple method that can achieve high spatial resolution, but the sensation only presents when the finger moves, because users do not detect the electro-static force itself, only the deformation produced by contact between the skin and the electrode, and the relative movement of the finger. The other type of display is an electro-tactile display [9][10][11][12][13]. In contrast to an electro-static …","cites":"0","conferencePercentile":"8.888888889"},{"venue":"World Haptics","id":"c6419ccf4340832b6a23217674ca1a051a3a1416","venue_1":"World Haptics","year":"2013","title":"The TaSSt: Tactile sleeve for social touch","authors":"Gijs Huisman, Aduén Darriba Frederiks, Betsy van Dijk, Dirk Heylen, Ben J. A. Kröse","author_ids":"1701252, 2607514, 1727902, 1678537, 1804676","abstract":"In this paper we outline the design process of the TaSST (Tactile Sleeve for Social Touch), a touch-sensitive vibrotactile arm sleeve. The TaSST was designed to enable two people to communicate different types of touch over a distance. The touch-sensitive surface of the sleeve consists of a grid of 4x3 sensor compartments filled with conductive wool. Each compartment controls the vibration intensity of a vibration motor, located in a grid of 4x3 motors beneath the touch-sensitive layer. An initial evaluation of the TaSST revealed that it was mainly suitable for communicating protracted (e.g. pressing), and simple (e.g. poking) touches.","cites":"26","conferencePercentile":"100"},{"venue":"World Haptics","id":"21d91858d8855d164092226aefa09c2a13cdc607","venue_1":"World Haptics","year":"2011","title":"The haptic crayola effect: Exploring the role of naming in learning haptic stimuli","authors":"Inwook Hwang, Karon E. MacLean, Matthew Brehmer, Jeff Hendy, Andreas Sotirakopoulos, Seungmoon Choi","author_ids":"1791758, 5658688, 2086011, 1875883, 2063439, 1718126","abstract":"A haptic icon is a short physical stimulus attached to a simple meaning , which provides information and feedback to a user. To scale the utility demonstrated for small icon sets to larger ones, we need efficient strategies to help users learn subtle distinctions among stimuli, in a modality for which they may not hold detailed descriptive per-cepts. This paper investigates the effect of naming haptic stimuli – i.e. explicitly creating a linguistic marker – on the accuracy with which users are able to identify, distinguish, and recall stimuli. We conducted a between-subjects experiment using 60 participants equally divided among three naming conditions: no names, pre-selected non-descriptive names, and self-selected names. The experiment examined the impact of naming strategy on the ability of participants to identify stimuli in a nonverbal matching test, and on remembering stimulus names. For this challenging task and the degree of learning afforded, naming did not significantly impact accuracy of matching stimuli to meanings for all participants. However , more than twice of many of those allowed to choose names reported the ability to remember and distinguish stimuli than those required to use non-descriptive names, and many participants felt that the names were useful. Of middle-performing participants, the self-selected names group performed significantly better than the non-descriptive names group, and appeared to progress more quickly in learning. We summarize evidence for a trend that might widen with refined naming strategies and more extensive learning.","cites":"2","conferencePercentile":"37.77777778"},{"venue":"World Haptics","id":"a678858c457c28d1d83d39d747933fd0cd7a3954","venue_1":"World Haptics","year":"2013","title":"Illusion of motion induced by tendon electrical stimulation","authors":"Hiroyuki Kajimoto","author_ids":"1776927","abstract":"Kinesthetic illusion is a well-known phenomenon elicited by vibratory stimulation to muscle tendon, which presumably causes muscle spindle activity. It is a candidate for kinesthetic sense presentation by direct receptors stimulation, which may lead to novel compact or immobile haptic displays. However, kinesthetic illusion requires strong mechanical vibrations, which hinders its practical use. I proposed to use electrical stimulation to muscle tendon, in which Golgi tendon organ resides, to generate the illusion. The experimental results revealed that tendon electrical stimulation elicited a similar illusion of motion to the kinesthetic illusion.","cites":"0","conferencePercentile":"14.1509434"},{"venue":"World Haptics","id":"135acc146c465391d13d98ebcf9c0dac0e0c16d7","venue_1":"World Haptics","year":"2013","title":"Natural variation in skin thickness argues for mechanical stimulus control by force instead of displacement","authors":"Yuxiang Wang, Kara L. Marshall, Yoshichika Baba, Ellen A. Lumpkin, Gregory J. Gerling","author_ids":"4509743, 2217804, 2435976, 3118889, 2689065","abstract":"The neural response to touch stimuli is influenced by skin properties as well as the delivery of stimuli. Here, we compare stimuli controlled by displacement and force, and analyze the impact on firing rates of slowly adapting type I afferents as skin thickness and elasticity change. Uniaxial compression tests were used to measure the mechanical properties of mouse hind limb skin (n=5), resulting in a range of skin thickness measurements (211.6-530.6 μm) and hyper- and visco-elastic properties (average coefficient of variation=0.27).Values were integrated to an axisymmetric finite element model using an Ogden strain energy function. This calculated the propagation of surface loads to tactile end-organ locations, where maximum compressive stress and its rate were sampled and linearly regressed to firing rate. For the observed range of skin thickness, firing response was predicted under both force and displacement control of a ramp-and-hold stimulus. Over the ramp phase of stimulation, the variance in predicted firing rate was higher under displacement than under force control (22.2versus 4.9 Hz) with a similar trend in the sustained phase of stimulation (4.6versus1.3Hz). Given that skin thickness varies significantly between specimens, for human skin perhaps seven more so than for mice, the use of force control is predicted to decrease experimental variance in neurophysiological and psychophysical responses.","cites":"2","conferencePercentile":"51.88679245"},{"venue":"World Haptics","id":"31d81513910f82c235af6cdd944a6175f9af7415","venue_1":"World Haptics","year":"2011","title":"Towards an objective quality evaluation framework for haptic data reduction","authors":"Rahul Gopal Chaudhari, Eckehard G. Steinbach, Sandra Hirche","author_ids":"2612650, 7252930, 1793567","abstract":"High packet rates in telepresence and teleaction systems pose grave challenges to teleoperation over existing communication infrastructure like the Internet. To counter these issues, efficient perceptually motivated packet-rate reduction schemes have been developed. These schemes are conventionally evaluated for perceived quality via subjective user tests. Such tests are time-consuming, expensive and require precise control of experimental conditions. Computer modeling of telepresence sessions can, on the other hand, bring re-peatability, ease of observation, definite control over system parameters and task description and fairness of comparison. In this paper, we present first steps towards a methodology and a framework to model and simulate a networked haptic interaction and evaluate it objectively for the quality of experience. Towards this purpose, we model the human control action and haptic perception process in teleoperation. Our results show that simulations of these models for a range of data reduction scheme parameters produce quality estimates whose trend is comparable to carefully performed subjective user tests.","cites":"4","conferencePercentile":"62.22222222"},{"venue":"World Haptics","id":"b1b0de692fdfe447a5a9e760c81d365ab2cdb5ff","venue_1":"World Haptics","year":"2013","title":"Stability analysis of trilateral haptic collaboration","authors":"Jian Li, Mahdi Tavakoli, Qi Huang","author_ids":"1701502, 3111653, 2936526","abstract":"This paper presents a criterion for absolute stability of a general class of three-port networks. Trilateral haptic systems, which have recently found many interesting applications, can be modeled as three-port networks. Traditionally, existing criteria (Llewellyn's criterion) have facilitated the stability analysis of bilateral haptic systems modeled as two-port networks. If the same criteria were to be used for stability analysis of a three-port network, its third port would need to be assumed known for it to reduce to a two-port network. However, this is restrictive because, according to the definition of absolute stability, all three terminations of the three-port network must be allowed to be arbitrary (while passive). In this paper, extending Llewellyn's criterion, we present closed-form necessary and sufficient conditions for absolute stability of a general class of three-port networks – the three terminations need to be passive but are otherwise arbitrary. To this end, we first find a symmetrization condition under which a general asymmetric impedance (or admittance) matrix Z 3×3 has an equivalent symmetric counterpart Z eq ; this Z eq models a reciprocal three-port network with the same stability characterization as the general nonreciprocal three-port network modeled by Z. Then, based on the equivalence of passivity and absolute stability for the equivalent reciprocal network , an absolute stability condition for the original nonreciprocal network is derived. To show how the resulting absolute stability criterion can be utilized at the system design stage, we have applied it to the problem of designing controllers for triple-user collaborative haptic virtual environment systems. The validity of the resulting absolute stability conditions have been verified via simulations.","cites":"5","conferencePercentile":"83.01886792"},{"venue":"World Haptics","id":"dcfd388ee433ebbae5574fe3a41096615de36ed3","venue_1":"World Haptics","year":"2013","title":"Conservatism of passivity criteria for stability analysis of trilateral haptic systems","authors":"Jian Li, Mahdi Tavakoli, Victor Mendez, Qi Huang","author_ids":"1701502, 3111653, 3165389, 2936526","abstract":"Trilateral haptic systems can be modeled as three-port networks. Analysis of coupled stability of a three-port network can be accomplished in either the passivity or the absolute stability frameworks assuming all three ports are connected to passive but otherwise unknown terminations. This paper first reviews our recent results in terms of passivity and absolute stability criteria for general three-port networks – both criteria are founded on the properties of a positive-real Hermitian matrix. Next, we show that the absolute stability criterion is less conservative than the passivity criterion and that the two criteria become the same when the trilateral system is represented by a reciprocal immitance matrix. Then, to show how the two criteria may be utilized at the system design stage, we apply them to the problem of designing controllers for a dual-user haptic teleoperation system. Using the two criteria, controllers are then designed and compared in terms of conservatism and performance in simulations.","cites":"3","conferencePercentile":"66.03773585"},{"venue":"World Haptics","id":"8471a8da4f5c828750aecb965ff5ab0250c00635","venue_1":"World Haptics","year":"2011","title":"Control space of apparent haptic motion","authors":"Ali Israr, Ivan Poupyrev","author_ids":"1769549, 1736819","abstract":"In this paper, we present three experiments to measure the control parameter space of apparent haptic motion using variety of stimulation attributes and body sites. In Exp. 1 we measured the range of Stimulus Onset Asynchrony (SOA) that created continuous motion between two vibrating points on the dorsal forearm and on the back by varying the frequency, intensity and duration of stimulation. The SOA space for apparent motion varied with duration and body site but not with frequency and intensity of stimulation. In Exp. 2, we measured the SOA space for moving sensations when direction of motion and spacing between actuators were varied. On the forearm, the SOA space was influenced by both the direction and spacing, however at the back; it was only affected by the direction of actuation. Finally, in Exp. 3 we measured the SOA space using four or more actuation points creating two-dimensional apparent motion. The results of the present study are discussed in context of designing haptic contents for movies, rides and video games. 1 INTRODUCTION Touch is a dominant part of our daily interactions and we feel rich and myriad variations in sensations when we touch objects around us and when these objects touch us back. It enables us to explore surfaces and textures, to manipulate objects, to feel and understand our surroundings, and to create personal connections with objects and individuals. Developing control schemes that artificially produces realistic touch sensations is not only a major research challenge but it also enables to create immersive and absorbing user experiences [12]. Our research is focused on developing such tools and control schemes that enhances user experiences in a wide range of environmental settings, e.g. while driving a car or watching a movie. This paper investigates control schemes for producing continuous moving sensations on the skin. Moving tactile sensations is a common and effective way to communicate, express, alert and direct user's attention [5]. For example, Israr et al. utilized motion cues on the fingers to translate varying formant features of speech segments [7] and Tan et al. displayed moving tactile sensations on the back to provide directional and attentional cues [14]. In addition , moving tactile sensations evoke rich and variety of real life user experiences. Gibson listed such common sensations as stroking , rubbing, caressing, the crawling of an insect, scratching, rolling and the brushing of a leaf, etc. [6]. Combining these moving sensations …","cites":"9","conferencePercentile":"90"},{"venue":"World Haptics","id":"41063e61d057ff7447e829a4c805ffb497dfdc1e","venue_1":"World Haptics","year":"2015","title":"The Slip-Pad: A haptic display using interleaved belts to simulate lateral and rotational slip","authors":"Colin Ho, Jonathan Kim, Sachin Patil, Kenneth Y. Goldberg","author_ids":"2311278, 2013666, 1702660, 1733062","abstract":"— We introduce a novel haptic display designed to reproduce the sensation of both lateral and rotational slip on a user's fingertip. The device simulates three-degrees-of-freedom of slip by actuating four interleaved tactile belts on which the user's finger rests. We present the specifications for the device, the mechanical design considerations, and initial evaluation experiments. We conducted experiments on user discrimination of tangential lateral and rotational slip. Initial results from our preliminary experiments suggest the device design has potential to simulate both tangential lateral and rotational slip.","cites":"1","conferencePercentile":"59.61538462"},{"venue":"World Haptics","id":"a48fae3be29d6b15d93eb75e6cf70ca8679454c1","venue_1":"World Haptics","year":"2015","title":"Touching the invisible: Localizing ultrasonic haptic cues","authors":"Dong-Bach Vo, Stephen A. Brewster","author_ids":"2207678, 1721608","abstract":"While mid-air gestures offer new possibilities to interact with or around devices, some situations, such as interacting with applications, playing games or navigating, may require visual attention to be focused on a main task. Ultrason-ic haptic feedback can provide 3D spatial haptic cues that do not demand visual attention for these contexts. In this paper, we present an initial study of active exploration of ultrasonic haptic virtual points that investigates the spatial localization with and without the use of the visual modality. Our results show that, when providing haptic feedback giving the location of a widget, users perform 50% more accurately compared to providing visual feedback alone. When provided with a haptic location of a widget alone, users are more than 30% more accurate than when given a visual location. When aware of the location of the haptic feedback, active exploration decreased the minimum recommended widget size from 2cm 2 to 1cm 2 when compared to passive exploration from previous studies. Our results will allow designers to create better mid-air interactions using this new form of haptic feedback. Sophisticated and affordable sensors have lead many to consider touchless gestural interaction in new application contexts such as desktop computers, gaming, interactive tabletops or inside cars [12,14,17]. In addition to simple tasks such as pan and zoom or switching programs, gestures above the keyboard allow users to manipulate complex widgets without the burden of using another device, such as a mouse. For example, it is possible to enable a colour picker widget with a key on the keyboard and control the wheel with mid-air gestures [17]. Mid-air gestures also provide rich interaction techniques to execute sophisticated commands and give six degrees of freedom with which to manipulate digital content [12]. However, a key limitation with the research and products in this area is that they provide no haptic feedback; users can gesture but they cannot feel the controls they are interacting with. Gestures above the keyboard can limit the increasing complexity of keyboards by addressing special functionalities such as media controls keys, numeric keypads, specific or additional keyboard layouts, shortcuts, or even specific input controllers like sliders or dials. For example, introducing layers of configurable virtual input controllers in the space around the keyboard would enable a rich set of complementary controllers for secondary or specific tasks (Figure 1). However, this requires the ability to locate such controllers easily and without decreasing …","cites":"0","conferencePercentile":"26.92307692"},{"venue":"World Haptics","id":"dd3d034d03b92664844b49c17d18bdb171fb8a99","venue_1":"World Haptics","year":"2011","title":"Edge sharpness perception with force and contact location information","authors":"Jaeyoung Park, Andrew J. Doxon, William R. Provancher, David E. Johnson, Hong Z. Tan","author_ids":"1874079, 2622373, 1728218, 1929424, 1698913","abstract":"The effect of contact location information on the perception of virtual edges was investigated by comparing human edge sharpness discrimination under the force-alone and force-plus-contact-location conditions. The virtual object consisted of the 2D profile of an edge with two adjoining surfaces. Edge sharpness JNDs for both conditions increased from about 2 to 7 mm as the edge radii increased from 2.5 to 20.0 mm, and no significant difference was found between the two conditions. A follow-up experiment with the contact-location alone condition resulted in higher (worse) edge sharpness discrimination thresholds, especially at higher edge radius values. Our results suggest that contact location cues alone are capable of conveying edge sharpness information, but that force cues dominate edge sharpness perception when both types of cues are available. 1 INTRODUCTION AND BACKGROUND Most haptic systems can be categorized into three groups: vibrotactile displays, force-feedback devices and fingertip displays. Vibrotactile displays use vibrating elements such as resonant-type tactors to stimulate skin surfaces with low-amplitude and high-frequency vibratory signals. Vibrotactile feedback has been widely used for sensory substitution in the past [1] and more recently, in mobile [2-3] and wearable [4-6] applications. Force-feedback devices stimulate the receptors located in muscles, tendons and joints by imparting forces to the user's hand via a manipulandum (e.g., stylus) or thimble interface. Examples of commercially available force-feedback devices include the PHANToM (Sensable Technology, Woburn, MA), the OMEGA series (Force Dimension, Switzerland) and the Maglev (Butterfly Haptics, Pittsburgh, PA). These devices can provide realistic force interactions between an interface tool and objects in a virtual environment. They are used in a wide range of applications including teleoperation [7], medical training [8], and education [9-10]. A major limitation of both vibrotactile displays and force-feedback devices is that they deprive the user of distributed stress and strain information on the fingertips. Numerous studies have demonstrated the importance of cutaneous information on the fingertips for object identification [11] and tactile shape perception [12-13]. Fingertip displays attempt to restore the missing cutaneous information, and the present study belongs to this growing research area. The term \" fingertip haptics \" was first coined by Colgate's group at Northwestern University [14]. Fingertip displays include pin-array devices [15], actuated plates that convey surface orientation and curvature [16-17], contact area display [18], slip display [14], contact location display [19-20], skin stretch displays [21-23], thermal displays [24] and variable-friction surfaces modulated mechanically [25] or electrically [26]. The present …","cites":"2","conferencePercentile":"37.77777778"},{"venue":"World Haptics","id":"7c8447714d54ee9bda4a950e769a65100bad6b41","venue_1":"World Haptics","year":"2015","title":"Haptic keyclick feedback improves typing speed and reduces typing errors on a flat keyboard","authors":"Zhaoyuan Ma, Darren Edge, Leah Findlater, Hong Z. Tan","author_ids":"1903011, 1741074, 1689620, 1698913","abstract":"— The present study used a flat keyboard without moving keys and enabled with haptic keyclick feedback to examine the effect of haptic keyclick feedback on touch typing performance. We investigated, with well-controlled stimuli and a within-participant design, how haptic keyclick feedback might improve typing performance in terms of typing speed, typing efficiency and typing errors. Of the three kinds of haptic feedback we tested, all increased typing speed and decreased typing errors compared to a condition without haptic feedback. We did not find significant differences among the types of haptic feedback. We also found that auditory keyclick feedback alone is not as effective as haptic keyclick feedback, and the addition of auditory feedback to haptic feedback does not lead to any significant improvement in typing performance. We also learned that global haptic keyclick feedback simulated through local keyclick feedback on each key (as opposed to haptic feedback all over the keyboard) might have the additional and unexpected benefit of helping a typist to locate keys on a keyboard. Furthermore, the participants preferred auditory or haptic keyclick feedback to no feedback, and haptic feedback restricted to the typing finger alone is preferred to that over a larger area of the keyboard.","cites":"0","conferencePercentile":"26.92307692"},{"venue":"World Haptics","id":"a53a4be8ef201f3288450205c8df83072cc5331b","venue_1":"World Haptics","year":"2011","title":"An ungrounded pen-shaped kinesthetic display: Device construction and applications","authors":"Sho Kamuro, Kouta Minamizawa, Susumu Tachi","author_ids":"1694030, 1711743, 7688338","abstract":"In this paper, we implement an ungrounded pen-shaped kinesthetic display and construct a three-dimensional (3D) haptic interaction system. The ungrounded pen-shaped kinesthetic display provides kinesthetic sensations to a user's fingers without the use of mechanical linkages. Therefore, the user can move his/her hand freely in air and interact with virtual environments with sensation of touching. We verified the ability of the device to provide forces and to represent a virtual surface for 3D input. Then we constructed a 3D haptic interaction system in that the user can touch virtual objects displayed as 3D images directly. We also applied the device to an interface for 3D modeling and constructed a 3D haptic modeling system in that the user can create touchable 3D models by sketching two-dimensional (2D) figures in air. 1 INTRODUCTION In recent times, much research has been conducted on haptic interfaces. By integrating with three-dimensional (3D) displays, haptic interfaces realize users to touch 3D virtual objects and can improve existence of virtual environments. Many haptic interfaces have been proposed, and a pen-shaped haptic interface is one of major types of them. To use a pen-shaped device, a user is merely required to hold it and can interact with virtual objects with sensation of pecking or tracing by the tip of the pen. PHANToM [1] is a most popular pen-shaped haptic interface. PHANToM enables a user to perceive kinesthetic sensations on his/her hand with the help of mechanical linkages, which are driven by multiple motors. This device has been applied for many systems like 3D visual-haptic interaction systems [2] or 3D modeling systems [3, 4, and 5]. However, there is one unavoidable problem in using PHANToM as an interface; this device requires to be grounded to represent kinesthetic sensations, and therefore it restricts movements of the user's hand within the range of the linkages. When using grounded haptic interfaces like PHANToM, the user sees a monitor and move his/her hand at a position where the devices are placed and the user cannot touch displayed virtual objects directly. On the other hand, wUbi-Pen [6], ImpAct[7], and Senstylus [8] are ungrounded pen-shaped interfaces and can provide haptic sensations without limitations of hand movements. However, the wUbi-Pen and ImpAct are used while being touch with a screen surface and cannot be used for 3D spatial interactions in air. Senstylus, on the other hand, is a dual-rumble feedback device for 3D computer-aided-design (CAD) applications. …","cites":"3","conferencePercentile":"52.22222222"},{"venue":"World Haptics","id":"3cd4ca8a91c20a3a7b4cc76e33a23405de2aa819","venue_1":"World Haptics","year":"2011","title":"Learning force concepts using visual trajectory and haptic force information at the elementary school level","authors":"J. Jay Young, Carolyn Stolfi, Hong Z. Tan, Joël Chevrier, Brien Dick, Gary R. Bertoline","author_ids":"2737152, 2236925, 1698913, 2036575, 3257402, 3159961","abstract":"The present study investigated the use of visual trajectory and haptic force information in learning concepts involving force. Specifically, learning modules for instructing buoyant forces were developed for use with a computer monitor and a force feedback device. Students from an elementary school at the fourth and sixth grades were recruited to participate in the study. The students were separated into visual and visuohaptic groups to measure the possible benefits haptic feedback might provide as compared to the vision-alone condition. A 10-question content test was developed and administered before and after the learning activities. The pretest and posttest scores showed that all students benefited from the computer simulations. The visuohaptic group did not perform significantly better than the visual group. An important finding was that the fourth graders learned as much as the sixth graders, despite their younger age and little prior exposure to concepts such as density and volume, which are important for understanding buoyancy. Future work will design instructional and assessment materials that focus more on the haptic modality. 1 INTRODUCTION Haptic perception as a pedagogical strategy for understanding STEM (science, technology, engineering, and mathematics) concepts has been a driving force toward using haptic devices in the classroom. The desire to provide tangible evidence for abstract topics offers potential benefits for making knowledge more accessible and engaging to learners. Recognizing the potential of haptics technology in providing a \" hands-on \" learning experience for students, many researchers have utilized force-feedback devices in teaching dynamics, biology and physics concepts [1-7]. Despite the enthusiastic expectations of the researchers, however, the results have been mixed and \" (previous studies) have yet to provide empirical evidence for the existence of a cognitive impact of haptic technology \" [8]. While some studies demonstrate the unequivocal benefits of force feedback in training and learning [9-10], others paint a less than clear-cut picture [11]. It is our view that haptics will have a bigger impact in presenting information that cannot be easily conveyed visually, such as the magnitude and direction of buoyant force. Therefore, the present study investigated the use of visual trajectory and haptic force information in creating learning modules for instructing concepts related to buoyant forces. We also hypothesized that the use of visuohaptic simulations may be particularly beneficial to younger learners who have yet to develop the mathematical skills to derive force values from visual portrayal of object trajectory. Doing so requires …","cites":"1","conferencePercentile":"22.22222222"},{"venue":"World Haptics","id":"e4b3d07ad576ac5c6b8559e61771f47a6a157695","venue_1":"World Haptics","year":"2011","title":"Rate of human motor adaptation under varying system dynamics","authors":"Ahmetcan Erdogan, Ali Israr, Marcia Kilchenman O'Malley, Volkan Patoglu","author_ids":"3096106, 1769549, 1793748, 1751652","abstract":"We explore the effects of parameters constituting a second order dynamic system on the rate of human motor adaptation while performing a rhythmic dynamic task. In our experiments, participants excite virtual second-order systems at resonance via a haptic interface. After overtraining subjects with a nominal system, we unexpectedly change the system parameters and study the resulting motor adaptation in catch trials. Through four experiment seatings, we demonstrate the effects of dynamic system parameters on human motor adaptation. Results indicate that gain and damping parameters significantly affect the rate of adaptation. In particular, as the effort required to complete the task increases, the rate of adaptation decreases, indicating a trade-off between task performance and the effort required to perform the task.","cites":"0","conferencePercentile":"8.888888889"},{"venue":"World Haptics","id":"342e2739836e027cee6d5052818295bcc3465ebf","venue_1":"World Haptics","year":"2011","title":"On the 1/f noise and non-integer harmonic decay of the interaction of a finger sliding on flat and sinusoidal surfaces","authors":"Michael Wiertlewski, Charles Hudin, Vincent Hayward","author_ids":"3265090, 3174635, 8113012","abstract":"Fluctuations of the frictional force arising from the stroke of a finger against flat and sinusoidal surfaces are studied. A custom-made high-resolution friction force sensor, able to resolve milli-newton forces, was used to record those fluctuations as well as the net, low-frequency components of the interaction force. Measurements show that the fluctuations of the sliding force are highly non-stationary. Despite their randomness, force spectra averages reveal regularities. With a smooth, flat, but not mirror-finish, surface the background noise follows a 1/ f trend. Recordings made with pure-tone sinusoidal gratings reveal complexities in the interaction between a finger and a surface. The fundamental frequency is driven by the periodicity of the gratings and harmonics follow a non-integer power-law decay that suggests strong nonlinearities in the fingertip interaction. The results are consistent with the existence of a multiplicity of simultaneous and rapid stick-slip relaxation oscillations. Results have implications for high fidelity haptic rendering and biotribology.","cites":"19","conferencePercentile":"97.77777778"},{"venue":"World Haptics","id":"76a1e2af788505d714aad95ca7979ee60487c31a","venue_1":"World Haptics","year":"2013","title":"An asymmetry in force perception contingent on motion reversal","authors":"Yon Visell, Vincent Hayward","author_ids":"3322706, 8113012","abstract":"We investigated the perception of differences between direction-dependent, movement-opposing forces. The magnitude of these forces changed in whenever the direction of motion reversed. They were felt by participants during an experiment that required them to scan a virtual surface, represented by a planar haptic interface, via left-right motions of the index finger. We found that individuals are surprisingly insensitive to changes in opposing force magnitude that are contingent on reversals in direction of motion, despite large contrasts in force magnitude. Forces of 1 N failed consistently to be discriminated from forces of 0 N during sequential presentation at the highest speeds. As the mean scanning speed of the digit was reduced , the effect progressively vanished. The effect we observed is simple and robust enough to be demonstrated on virtually any hap-tic force-feedback interface. We suggest possible interpretations based on temporal information processing in the nervous system, on physiology and biomechanics, and through inferences that the nervous system may rely on to relate motor commands to sensory input during dynamic haptic interaction. The results obtained raise fundamental questions about the perceptual interpretation of kines-thetic stimuli involving rapid movement, and may also suggest a reconsideration of requirements for haptic interfaces.","cites":"2","conferencePercentile":"51.88679245"},{"venue":"World Haptics","id":"405b93ec0be8b96be1cf7ecb8296446d3ce50cf4","venue_1":"World Haptics","year":"2013","title":"Haptic contour following and feature detection with a contact location display","authors":"Jaeyoung Park, William R. Provancher, David E. Johnson, Hong Z. Tan","author_ids":"1874079, 1728218, 1929424, 1698913","abstract":"We investigate the role of contact location information on the perception of local features during contour following in a virtual environment. An absolute identification experiment is conducted under force-alone and force-plus-contact-location conditions to investigate the effect of the contact location information. The results show that the participants identify the local features significantly better in terms of higher information transfer for the force-plus-contact-location condition, while no significant difference was found for measures of the efficacy of contour following between the two conditions. Further data analyses indicate that the improved identification of local features with contact location information is due to the improved identification of small surface features. 1 INTRODUCTION Until recently, if a user wanted to feel a virtual object via touch, it was through a force-feedback device in most cases. Most force displays are designed to render forces through single-point interactions between a tool tip and a virtual object's surface. One way to provide a user with increased haptic information is to increase the number of contact points by using multiple force feedback devices. Frisoli et al. showed, however, that increasing the number of force feedback contact points from one to three did not significantly improve virtual object recognition performance [1]. Jansson and Monaci also showed that without distributed information at contact areas, increasing the number of contact points alone did not lead to a significant benefit in identifying real objects. Instead, recognition of objects was significantly improved when spatially distributed information was available at each contact area on bare fingers [2]. The findings from the previous studies suggest that for improved haptic perception and exploration of virtual objects, it is desirable to provide not only point-contact force feedback but also cutaneous contact information. Several fingertip displays have been designed so far (e.g., [3-8]), including the contact location display (CLD) that is used in the present study [9]. Contact location information conveyed via fingertip displays contributes to haptic object exploration and perception in tasks such as contour following. Lederman and Klatzky show that during haptic exploration of an object, hand movements vary by the type of knowledge that one is trying to acquire about the object. A contour following exploratory procedure is typically used when the precise shape details of the object are desired [10]. Kuchenbecker et al. showed that cutaneous fingertip contact information improved the accuracy and reduced the time in a contour following task [11]. Contact information is …","cites":"0","conferencePercentile":"14.1509434"},{"venue":"World Haptics","id":"b6a25f9011faab710ce11b267385865301505255","venue_1":"World Haptics","year":"2015","title":"Effect of information content in sensory feedback on typing performance using a flat keyboard","authors":"Jin Ryong Kim, Hong Z. Tan","author_ids":"1747661, 1698913","abstract":"— We investigate the effect of information content in sensory feedback on typing performance using a flat keyboard. We build a flat keyboard apparatus with haptic and auditory keyclick feedback. We evaluate and compare typing performance with key-press confirmation and key-correctness information through sensory feedback. Twelve participants are asked to touch-type a number of randomly selected phrases under various combinations of visual, auditory and haptic sensory feedback conditions. The results show that typing speed is not significantly affected by the information content in sensory feedback, but the uncorrected error rate is significantly lower when key-correctness information is available. The results also show that key-correctness information leads to more corrected errors and lowers typing efficiency. Our findings are useful for developing flat keyboards with assistive information through sensory feedback. Our study is the first step towards improving typing performance on flat keyboards by delivering more advanced and comprehensive assistive information beyond the visual channel.","cites":"0","conferencePercentile":"26.92307692"},{"venue":"World Haptics","id":"1912f608ff5891f3a95d5a7f634af7453028ff72","venue_1":"World Haptics","year":"2011","title":"Development of aerial-input and aerial-tactile-feedback system","authors":"Takayuki Hoshi","author_ids":"1789842","abstract":"A system is proposed which enables users not only to operate computers by moving their hands in mid-air but also to feel touch feedback on their hands. The system consists of a PC, a marker-less hand-tracker for input, and a non-contact tactile display for feedback. The tactile display utilizes ultrasound to produce tactile stimulation from a distance. It is based on a nonlinear phenomenon of ultrasound (acoustic radiation pressure) and the phased array focusing technique. The principles are described and the prototype system is introduced. 1 INTRODUCTION Recently, various technologies are developed which enable users to operate computers by moving their hands in air. Combination of an IR-LED illuminator, a retro-reflector attached on a user's finger, and an IR camera is demonstrated in [1]. aeroTAP [2] extracts a user's finger from the images captured by a normal webcam. A high-speed camera is used to track a user's finger in [3]. Mgestyk [4] and Kinect [5] utilize depth cameras to sense the position of a user's hand and recognize gestures. These natural user interfaces (NUI) would be used as interfaces with PCs, games, portable devices, digital signage, and so on. They are also promising in hospitals, food factories, and public spaces because the interfaces keep users' hands away from getting dirty. For the technologies, together with conventional visual and/or audio feedback, tactile feedback is required in order to provide an enhanced and more intuitive user experience. One of the requirements for a tactile display to be combined with NUI is allowing users to move their arms, hands, and fingers freely. It is most preferable that users are not required to touch on or hold any devices, unlike general tactile displays [6]. There are three types of conventional strategies for tactile feedback in a free space. The first is attaching tactile devices on user's fingers and/or palms. Employed devices are, for example, vibrotactile stimulators (CyberTouch [7]), motor-driven belts (GhostGlove [8]), or pin-array units (SaLT [9]). In this strategy, the skin and the device are always in contact and that leads to undesired touch feelings. The second is controlling the positions of tactile devices so that they contact with the skin only when tactile feedback is required. In the master-slave system shown in [10], the encounter-Figure 1. Developed aerial-input and aerial-tactile-feedback system. It consists of a PC, a depth camera, and an ultrasound-based tactile display. type force feedback is realized by the exoskeleton …","cites":"9","conferencePercentile":"90"},{"venue":"World Haptics","id":"13df13972418b2ee400163e396bd1012a924d416","venue_1":"World Haptics","year":"2013","title":"Effects of multi-modal guidance for the acquisition of sight reading skills: A case study with simple drum sequences","authors":"In Lee, Seungmoon Choi","author_ids":"1752383, 1718126","abstract":"We introduce a learning system for the sight reading of simple drum sequences. Sight reading is a cognitive-motor skill that requires reading of music symbols and actions of multiple limbs for playing the music. The system provides knowledge of results (KR) pertaining to the learner's performance by color-coding music symbols, and guides the learner by indicating the corresponding action for a given music symbol using additional auditory or vibrotactile cues. To evaluate the effects of KR and guidance cues, three learning methods were experimentally compared: KR only, KR with auditory cues, and KR with vibrotactile cues. The task was to play a random 16-note-long drum sequence displayed on a screen. Thirty university students learned the task using one of the learning methods in a between-subjects design. The experimental results did not show statistically significant differences between the methods in terms of task accuracy and completion time.","cites":"1","conferencePercentile":"35.8490566"},{"venue":"World Haptics","id":"515a1891f2d8e1a0d008717de62dd42a75e2785d","venue_1":"World Haptics","year":"2011","title":"Haptically assisted golf putting through a planar four-cable system","authors":"Peter Y. Huang, Jacquelyn A. Kunkel, Jordan Brindza, Katherine J. Kuchenbecker","author_ids":"7888988, 3013521, 2173357, 1716879","abstract":"Individuals learning a new sport often repeat a motion hundreds or thousands of times to try to perfect their form. The quintessential example of this process may be a beginning golfer struggling to learn to putt, where strokes must be precise and consistent in order to place the ball in the hole. This paper presents a four-cable haptic device designed to help golfers learn to improve their putting accuracy. This planar three-DOF system provides feedback that consists of two Cartesian forces and one angular moment. We present the system's design and kinematics, along with a closed-loop controller that helps the user keep the putter head at the correct angle in the plane. We evaluated our design through a study in which five subjects used the system to repeatedly putt at a target both with and without assistance. While assistance did not change the mean of the putting distribution, it did significantly affect the variance for some subjects ABSTRACT Individuals learning a new sport often repeat a motion hundreds or thousands of times to try to perfect their form. The quintessential example of this process may be a beginning golfer struggling to learn to putt, where strokes must be precise and consistent in order to place the ball in the hole. This paper presents a four-cable haptic device designed to help golfers learn to improve their putting accuracy. This planar three-DOF system provides feedback that consists of two Cartesian forces and one angular moment. We present the system's design and kinematics, along with a closed-loop controller that helps the user keep the putter head at the correct angle in the plane. We evaluated our design through a study in which five subjects used the system to repeatedly putt at a target both with and without assistance. While assistance did not change the mean of the putting distribution, it did significantly affect the variance for some subjects.","cites":"2","conferencePercentile":"37.77777778"},{"venue":"World Haptics","id":"8d37bbdf963ee503e941ec1660a326656df06e54","venue_1":"World Haptics","year":"2013","title":"What's around me? Multi-actuator haptic feedback on the wrist","authors":"Sabrina A. Panëels, Margarita Anastassova, Steven Strachan, Sophie Pham Van, Saranya Sivacoumarane, Christian Bolzmacher","author_ids":"2704085, 2450105, 2817407, 2971089, 2051122, 2384034","abstract":"We present the design, implementation and evaluation of a novel wrist-based vibrotactile multi-actuator bracelet, based on a co-planar circular configuration of actuators, for the provision of intuitive and informative haptic feedback for navigation tasks. A two-phase evaluation was conducted in order to assess the perception of the vibrotactile feedback provided by the bracelet and in particular, the ability of users to discriminate a range of vibrotactile patterns. First, a pilot study designed to test perception of different kinds of pattern was conducted with the aim of both refining the pattern design and aiding the choice of a discriminable set of patterns. Second , an identification experiment with the previously chosen set of patterns was conducted with the aim of conveying navigational directions and points of interest to the user. Results highlighted the difficulties in identifying the number of activated actuators as well as their position on the wrist, which subsequently had an impact on the pattern recognition. It was found that one-way horizontal and vertical movements were difficult to perceive correctly, however , less specific movements such as circular or alternating lateral movements and rhythm proved to be suitable parameters for the perception of patterns as long as the patterns were not too similar in design.","cites":"6","conferencePercentile":"87.73584906"},{"venue":"World Haptics","id":"c0f71ec93be167544cde9f0a4b8982ac271f6105","venue_1":"World Haptics","year":"2013","title":"ViPong: Probabilistic haptic feedback for eyes-free interaction","authors":"Steven Strachan, Michael Wiertlewski, Harald Zophoniasson, Margarita Anastassova","author_ids":"2817407, 3265090, 1816469, 2450105","abstract":"We describe a mechanism for the delivery of haptic feedback to users of a simple game via the use of probabilistic inference. This not only enables the creation of dynamically changing game conditions but also a more adaptable, accessible and enjoyable haptic gaming environment for potential use by visually impaired users. The ViPong proof of concept application uses a mouse instru-mented with a custom built lateral vibrator to enable a person to compete eyes-free in a game of pong using only haptic feedback linked to the position of the ball. A preliminary user study shows that it is possible to build eyes-free games using such a mechanism for haptic feedback generation. It also shows that there is some effect on the game play from varying levels of uncertainty injected into the algorithm, with participants performing less well under condition where the uncertainty added to the position of the game ball is high.","cites":"1","conferencePercentile":"35.8490566"},{"venue":"World Haptics","id":"b9cb54d3f27637b895c71cd03f2c164257beddc0","venue_1":"World Haptics","year":"2013","title":"Lump detection with a gelsight sensor","authors":"Xiaodan Jia, Rui Li, Mandayam A. Srinivasan, Edward H. Adelson","author_ids":"3026909, 1704992, 8138389, 1788148","abstract":"MIT ABSTRACT A GelSight sensor is a tactile sensing device comprising a clear elastomeric pad covered with a reflective membrane, coupled with optics to measure the membrane's deformations. When the pad is pressed against an object's surface, the membrane changes shape in accord with mechanical and geometrical properties of the object. Since soft tissue is more compliant than hard tissue, one can detect an embedded lump by pressing the GelSight pad against the tissue surface and observing the hump that forms over the lump. We tested this system's sensitivity by constructing phantoms of soft rubber with hard embedded lumps. The system is quite sensitive; for example it could detect a 2mm lump at a depth of 5mm. The sensor was more sensitive than previous tactile lump detectors. It was also better than human observers using their fingertips. Such a capability could help in tumor screening, and could augment the sensory information available in telemedicine or minimally invasive surgery.","cites":"3","conferencePercentile":"66.03773585"},{"venue":"World Haptics","id":"393242af1fb2bf7bb3ce20c5b0ae7730bbd08011","venue_1":"World Haptics","year":"2011","title":"Design of body-grounded tactile actuators for playback of human physical contact","authors":"Andrew A. Stanley, Katherine J. Kuchenbecker","author_ids":"3086460, 1716879","abstract":"We present four wearable tactile actuators capable of recreating physical sensations commonly experienced in human interactions, including tapping on, dragging across, squeezing, and twisting an individual's wrist. In seeking to create tactile signals that feel natural and are easy to understand, we developed movement control interfaces to play back each of these forms of actual human physical contact. Through iterative design, prototyping, programming, and testing, each of these servo-motor-based mechanisms produces a signal that is gradable in magnitude, can be played in a variety of temporal patterns, is localizable to a small area of skin, and, for three of the four actuators, has an associated direction. Additionally, we have tried to design toward many of the characteristics that have made high frequency vibration the most common form of wearable tactile feedback, including low cost, light weight, comfort, and small size. Bolstered by largely positive comments from naive users during an informal testing session, we plan to continue improving these devices for future use in tactile motion guidance. ABSTRACT We present four wearable tactile actuators capable of recreating physical sensations commonly experienced in human interactions, including tapping on, dragging across, squeezing, and twisting an individual's wrist. In seeking to create tactile signals that feel natural and are easy to understand, we developed movement control interfaces to play back each of these forms of actual human physical contact. Through iterative design, prototyping, programming, and testing, each of these servo-motor-based mechanisms produces a signal that is gradable in magnitude, can be played in a variety of temporal patterns, is localizable to a small area of skin, and, for three of the four actuators, has an associated direction. Additionally , we have tried to design toward many of the characteristics that have made high frequency vibration the most common form of wearable tactile feedback, including low cost, light weight, comfort , and small size. Bolstered by largely positive comments from naive users during an informal testing session, we plan to continue improving these devices for future use in tactile motion guidance.","cites":"8","conferencePercentile":"83.33333333"},{"venue":"World Haptics","id":"6b7558ec856cf1b66a59f283350d9bad1ed929b4","venue_1":"World Haptics","year":"2013","title":"Aerial display of vibrotactile sensation with high spatial-temporal resolution using large-aperture airborne ultrasound phased array","authors":"Keisuke Hasegawa, Hiroyuki Shinoda","author_ids":"1782349, 1715925","abstract":"We fabricated a tactile display which can generate vibrotactile sensation on human skin on which no equipment is mounted. It utilizes focused airborne ultrasound radiation pressure for stimulation. The workspace of our new tactile display is widened to a cube of 1m x 1m x 1m, which allows users free motions in it. In order to widen the workspace, our new prototype integrates multiple ultrasound transducer units and achieves a large aperture airborne ultrasound phased array. As the workspace is widened, it has become possible to stimulate arbitrary regions all over a human body. The amplitude of imposed radiation pressure can be time-variant. The profiles of generated vibrotactile stimuli can be designed with a temporal resolution of 0.5 ms and 320-level quantization of radiation pressure amplitude. It is easy to choose a recorded waveform and reproduce it as vibrotactile stimuli at an arbitrary spatial point. This paper introduces how our new tactile display works and reports its performance evaluation. 1 INTRODUCTION Tactile displays have been of interests among researchers and a great variety of devices have been developed. In general, the time-variant component in tactile sensation is considered to be important for human in determining various tactile textures. The four types of major mechanoreceptors are well known for their coherent time-space characteristics and their contribution to tactile information transmission has also been widely investigated. This temporally characterized tactile sensation is in particular called vibrotactile sensation and many researches of tactile information display focus on representation of it [1][2]. Most of the current vibrotactile devices need to be mounted or held on human bodies. It means that only surfaces of human bodies in contact with the device can receive vibrotactile stimuli. In addition, free movement of users may be constrained by the mounted devices. In a few attempts to generate noncontact tactile sensation by using air jet [3], the workspace is still constrained within the near field of the jet nozzle and the design freedom in temporal profile of stimulation seems limited. There have been wearable vibrotactile displays e.g. [4], nevertheless, to the best of our knowledge, a system which can remotely stimulate from top to toe has not been developed yet. In public use or applications for alarming, the requirement of wearing some special devices in advance can be a crucial problem. If we can construct a system which generates tactile sensations in arbitrary positions all over our bodies without …","cites":"9","conferencePercentile":"97.16981132"},{"venue":"World Haptics","id":"c235b4ea6abb75253efc13bb12f01f5a6760eac4","venue_1":"World Haptics","year":"2011","title":"Presenting spatial tactile messages with a hand-held device","authors":"Jussi Rantala, Kalle Myllymaa, Roope Raisamo, Jani Lylykangas, Veikko Surakka, Peter B. Shull, Mark R. Cutkosky","author_ids":"2182905, 1778627, 1749337, 1803865, 1718377, 3111914, 1698041","abstract":"This paper introduces a multi-actuator tactile device designed for remote touch communication. While closely-spaced high-frequency vibrotactile actuators can be difficult to distinguish, our system utilized four linear DC motors for presenting spatial tactile messages through low-frequency actuation. An experiment was conducted to determine accuracy for recognizing stimuli presented on the palm of the hand. Participants were asked to identify 10 predefined stimulus patterns created from the four linear actuators positioned in either a diamond or square configuration. Results showed that positional, linear, and circular stimuli were recognized with mean response accuracies of 98.8, 96.5, and 90.2 %, respectively. No statistically significant differences were found between the actuator configurations. These findings can be utilized in developing a remote communication channel that supports the transfer of spatial aspects of touch such as mapping the location of finger touch of one user to tactile sensation on the palm of another user. 1 INTRODUCTION Touch is an essential part of social interaction between people. It is used in our daily lives for expressing, for example, support and compliance [9]. Due to the inherent requirement of a shared physical space, interaction via the sense of touch has traditionally been limited to face-to-face situations. Recently, there has been a range of research on developing a remote touch communication channel. The studies have strived for simulating a human touch by using artificial haptic stimulation. Encouragingly, partial support has been found for the assumption that mediated social touch and real touch are perceived similarly [5]. Also, it has been argued that emotional content can be transferred between two users via haptics [18]. In several previous studies, the user's hand has been used as a site for presenting remotely created tactile feedback (i.e., touch messages). The hand is an area that is classified as a non-vulnerable body part in terms of acceptability of touch [9] and is highly sensitive to touch stimulation [12]. The fingertip, in particular, has been widely utilized in tactile displays (e.g., [13][22]) due to its superior tactile sensitivity. However, from the point of view of interpersonal touch communication, the available skin area of the fingertip is not large enough for presenting multi-dimensional touches in their original scale (e.g., sensation caused by stroking). The palm has larger stimulation area and sufficient spatial resolution as two contact points are perceived as separate when they are positioned at least 10 mm apart [20]. Also, when carrying a mobile …","cites":"2","conferencePercentile":"37.77777778"},{"venue":"World Haptics","id":"8004c79eaec60447af6fff5ea9a72da250fd7a3d","venue_1":"World Haptics","year":"2013","title":"Six-oof haptic interaction with fluids, solids, and their transitions","authors":"Gabriel Cirio, Maud Marchal, Miguel A. Otaduy, Anatole Lécuyer","author_ids":"3282744, 1722424, 1704342, 1693899","abstract":"Haptic interaction with different types of materials in the same scene is a challenging task, mainly due to the specific coupling mechanisms that are usually required for either fluid, deformable or rigid media. Dynamically-changing materials, such as melting or freezing objects, present additional challenges by adding another layer of complexity in the interaction between the scene and the haptic proxy. In this paper, we address these issues through a common simulation framework, based on Smoothed-Particle Hydrody-namics, and enable haptic interaction simultaneously with fluid, elastic and rigid bodies, as well as their melting or freezing. We introduce a mechanism to deal with state changes, allowing the perception of haptic feedback during the process, and a set of dynamic mechanisms to enrich the interaction through the proxy. We decou-ple the haptic and visual loops through a dual GPU implementation. An initial evaluation of the approach is performed through performance and feedback measurements, as well as a small user study assessing the capability of users to recognize the different states of matter they interact with.","cites":"0","conferencePercentile":"14.1509434"},{"venue":"World Haptics","id":"bb80bd5a82d93b5b2e26a80aa88906705f7fe3f7","venue_1":"World Haptics","year":"2011","title":"Extensions to haptic augmented reality: Modulating friction and weight","authors":"Seokhee Jeon, Jean-Claude Metzger, Seungmoon Choi, Matthias Harders","author_ids":"7633801, 1860693, 1718126, 1744995","abstract":"Haptic augmented reality merges real and virtual feedback, allowing a user to touch the real environment augmented with virtual haptic stimuli. A key functionality of this technology is altering the haptic properties of real objects by means of virtual haptic feedback. Previously, we have developed a haptic augmentation system in which object stiffness was modulated. In this paper, we extend our framework to cover further haptic properties: friction and weight. Simple but effective algorithms for estimating and altering these properties have been developed. The first approach allows us to change the inherent friction between a tool tip and a surface to a desired one identified in an offline process. The second technique enables a user to perceive an altered weight when lifting an object at two interaction points. The performance of the proposed algorithms has been evaluated on real objects. The errors remain within reasonable bounds and compare well to the relevant perceptual Weber fractions. Limitations of our technique are identified, and possible extensions are proposed.","cites":"2","conferencePercentile":"37.77777778"},{"venue":"World Haptics","id":"433fb81d733322b156fdc614d07517b864e277da","venue_1":"World Haptics","year":"2013","title":"Design and optimization of support structures for tactile feedback","authors":"Iris Jiang, Yuki Ishikawa, Jack Lindsay, Blake Hannaford","author_ids":"2148756, 3205527, 3157184, 2036485","abstract":"Vibration motors are often used to generate tactile feedback to enhance human-machine interactions and provide information about the environment. We are interested in using these motors to enhance user feedback when wearing below-knee prostheses by providing informational cues via vibrations on the thigh. Our initial designs to hold the motors against the thigh resulted in a weak perception of vibration. We took an engineering approach to improve sensation by modeling the system and designing a new device that maximized skin displacement. Our results show the new suspended design increased skin displacement for both types of vibrational motors. 1 INTRODUCTION Skin is a very effective channel for conveying information through the sense of touch. Sensations on the skin can be localized [1], recognized quickly [2-3], and require a low cognitive load to process [4]. Vibrotactile feedback in particular has been commonly used for sensory substitution [5-8], navigation [2, 9], virtual environment interfaces [6, 10], and rehabilitation [10-12]. Placement of a vibrotactile actuator is versatile, so different locations can be stimulated depending on the application. Vibrational motors used on the skin tend to be small and light weight [13]. The most common types of actuators are linear resonance actuators (LRAs) and eccentric rotating mass motors (ERMs). LRAs operate by oscillating an electric field to vibrate a magnet connected to the case by a spring, and require an AC input. ERMs are DC motors that have an offset mass rotating about the center axis. The non-symmetric rotating mass causes displacement of the motor body at high frequencies to produce vibration. Lower body amputees suffer from a lack of feedback from their prosthetics and have a high incidence of tripping and falling [14-15]. Providing haptic feedback about the state of the prosthetic leg provides a means to decrease these harmful occurrences [16]. Notifying users early on about a loose fitting socket, which causes pistoning and instability [17], can prompt them to add more socks until the fit is snug. Additionally, we might be able to warn users of immediate dangers which will lead to immediate falls, such as catching the foot or stepping on a slippery surface. These signals require fast response, and vibrating motors can be actuated in under 20 milliseconds [18]. The compactness and speed of these motors in addition to the skin's ability to sense vibrations make vibration a great method for delivering information from a prosthetic leg to its user. …","cites":"1","conferencePercentile":"35.8490566"},{"venue":"World Haptics","id":"ec4bd5e77f1fb3fd4f92153ca713ea26432e7c13","venue_1":"World Haptics","year":"2015","title":"Active touch perception produced by airborne ultrasonic haptic hologram","authors":"Seki Inoue, Yasutoshi Makino, Hiroyuki Shinoda","author_ids":"1724700, 1712395, 1715925","abstract":"— A method to present volumetric haptic objects in the air using spatial modulation of ultrasound is proposed. Previous methods of airborne ultrasonic tactile display were based on vibrotactile radiation pressure and sensor feedback systems, which result in low spatial receptive resolution. The proposed approach produces a spatially standing haptic image using stationary ultrasonic waves that enable users to touch 3D images without depending on vibrotactile stimulation and sensor feedback. The omnidirectional spatial modulated hap-tic images are generated by a phased array surrounding a workspace, which enables enough power to feel shapes without vibrotactile technique. Compared with previous methods, the proposed method can create a completely silent image without temporal ultrasonic modulation noise that is free of the problems caused by feedback delay and errors. To investigate the active touch profiles of an ultrasonic image, this paper discusses a method to synthesize a haptic holographic image, the evaluation of our algorithm, and the results of pressure measurement and subjective experiments.","cites":"3","conferencePercentile":"94.23076923"},{"venue":"World Haptics","id":"9d161dec86d3875582f44097a6353b6fdf46bc55","venue_1":"World Haptics","year":"2011","title":"Lessons in using vibrotactile feedback to guide fast arm motions","authors":"Karlin Bark, Preeya Khanna, Rikki Irwin, Pulkit Kapur, Steven A. Jax, Laurel J. Buxbaum, Katherine J. Kuchenbecker","author_ids":"1942856, 2096341, 2069532, 2381202, 3209369, 2259304, 1716879","abstract":"We present and evaluate an arm-motion guidance system that uses magnetic tracking sensors and low cost vibrotactile actuators. The system measures the movement of the user's arm and provides vibration feedback at the wrist and elbow when they stray from the desired motion. An initial study was conducted to investigate whether adding tactile feedback to visual feedback reduces motion errors when a user is learning a new arm trajectory. Although subjects preferred it, we found that the addition of tactile feedback did not affect motion tracking performance. We also found no strong preference or performance differences between attractive and repulsive tactile feedback. Some factors that may have influenced these results include the speed and the complexity of the tested motions, the type of tactile actuators and drive signals used, and inconsistencies in joint angle estimation due to Euler angle gimbal lock. We discuss insights from this analysis and provide suggestions for future systems and studies in tactile motion guidance. ABSTRACT We present and evaluate an arm-motion guidance system that uses magnetic tracking sensors and low cost vibrotactile actuators. The system measures the movement of the user's arm and provides vibration feedback at the wrist and elbow when they stray from the desired motion. An initial study was conducted to investigate whether adding tactile feedback to visual feedback reduces motion errors when a user is learning a new arm trajectory. Although subjects preferred it, we found that the addition of tactile feedback did not affect motion tracking performance. We also found no strong preference or performance differences between attractive and repulsive tactile feedback. Some factors that may have influenced these results include the speed and the complexity of the tested motions, the type of tactile actuators and drive signals used, and inconsistencies in joint angle estimation due to Euler angle gimbal lock. We discuss insights from this analysis and provide suggestions for future systems and studies in tactile motion guidance.","cites":"8","conferencePercentile":"83.33333333"},{"venue":"World Haptics","id":"6afe91b133d738a2c36e0486d422129361cfff0a","venue_1":"World Haptics","year":"2013","title":"2-DOF contact location display for manipulating virtual objects","authors":"Seiedmuhammad Yazdian, Andrew J. Doxon, David E. Johnson, Hong Z. Tan, William R. Provancher","author_ids":"2736547, 2622373, 1929424, 1698913, 1728218","abstract":"A novel, low inertia, two degree-of-freedom (2-DOF) contact location display (CLD) device has been designed, prototyped, and tested. This device positions a small spherical contactor beneath the user's fingerpad at the point of contact between the finger and a virtual surface. Kinesthetic forces are provided by a custom haptic device attached to the CLD. The contactor is remotely driven by push-pull wires to reduce the effective inertia of the device at the user's fingertip; however, this design results in significant mechanical backlash. This backlash is characterized and partially compensated for in software. An experiment was used to evaluate several methods of rendering tactile feedback, each using a different method of prepositioning the contactor. The results show no statistical performance differences between rendering conditions. However, a post-experiment survey shows that participants perceived contact location + kinesthetic feedback as more realistic than pure kinesthetic feedback. 1 INTRODUCTION AND BACKGROUND Kinesthetic (force) and tactile (cutaneous) feedback provide important cues when exploring or manipulating objects with our hands. Without tactile information, it is hard to perform simple tasks like typing on a keyboard or grasping a pen. The tactile information provided when touching an object informs us about the local characteristics of the contact (e.g., texture, curvature, and temperature) [1]. Thus, when rendering virtual environments, providing tactile feedback in addition to kinesthetic feedback can enhance the user's ability to explore and manipulate virtual objects [2], [3]. There have been numerous successful efforts in providing haptic kinesthetic feedback cues to a user's finger or hand. Good examples of these devices include SensAble Technology's Phantom and Force Dimension's Omega which display interaction forces through interfaces such as a thimble, stylus, or handle. One drawback of these types of devices is that they cannot render local contact properties. Many studies have investigated tactile device designs to provide local contact properties in a natural and intuitive way. One such design for providing tactile feedback is a pin array device. Individual pins are positioned by a series of actuators to mimic the local profile of a virtual surface (e.g., [4]). While these devices are efficient at conveying tactile information, they are typically large, heavy, and complex due to a high pin density requirement. These properties make it difficult to mount them to kinesthetic feedback devices. Thus, pin array devices have mostly been tested in isolated tactile feedback conditions. Despite these difficulties, Sarakoglou et al. recently combined a compact 4x4 …","cites":"0","conferencePercentile":"14.1509434"},{"venue":"World Haptics","id":"715505bbf5fc88a18c57f96afda39aebee508bd2","venue_1":"World Haptics","year":"2011","title":"Tactile enhancement structure mimicking hair follicle receptors","authors":"Ryuta Okazaki, Michi Sato, Shogo Fukushima, Masahiro Furukawa, Hiroyuki Kajimoto","author_ids":"2812591, 2494645, 1844978, 1848375, 1776927","abstract":"We propose a tactile enhancement structure inspired by hair follicle receptors. Unlike other receptors, part of the hair follicle receptor is exposed to the outside. Recent research has shown that skin hair contributes to perception of minute forces that cannot be perceived with glabrous skin. We considered how the skin perceives these minute forces. Our tactile enhancement device mimics the structure of hair follicle receptors. A matrix structure simulating artificial body hair is driven by minute forces external to the skin surface. This structure can be used on any surface of the human body because it is fully composed of passive elements. 1 INTRODUCTION Human tactile sensitivity is largely dependent on highly sensitive tactile receptors and mechanical structures surrounding tactile receptors. For example, papillary ridges contribute to the sensitivity of the Meissner corpuscle [1]. Maeno et al. analyzed the structure of finger skin using finite element analysis and found that both the geometry of the papillae and the epidermal ridges are important to increase the sensitivity of tactile sensation [2]. Also, Gerling et al. reported an enhancing effect of the fingertip for edge detection [3]. Thus, there are many facets to the structure of human skin and structural models of human skin have been developed with various methods [4][5]. Recently, these findings were used to develop artificial tactile sensors [6]. On the other hand, external structures, notably hair, also play an important role. Sato [7] clarified the phenomenon by which water surfaces are perceived by hair. Water flow bends hair, exciting hair follicle receptors (Figure 1). This mechanism can be considered as a type of impedance transformation mechanism, similar to the \"tactile contact lens\" proposed by Kikuuwe et al.[8]. In the tactile contact lens, small deformations are expanded by a lever mechanism, whereas in human hair, small air/water flow is translated to skin deformation by a lever mechanism. In both mechanisms, the mechanical lever structure converts external mechanical energy to a dynamic range that is appropriate for human perception. In this study, we propose a tactile enhancement structure that mimics the mechanism by which human hair follicles detect sensation (Figure 2). The matrix of artificial hairs is driven by minute stimulation from the external world, transferring a magnified force to the skin surface. The device allows users to feel a normally unnoticeable water surface, which is known to be important for swimmer training [9] (Figure 3). We then describe an …","cites":"0","conferencePercentile":"8.888888889"}]}