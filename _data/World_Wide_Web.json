{"World_Wide_Web.csv":[{"venue":"World Wide Web","id":"8438dd52f49c2b59693df3754a109b155035f3df","venue_1":"World Wide Web","year":"2011","title":"Distributed processing of continuous sliding-window k-NN queries for data stream filtering","authors":"Kresimir Pripuzic, Ivana Podnar Zarko, Karl Aberer","author_ids":"1709498, 1700129, 1751802","abstract":"A sliding-window k-NN query (k-NN/w query) continuously monitors incoming data stream objects within a sliding window to identify k closest objects to a query. It enables effective filtering of data objects streaming in at high rates from potentially distributed sources, and offers means to control the rate of object insertions into result streams. Therefore k-NN/w processing systems may be regarded as one of the prospective solutions for the information overload problem in applications that require processing of structured data in real-time, such as the Sensor Web. Existing k-NN/w processing systems are mainly centralized and cannot cope with multiple data streams, where data sources are scattered over the Internet. In this paper, we propose a solution for distributed continuous k-NN/w processing of structured data from distributed streams. We define a k-NN/w processing model for such setting, and design a distributed k-NN/w processing system on top of the Content-Addressable Network (CAN) overlay. An extensive evaluation using both real and synthetic data sets demonstrates the feasibility of the proposed solution because it balances the load among the peers, while the messaging overhead within the P2P network remains reasonable. Moreover, our results clearly show the solution is scalable for an increasing number of queries and peers.","cites":"4","conferencePercentile":"30.76923077"},{"venue":"World Wide Web","id":"1832947daf23e31b9310407c5e38cd4cf82fd79c","venue_1":"World Wide Web","year":"2010","title":"Human Intelligence in the Process of Semantic Content Creation","authors":"Katharina Siorpaes, Elena Paslaru Bontas Simperl","author_ids":"1980497, 2927032","abstract":"Despite significant progress over the last years the large-scale adoption of semantic technologies is still to come. One of the reasons for this state of affairs is assumed to be the lack of useful semantic content, a prerequisite for almost every IT system or application using semantics. Through its very nature, this content can not be created fully automatically, but requires, to a certain degree, human contribution. The interest of Internet users in semantics, and in particular in creating semantic content, is, however, low. This is understandable if we think of several characteristics exposed by many of the most prominent semantic technologies, and the applications thereof. One of these characteristics is the high barrier of entry imposed. Interacting with semantic technologies today requires specific skills and expertise on subjects which are not part of the mainstream IT knowledge portfolio. A second characteristic are the incentives that are largely missing in the design of most semantic applications. The benefits of using machine-understandable content are in most applications fully decoupled from the effort of creating and maintaining this content. In other words, users do not have a motivation to contribute to the process. Initiatives in the areas of the Social Semantic Web acknowledged this problem, and identified mechanisms to motivate users to dedicate more of their time and resources to participate in the semantic content creation process. Still, even if incentives are theoretically in place, available human labor is limited and must only be used for those tasks that are heavily dependent on human intervention, and cannot be reliably automated. In this article, we concentrate on this step in between. As a first contribution, we analyze the process of semantic content creation in order to identify those tasks that are inherently human-driven. When building semantic applications involving these specific tasks, one has to install incentive schemes that are likely to encourage users to perform exactly these tasks that crucially rely on manual input. As a second contribution of the article, we propose incentives or incentive-driven tools that can be used to increase user interest in semantic content creation tasks. We hope that our findings will be adopted as recommendations for establishing a fundamentally new form of design of semantic applications by the semantic technologies community.","cites":"37","conferencePercentile":"100"},{"venue":"World Wide Web","id":"89225b51e009d9bb9ba9ef7a8137d2f63cc1668e","venue_1":"World Wide Web","year":"2007","title":"Distributed Context Monitoring for the Adaptation of Continuous Services","authors":"Claudio Bettini, Dario Maggiorini, Daniele Riboni","author_ids":"1725133, 2711834, 1802743","abstract":"This paper describes a middleware designed for distributed context acquisition and reconciliation intended to support the adaptation of continuous Internet services, like e.g., multimedia streaming. These services persist in time, and are characterized by multiple transmissions of data by the service provider, as a result of a single request from the user. Adapting these services to the current context requires the continuous monitoring of context data, and a real-time adjustment of the adaptation parameters upon the detection of a relevant context change. The proposed solution is based on asynchronous context change notifications, and specific techniques have been designed to minimize the number of unnecessary updates and the re-evaluation of policies. The paper also provides experimental results obtained by developing an adaptive video streaming system and running it on top of the proposed middleware.","cites":"15","conferencePercentile":"58.33333333"},{"venue":"World Wide Web","id":"6888febcd48e097fa9af0006614cb3415ab6af4d","venue_1":"World Wide Web","year":"2005","title":"A Context-Aware HTML/XML Document Transmission Process for Mobile Wireless Clients","authors":"Huamin Chen, Prasant Mohapatra","author_ids":"1713474, 1697868","abstract":"Delivery and rendering of HTML/XML documents has been a core task in many contemporary networking applications. In mobile wireless networks, efficient handling of these types of documents is necessary due to the frequent disconnections, packet loss, and high bit error rate. One approach to address the challenge is the ability to process and reuse the partial data. Current application protocols like HTTP cannot support this approach due to the following constraints: TCP's in-order data uploading to the applications and tag matching. We propose a context-aware transmission process (CATP) to run on top of UDP. This protocol does not transmit HTML/XML files in-order. Instead, it reorganizes the files and transmit tags first before transporting their enclosed data. Conforming browsers receive the file structures and fill in with subsequent data packets in whatever sequence they arrive. As a result, lost and delayed packets do not hinder rendering of those that are logically behind but have already arrived at the client sides. Thus the retransmission of the lost frames can be concealed and overall user perceived performance improved. The user-perceivable performance is quantified in terms of silent time during which no activity is observed at the browser display. The protocol also facilitates partial content caching, amortizing network transmission overhead, and non-interactive applications of Web services. We validated this protocol through prototype implementation and compared the performance with TCP and in-order delivery UDP schemes. Our protocol provides better user-perceivable performance under various loss rates and document sizes. delivery and rendering.","cites":"4","conferencePercentile":"25"},{"venue":"World Wide Web","id":"3f64b966415802ec90a372a2abf45ae2b619cf08","venue_1":"World Wide Web","year":"2006","title":"Ranking Pages by Topology and Popularity within Web Sites","authors":"José Borges, Mark Levene","author_ids":"7016696, 1722499","abstract":"We compare two link analysis ranking methods of web pages in a site. The first, called Site Rank, is an adaptation of PageRank to the granularity of a web site and the second, called Popularity Rank, is based on the frequencies of user clicks on the outlinks in a page that are captured by navigation sessions of users through the web site. We ran experiments on artificially created web sites of different sizes and on two real data sets, employing the relative entropy to compare the distributions of the two ranking methods. For the real data sets we also employ a nonparametric measure, called Spearman's footrule, which we use to compare the top-ten web pages ranked by the two methods. Our main result is that the distributions of the Popularity Rank and Site Rank are surprisingly close to each other, implying that the topology of a web site is very instrumental in guiding users through the site.","cites":"6","conferencePercentile":"43.33333333"},{"venue":"World Wide Web","id":"bd4a4073546f9726428b7618a44290547416ebce","venue_1":"World Wide Web","year":"2011","title":"Guest editorial: mobile services on the Web","authors":"Quan Z. Sheng, Muhammad Younas, Dimitrios Georgakopoulos","author_ids":"1713128, 3353501, 5958777","abstract":"Advances in the Web and mobile technologies offer new and exciting services to users in various domains such as e-business, healthcare, entertainment, and scientific activities. With the advances in mobile technologies, the Web gets richer in its contents and usability. In addition to its widespread usability in the e-commerce, education, and media, the Web has established its roots in exchanging and sharing information in social communities. For example, user-generated contents in the social networks have transformed the Web into a new era of the Web 2.0—these contents comprise a wealth of information often involving multimedia data such as audio, video, pictures and blogs. Indeed, the Web is slowly evolving from current \" Web of Content \" , \" Web of People \" , into \" Web of Things and Services \" , given the recent advances such as radio-frequency identification (RFID), sensor networks, and service-oriented computing (SOC). These new developments however introduce many new challenging and unsolved problems. One of the major issues is to deal with the resource scarcity in mobile environments. Though mobile devices and wireless networks are improving their resources, they are still far behind the wired networks and desktop PCs in terms of bandwidth, memory, processing speed and battery power. In addition, users expect mobile services to be intelligent and context-aware.","cites":"0","conferencePercentile":"11.53846154"},{"venue":"World Wide Web","id":"823ff64b3bd9e2f728ed85a421d67db9c584318e","venue_1":"World Wide Web","year":"2007","title":"Model-driven Engineering of Active Context-awareness","authors":"Stefano Ceri, Florian Daniel, Federico Michele Facca, Maristella Matera","author_ids":"1705257, 1797572, 1944488, 1727982","abstract":"More and more Web users ask for contents and services highly tailored to their particular contexts of use. Especially due to the increasing affordability of new and powerful mobile communication devices , they also appreciate the availability of ubiquitous access, independent from the device actually in use. Due to such premises, traditional software design methods need to be extended, and new issues and requirements need to be addressed for supporting context-aware access to services and applications. In this paper we propose a model-driven approach towards adaptive, context-aware Web applications, accompanied by a general-purpose execution framework enabling active context-awareness. Whereas conventional adaptive hypermedia systems address the problem of adapting HTML pages in response to user-generated requests, in this work we especially stress the importance of user-independent, context-triggered adaptivity actions. This finally leads us to interpret the context as an active actor, operating independently from users during their navigations.","cites":"18","conferencePercentile":"70.83333333"},{"venue":"World Wide Web","id":"035e7e03ac7da20e63cc2ee6d4dcf895e9c5c567","venue_1":"World Wide Web","year":"1999","title":"Mercator: A Scalable, Extensible Web Crawler","authors":"Allan Heydon, Marc Najork","author_ids":"3283826, 1763978","abstract":"This paper describes Mercator, a scalable, extensible Web crawler written entirely in Java. Scalable Web crawlers are an important component of many Web services, but their design is not well-documented in the literature. We enumerate the major components of any scalable Web crawler, comment on alternatives and tradeoffs in their design, and describe the particular components used in Mercator. We also describe Mercator's support for extensibility and customizability. Finally, we comment on Mercator's performance, which we have found to be comparable to that of other crawlers for which performance numbers have been published.","cites":"239","conferencePercentile":"88.88888889"},{"venue":"World Wide Web","id":"ecf0b4629b63a38df1ba96d5c0363ddd771f00b8","venue_1":"World Wide Web","year":"1999","title":"The SGF Metadata Framework and Its Support for Social Awareness on the World Wide Web","authors":"Olivier Liechti, Mark Sifer, Tadao Ichikawa","author_ids":"3199753, 1727759, 1737975","abstract":"In this article, we first briefly introduce the idea of metadata and explain how it is transforming the Web into an information space that can be accessed not only by humans, but also by software agents. We then consider one particular application of metadata, the description of Web sites structures in a machine understandable way. We introduce the Structured Graph Format (SGF), an XML-based format used to describe Web spaces as a structured graphs. We then describe the SGF framework, built around the format specification. The framework integrates components that support both the generation, distribution and processing of SGF metadata. We first describe SGF consumers, components that process the metadata for some purpose. As an example, we present SGViewer, a consumer that uses the metadata to generate interactive site maps. We then review three approaches to the problem of generating SGF metadata. These approaches highlight a tradeoff between the quality and the cost of metadata. A number of SGF producers, components that support the generation of metadata, are described. We then argue for the need to increase social awareness on the WWW, making it easier to monitor the activity occurring within Web sites. We explain how the notion of awareness has been extensively studied in Computer Supported Cooperative Work (CSCW) settings and show that it can be applied to the Web in different ways. We then show that the SGF framework provides a foundation for building awareness systems on the Web, with two main advantages. First, we explain that because SGF metadata supports the definition of regions within a Web site, at different granularities, it ensures the scalability of monitoring systems. It gives users of these systems a very flexible way to define regions of interest and thus to monitor activity in more meaningful ways. Second, we show that the site maps generated on the basis of SGF metadata provide an efficient way to represent the activity occurring within the monitored site. We contrast these explicit representations, useful to analyze activity, with abstract representations, useful to maintain peripheral awareness about ongoing activity on the Web.","cites":"3","conferencePercentile":"11.11111111"},{"venue":"World Wide Web","id":"38ff8ffeb4da3d83d359077ed75a74bc0e6f289f","venue_1":"World Wide Web","year":"2002","title":"RAL: An Algebra for Querying RDF","authors":"Flavius Frasincar, Geert-Jan Houben, Richard Vdovjak, Peter Barna","author_ids":"1729599, 1703821, 1738027, 1746460","abstract":"To make the World Wide Web machine-understandable there is a strong demand both for languages describing metadata and for languages querying meta-data. The Resource Description Framework (RDF), a language proposed by W3C, can be used for describing metadata about (Web) resources. RDF Schema (RDFS) extends RDF by providing means for creating application specific vocabularies (on-tologies). While the two above languages are widely acknowledged as a standard means for describing Web metadata, a standardized language for querying RDF metadata is still an open issue. Research groups coming both from industry and academia are presently involved in proposing several RDF query languages. Due to the lack of an RDF algebra such query languages use APIs to describe their semantics and optimization issues are mostly neglected. This paper proposes RAL (an RDF algebra) as a reference mathematical study for RDF query languages and for performing RDF query optimization. We define the data model, we present the operators to manipulate the data, and we address the application of RAL for query optimization. RAL includes: extraction operators to retrieve the needed resources from the input RDF model, loop operators to support repetition, and construction operators to build the resulting RDF model.","cites":"41","conferencePercentile":"100"},{"venue":"World Wide Web","id":"ce8ba8f7aa6ce3e6a6c4a974d580f9bceac629ed","venue_1":"World Wide Web","year":"2007","title":"Rule-based Adaptation of Web Information Systems","authors":"Roberto De Virgilio, Riccardo Torlone, Geert-Jan Houben","author_ids":"1711693, 1718274, 1703821","abstract":"Mobile devices provide a variety of ways to access information resources available on the Web and a high level of adaptability to different aspects of the context (such as the device capabilities, the network QoS, the user preferences, and the location) is strongly required in this scenario. In this paper, we present a rule-based approach supporting the automatic adaptation of content delivery in Web Information Systems. The approach relies on the general notions of profile and configuration. The former is used to model a variety of context characteristics in a uniform way. The latter describes, in abstract terms, how to build the various levels of a suitable Web interface (content, navigation and presentation). We propose an original notion of adaptation rule that can be used to specify, in a declarative way, how to build a configuration that satisfies the requirements of adaptation for a profile. The evaluation process defined for these rules supports: (1) the handling of many separately specified adaptation requirements according to different aspects of the context, possibly not fixed in advance, and (2) their integration into one coherent recipe for adaptation. We also describe the architecture and functionality of a prototype implementing the proposed approach and illustrate experimental results supporting its flexibility and efficiency. Keywords mobile devices · web information systems · adaptive applications · context awareness · data intensive web sites","cites":"4","conferencePercentile":"20.83333333"},{"venue":"World Wide Web","id":"65baf564e8f6843aed47884af933781016c0bc23","venue_1":"World Wide Web","year":"2007","title":"The UM-MAIS Methodology for Multi-channel Adaptive Web Information Systems","authors":"Carlo Batini, Davide Bolchini, Stefano Ceri, Maristella Matera, Andrea Maurino, Paolo Paolini","author_ids":"1693220, 1780806, 1705257, 1727982, 1743266, 1769550","abstract":"Multichannel Adaptive Web Information Systems (WISs) are emerging as a new class of information systems, characterized by their powerful use of mobility and context-awareness. Different methodologies have been proposed so far for the analysis and design of Multichannel Adaptive WISs, specifically focused on the front-end layer or the back-end layer, but no methodology has aimed to cover all the lifecycle and to design all the components that characterize Multichannel Adaptive WIS. This paper fills such a gap, by presenting UM-MAIS (Unified Methodology for Multichannel Adaptive Information Systems), a new methodology that capitalizes on well-established existing methods. It supports the analysis and design of the various components of Multichannel Adaptive WISs (including the user's experience) in a comprehensive and unified manner with special emphasis on context modeling, personalization, and adaptation.","cites":"4","conferencePercentile":"20.83333333"},{"venue":"World Wide Web","id":"270aa3b4a662e00996cdfac26ad067631a5e9ac5","venue_1":"World Wide Web","year":"1999","title":"Distributions of Surfers' Paths Through the World Wide Web: Empirical Characterizations","authors":"Peter Pirolli, James E. Pitkow","author_ids":"1687720, 2902766","abstract":"Surfing the World Wide Web (WWW) involves traversing hyperlink connections among documents. The ability to predict surfing patterns could solve many problems facing producers and consumers of WWW content. We analyzed WWW server logs for a WWW site, collected over ten days, to compare different path reconstruction methods and to investigate how past surfing behavior predicts future surfing choices. Since log files do not explicitly contain user paths, various methods have evolved to reconstruct user paths. Session times, number of clicks per visit, and Levenshtein Distance analyses were performed to show the impact of various reconstruction methods. Different methods for measuring surfing patterns were also compared. Markov model approximations were used to model the probability of users choosing links conditional on past surfing paths. Information-theoretic (entropy) measurements suggest that information is gained by using longer paths to estimate the conditional probability of link choice given surf path. The improvements diminish, however, as one increases the length of path beyond one. Information-theoretic (Total Divergence to the Average entropy) measurements suggest that the conditional probabilities of link choice given surf path are more stable over time for shorter paths than longer paths. Direct examination of the accuracy of the conditional probability models in predicting test data also suggests that shorter paths yield more stable models and can be estimated reliably with less data than longer paths.","cites":"91","conferencePercentile":"77.77777778"},{"venue":"World Wide Web","id":"5d37796c48d550de408cc22fc3ce9258916c60fa","venue_1":"World Wide Web","year":"2010","title":"A Wikipedia Matching Approach to Contextual Advertising","authors":"Alexander N. Pak, Chin-Wan Chung","author_ids":"2037017, 1733783","abstract":"Contextual advertising is an important part of today's Web. It provides benefits to all parties: Web site owners and an advertising platform share the revenue, advertisers receive new customers, and Web site visitors get useful reference links. The relevance of selected ads for a Web page is essential for the whole system to work. Problems such as homonymy and polysemy, low intersection of keywords and context mismatch can lead to the selection of irrelevant ads. Therefore, a simple keyword matching technique gives a poor accuracy. In this paper, we propose a method for improving the relevance of contextual ads. We propose a novel \" Wikipedia matching \" technique that uses Wikipedia articles as \" reference points \" for ads selection. We show how to combine our new method with existing solutions in order to increase the overall performance. An experimental evaluation based on a set of real ads and a set of pages from news Web sites is conducted. Test results show that our proposed method performs better than existing matching strategies and using the Wikipedia matching in combination with existing approaches provides up to 50% lift in the average precision. TREC standard measure bpref-10 also confirms the positive effect of using Wikipedia matching for the effective ads selection.","cites":"8","conferencePercentile":"77.77777778"},{"venue":"World Wide Web","id":"ce15fa43f874ae428d5c45cb0f21e97e172c004b","venue_1":"World Wide Web","year":"2011","title":"Efficient top-K approximate searches against a relation with multiple attributes","authors":"Wei Lu, Jinchuan Chen, Xiaoyong Du, Jieping Wang, Wei Pan","author_ids":"1689132, 7558310, 1688063, 5660805, 4267785","abstract":"In this paper, we study the problem of efficiently identifying K records that are most similar to a given query record, where the similarity is defined as: (1) for each record, we calculate the similarity score between the record and the query record over each individual attribute using a specific similarity function; (2) an aggregate function is utilized to combine these similarity scores with weights and the aggregated value is served as the similarity of the record. After similarities of all records have been computed, K records with the greatest similarities can further be identified. Under this framework, unfortunately, the computational cost will be extremely expensive when the cardinality of relation is large as computation of similarity for each record is required. As a result, in this paper, we propose two efficient algorithms, named ScanIndex and Top-Down (TD for short), to cope with this problem. With respect to ScanIndex, similarity scores that are equal to zero over individual attributes are free from computation. Based on ScanIndex, with respect to TD, similarity scores less than thresholds (rather than zero) over individual attributes are skipped, where these thresholds are improved dynamically over time. Experimental results demonstrate that, comparing with the naive approach, the performance can be improved by two orders of magnitude using ScanIndex and TD.","cites":"1","conferencePercentile":"23.07692308"},{"venue":"World Wide Web","id":"7530be25bb11cdee655fdf0f72e91568a58657aa","venue_1":"World Wide Web","year":"2000","title":"Searching for multimedia: analysis of audio, video and image Web queries","authors":"Bernard J. Jansen, Abby Goodrum, Amanda Spink","author_ids":"1692872, 1768212, 1750645","abstract":"The development of digital libraries has enhanced the integration of textual and multimedia information in many document collections. The World Wide Web provides the connectivity for many digital library users. Studies exploring the searching characteristics of Web users are an important and a growing area of research. Most Web user studies have focused on general Web searching, regardless of subject matter or format. Little research has examined how Web users search for multimedia information. Our study examines users' multimedia searching on a major Web search service. The data set examined consisted of 1,025,908 queries from 211,058 users of Excite , a major Web search service. From this data set, we identified and analyzed queries for audio, image, and video queries. Our findings were compared to results from general Web searching studies. Implications for the design of Web searching services and interfaces are discussed.","cites":"19","conferencePercentile":"75"},{"venue":"World Wide Web","id":"48e6d0461dd40f96ed51da326fb609a5ec63cf7b","venue_1":"World Wide Web","year":"1998","title":"The AT&T Internet Difference Engine: Tracking and Viewing Changes on the Web","authors":"Fred Douglis, Thomas Ball, Yih-Farn Robin Chen, Eleftherios Koutsofios","author_ids":"1782350, 3226160, 2231574, 2621476","abstract":"The AT&T Internet Diierence Engine (aide) is a system that nds and displays changes to pages on the World Wide Web. The system consists of several components, including a web-crawler that detects changes, an archive of past versions of pages, a tool called HtmlDii to highlight changes between versions of a page, and a graphical interface to view the relationship between pages over time. This paper describes aide, with an emphasis on the evolution of the system and experiences with it. It also raises some sociological and legal issues.","cites":"66","conferencePercentile":"100"},{"venue":"World Wide Web","id":"2b7cfed8fd5b5d633c96439d2f05efa06097750a","venue_1":"World Wide Web","year":"2009","title":"Finding User's Interest Blocks using Significant Implicit Evidence for Web Browsing on Small Screen Devices","authors":"Xin Yang, Peifeng Xiang, Yuanchun Shi","author_ids":"6826800, 1707918, 1732440","abstract":"Recent researches on improving the efficiency and user experience of Web browsing on handhelds are seeking to solve the problem by re-authoring Web pages or making adaptations and recommendations according to user preference. Their basis is a good understanding of the relationship between user behaviors and user preference. We propose a practical method to find user's interest blocks by machine learning using the combination of significant implicit evidences, which is extracted from four aspects of user behaviors: display time, viewing information items, scrolling and link selection. We also develop a customized Web browser for small screen devices to collect user behaviors accurately. For evaluation, we conduct an on-line user study and make statistical analysis based on the dataset, which shows that most types of the suggested implicit evidences are significant, and viewing information items is the least indicative aspect of user behaviors. The dataset is then processed off-line to find user's interest blocks using the proposed method. Experimental results demonstrate the effectiveness of finding user's interest blocks by machine learning using the combination of significant implicit evidences. Further analysis reveals the great effect of users and moderate effect of Websites on the usefulness of significant implicit evidences.","cites":"3","conferencePercentile":"16.66666667"},{"venue":"World Wide Web","id":"25593a3ffc8e82fa21dceec34e702c762324b0e6","venue_1":"World Wide Web","year":"2009","title":"Graph Theoretic Topological Analysis of Web Service Networks","authors":"Hyunyoung Kil, Seog-Chan Oh, Ergin Elmacioglu, Wonhong Nam, Dongwon Lee","author_ids":"1928204, 2996903, 3179332, 3330098, 1784227","abstract":"Using graph theory, we analyze the topological landscape of web service networks formed by real-world data set, either downloaded from web service repositories or crawled by a search engine. We first propose a flexible framework to study syntactic web service matchmaking in a unified manner. Under the framework, then, the data set is analyzed from diverse perspectives and granularity. By and large, the data set is shown to exhibit small world network well and power-law-like distribution to some extent. Finally, using random graph theory, we demonstrate how to accurately estimate the size of the giant component of such web service networks.","cites":"21","conferencePercentile":"100"},{"venue":"World Wide Web","id":"f6600e105ccf085e37a09e72a8e848117e8582d1","venue_1":"World Wide Web","year":"1998","title":"Integrating Database and World Wide Web Technologies","authors":"Ling Feng, Hongjun Lu","author_ids":"6257025, 1823100","abstract":"Integrating database and World Wide Web technologies is another topic where industrial and practical activities lead ahead of academic ones. The purpose of this article is to survey the related activities from database people's view and stimulate the interests among the database community. It covers three aspects. First, the eeorts that apply established database techniques to retrieving Web information are summarized. These eeorts aim to overcome the inadequacy of le system technology on which the Web is based, so that information can be retrieved easily and quickly from the Web. Second, various approaches to interfacing databases via the Web are discussed, with examples of accomplished prototypes and commercial products showing recent advances. Finally, some possible extensions to the traditional database techniques are investigated for building fully edged Web-based database applications.","cites":"9","conferencePercentile":"62.5"},{"venue":"World Wide Web","id":"d0150ef64a065d4494b4f33717874cfc490695c4","venue_1":"World Wide Web","year":"2007","title":"Interactive Paper as a Mobile Client for a Multi-channel Web Information System","authors":"Beat Signer, Michael Grossniklaus, Moira C. Norrie","author_ids":"1725701, 1786155, 1685670","abstract":"We describe how interactive paper can be used together with a multi-channel web information system to build a platform for experimenting with multi-modal context-aware mobile information services. As an application, we present a tourist guide for visitors to an international festival that was developed to investigate alternative modes of information delivery and interaction in mobile environments. The guide is based around a set of interactive paper documents—an event brochure, map and bookmark. The brochure and map augment the printed content through interaction using a digital pen for link activation and speech for information delivery. The digital pen is also used for data capture of event ratings and reviews. The bookmark provides access to advanced searches and ticket reservations. We describe the architecture and operation of the system, highlighting the challenges of extending a web information system to support both the generation of the paper documents and the interaction from these documents, alongside more traditional access channels. Finally, we discuss the range of context-aware interactions that is supported by this new mobile platform.","cites":"7","conferencePercentile":"37.5"},{"venue":"World Wide Web","id":"22d29ed84a7cece2e3f017773665e1fea4476eab","venue_1":"World Wide Web","year":"2008","title":"Prefetching in Content Distribution Networks via Web Communities Identification and Outsourcing","authors":"Antonis Sidiropoulos, George Pallis, Dimitrios Katsaros, Konstantinos Stamos, Athena Vakali, Yannis Manolopoulos","author_ids":"2807623, 1777051, 1720459, 2579580, 1741423, 1796253","abstract":"Content distribution networks (CDNs) improve scalability and reliability, by replicating content to the \" edge \" of the Internet. Apart from the pure networking issues of the CDNs relevant to the establishment of the infrastructure, some very crucial data management issues must be resolved to exploit the full potential of CDNs to reduce the \" last mile \" latencies. A very important issue is the selection of the content to be prefetched to the CDN servers. All the approaches developed so far, assume the existence of adequate content popularity statistics to drive the prefetch decisions. Such information though, is not always available, or it is extremely volatile, turning such methods problematic. To address this issue, we develop self-adaptive techniques to select the outsourced content in a CDN infrastructure, which requires no apriori knowledge of request statistics. We identify clusters of \" correlated \" Web pages in a site, called Web site communities, and make these World Wide Web communities the basic outsourcing unit. Through a detailed simulation environment, using both real and synthetic data, we show that the proposed techniques are very robust and effective in reducing the user-perceived latency, performing very close to an unfeasible, off-line policy, which has full knowledge of the content popularity.","cites":"11","conferencePercentile":"83.33333333"},{"venue":"World Wide Web","id":"15f4b13502665404dd344390f9effdbcddb7d4aa","venue_1":"World Wide Web","year":"2002","title":"User Intention Modelling in Web Applications Using Data Mining","authors":"Zheng Chen, Fan Lin, Huan Liu, Wei-Ying Ma, Wenyin Liu","author_ids":"1705657, 3892162, 2365866, 1705244, 4163820","abstract":"The problem of inferring a user's intentions in Machine–Human Interaction has been the key research issue for providing personalized experiences and services. In this paper, we propose novel approaches on modeling and inferring user's actions in a computer. Two linguistic features – keyword and concept features – are extracted from the semantic context for intention modeling. Concept features are the conceptual generalization of keywords. Association rule mining is used to find the proper concept of corresponding keyword. A modified Naïve Bayes classifier is used in our intention modeling. Experimental results have shown that our proposed approach achieved 84% average accuracy in predicting user's intention, which is close to the precision (92%) of human prediction.","cites":"24","conferencePercentile":"75"},{"venue":"World Wide Web","id":"c7298547d3d1c17cd596718de4bd2a73890c31b4","venue_1":"World Wide Web","year":"1998","title":"Implementing an Open Link Service for the World Wide Web","authors":"Lynn A. Carr, David De Roure, Wendy Hall, Gary Hill","author_ids":"3356342, 1708123, 1685385, 1784415","abstract":"ii ABSTRACT Links are the key element for changing a text into a hypertext, and yet the WWW provides limited linking facilities. Modelled on Open Hypermedia research the Distributed Link Service provides an independent system of link services for the WorldWide Web and allows authors to create configurable navigation pathways for collections of WWW resources. This is achieved by adding links to documents as they are delivered from a WWW server, and by allowing the users to choose the sets of links that they will see according to their interests. This paper describes the development of the link service, the facilities that it adds for users of the WWW and its specific use in an Electronic Libraries project.","cites":"18","conferencePercentile":"75"}]}